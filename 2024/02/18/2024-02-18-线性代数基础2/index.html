<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>MIT 线性代数公开课笔记（二） | 鸟布的博客</title><meta name="author" content="鸟布"><meta name="copyright" content="鸟布"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="该笔记主要内容为正交矩阵；投影矩阵 P；最小二乘法；Gram-Schmidt 正交化；行列式；代数余子式；特征值与特征向量；对角化处理；矩阵幂。该笔记主要参考了 MLNLP 的关于该公开课的 GitHub 公开项目的笔记：https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;MLNLP-World&amp;#x2F;MIT-Lin"><link rel="shortcut icon" href="https://s2.loli.net/2022/09/08/Ygib4lfw6z1khnr.png"><link rel="canonical" href="https://ybniaobu.github.io/2024/02/18/2024-02-18-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%802/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 鸟布","link":"链接: ","source":"来源: 鸟布的博客","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'MIT 线性代数公开课笔记（二）',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-03-18 18:48:10'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/images/wechat%20avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">29</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-bars"></i><span> 目录</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/images/black.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="鸟布的博客"><span class="site-name">鸟布的博客</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-bars"></i><span> 目录</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">MIT 线性代数公开课笔记（二）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-02-18T05:52:33.000Z" title="发表于 2024-02-18 13:52:33">2024-02-18</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-03-18T10:48:10.621Z" title="更新于 2024-03-18 18:48:10">2024-03-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E5%AD%A6/">数学</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E5%AD%A6/3d%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/">3d数学基础</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E5%AD%A6/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">线性代数</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">16.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>64分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="MIT 线性代数公开课笔记（二）"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote>
<p>该笔记主要内容为正交矩阵；投影矩阵 P；最小二乘法；Gram-Schmidt 正交化；行列式；代数余子式；特征值与特征向量；对角化处理；矩阵幂。<br>该笔记主要参考了 MLNLP 的关于该公开课的 GitHub 公开项目的笔记：<a target="_blank" rel="noopener" href="https://github.com/MLNLP-World/MIT-Linear-Algebra-Notes">https://github.com/MLNLP-World/MIT-Linear-Algebra-Notes</a><br>公开课 B 站 bv 号：BV16Z4y1U7oU</p>
</blockquote>
<h1 id="第十四课-正交向量与正交子空间"><a href="#第十四课-正交向量与正交子空间" class="headerlink" title="第十四课 正交向量与正交子空间"></a>第十四课 正交向量与正交子空间</h1><div  align="center">  
<img src="https://s2.loli.net/2024/02/18/iwvTI9XHNrf4QjB.png" width = "60%" height = "60%" alt="图4 - 四个子空间的关系"/>
</div>

<h2 id="向量正交"><a href="#向量正交" class="headerlink" title="向量正交"></a>向量正交</h2><p><strong>正交 Orthogonal </strong>就是<strong>垂直 perpendicular</strong> 的另一种说法。两向量正交的判据之一是其点积 $\,x^Ty = y^Tx = 0\,$。</p>
<p>可以根据勾股定理（毕达哥拉斯定理 Pythagorean theorem）推出上述判断，当两个向量的夹角为 90 度时，x，y 满足：  </p>
<script type="math/tex; mode=display">|x|^2 + |y|^2 = |x + y|^2</script><p>其中 $\,|x|^2 = x^Tx\,$（x 为 列向量），可得：</p>
<script type="math/tex; mode=display">x^Tx + y^Ty = (x + y)^T(x + y) = x^Tx + y^Ty + x^Ty + y^Tx</script><p>可得 $\,x^Ty + y^Tx = 0\,$，因 $\,x^Ty\,$ 与 $\,y^Tx\,$ 其实是一样的，都表示两个一维向量的点乘，故若两个向量正交，则 $\,x^Ty = y^Tx = 0\,$。</p>
<blockquote>
<p>零向量与所有向量都正交。</p>
</blockquote>
<h2 id="子空间正交"><a href="#子空间正交" class="headerlink" title="子空间正交"></a>子空间正交</h2><p><strong>两个子空间正交</strong>就是：<strong>一个子空间中的任意一个向量，都与另一个子空间中的任意一个向量正交。</strong></p>
<p>在三维空间中，假设世界原点为黑板和地板交接处的一点，黑板所在的平面（子空间）和地板所在平面（子空间）不是正交关系，沿两者的交线方向的向量同时属于两个平面，但并不与自己正交。即两个平面在某一非零向量处相交，那这两个平面一定不正交，因为相交处的这个非零向量无法满足空间正交定义。</p>
<p>再从子空间角度看一看正交空间，以 $\,R^2\,$ 的子空间为例，一个平面上的子空间有三种：<br>①整个平面 D；<br>②过原点的直线 L；<br>③原点 O。</p>
<p>看一看这些子空间之间的正交，以 L 为例：<br>①L 与 D 什么时候正交？<br>一个平面上的直线不可能与这个平面垂直；<br>②L 什么时候与 O 正交？<br>L 与 O 永远是正交的；<br>③L 什么时候与另一个 L 正交？<br>由正交的定义，两条直线在原点处互相垂直，这两个 L 空间才正交。</p>
<h2 id="零空间与行空间的正交关系"><a href="#零空间与行空间的正交关系" class="headerlink" title="零空间与行空间的正交关系"></a>零空间与行空间的正交关系</h2><p>零空间与行空间之间是正交的，得到这个结论并不难，我们把 A 写成行向量形式，再看 Ax = 0 这个方程：  </p>
<script type="math/tex; mode=display">\begin{bmatrix} R_1 \\ R_2 \\ ... \\ ... \\ R_m \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \\ ... \\ ... \end{bmatrix} = \begin{bmatrix} R_1(x_1, x_2, ...) \\ R_2(x_1, x_2, ...) \\ ... \\ ... \\ R_m(x_1, x_2, ...) \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \\ ... \\ ... \\ 0 \end{bmatrix}</script><p>x 与矩阵 A 的行向量点积都等于 0，则它和矩阵 A 行向量的线性组合进行点积也为 0，所以 x 与 A 的行空间正交。x 为零空间内的任意向量，所以零空间与行空间正交。同理可以证明列空间与左零空间正交。</p>
<hr>
<p>行空间和零空间类似于把 $\,R^n\,$ 空间分割成了两个正交的子空间。例如对于矩阵：$\,A = \begin{bmatrix} 1 &amp; 2 &amp; 5 \\ 2 &amp; 4 &amp; 10 \end{bmatrix}\,$，其行空间是 1 维的，向量 (1, 2, 5) 是它的基向量，而其零空间是垂直于 (1, 2, 5) 并穿过原点的二维平面。行空间和零空间不仅仅是正交，并且其维数之和等于 n，我们称行空间和零空间为 $\,R^n\,$ 空间内的<strong>正交补 orthogonal complements</strong>。这表示零空间包含所有和行空间正交的向量，反之亦然。</p>
<blockquote>
<p>想想我们之前提到的黑板和地板平面不是正交子空间的例子，二者都在三维空间中，分别为二维空间，因此不可能正交。一个空间中正交子空间的维数之和不可能超过原空间的维数。</p>
</blockquote>
<h2 id="无解方程的最优解"><a href="#无解方程的最优解" class="headerlink" title="无解方程的最优解"></a>无解方程的最优解</h2><p>下面讨论如何求解一个无解方程组 Ax = b 的解（引出下一节的内容）。矩阵的数据来源于实际测量，那么就势必会有测量不准确的时候，如果 A 是长方形矩阵，m 大于 n。当左侧方程数特别多的时候，容易混入“坏”数据，方程变得无解。但是对于数据的可信度我们无从判断，线性代数要做的就是在这种条件下求一个方程的“最优解”。矩阵 $\,A^TA\,$ 会发挥重要作用，它是一个 n x n 方阵，并且是对称矩阵。</p>
<p>将方程改写成：$\,A^TA \hat {x} = A^Tb\,$，即求解 $\,\hat {x}\,$ 这个最优解。我们利用了 $\,A^TA\,$ 矩阵的特殊性质如下：<br>①设 A 为 m × n 矩阵，则 $\,A^TA\,$ 为 n × n 矩阵；<br>②$\,A^TA\,$，总为对称矩阵。$\,(A^TA)^T = A^TA\,$，故 $\,A^TA\,$ 总是对称的。</p>
<p>有一点需要注意，$\,A^TA\,$ 矩阵不一定总是可逆的，所以在求解时要注意 A 的特点。很明显，当 A 矩阵列向量线性相关时候，$\,A^TA\,$ 就不可逆了。因此若要 $\,A^TA\,$ 矩阵可逆，则要求 A 的零空间只有零向量，即 A 的列向量线性无关。</p>
<h1 id="第十五课-子空间投影"><a href="#第十五课-子空间投影" class="headerlink" title="第十五课 子空间投影"></a>第十五课 子空间投影</h1><p>这节主要讲<strong>投影 projection</strong>，从向量的投影入手，延伸到高维投影，并将投影用矩阵形式给出。做投影即是向另一个向量上做垂线，跟上节课的正交有联系。</p>
<h2 id="向量投影"><a href="#向量投影" class="headerlink" title="向量投影"></a>向量投影</h2><div  align="center">  
<img src="https://s2.loli.net/2024/02/19/xU4EQOj73XNgM2F.jpg" width = "50%" height = "50%" alt="图5 - 向量投影"/>
</div>

<p>投影问题的几何解释就是：如何在向量 a 的方向上寻找与向量 b 距离最近的一点。从图中可以看出，这个距离最近的点 p 就位于穿过 b 点并与向量 a 正交的直线与向量 a 所在直线的交点，即 b 在 a 上的投影。</p>
<blockquote>
<p>如果我们将向量 p 视为 b 的一种近似，则长度 e = b - p 就是这一近似的误差。</p>
</blockquote>
<p>因为 p 在向量 a 的方向上，因此可以令 p = xa，而因为它和 e 正交，我们可以得到方程：  </p>
<script type="math/tex; mode=display">a^Te = a^T(b - p) = a^T(b - xa) = 0</script><p>可得：  </p>
<script type="math/tex; mode=display">x = \frac {a^Tb} {a^Ta}, p = xa = a \frac {a^Tb} {a^Ta}</script><p>如果 b 变为原来的 2 倍，则 p 也变为原来的 2 倍。而如果 a 变为原来的 2 倍，p 不发生变化。从几何上和计算中都会得到验证。</p>
<h2 id="投影矩阵"><a href="#投影矩阵" class="headerlink" title="投影矩阵"></a>投影矩阵</h2><p>接下来我们将投影问题用投影矩阵的方式进行描述，即 $\,p = Pb\,$，其中 $\,P\,$ 为投影矩阵。</p>
<p>根据 $\,p = xa = a \frac {a^Tb} {a^Ta}\,$，可知 $\,P = \frac {aa^T} {a^Ta}\,$，注意当 a 是列向量时，分母 $\,a^Ta\,$ 是一个数，分子 $\,aa^T\,$ 是一个矩阵。</p>
<p>观察这个矩阵可知，因为 a 是列向量，$\,aa^T\,$ 得到的必然是秩一矩阵，矩阵 P 的列空间就是向量 a 所在的直线，矩阵 P 的秩为 1。同样，投影矩阵 P 是一个对称矩阵，即 $\,P^T = P\,$；另一方面，如果投影两次，第二次投影还在原来的位置，即 $\,P^2 = P\,$。</p>
<h2 id="Why-Project"><a href="#Why-Project" class="headerlink" title="Why Project"></a>Why Project</h2><p>如上一节结尾所述，方程 Ax = b 有可能无解，我们需要得到方程的“最优解”。这里的问题在于向量 Ax 一定在矩阵 A 的列空间之内，但是 b 不一定，因此我们希望将 b 投影到 A 的列空间得到 p，将问题转化为 $\,A\hat {x} = p\,$。</p>
<h2 id="平面投影"><a href="#平面投影" class="headerlink" title="平面投影"></a>平面投影</h2><div  align="center">  
<img src="https://s2.loli.net/2024/02/19/7uG81TXxNLzUKnQ.jpg" width = "50%" height = "50%" alt="图6 - 平面投影"/>
</div>

<p>$\,a_1\,$，$\,a_2\,$ 构成平面的一组基，平面是矩阵 $\,A = \begin{bmatrix} a_1 &amp; a_2\end{bmatrix}\,$ 的列空间。</p>
<p>p 在平面上，即 $\,p = \hat {x_1} a_1 + \hat {x_2} a_2\,$，即 $\,p = A\hat {x}\,$。</p>
<p>而 $\,e = b - p = b - A \hat {x}\,$ 与投影平面正交，也就是 $\,e\,$ 与 $\,a_1\,$ 和 $\,a_2\,$ 均正交，可得 $\,a_1^T(b - A \hat {x}) = 0\,$ 和 $\,a_2^T(b - A \hat {x}) = 0\,$。</p>
<p>因为 $\,a_1\,$ 和 $\,a_2\,$ 分别为矩阵 A 的列向量，即 $\,a_1^T\,$ 和 $\,a_2^T\,$ 为矩阵 $\,A^T\,$ 的行向量，所以将两个方程式写成矩阵形式即为 $\,A^T(b - A \hat {x}) = 0\,$，这与一维投影的方程形式相同，一维投影只是 A 只有一列的情况下。</p>
<p>$\,A^T(b - A \hat {x}) = 0\,$ 这个公式说明了，向量 $\,e = b - A \hat {x}\,$ 存在于矩阵 $\,A^T\,$ 的零空间 $\,N(A^T)\,$ ，即 e 向量与 $\,A^T\,$ 的行向量正交，也就与 A 的列向量正交。</p>
<hr>
<p>将方程 $\,A^T(b - A \hat {x}) = 0\,$ 改写，可得 $\,A^TA \hat {x} = A^Tb\,$，也就是上一节结尾的公式。</p>
<p>我们要注意一点：不能直接在两边左乘 $\,(A^T)^{-1}\,$。因为 $\,A^T\,$ 不一定是方阵，不一定有逆矩阵。但是这里 A 为两个基向量构成的矩阵，两个基向量线性无关，根据上节的知识，$\,A^TA\,$是可逆的。在两侧同时左乘 $\,(A^TA)^{-1}\,$：</p>
<script type="math/tex; mode=display">\hat x = (A^TA)^{-1} A^T b</script><p>代入 $p = A \hat {x}$：  </p>
<script type="math/tex; mode=display">p = A \hat x = A(A^TA)^{-1} A^T b</script><p>即投影矩阵为：  </p>
<script type="math/tex; mode=display">P =  A(A^TA)^{-1} A^T</script><p>可以看出，之前一维的 $\,P = \frac {aa^T} {a^Ta}\,$ 是上式的特殊情况。</p>
<p>因为矩阵 A 不是方阵，无法简单地用 $\,(A^TA)^{-1} = A^{-1}(A^T)^{-1}\,$ 对投影矩阵进行化简。若 A 是可逆方阵，则化简得到 P = I。此时 A 的列空间就是整个 $\,R^n\,$ 空间，b 到这个空间的投影就是其本身，投影矩阵等于单位阵。</p>
<p>对 $\,P =  A(A^TA)^{-1} A^T\,$ 用矩阵乘法的结合律和矩阵乘积的转置公式，可以证明投影矩阵的性质：$\,P^T = P\,$，$\,P^2 = P\,$。</p>
<h2 id="最小二乘法-Least-Squares-初涉"><a href="#最小二乘法-Least-Squares-初涉" class="headerlink" title="最小二乘法 Least Squares 初涉"></a>最小二乘法 Least Squares 初涉</h2><p>应用投影矩阵求方程组最优解的方法，最常用于“最小二乘法”拟合曲线。</p>
<p>例如：求解三个点（1，1），（2,2），（3，2）拟合的直线方程</p>
<p>我们假设最优直线方程：b = C + Dt，代入三个点列出方程。</p>
<script type="math/tex; mode=display">C + D = 1</script><script type="math/tex; mode=display">C + 2D = 2</script><script type="math/tex; mode=display">C + 3D = 2</script><p>矩阵形式为：</p>
<script type="math/tex; mode=display">\begin{bmatrix} 1 & 1 \\ 1 & 2 \\ 1 & 3 \end{bmatrix} \begin{bmatrix} C \\ D \end{bmatrix} = \begin{bmatrix} 1 \\ 2 \\ 2 \end{bmatrix}</script><p>这个的方程 Ax = b 是无解的，解决办法就是求其最优解，即方程 $\,A^TA \hat {x} = A^Tb\,$ 的解。</p>
<p>最小二乘法下节还会详述。</p>
<h1 id="第十六课-投影矩阵和最小二乘法"><a href="#第十六课-投影矩阵和最小二乘法" class="headerlink" title="第十六课 投影矩阵和最小二乘法"></a>第十六课 投影矩阵和最小二乘法</h1><h2 id="投影矩阵回顾"><a href="#投影矩阵回顾" class="headerlink" title="投影矩阵回顾"></a>投影矩阵回顾</h2><p>上一节中介绍过投影矩阵 P，即：  </p>
<script type="math/tex; mode=display">P = A(A^TA)^{-1}A^T</script><p>投影矩阵 P 与一向量 b 的乘积可以理解为：将 b 向量投影到它在列空间中的最近一点上，类似于上节课中，将 p 投影到平面上的过程。</p>
<p>两个问题：  </p>
<p>①如果 b 在矩阵 A 的列空间里，则 Pb = ？  </p>
<p>此时 Pb = b，因为 b 本身就在 A 列空间中。b 在 A 的列空间里，就一定可以写成：$\,Ax = b\,$。代入投影矩阵：$\,A(A^TA)^{-1}A^TAx = A(A^TA)^{-1}(A^TA)x = Ax = b\,$</p>
<p>②如果 b 垂直于 A 的列空间，则 Pb = ？<br>此时 Pb = 0，此时没有投影。b 垂直于 A 的列空间，也就垂直于 A 的所有列向量，故 b 在左零空间中，即 $\,A^Tb = 0\,$。代入投影矩阵：$\,A(A^TA)^{-1}A^Tb = A(A^TA)^{-1}0 = 0\,$</p>
<p>通过上面两个问题，我们可以看出来，一个向量 b 总有两个分量，一个分量在 A 的列空间中，另一个分量垂直于 A 的列空间。而投影矩阵的作用就是保留列空间中的那个分量，拿掉垂直于列空间的分量。</p>
<div  align="center">  
<img src="https://s2.loli.net/2024/02/21/iTJeK6R5ts7OSVL.jpg" width = "30%" height = "30%" alt="图7 - 投影矩阵的理解"/>
</div>

<p>$\,b = p + e\,$，p 就是投影矩阵作用于 b 上得到的向量，而 e 这个左零空间中的分量，如果也用类似投影矩阵来表示的话，就是：$\,p = Pb\,$，$\,e = b - p = b - Pb = (I - P)b \,$。$\,I-P\,$可以看作是左零空间的投影矩阵，并且 $\,(I - P)^T = I - P\,$，$\,(I - P)^2 = I - P\,$。</p>
<h2 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h2><p>接着上节课的例子：  </p>
<script type="math/tex; mode=display">\begin{bmatrix} 1 & 1 \\ 1 & 2 \\ 1 & 3 \end{bmatrix} \begin{bmatrix} C \\ D \end{bmatrix} = \begin{bmatrix} 1 \\ 2 \\ 2 \end{bmatrix}</script><p>这个的方程 Ax = b 是无解的，解决办法就是求其最优解，最优解的含义即为直线与各点之间的误差（偏移量）最小，为了便于计算，研究它们的平方和：$\,|e|^2 = |Ax - b|^2\,$，因此就是寻找具有最小误差平方和的解 x，这就是所谓的“最小二乘”问题。</p>
<div  align="center">  
<img src="https://s2.loli.net/2024/02/21/bdhuCi1Zo9qctK2.jpg" width = "30%" height = "30%" alt="图8 - 误差"/>
</div>

<p>从几何上讨论求解过程，就是试图寻找数据点到直线距离的平方和 $\,e_1^2 + e_2^2 + e_3^2\,$ 最小的情况。另一种看法是，对于 $\,R^3\,$ 空间上的向量 b，它投影到矩阵 A 的列空间中会得到向量 p = [p1 p2 p3]，投影到矩阵 A 的左零空间中则为 e。</p>
<p>计算如下，使用上节课中我们介绍的方程：  </p>
<script type="math/tex; mode=display">A^TA \hat {x} = A^Tb</script><p>对应方程：$\,\begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 2 \\ 1 &amp; 3 \end{bmatrix} \begin{bmatrix} C \\ D \end{bmatrix} = \begin{bmatrix} 1 \\ 2 \\ 2 \end{bmatrix}\,$，其中 $\,A = \begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 2 \\ 1 &amp; 3 \end{bmatrix}\,$，$\,\hat x = \begin{bmatrix} \hat c \\ \hat d \end{bmatrix}\,$，$\,b = \begin{bmatrix} 1 \\ 2 \\ 2 \end{bmatrix}\,$。</p>
<p>其中 $\,A \hat {x} = b\,$ 可以写成增广矩阵模式，故 $\,A^TA \hat {x} = A^Tb\,$ 可以写成：</p>
<script type="math/tex; mode=display">\begin{bmatrix} 1 & 1 & 1 \\ 1 & 2 & 3 \end{bmatrix} \left[ \begin{array}{cc|c} 1 & 1 & 1 \\ 1 & 2 & 2 \\ 1 & 3 & 2 \end{array} \right] = \left[ \begin{array}{cc|c} 3 & 6 & 5 \\ 6 & 14 & 11 \end{array} \right]</script><p>即有：  </p>
<script type="math/tex; mode=display">\begin{bmatrix} 3 & 6 \\ 6 & 14 \end{bmatrix} \begin{bmatrix} \hat {C} \\ \hat {D} \end{bmatrix} = \begin{bmatrix} 5 \\ 11 \end{bmatrix}</script><p>解得：</p>
<script type="math/tex; mode=display">\hat {C} = 2/3，\hat {D} = 1/2</script><p>得到直线表达式 y = 2/3 + t/2。</p>
<p>还可以从误差最小的角度出发求解：  </p>
<script type="math/tex; mode=display">e_1^2 + e_2^2 + e_3^2 = (C + D - 1)^2 + (C + 2D - 2)^2 + (C + 3D - 2)^2</script><p>对等号右边的表达式求偏导数，极值出现在偏导数为 0 的位置。求偏导最终会得到相同的线性方程组和相同的解。</p>
<p>得到直线表达式 y = 2/3 + t/2。将 t = 1, 2, 3 分别代入，以及 b = p + e 可得：  </p>
<script type="math/tex; mode=display">b = \begin{bmatrix} 1 \\ 2 \\ 2 \end{bmatrix}, p = \begin{bmatrix} 7/6 \\ 10/6 \\ 13/6 \end{bmatrix}, e = \begin{bmatrix} -1/6 \\ 2/6 \\ -1/6 \end{bmatrix}</script><p>得到如下性质：<br>①误差向量与投影向量 p 垂直（二者点乘为 0）<br>②误差向量不仅仅垂直于 p，它还垂直于列空间中的每一个向量。</p>
<h2 id="矩阵-A-TA"><a href="#矩阵-A-TA" class="headerlink" title="矩阵 $\,A^TA\,$"></a>矩阵 $\,A^TA\,$</h2><p>之前有一个结论没有验证过：如果矩阵 A 各列线性无关，则矩阵 $\,A^TA\,$ 可逆。</p>
<p>引入之前几节的结论：如果矩阵可逆，则其对应的零空间仅为零向量。$\,x^Tx\,$ 对应是在求 x 的长度（x 是列向量）。如果 $\,x^Tx = 0\,$，则 x = 0（x 是列向量）。</p>
<p>假设存在 x 使得 $\,A^TAx = 0\,$。则有 $\,x^TA^TAx = 0 = (Ax)^T(Ax)\,$，可推得 Ax = 0，因为 A 各列线性无关，所以也就推得了 x 必为零向量。即 $\,A^TA\,$ 为可逆矩阵。</p>
<h2 id="标准正交基"><a href="#标准正交基" class="headerlink" title="标准正交基"></a>标准正交基</h2><p>这部分是引出下节的部分，内容较少：</p>
<p>如果矩阵的列向量是互相垂直的单位向量，则它们一定是线性无关的。我们将这种向量称之为<strong>标准正交 orthonormal</strong>。</p>
<p>例如：$\,\begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix}\,$，$\,\begin{bmatrix} 0 \\ 1 \\ 0 \end{bmatrix}\,$，$\,\begin{bmatrix} 0 \\ 0 \\ 1 \end{bmatrix}\,$，以及 $\,\begin{bmatrix} \cos \theta \\ \sin \theta \end{bmatrix}\,$ 和 $\,\begin{bmatrix} -\sin \theta \\ \cos \theta \end{bmatrix}\,$。</p>
<h1 id="第十七课-正交矩阵和施密特正交化"><a href="#第十七课-正交矩阵和施密特正交化" class="headerlink" title="第十七课 正交矩阵和施密特正交化"></a>第十七课 正交矩阵和施密特正交化</h1><h2 id="标准正交向量-Orthonormal-vectors"><a href="#标准正交向量-Orthonormal-vectors" class="headerlink" title="标准正交向量 Orthonormal vectors"></a>标准正交向量 Orthonormal vectors</h2><p>满足如下条件的向量 $\,q_1, q_2, q_3\,$ 为标准正交：  </p>
<script type="math/tex; mode=display">q_i^Tq_j = \begin{cases} 0 & i \ne j \\[2ex] 1 & i = j \end{cases}</script><p>即，这些向量都具有单位长度 1，并且彼此正交。标准正交向量是线性无关的。</p>
<h2 id="标准正交矩阵-Orthonormal-matrix"><a href="#标准正交矩阵-Orthonormal-matrix" class="headerlink" title="标准正交矩阵 Orthonormal matrix"></a>标准正交矩阵 Orthonormal matrix</h2><p>所谓标准正交矩阵 Q，就是将标准正交向量组中的 $\,q_1, q_2 ··· q_n\,$ 列在同一个<br>矩阵中：  </p>
<script type="math/tex; mode=display">Q = \begin{bmatrix} q_1 & ... & q_n \end{bmatrix}</script><p>这样的标准正交矩阵有一个很好的性质：  </p>
<script type="math/tex; mode=display">Q^TQ = \begin{bmatrix} q_1 \\ q_2 \\ ... \\ q_n \end{bmatrix} \begin{bmatrix} q_1 & q_2 & ... & q_n \end{bmatrix} = \begin{bmatrix} 1 & 0 & \cdots & 0 & 0 \\ 0 & 1 & \cdots & 0 & 0 \\ \vdots & \vdots & \ddots & \vdots & \vdots \\ 0 & 0 & \cdots & 1 & 0 \\ 0 & 0 & \cdots & 0 & 1 \end{bmatrix} = I</script><p>注意这里的标准正交矩阵 Q 可以不是方阵；一个标准正交的方阵我们称之为<strong>正交矩阵 orthogonal matrix</strong>。如果 Q 为方阵，因为 $\,Q^TQ = I\,$，所以 $\,Q^T = Q^{-1}\,$。</p>
<p>正交矩阵不要忘了单位化。例如，$\,\begin{bmatrix} 1 &amp; 1 \\ 1 &amp; -1 \end{bmatrix}\,$，这个矩阵各列是正交的，但并不是正交矩阵，因为没有单位化，正确的正交矩阵是 $\,\frac {1} {\sqrt 2}\begin{bmatrix} 1 &amp; 1 \\ 1 &amp; -1 \end{bmatrix}\,$。由这个矩阵可以延伸出<strong>阿达马矩阵 Adamar Matrix</strong>，这里不做详细介绍。</p>
<h2 id="标准正交矩阵的作用"><a href="#标准正交矩阵的作用" class="headerlink" title="标准正交矩阵的作用"></a>标准正交矩阵的作用</h2><p>记得上面介绍的投影矩阵 $\,P = A(A^TA)^{-1}A^T\,$，若 A 矩阵是标准正交矩阵 Q 时：  </p>
<script type="math/tex; mode=display">Q(Q^TQ)^{-1}Q^T = QQ^T</script><p>特别的，当 Q 时方阵（正交阵）时，由于此时 $\,Q^T = Q^{-1}\,$。所以投影矩阵即为 I。</p>
<p>很多复杂问题使用标准正交向量之后都变得简单。如果基为标准正交，则方程 $\,A^TA \hat {x} = A^Tb\,$ 的解变为 $\,\hat {x} = Q^Tb\,$，$\,\hat {x}\,$ 的分量 $\,\hat {x_i} = q_i^Tb\,$。</p>
<h2 id="施密特正交化-Gram-Schmidt"><a href="#施密特正交化-Gram-Schmidt" class="headerlink" title="施密特正交化 Gram-Schmidt"></a>施密特正交化 Gram-Schmidt</h2><p><strong>施密特正交化 Gram-Schmidt Orthogonalization</strong> 即从线性无关向量组入手，将其矩阵标准正交化。</p>
<p>有两个线性无关的向量 a，b。我们想从中得到标准正交向量 $\,q_1\,$，$\,q_2\,$。</p>
<p>Schmidt 给出的结论是如果我们有一组正交基 A 和 B（注意这个小节 A，B，C 均为向量），那么我们令它们除以自己的长度就得到标准正交基：  </p>
<script type="math/tex; mode=display">q_1 = \frac {A} {|A|}, q_2 = \frac {B} {|B|}</script><p>Gram 做了重要的工作，在 a 和 b 张成的空间中，将 a 向量定为 A 向量，然后将 b 向量投影到 a 向量上。然后取 B = b - p：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2024/02/22/abOJoXkDYQEpyv2.jpg" width = "40%" height = "40%" alt="图9 - 二维施密特正交化"/>
</div>

<p>即：  </p>
<script type="math/tex; mode=display">B = b - \cfrac {A^Tb} {A^TA} A</script><p>验证 A 与 B 是否正交：$\,A^TB = A^T(b - \cfrac {A^Tb} {A^TA} A) = 0\,$，说明 A 与 B 是正交的。接下来通过 $\,q_1 = \cfrac {A} {|A|}, q_2 = \cfrac {B} {|B|}\,$ 单位化各个向量，就得到了 a, b 空间的标准正交基。</p>
<hr>
<p>同样的道理，推广到三维：</p>
<div  align="center">  
<img src="https://s2.loli.net/2024/02/22/AyuORYN4vqm5oCj.jpg" width = "40%" height = "40%" alt="图10 - 三维施密特正交化"/>
</div>

<p>寻找三个正交的向量 A, B, C 的话，其中 A，B 方法不变：</p>
<script type="math/tex; mode=display">A = a</script><script type="math/tex; mode=display">B = b - \cfrac {A^Tb} {A^TA} A</script><p>而 C 通过将 c 减去在 A, B 上的投影就可以得到：  </p>
<script type="math/tex; mode=display">C = c - \cfrac {A^Tb} {A^TA} A - \cfrac {B^Tc} {B^TB} B</script><p>得到三个正交的向量 A, B, C，再进行单位化即可。</p>
<hr>
<p>示例：$\,a = \begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix}\,$，$\,b = \begin{bmatrix} 1 \\ 0 \\ 2 \end{bmatrix}\,$，求标准正交矩阵 Q。</p>
<script type="math/tex; mode=display">A = a = \begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix}</script><script type="math/tex; mode=display">B = b - \cfrac {A^Tb} {A^TA} A = \begin{bmatrix} 1 \\ 0 \\ 2 \end{bmatrix} - \frac {3} {3} \begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix} = \begin{bmatrix} 0 \\ -1 \\ 1 \end{bmatrix}</script><p>再进行单位化，得到标准正交矩阵 Q：</p>
<script type="math/tex; mode=display">Q = \begin{bmatrix} q_1 & q_2 \end{bmatrix} = \begin{bmatrix} 1/\sqrt {3} & 0 \\ 1/\sqrt {3} & -1/\sqrt {2} \\ 1/\sqrt {3} & 1/\sqrt {2} \end{bmatrix}</script><p>观察矩阵 $\,A = \begin{bmatrix} 1 &amp; 1\\ 1 &amp; 0 \\ 1 &amp; 2 \end{bmatrix}\,$ 和矩阵 Q 的列空间，它们是相同的，也就是说我们的正交化过程都是在同一个空间中进行的，只是最后得到了一个更好的标准正交基而已。</p>
<p>从矩阵的角度来看，类似于 A 的 LU 分解，在 Gram-Schmidt 正交化中，A 可分解为 Q 与 R。其中 R 是上三角矩阵：$\,A = QR\,$</p>
<script type="math/tex; mode=display">A = \begin{bmatrix} a_1 & a_2 \end{bmatrix}</script><script type="math/tex; mode=display">Q = \begin{bmatrix} q_1 & q_2 \end{bmatrix}</script><script type="math/tex; mode=display">R = \begin{bmatrix} a_1^Tq_1 & a_2^Tq_1 \\ a_1^Tq_2 & a_2^Tq_2 \end{bmatrix}</script><p>其中 R 中的 $\,a_1^Tq_2\,$ 为 0，这是因为 $\,a_1\,$ 就是 $\,q_1\,$ 的方向，而 $\,q_1\,$ 和 $\,q_2\,$ 为标准正交向量，因此 $\,q_2\,$ 的方向与 $\,a_1\,$ 垂直，因此内积为 0。</p>
<p>R 在 Q 右侧相当于对 Q 做列操作，即 A 的列向量是 Q 列向量的线性组合。</p>
<h1 id="第十八课-行列式及其性质"><a href="#第十八课-行列式及其性质" class="headerlink" title="第十八课 行列式及其性质"></a>第十八课 行列式及其性质</h1><p>接下来课程进入了下一个部分，之前学习了大量长方形矩阵的性质，现在我们集中讨论方阵的性质，包括<strong>行列式 determinants</strong> 和<strong>特征值 Eigen values</strong>。</p>
<h2 id="行列式-Determinants"><a href="#行列式-Determinants" class="headerlink" title="行列式 Determinants"></a>行列式 Determinants</h2><p>行列式是跟每个方阵都有关的一个数字。这个数字包含了这个矩阵的很多性质，比如方阵行列式为 0，<br>则方阵不可逆。矩阵 A 的行列式记作：  </p>
<script type="math/tex; mode=display">det(A) 或 | A |</script><h2 id="行列式的性质"><a href="#行列式的性质" class="headerlink" title="行列式的性质"></a>行列式的性质</h2><p>直接给出 n 阶行列式的公式，则一下子代入了大量信息，并不利于接受这个概念，我们从行列式的三个性质开始讲起，这三个性质定义了行列式。</p>
<p><strong>性质一</strong>：对于单位阵 I，有：$\,det(I) = 1\,$。</p>
<script type="math/tex; mode=display">\begin{vmatrix} 1 & 0 \\ 0 & 1 \end{vmatrix} = 1</script><p><strong>性质二</strong>：交换两行后，行列式的值相反。可以推知置换矩阵的行列式是 +1 或者 -1。</p>
<script type="math/tex; mode=display">\begin{vmatrix} 0 & 1 \\ 1 & 0 \end{vmatrix} = -1</script><p><strong>性质三①</strong>：如果在矩阵的一行乘上 t，则行列式的值就要乘上 t：  </p>
<script type="math/tex; mode=display">\begin{vmatrix} ta & tb \\ c & d \end{vmatrix} = t\begin{vmatrix} a & b \\ c & d \end{vmatrix}</script><p><strong>性质三②</strong>：行列式是一个线性函数，但是这个线性单独反映在每一行上。即：</p>
<script type="math/tex; mode=display">\begin{vmatrix} a + a' & b + b' \\ c & d \end{vmatrix} = \begin{vmatrix} a & b \\ c & d \end{vmatrix} + \begin{vmatrix} a' & b' \\ c & d \end{vmatrix}</script><hr>
<p>更多的性质可以从以上的三条性质中推导出来：  </p>
<p><strong>性质四</strong>：如果矩阵的两行是完全相同的，则它的行列式为 0。</p>
<p>这可以从第二条性质推导出来，因为交换这个相同的两行，行列式应该变号；但是新生成的矩阵跟原矩阵没有区别，因此行列式应该不变，所以有 det = -det，所以 det 等于 0。</p>
<p><strong>性质五</strong>：从矩阵的行 k 减去另一行的 i 倍，对应的行列式值不发生改变：  </p>
<script type="math/tex; mode=display">\begin{align*} \begin{vmatrix} a & b \\ c - ta & d - tb \end{vmatrix} &= \begin{vmatrix} a & b \\ c & d \end{vmatrix} - \begin{vmatrix} a & b \\ ta & tb \end{vmatrix} \\ &= \begin{vmatrix} a & b \\ c & d \end{vmatrix} - t\begin{vmatrix} a & b \\ a & b \end{vmatrix} \\ &= \begin{vmatrix} a & b \\ c & d \end{vmatrix} \end{align*}</script><p><strong>性质六</strong>：如果有一行为零，那么 A 的行列式为 0： </p>
<p>这个性质很简单，让性质 3 中的 t = 0，行列式值也为 0。</p>
<p><strong>性质七</strong>：上三角矩阵对应的行列式的值等于其对角线上元素的乘积。  </p>
<p>性质五告诉我们行消元的过程，行列式的数值没有发生变化，即三角阵通过行消元法得到对角阵的行列式不变；性质三①告诉我们对角阵的行列式等于其主元的乘积再乘以单位阵的行列式；性质一表明单位阵行列式为 1。故有：  </p>
<script type="math/tex; mode=display">\begin{align*} \begin{bmatrix} d_1 & * & * & \cdots & * \\ 0 & d_2 & * & \cdots & * \\ 0 & 0 & \ddots & \ddots & * \\ \vdots & \vdots & \ddots & \ddots & \vdots \\ 0 & 0 & \cdots & \cdots & d_n \end{bmatrix} &= \begin{bmatrix} d_1 & 0 & 0 & \cdots & 0 \\ 0 & d_2 & 0 & \cdots & 0 \\ 0 & 0 & \ddots & \ddots & 0 \\ \vdots & \vdots & \ddots & \ddots & \vdots \\ 0 & 0 & \cdots & \cdots & d_n \end{bmatrix} \\ &= d_1d_2 \cdots d_n \begin{bmatrix} 1 & 0 & 0 & \cdots & 0 \\ 0 & 1 & 0 & \cdots & 0 \\ 0 & 0 & \ddots & \ddots & 0 \\ \vdots & \vdots & \ddots & \ddots & \vdots \\ 0 & 0 & \cdots & \cdots & 1 \end{bmatrix} \\ &= d_1d_2 \cdots d_n \end{align*}</script><p><strong>性质八</strong>：当且仅当矩阵 A 为奇异矩阵时，其行列式为 0。当且仅当 A 可逆，行列式不为 0。  </p>
<p>如果矩阵 A 为奇异阵，则必可通过消元法使得矩阵的某行全等于零，则按照性质六，A 的行列式为 0。如果其不是奇异阵，则通过消元可以得到一个上三角矩阵，且其主元均不为 0，则按照性质七，行列式的数值等于主元的乘积也不等于 0。</p>
<blockquote>
<p>计算非奇异矩阵的行列式有确切的公式，但通常计算机是靠消元的方法来转化为三角阵，然后将主元相乘来进行计算的。</p>
</blockquote>
<p><strong>性质九</strong>：方阵乘积的行列式 = 方阵行列式的乘积，即：$\,|AB| = |A||B|\,$。</p>
<p>由此结论可知：<br>①可逆矩阵的行列式与其逆矩阵的行列式互为倒数：$\,AA^{-1} = I \rightarrow |A||A^{-1}| = 1\,$  </p>
<p>②矩阵平方的行列式等于矩阵行列式的平方：$\,|A^2| = (|A|)^2\,$  </p>
<p>③$\,|kA| = k^n|A|\,$，其中 k 为常数，A 为 n 阶矩阵，提出了每一行中的 k。</p>
<p><strong>性质十</strong>：$\,|A^T| = |A|\,$。</p>
<p>证明：矩阵消元可得 $\,A = LU\,$，则 $\,A^T = U^TL^T\,$，由性质九可知 $\,|A| = |L||U|\,$，$\,|A^T| = |L^T||U^T|\,$。第四课中的 LU 分解中介绍过，L 是一个主对角线全为 1 的下三角矩阵(因为消元过程总是向下消元)。而 U 是一个上三角矩阵。很明显。像 U,L 这样的上/下三角矩阵，不论转置与否，其行列式都为对角线上各元素乘积，即 $\,|L^T| = |L|\,$，$\,|U^T| = |U|\,$。故$\,|A^T| = |A|\,$</p>
<p>因为性质十成立，交换行和交换列本质上没什么区别，之前的性质都可以应用在列变换上。</p>
<blockquote>
<p>这一课结尾时，教授提到了行交换的奇偶问题，这个问题很重要，因为行交换的奇偶性会影响最终值的正负号，所以置换矩阵行列式的正负性受其行交换次数影响。</p>
</blockquote>
<h1 id="第十九课-行列式公式和代数余子式"><a href="#第十九课-行列式公式和代数余子式" class="headerlink" title="第十九课 行列式公式和代数余子式"></a>第十九课 行列式公式和代数余子式</h1><p>认识到了行列式的性质后，可以推导出其公式：  </p>
<h2 id="行列式公式"><a href="#行列式公式" class="headerlink" title="行列式公式"></a>行列式公式</h2><p>从上节课的十个性质出发可以得到二阶方阵的行列式公式：  </p>
<script type="math/tex; mode=display">\begin{align*} \begin{vmatrix} a & b \\ c & d \end{vmatrix} &= \begin{vmatrix} a & 0 \\ c & d \end{vmatrix} + \begin{vmatrix} 0 & b \\ c & d \end{vmatrix} \\ &= \begin{vmatrix} a & 0 \\ c & 0 \end{vmatrix} + \begin{vmatrix} a & 0 \\ 0 & d \end{vmatrix} + \begin{vmatrix} 0 & b \\ c & 0 \end{vmatrix} + \begin{vmatrix} 0 & b \\ 0 & d \end{vmatrix} \\ &= 0 + ad - bc + 0 \\ &= ad - bc \end{align*}</script><p>观察上面的求解过程，不难发现，行列式其实取决于那些分解后非零的行列式的和，这些非零行列式有这样一个特点：各行格列均有元素。根据这个特点，我们可以简化更高阶的行列式解法。接下来将问题扩展到三阶：  </p>
<script type="math/tex; mode=display">\begin{align*} \begin{vmatrix} a_{11} & a_{12} & a_{13} \\ a_{21} & a_{22} & a_{23} \\ a_{31} & a_{32} & a_{33} \end{vmatrix} &= \begin{vmatrix} a_{11} & 0 & 0 \\ 0 & a_{22} & 0 \\ 0 & 0 & a_{33} \end{vmatrix} + \begin{vmatrix} a_{11} & 0 & 0 \\ 0 & 0 & a_{23} \\ 0 & a_{32} & 0 \end{vmatrix} + \begin{vmatrix} 0 & a_{12} & 0 \\ a_{21} & 0 & 0 \\ 0 & 0 & a_{33} \end{vmatrix} \\ &+ \begin{vmatrix} 0 & a_{12} & 0 \\ 0 & 0 & a_{23} \\ a_{31} & 0 & 0 \end{vmatrix} + \begin{vmatrix} 0 & 0 & a_{13} \\ a_{21} & 0 & 0 \\ 0 & a_{32} & 0 \end{vmatrix} + \begin{vmatrix} 0 & 0 & a_{13} \\ 0 & a_{22} & 0 \\ a_{31} & 0 & 0 \end{vmatrix} \\ &= a_{11}a_{22}a_{33} - a_{11}a_{23}a_{32} - a_{12}a_{21}a_{33} + a_{12}a_{23}a_{31} + a_{13}a_{21}a_{32} - a_{13}a_{22}a_{31} \end{align*}</script><p>下面通过类比得到一般公式，这个拆分过程其实是每次从一行中选择某一列上相交位置的元素来累乘，而且各行选定的列不相同。注意该项的符号的正负，写成以下形式：  </p>
<script type="math/tex; mode=display">det(A) = \sum_{n!} \pm a_{1 \alpha} a_{2 \beta} a_{3 \gamma} \cdots a_{n \omega}</script><p>其中列标号 $\,\alpha, \beta, \gamma \cdots \,$ 是列标号（1, 2, 3 … n）的某个排列。比如说对于单位阵而言，只有 $\,\alpha = 1, \beta = 2, \cdots \omega = n \,$，所得到的行列式为 +1，其它都为零，所以单位阵的行列式为 1。用以下例子来更好的说明：  </p>
<script type="math/tex; mode=display">\begin{vmatrix} 0 & 0 & 1 & 1 \\ 0 & 1 & 1 & 0 \\ 1 & 1 & 0 & 0 \\ 1 & 0 & 0 & 1 \end{vmatrix} = \begin{vmatrix} 0 & 0 & 0 & 1 \\ 0 & 0 & 1 & 0 \\ 0 & 1 & 0 & 0 \\ 1 & 0 & 0 & 0 \end{vmatrix} + \begin{vmatrix} 0 & 0 & 1 & 0 \\ 0 & 1 & 0 & 0 \\ 1 & 0 & 0 & 0 \\ 0 & 0 & 0 & 1 \end{vmatrix}</script><p>列标号取（4, 3, 2, 1）得到第一个拆分行列式，符号为正，因为只要经过两次交换就能变为（1, 2, 3, 4）。第二个为（3, 2, 1, 4），因为只需交换一次就可变为正序，所以符号为负。因此本行列式为 0。</p>
<h2 id="代数余子式-Cofactor-formula"><a href="#代数余子式-Cofactor-formula" class="headerlink" title="代数余子式 Cofactor formula"></a>代数余子式 Cofactor formula</h2><p>利用代数余子式我们可以更方便地求解行列式，其作用即是将 n 阶行列式化成 n-1 阶。</p>
<p>比如上面的三阶矩阵：  </p>
<script type="math/tex; mode=display">det(A) = \begin{vmatrix} a_{11} & 0 & 0 \\ 0 & a_{22} & a_{23} \\ 0 & a_{32} & a_{33} \end{vmatrix} + \begin{vmatrix} 0 & a_{12} & 0 \\ a_{21} & 0 & a_{23} \\ a_{31} & 0 & a_{33} \end{vmatrix} + \begin{vmatrix} 0 & 0 & a_{13} \\ a_{21} & a_{22} & 0 \\ a_{31} & a_{32} & 0 \end{vmatrix}</script><p>将原公式中属于矩阵第一行的 $\,a_{1j}\,$ 提出来，其系数即为代数余子式，是一个低阶行列式的值。这个低阶行列式是由原矩阵去掉 $\,a_{1j}\,$ 所在的行和列组成的。</p>
<p>对于 n 阶方阵，其行列式的代数余子式公式为：  </p>
<script type="math/tex; mode=display">det(A) = a_{11}C_{11} + a_{12}C_{12} + \cdots + a_{1n}C_{1n}</script><p>$\,a_{ij}\,$ 位置对应的代数余子式 $\,C_{ij}\,$ 为去掉原行列式中第 i 行第 j 列后剩余元素组成的矩阵的行列式值与 $\,a_{ij}\,$ 的乘积的正或负值。当 i + j 为偶数时为正，奇数为负，可以理解为：$\,(-1)^{i+j}\,$ * 剩余元素组成的行列式值。</p>
<p>对于矩阵行列式的计算，消元的得到主元是一个很好的方法，与之相比行列式的展开公式较为复杂，而代数余子式的方法介于两者之间，它的核心想法是通过降阶来将原来的行列式展开成更简单的行列式。</p>
<hr>
<p>接下来通过一种特殊的矩阵熟悉一下按行展开行列式的计算方法：</p>
<p>举三对角阵 tridiagonal matrix 为例，它除了对角线和对角线两侧相邻的元素之外，其它元素均为 0。</p>
<script type="math/tex; mode=display">A_4 = \begin{bmatrix} 1 & 1 & 0 & 0 \\ 1 & 1 & 1 & 0 \\ 0 & 1 & 1 & 1 \\ 0 & 0 & 1 & 1 \end{bmatrix}</script><p>我们可以从 1 阶开始算起：$\,|A_1| = 1\,$，$\,|A_2| = \begin{vmatrix} 1 &amp; 1 \\ 1 &amp; 1 \end{vmatrix} = 0\,$，$\,|A_3| = \begin{vmatrix} 1 &amp; 1 &amp; 0 \\ 1 &amp; 1 &amp; 1 \\ 0 &amp; 1 &amp; 1 \end{vmatrix} = -1\,$</p>
<p>则有 $\,|A_4| = 1\begin{vmatrix} 1 &amp; 1 &amp; 0 \\ 1 &amp; 1 &amp; 1 \\ 0 &amp; 1 &amp; 1 \end{vmatrix} - 1\begin{vmatrix} 1 &amp; 1 &amp; 0 \\ 0 &amp; 1 &amp; 1 \\ 0 &amp; 1 &amp; 1 \end{vmatrix} = |A_3| - 1|A_2| = -1\,$</p>
<p>从三对角阵的特殊结构我们可以得到：$\,|A_n| = |A_{n-1}| - 1|A_{n-2}|\,$，由 1 组成的 n 阶三对角阵的行列式从 1 阶开始按照 1, 0, -1, -1, 0, 1 进行循环。</p>
<h1 id="第二十课-克莱姆法则、逆矩阵、体积"><a href="#第二十课-克莱姆法则、逆矩阵、体积" class="headerlink" title="第二十课 克莱姆法则、逆矩阵、体积"></a>第二十课 克莱姆法则、逆矩阵、体积</h1><p>这一节强调行列式的应用，包含三个方面：克莱姆法则、逆矩阵、体积</p>
<h2 id="逆矩阵公式"><a href="#逆矩阵公式" class="headerlink" title="逆矩阵公式"></a>逆矩阵公式</h2><p>逆矩阵公式：  </p>
<script type="math/tex; mode=display">A^{-1} = \frac {1} {|A|} C^T</script><p>$\,C^T\,$ 为代数余子式矩阵 C 的转置矩阵，称为伴随矩阵 adjoint matrix。代数余子式矩阵 C 为矩阵 A 的各个元素的对应的代数余子式组成的矩阵。比如，二阶逆矩阵公式为：  </p>
<script type="math/tex; mode=display">\begin{bmatrix} a & b \\ c & d \end{bmatrix}^{-1} = \frac {1} {ad - bc} \begin{bmatrix} d & -b \\ -c & a \end{bmatrix}</script><hr>
<p>验证上述公式，上述公式等价于：  </p>
<script type="math/tex; mode=display">AC^T = |A|I</script><p>将其展开观察：  </p>
<script type="math/tex; mode=display">AC^T = \begin{bmatrix} a_{11} & \cdots & a_{1n} \\ \vdots & \ddots & \vdots \\ a_{n1} & \cdots & a_{nn} \end{bmatrix} \begin{bmatrix} C_{11} & \cdots & C_{n1} \\ \vdots & \ddots & \vdots \\ C_{1n} & \cdots & C_{nn} \end{bmatrix}</script><p>矩阵 $\,AC^T\,$ 第一行第一列的元素等于矩阵 A 第一行和矩阵 $\,C^T\,$ 第一列进行点积，计算可得：  </p>
<script type="math/tex; mode=display">\sum_{j=1}^n a_{1j}C_{1j} = det(A)</script><p>这就是计算 A 行列式的计算公式。可以得到矩阵 $\,AC^T\,$ 对角线上所有的元素都是如此，因此其对角戏上的元素都等于 det(A)。</p>
<p>而对于非对角线元素，我们以第二行第一列的元素为例，其计算公式为：  </p>
<script type="math/tex; mode=display">\sum_{j=1}^n a_{2j}C_{1j} = det(A_s)</script><p>这可以视为矩阵 $\,A_s\,$ 的行列式数值，各个代数余子式的形式不变，但是与代数余子式相乘的变为了矩阵 A 第二行的元素。也就是说这个 $\,A_s\,$ 的样子相对于第一行为 A 的第二行，其他行和 A 一样，即：  </p>
<script type="math/tex; mode=display">det(A_s) = \begin{vmatrix} a_{21} & a_{22} & \cdots & a_{2n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ a_{31} & a_{32} & \cdots & a_{3n} \\ \vdots & \ddots & \ddots & \vdots \\ a_{n1} & a_{n2} &\cdots & a_{nn} \end{vmatrix} = 0</script><p>因为该矩阵中前两行完全相同，按照行列式性质 4，$\,det(A_s)=0\,$。</p>
<p>因此矩阵 $\,AC^T\,$ 为：  </p>
<script type="math/tex; mode=display">AC^T = \begin{bmatrix} det(A) & 0 & \cdots & 0 \\ 0 & det(A) & \cdots & 0 \\ \vdots & \ddots & \ddots & \vdots \\ 0 & 0 &\cdots & det(A) \end{bmatrix} = det(A)I</script><h2 id="克莱姆法则-Cramer’s-Rule"><a href="#克莱姆法则-Cramer’s-Rule" class="headerlink" title="克莱姆法则 Cramer’s Rule"></a>克莱姆法则 Cramer’s Rule</h2><p>对于可逆矩阵 A，方程 $\,Ax=b\,$ 必然有解 $\,x=A^{-1}b\,$，将逆矩阵的公式带入其中，则有：</p>
<script type="math/tex; mode=display">x = A^{-1}b = \cfrac {1} {det(A)} C^Tb</script><p>克莱姆法则是从另一个角度来看待这个公式。实际上 x 的分量 $\,x_j = \cfrac {det(B_j)} {det(A)}\,$。$\,C^Tb\,$ 为矩阵 $\,B_j\,$ 的行列式值。</p>
<p>其中矩阵 $\,B_j\,$ 为用向量 b 替换矩阵 A 的第 j 列所得到的新矩阵。例如：  </p>
<script type="math/tex; mode=display">B_1 = \begin{bmatrix} b_1 & a_{12} & \cdots & a_{1n} \\ b_2 & a_{22} & \cdots & a_{2n} \\ b_3 & a_{32} & \cdots & a_{3n} \\ \vdots & \ddots & \ddots & \vdots \\ b_n & a_{n2} & \cdots & a_{nn} \end{bmatrix}, B_n = \begin{bmatrix} a_{11} & a_{12} & \cdots & b_1 \\ a_{21} & a_{22} & \cdots & b_2 \\ a_{31} & a_{32} & \cdots & b_3 \\ \vdots & \ddots & \ddots & \vdots \\ a_{n1} & a_{n2} & \cdots & b_n \end{bmatrix}</script><p>矩阵 $\,B_j\,$ 的行列式的数值从第 j 列用代数余子式进行展开计算，正好是伴随矩阵 $\,C^T\,$ 的第 j 行与向量 b 点积的结果。此处我们用到了行列式的性质十。</p>
<p>$\,C^T\,$ 矩阵为：  </p>
<script type="math/tex; mode=display">C^T = \begin{bmatrix} C_{11} & \cdots & C_{n1} \\ \vdots & \ddots & \vdots \\ C_{1n} & \cdots & C_{nn} \end{bmatrix}</script><p>即：  </p>
<script type="math/tex; mode=display">(C^Tb)_1 = \begin{bmatrix} C_{11} & \cdots & C_{n1} \end{bmatrix}  \begin{bmatrix} b_1 \\ \cdots \\ b_n \end{bmatrix} = \begin{vmatrix} b_1 & a_{12} & \cdots & a_{1n} \\ b_2 & a_{22} & \cdots & a_{2n} \\ b_3 & a_{32} & \cdots & a_{3n} \\ \vdots & \ddots & \ddots & \vdots \\ b_n & a_{n2} & \cdots & a_{nn} \end{vmatrix} = |B_1|</script><p>就这样，我们得到了另一种解方程 Ax = b 的方法。相比于消元法，采用克莱姆法则计算方程的解，效率较低。</p>
<h2 id="体积"><a href="#体积" class="headerlink" title="体积"></a>体积</h2><p><strong>矩阵 A 行列式的绝对值等于以矩阵 A 行（列）向量为边所构成的平行六面体的体积。行列式的正负对应左手系和右手系。</strong></p>
<p>如果矩阵 A 是单位矩阵，则其构成的是三个边长均为 1 且互相垂直的立方体，其体积为 1。这也是行列式的性质 1。</p>
<p>如果矩阵 A 为正交矩阵 Q，则其构成的也是三个边边长为1且三边互相垂直的立方体，其体积也为 1。</p>
<p>交换矩阵 A 中的行并不会改变其行列式的绝对值，显然也不会改变向量围成的体积，因此这也和体积理论相符。这是行列式的性质 2。</p>
<p>对于长方体，也非常直观，当你将其中一条边的边长增加 2 倍时，平行六面体的体积也会增加 2 倍，这相当于性质 3a。</p>
<p>对于性质 3b，实际上是要求体积理论摆脱角度的限制（之前几条完全都是在直角的背景下讨论得），我们可以在二维条件下简单证明。</p>
<div  align="center">  
<img src="https://s2.loli.net/2024/03/02/BXEp8ZanfyMCwsY.png" width = "40%" height = "40%" alt="图11 - 行列式性质 3b"/>
</div>

<p>从上面的二维图像可以看出来，$\,\begin{vmatrix} a + a’ &amp; b + b’ \\ c &amp; d \end{vmatrix}\,$ 对应的面积和 $\,\begin{vmatrix} a &amp; b \\ c &amp; d \end{vmatrix}\,$ 的面积与 $\,\begin{vmatrix} a’ &amp; b’ \\ c &amp; d \end{vmatrix}\,$ 的面积的和相等。高维类似。</p>
<p>有上面的启发，求过原点的三角形面积就可以用行列式求解 $\,S = 1/2\begin{vmatrix} a &amp; b \\ c &amp; d \end{vmatrix}\,$。</p>
<p>而不过原点的三角形，三个顶点为 $\,(x_1,y_1)\,$、$\,(x_2,y_2)\,$、$\,(x_3,y_3)\,$，其面积等于 $\,S = 1/2\begin{vmatrix} x_1 &amp; y_1 &amp; 1 \\ x_2 &amp; y_2 &amp; 1 \\ x_3 &amp; y_3 &amp; 1 \end{vmatrix}\,$。可以把它理解为高为 1 的体积。</p>
<h1 id="第二十一课-特征值和特征向量"><a href="#第二十一课-特征值和特征向量" class="headerlink" title="第二十一课 特征值和特征向量"></a>第二十一课 特征值和特征向量</h1><p>在这个议题下讨论的都是方阵。</p>
<h2 id="特征值和特征向量"><a href="#特征值和特征向量" class="headerlink" title="特征值和特征向量"></a>特征值和特征向量</h2><p><strong>特征值 eigenvalues</strong> 与<strong>特征向量 eigenvectors</strong> 的定义：对矩阵 A，若有 $\,Ax = \lambda x\,$，则 $\,x\,$ 为矩阵 A 的特征向量，$\,\lambda\,$ 为矩阵的特征值。</p>
<p>解特征值与特征向量的意义：对于不同的向量 x，Ax 这个式子像是一个函数，输入一个向量 x，则输出一个向量 Ax。而在我们输入的众多向量 x 生成的 Ax 中，会有这样的向量 Ax，它们平行于 x，即  $\,Ax = \lambda x\,$。</p>
<hr>
<p>①特别注意下特征值为 0 的情况，如果 0 是矩阵的特征值，则有 Ax = 0x = 0。特征值 0 所对应的向量生成了矩阵的零空间。如果矩阵 A 为不可逆矩阵，则 0 是其特征值之一。</p>
<p>②对于投影矩阵，特征值是多少。若该投影矩阵将向量投影到一个平面上，对于平面上的任意 $\,x_1\,$ 来说，投影矩阵根本不会影响它的大小，所以就有 $\,Ax_1 = x_1\,$ 恒成立，即 $\,\lambda = 1\,$。如果对垂直于平面的任意 $\,x_2\,$，投影矩阵作用在此向量之后始终会有：$\,Ax_1 = 0\,$，即 $\,\lambda = 0\,$。矩阵 A 的所有特征向量张成了整个空间，投影矩阵为对称矩阵。  </p>
<p>③矩阵 $\,A = \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix}\,$，具有特征向量 $\,x = \begin{bmatrix} 1 \\ 1 \end{bmatrix}\,$，对应特征向量为 1；另一个特征向量为 $\,x = \begin{bmatrix} 1 \\ -1 \end{bmatrix}\,$，对应的特征向量为 -1。这些特征向量张成了整个空间。因为是对称矩阵，其特征向量互相垂直。</p>
<hr>
<h2 id="特征值求解方法"><a href="#特征值求解方法" class="headerlink" title="特征值求解方法"></a>特征值求解方法</h2><p>任意 n x n 矩阵 A 具有 n 个特征值，并且它们的和等于矩阵对角线上的元素之和，这个数值为矩阵的<strong>迹 trace</strong>。对于二阶矩阵，在已知一个特征值的条件下，可以据此得到另一个特征值。</p>
<p>方程 $\,Ax = \lambda x\,$ 中特征值和特征向量均未知，没法直接求解。因此我们做如下数学处理： $\,Ax = \lambda x \rightarrow (A - \lambda I)x = 0\,$，则 $\,A - \lambda I\,$ 为奇异矩阵，因此 $\,det(A - \lambda I) = 0\,$。在这个没有 x 的方程中，可以解得 n 个特征值，但是有可能方程有重根，则会得到重复的特征值。最后利用 $\,(A - \lambda I)x = 0\,$ 求解零空间中的向量即为矩阵的特征向量。</p>
<p>【示例一】求矩阵 $\,A = \begin{bmatrix} 3 &amp; 1 \\ 1 &amp; 3 \end{bmatrix}\,$ 的特征向量与特征值：</p>
<script type="math/tex; mode=display">det(A - \lambda I) = \begin{vmatrix} 3 - \lambda & 1 \\ 1 & 3 - \lambda \end{vmatrix} = (3 - \lambda)^2 - 1 = \lambda^2 - 6 \lambda + 8</script><p>解得 $\,\lambda_1 = 2\,$，$\,\lambda_2 = 4\,$。</p>
<script type="math/tex; mode=display">(A - 4I)x_1 = \begin{bmatrix} -1 & 1 \\ 1 & -1 \end{bmatrix} x_1 = 0</script><script type="math/tex; mode=display">(A - 2I)x_1 = \begin{bmatrix} 1 & 1 \\ 1 & 1 \end{bmatrix} x_2 = 0</script><p>解得 $\,x_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}\,$，$\,x_2 = \begin{bmatrix} -1 \\ 1 \end{bmatrix}\,$。</p>
<p>我们也可以看到①特征值之和与迹相等，都为 6；②特征值之积为 A 矩阵行列式的值，都为 8。</p>
<p>【示例二】在例 1 的基础上，如果矩阵 $\,A = \begin{bmatrix} 3 &amp; 1 \\ 1 &amp; 3 \end{bmatrix} + 3I \,$，那么它的特征值、特征向量将如何变化：根据题意，改变后的方程变为 $\,(A + 3I)x = \lambda x + 3x = (\lambda + 3)x\,$，即新的特征值变为 λ + 3，而对应的特征向量不会改变。</p>
<p>需要注意的是，两个矩阵的和的特征值不是两特征值直接相加之和，因为特征向量并不相同。</p>
<h2 id="复数特征值"><a href="#复数特征值" class="headerlink" title="复数特征值"></a>复数特征值</h2><p>矩阵 $\,Q = \begin{bmatrix} 0 &amp; -1 \\ 1 &amp; 0 \end{bmatrix} = \begin{bmatrix} cos90 &amp; -sin90 \\ sin90 &amp; cos90 \end{bmatrix}\,$ 是一个 90 度旋转矩阵。从矩阵的迹和行列式的值可以得到 $\,\lambda_1 + \lambda_2 = 0\,$，$\,\lambda_1 \lambda_2 = 1\,$</p>
<p>从矩阵的性质可知它的实数特征向量只有零向量，因为其他任何向量乘以旋转矩阵，向量的方向都会发生改变。计算可得：  </p>
<script type="math/tex; mode=display">det(Q - \lambda I) = \begin{bmatrix} -\lambda & -1 \\ 1 & -\lambda \end{bmatrix} = \lambda^2 + 1 = 0</script><p>可以解得 $\,\lambda = \pm i\,$。如果一个矩阵具有复数特征值 a + bi ，则它的共轭复数 a - bi 也是矩阵的特征值。<strong>实数特征值让特征向量伸缩而虚数让其旋转</strong>。</p>
<p>对称矩阵永远具有实数的特征值，而<strong>反对称矩阵 antisymmetric matrices</strong>，即满足 $\,A^T = -A\,$ 的矩阵，具有纯虚数的特征值。</p>
<h2 id="三角阵和重特征值-Triangular-matrices-and-repeated-eigenvalues"><a href="#三角阵和重特征值-Triangular-matrices-and-repeated-eigenvalues" class="headerlink" title="三角阵和重特征值 Triangular matrices and repeated eigenvalues"></a>三角阵和重特征值 Triangular matrices and repeated eigenvalues</h2><p>对于 $\,A = \begin{bmatrix} 3 &amp; 1 \\ 0 &amp; 3 \end{bmatrix}\,$ 的三角矩阵，特征值就是矩阵对角线上的元素。</p>
<script type="math/tex; mode=display">det(A - \lambda I) = \begin{bmatrix} 3 -\lambda & 1 \\ 0 & 3 -\lambda \end{bmatrix} = (3 - \lambda)^2 = 0</script><p>可以解得 $\,\lambda = \pm 3\,$。这时的特征向量只会有一个，也就是说，三角矩阵的结构的特殊性导致了其行列式为对角线上元素，而如果对角线上两个元素相等，那么就会造成特征向量短缺情况。</p>
<h1 id="第二十二课-对角化和矩阵的幂"><a href="#第二十二课-对角化和矩阵的幂" class="headerlink" title="第二十二课 对角化和矩阵的幂"></a>第二十二课 对角化和矩阵的幂</h1><h2 id="矩阵对角化"><a href="#矩阵对角化" class="headerlink" title="矩阵对角化"></a>矩阵对角化</h2><p>矩阵对角化，即一种矩阵分解方式。如果 A 有 n 个线性无关的特征向量，那么可以将它们组成一个可逆方阵 S，进而将矩阵分解：  </p>
<p>假设 A 的 n 个线性无关的特征向量组成矩阵 S，有：</p>
<script type="math/tex; mode=display">S = \begin{bmatrix} x_1 & x_2 & \cdots & x_n \end{bmatrix}</script><p>构造：</p>
<script type="math/tex; mode=display">AS = A \begin{bmatrix} x_1 & x_2 & \cdots & x_n \end{bmatrix}</script><p>由特征值定义可得：  </p>
<script type="math/tex; mode=display">A \begin{bmatrix} x_1 & x_2 & \cdots & x_n \end{bmatrix} = \begin{bmatrix} \lambda x_1 & \lambda x_2 & \cdots & \lambda x_n \end{bmatrix}</script><p>写成矩阵乘法形式：</p>
<script type="math/tex; mode=display">\begin{bmatrix} \lambda x_1 & \lambda x_2 & \cdots & \lambda x_n \end{bmatrix} = \begin{bmatrix} x_1 & x_2 & \cdots & x_n \end{bmatrix} \begin{bmatrix} {\lambda}_1 & 0 & \cdots & 0 \\ 0 & {\lambda}_2 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & {\lambda}_n \end{bmatrix}</script><p>将由特征值组成的此对角矩阵记为 $\,\Lambda\,$，即 $\,AS = S \Lambda\,$。因为矩阵 S 中的列向量线性无关，因此逆矩阵 $\,S^{-1}\,$ 存在。在等式两侧左乘逆矩阵，得到 $\,S^{-1}AS = \Lambda\,$，同样地，$\,A = S\Lambda S^{-1}\,$。</p>
<p>对于消元法而言，矩阵有 LU 分解，对于施密特正交法，矩阵有 QR 分解，而上面的推导是一种新的矩阵分解。</p>
<blockquote>
<p>之前曾经提到过消元进行行操作和列操作最后会得到“相抵标准型”。现在我们得到的是矩阵的“相似标准形”，它还保有矩阵操作的基本性质 - 特征值，而相抵标准型只剩下最内核的秩信息还保留着。</p>
</blockquote>
<h2 id="矩阵幂运算"><a href="#矩阵幂运算" class="headerlink" title="矩阵幂运算"></a>矩阵幂运算</h2><p>特征值给矩阵的幂计算提供了方法。如果 $\,Ax = \lambda x\,$，则有 $\,A^2x = \lambda Ax = {\lambda}^2 x\,$。这说明矩阵 $\,A^2\,$ 有和 A 一样的特征向量，而特征值为 $\,{\lambda}^2\,$。写成对角化形式则有：$\,A^2 = S\Lambda S^{-1}S\Lambda S^{-1} = S {\Lambda}^2 S^{-1}\,$，同理可得：$\,A^k = S {\Lambda}^k S^{-1}\,$。这说明 $\,A^k\,$ 有着和 A 一样的特征向量，而特征值为 $\,{\lambda}^k\,$。</p>
<p>【问题】若矩阵 A 存在 n 个线性无关的特征向量，那什么条件下能使矩阵的幂：$\,A^k\,$ 趋近为零？</p>
<p>解：当所有的特征值满足：$\,|{\lambda}_i| &lt; 1\,$，则当 k 趋近于无穷大时，矩阵 $\,A^k\,$ 趋近于零。</p>
<h2 id="重特征值-Repeated-eigenvalues"><a href="#重特征值-Repeated-eigenvalues" class="headerlink" title="重特征值 Repeated eigenvalues"></a>重特征值 Repeated eigenvalues</h2><p>注意<strong>矩阵是否能够成功对角化取决于该矩阵是否有 n 个线性无关的特征向量</strong>，而特征向量与特征值之间有着紧密的联系：<br>①如果矩阵 A 没有重复的特征值，矩阵就一定有 n 个线性无关的特征向量（这也就意味着，不同特征值对应特征向量线性无关）。<br>②但是如果有重复的特征值，结论不是完全否定的，也就是说这时也可能存在 n 个线性无关的特征向量。例如：10x10 的单位矩阵，其特征值只有 1，但是事实上我们可以取得 10 个线性无关的特征向量。  </p>
<p>对于如 $\,A = \begin{bmatrix} 2 &amp; 1 \\ 0 &amp; 2 \end{bmatrix}\,$ 的三角矩阵，特征值就是矩阵对角线上的元素 2。其特征向量在 $\,A - \lambda I\,$ 的零空间中，满足 $\,(A - \lambda I)x = \begin{bmatrix} 0 &amp; 1 \\ 0 &amp; 0 \end{bmatrix} x = 0\,$。求解可得 $\,x = \begin{bmatrix} 1 \\ 0 \end{bmatrix}\,$，而没有第二个特征向量。</p>
<h2 id="差分方程-Difference-equations"><a href="#差分方程-Difference-equations" class="headerlink" title="差分方程 Difference equations"></a>差分方程 Difference equations</h2><p>从给定的一个向量 $\,u_0\,$ 出发，我们可以通过对前一项乘以矩阵 A 得到下一项的方式，得到一个向量序列：$\,u_{k+1} = Au_k\,$。</p>
<p>$\,u_{k+1} = Au_k\,$ 为一个一阶差分方程，根据递推，不难得到：$\,u_{k} = A^ku_0\,$，即方程的解，但这种简洁形式并没有给出足够的信息，我们需要通过特征向量和矩阵的幂运算给出真实解的结构。</p>
<p>因为 $\,u_0\,$ 是 n 维的，n x n 的矩阵 A 具有 n 个线性无关的特征向量，所以我们可以把 $\,u_0\,$ 写为一个由 A 的 n 个特征向量组成的线性组合，类似于基：</p>
<script type="math/tex; mode=display">u_0 = c_1x_1 + c_2x_2 + \cdots + c_nx_n</script><p>再将 A 化为特征值形式：</p>
<script type="math/tex; mode=display">u_1 = Au_0 = c_1{\lambda}_1x_1 + c_2{\lambda}_2x_2 + \cdots + c_n{\lambda}_nx_n</script><script type="math/tex; mode=display">u_k = A^ku_0 = c_1{\lambda}_1^kx_1 + c_2{\lambda}_2^kx_2 + \cdots + c_n{\lambda}_n^kx_n = S {\Lambda}^k C</script><p>其中 $\,\Lambda\,$ 是特征值构成的对角阵，S 由特征向量构成，C 即系数。</p>
<p>下面用<strong>斐波那契数列</strong>进行举例。</p>
<p>【例】 斐波那契数列 0, 1, 1, 2, 3, 5, 8, 13, …试求第 100 项的值，以及它的增长速度有多快？</p>
<p>其通项公式为 $\,F_{k+2} = F_{k+1} + F_{k}\,$，如果我们以矩阵的方式来理解数列，则矩阵的特征值可以告诉我们数列中数值的增长速度。</p>
<p>我们希望构造一阶差分，但是仅仅上面这个方程是无法构造矩阵形式的，我们添加一个方程：令 $\,u_k = \begin{bmatrix} F_{k+2} \\ F_{k+1} \end{bmatrix}\,$，则有：</p>
<script type="math/tex; mode=display">F_{k+2} = F_{k+1} + F_{k}</script><script type="math/tex; mode=display">F_{k+1} = F_{k+1}</script><p>写成矩阵形式为：</p>
<script type="math/tex; mode=display">u_{k + 1} = \begin{bmatrix} 1 & 1 \\ 1 & 0 \end{bmatrix} u_{k}</script><p>这样我们成功将一个二阶方程化为了一个一阶方程组，也就是我们上面介绍 $\,u_{k + 1} = Au_{k}\,$ 形式。</p>
<p>观察矩阵 $\,A = \begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 0 \end{bmatrix}\,$ 的特征值和特征向量，因为其为对称矩阵，特征值为实数，且特征向量正交。</p>
<script type="math/tex; mode=display">det(A - \lambda I) = \begin{vmatrix} 1 - \lambda & 1 \\ 1 & - \lambda \end{vmatrix} = {\lambda}^2 - \lambda - 1 = 0</script><p>解得 $\, {\lambda}_1 = \cfrac { 1 + \sqrt 5} {2}\,$，$\, {\lambda}_2 = \cfrac { 1 - \sqrt 5} {2}\,$，绝对值大于 1 的 $\,{\lambda}_1\,$ 控制着在斐波那契数列的增长。</p>
<p>根据上面的介绍，$\,u_k = A^ku_0 = c_1{\lambda}_1^kx_1 + c_2{\lambda}_2^kx_2 + \cdots + c_n{\lambda}_n^kx_n\,$，而对于裴波那契数列来说，n = 2，有：$\,u_k = c_1{\lambda}_1^kx_1 + c_2{\lambda}_2^kx_2\,$。而 $\,{\lambda}_2\,$ 比 1 小，后一项趋于 0，所以影响数列变化的只剩下了 $\,{\lambda}_1\,$。</p>
<p>从特征值可以求得对应的特征向量 $\,x_1 = \begin{bmatrix} {\lambda}_1 \\ 1 \end{bmatrix}\,$ 和 $\,x_2 = \begin{bmatrix} {\lambda}_2 \\ 1 \end{bmatrix}\,$。</p>
<p>从 $\,u_0 = \begin{bmatrix} F_1 \\ F_0 \end{bmatrix} = \begin{bmatrix} 1 \\ 0 \end{bmatrix} = c_1x_1 + c_2x_2\,$，可以求得 $\,c_1 = \cfrac {1} {\sqrt {5}}\,$，$\,c_2 = -\cfrac {1} {\sqrt {5}}\,$。</p>
<script type="math/tex; mode=display">\begin{bmatrix} F_{100} \\ F_{99}\end{bmatrix} = A^{99} \begin{bmatrix} F_{1} \\ F_{0} \end{bmatrix} = \begin{bmatrix} {\lambda}_{1} & {\lambda}_{2} \\ 1 & 1 \end{bmatrix} \begin{bmatrix} {\lambda}_{1}^{99} & 0 \\ 0 & {\lambda}_{2}^{99} \end{bmatrix} \begin{bmatrix} c_{1} \\ c_{2} \end{bmatrix} = \begin{bmatrix} c_1{\lambda}_{1}^{100} & c_2{\lambda}_{2}^{100} \\ c_1{\lambda}_{1}^{99} & c_2{\lambda}_{2}^{99} \end{bmatrix}</script><p>可知：$\, F_{100} \approx c_1{\lambda}_{1}^{100}\,$</p>
<blockquote>
<p>特征值特征向量可以把矩阵的操作变成一个简单的参数，在物理中出现非常频繁。可以有如下理解：物理中常见的被研究物体都有一个自身的内禀结构，这个内在结构的方向往往和观察者也就是外场的坐标有区别。当我们给物体施加一个外场刺激的时候，比如说外力或者电场极化等等，物体沿着其内在结构的取向来响应外场，但是观察者从外场坐标下采集反馈。实际上矩阵在不同坐标之间实现变换，特征向量显示了物体内结构的方向，特征值则是在这个主方向上物体对外场的响应参数。在有的领域直接将特征值称为<strong>伸缩系数</strong>，实际上它反应了在其所对应的特征向量方向上，内结构与外场之间的相互关系。特征值还有一个应用是作为降维的判据，比如在<strong>图像压缩</strong>过程中，极小的特征值会被赋值为0，以此节省存储空间，也便于其它操作。反应在图像上，降维后的图像基本轮廓依旧清晰，图像细节有所牺牲。</p>
</blockquote>
<h1 id="第二十三课-微分方程和矩阵指数"><a href="#第二十三课-微分方程和矩阵指数" class="headerlink" title="第二十三课 微分方程和矩阵指数"></a>第二十三课 微分方程和矩阵指数</h1><p>本节介绍一阶线性常微分方程的矩阵解法，也就是将微分方程用矩阵抽象，通过“解耦”，计算出对应系数，最终得到解。这里会牵涉到 $\,e^{Ax}\,$，所以也会引出幂指数是矩阵时算式的计算问题。最后扩展介绍了高阶微分方程的降阶求解方法。 </p>
<h2 id="微分方程-Differential-equations"><a href="#微分方程-Differential-equations" class="headerlink" title="微分方程 Differential equations"></a>微分方程 Differential equations</h2><p>【例 1】</p>
<script type="math/tex; mode=display">\cfrac {du_1} {dt} = -u_1 + 2u_2</script><script type="math/tex; mode=display">\cfrac {du_2} {dt} = u_1 - 2u_2</script><p>初值条件 $\,u(0) = \begin{bmatrix} 1 \\ 0 \end{bmatrix}\,$，求 $\,u(t)\,$。</p>
<p>【解题流程】<br>解题之前首先要搞清楚这个微分方程的意义，u(0) 表明就是说明在最初 0 时刻，$\,u_1 = 1\,$，所有的值都在 $\,u_1\,$ 中；而此时 $\,u_2 = 0\,$，但是随着时间流逝，t 增加时，我们可以看到 $\,\cfrac {du_2} {dt} &gt; 0\,$。说明 $\,u_2\,$ 的导数大于 0，$\,u_2\,$ 会慢慢增加，$\,u_1\,$ 会慢慢减少。最终达到某一状态，这需要我们计算来得到。</p>
<p>列出方程 $\,\cfrac {du} {dt} = Au\,$，其中系数矩阵 A 综合了 $\,\cfrac {du_1} {dt}\,$ 与 $\,\cfrac {du_2} {dt}\,$，写作 $\,\begin{bmatrix} -1 &amp; 2 \\ 1 &amp; -2 \end{bmatrix}\,$</p>
<p>该矩阵 A 为奇异矩阵，因此存在一个特征值 $\,{\lambda}_1 = 0\,$，而矩阵的迹为 -3，因此还有一个特征值为 $\,{\lambda}_2 = -3\,$。特征向量为 $\,x_1 = \begin{bmatrix} 2 \\ 1 \end{bmatrix}\,$，$\,x_2 = \begin{bmatrix} 1 \\ -1 \end{bmatrix}\,$，</p>
<hr>
<p>我们先给出微分方程的矩阵解法的通解形式：</p>
<script type="math/tex; mode=display">\sum_{i = 0}^n C_i e^{\lambda_i t} x_i</script><p>通解形式是如何得到的这里不做研究。具体验证可以将通解看做几个纯指数解的组合，随便挑一个代入验证一下即可。</p>
<p>将矩阵 A 的特征值与特征向量，代入通解得到其形式如下：  </p>
<script type="math/tex; mode=display">u(t) = C_1e^{0t} \begin{bmatrix} 2 \\ 1 \end{bmatrix} + C_2e^{-3t} \begin{bmatrix} 1 \\ -1 \end{bmatrix}</script><p>代入初值 $\,u(0) = \begin{bmatrix} 1 \\ 0 \end{bmatrix}\,$，可以解得 $\,C_1 = C_2 = 1/3\,$，最终解：</p>
<script type="math/tex; mode=display">u(t) = \cfrac {1} {3} e^{0t} \begin{bmatrix} 2 \\ 1 \end{bmatrix} + \cfrac {1} {3}e^{-3t} \begin{bmatrix} 1 \\ -1 \end{bmatrix}</script><p>可以看出前一项为稳态状态，后一项随着时间衰减，最后趋于 0。</p>
<hr>
<p>通过这道题，我们可以得到解决微分方程过程中遇到的某些特点：</p>
<p>稳定性：并不是所有的系统都会达到稳态，矩阵的特征值会告诉我们 u(t) 的发展趋势。<br>①特征值是负数时，u(t)趋于 0。支配稳定性的是实部，虚部的作用是在单位圆上转圈。<br>②稳态存在时（如【例 1】中最后 t 趋于无穷时，u 趋于一个确数），一个<br>特征向量 = 0，其余的特征向量全部 &lt; 0。<br>③如果有任何特征值实数部分 &gt; 0，则解无法收敛。</p>
<h2 id="解耦"><a href="#解耦" class="headerlink" title="解耦"></a>解耦</h2><p>特征值和特征向量的作用是解耦，又称对角化，回到原来的方程 $\,\cfrac {du} {dt} = Au\,$，矩阵 A 使得 $\,u_1\,$，$\,u_2\,$ 之间相互耦合，令 $\,u = Sv\,$，其中 S 表示特征向量，v 表示特征向量用于线性组合的与 t 相关的项，抄写一下，方便理解：  </p>
<script type="math/tex; mode=display">u(t) = C_1 e^{\lambda_1 t} X_1 + C_2 e^{\lambda_2 t} X_2 = \begin{bmatrix} X_1 & X_2 \end{bmatrix} \begin{bmatrix} C_1 e^{\lambda_1 t} \\ C_2 e^{\lambda_2 t} \end{bmatrix} = Sv</script><p>回到方程 $\,\cfrac {du} {dt} = Au\,$：</p>
<script type="math/tex; mode=display">\cfrac {du} {dt} = \cfrac {d(Sv)} {dt} = ASv</script><script type="math/tex; mode=display">S \cfrac {dv} {dt} = ASv</script><script type="math/tex; mode=display">\cfrac {dv} {dt} = S^{-1}ASv = \Lambda v</script><p>这样的方式就相当于对原方程进行了解耦：</p>
<p>其中 $\,\cfrac {dv} {dt} = \begin{bmatrix} \lambda_1 C_1 e^{\lambda_1 t} \\ \lambda_2 C_2 e^{\lambda_2 t} \end{bmatrix} = \begin{bmatrix} \lambda_1 &amp; 0 \\ 0 &amp; \lambda_2 \end{bmatrix} \begin{bmatrix} C_1 e^{\lambda_1 t} \\ C_2 e^{\lambda_2 t} \end{bmatrix} = \Lambda v\,$</p>
<p>$\,\cfrac {dv} {dt}\,$ 中的每一项 $\,\cfrac {dv_i} {dt} = \lambda_i v_i = \lambda_i c_i e^{\lambda_i t} \,$，而原方程是耦合的</p>
<p>可得：  </p>
<script type="math/tex; mode=display">v(t) = \begin{bmatrix} c_1e^{\lambda_1t} \\ c_2e^{\lambda_2t} \end{bmatrix} = \begin{bmatrix} e^{\lambda_1t} & 0 \\ 0 & e^{\lambda_2t} \end{bmatrix} \begin{bmatrix} c_1 \\ c_2 \end{bmatrix} = e^{\Lambda t}v_0</script><p>于是 u(t) 通解还可以写成下面的形式：</p>
<script type="math/tex; mode=display">u(t) = Sv(t) = Se^{\Lambda t}S^{-1}u(0) = e^{A t} u(0)</script><h2 id="矩阵指数函数-e-At"><a href="#矩阵指数函数-e-At" class="headerlink" title="矩阵指数函数$\,e^{At}\,$"></a>矩阵指数函数$\,e^{At}\,$</h2><p>我们知道：</p>
<script type="math/tex; mode=display">e^x = 1 + x + \cfrac {x^2} {2!} + \cfrac {x^3} {3!} + \cfrac {x^4} {4!} + \cdots + \cfrac {x^n} {n!}</script><p>我们可以用上述幂级数的公式来定义矩阵型指数运算：  </p>
<script type="math/tex; mode=display">e^A = 1 + A + \cfrac {A^2} {2!} + \cfrac {A^3} {3!} + \cfrac {A^4} {4!} + \cdots + \cfrac {A^n} {n!}</script><script type="math/tex; mode=display">\begin{align*} e^At &= 1 + At + \cfrac {(At)^2} {2!} + \cfrac {(At)^3} {3!} + \cfrac {(At)^4} {4!} + \cdots + \cfrac {(At)^n} {n!} \\ &= SS^{-1}I + S \Lambda S^{-1}t + \cfrac {(S \Lambda S^{-1}t)^2} {2!} + \cfrac {(S \Lambda S^{-1}t)^3} {3!} + \cfrac {(S \Lambda S^{-1}t)^4} {4!} + \cdots + \cfrac {(S \Lambda S^{-1}t)^n} {n!} \\ &= SS^{-1}I + S \Lambda S^{-1}t + \cfrac {S \Lambda^2 S^{-1}t^2} {2!} + \cfrac {S \Lambda^3 S^{-1}t^3} {3!} + \cfrac {S \Lambda^4 S^{-1}t^4} {4!} + \cdots + \cfrac {S \Lambda^n S^{-1}t^n} {n!} \\ &= S(I + \Lambda t + \cfrac {\Lambda^2 t^2} {2!} + \cfrac {\Lambda^3 t^3} {3!} + \cfrac {\Lambda^4 t^4} {4!} + \cdots + \cfrac {\Lambda^n t^n} {n!}) S^{-1} \\ &= Se^{\Lambda t}S^{-1} \end{align*}</script><p>注意：这步的化简是有条件的，即 A 必须可以对角化，即有 n 个独立的特征向量，S 可逆。</p>
<p>上面的等式将对角矩阵与一般矩阵联系了起来，其中 $\,e^{\Lambda t}\,$ 即如下：  </p>
<script type="math/tex; mode=display">\begin{bmatrix} e^{\lambda_1t} & 0 & \cdots & 0 \\ 0 & e^{\lambda_2t} & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & e^{\lambda_n t} \end{bmatrix}</script><h2 id="二阶微分方程"><a href="#二阶微分方程" class="headerlink" title="二阶微分方程"></a>二阶微分方程</h2><p>解二阶微分方程时，我们可以将它降阶处理，转化为 2x2 的一阶问题进行处理，构造方法类似于我们对斐波那契数列的处理方法。</p>
<p>比如二阶微分方程：$\,y’’ + by’ + ky = 0\,$</p>
<p>令 $\,u = \begin{bmatrix} y’ \\ y \end{bmatrix}\,$，则：</p>
<script type="math/tex; mode=display">u' = \begin{bmatrix} y'' \\ y' \end{bmatrix} = \begin{bmatrix} -b & -k \\ 1 & 0 \end{bmatrix} \begin{bmatrix} y' \\ y \end{bmatrix}</script><p>如果是 n 阶微分方程，那么需要一个 n × n 矩阵，除了第一行和对角线下面一排斜线上的元素之外，这个系数矩阵其它元素均为 0，此时特征值和特征向量就会自动出现。</p>
<p>类似于：  </p>
<script type="math/tex; mode=display">\begin{bmatrix} a & b & c & d & e \\ 1 & 0 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 & 0 \\ 0 & 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 1 & 0 \end{bmatrix}</script><p>这样的矩阵将 n 阶微分方程转化为一阶向量方程。接下来只要使用一阶微分方程正常求解就可以了。</p>
<h1 id="第二十四课-马尔可夫矩阵和傅里叶级数"><a href="#第二十四课-马尔可夫矩阵和傅里叶级数" class="headerlink" title="第二十四课 马尔可夫矩阵和傅里叶级数"></a>第二十四课 马尔可夫矩阵和傅里叶级数</h1><p>本节介绍马尔可夫矩阵和傅里叶级数，两者是关于特征值和投影矩阵的应用。</p>
<h2 id="马尔科夫矩阵"><a href="#马尔科夫矩阵" class="headerlink" title="马尔科夫矩阵"></a>马尔科夫矩阵</h2><script type="math/tex; mode=display">A = \begin{bmatrix} 0.1 & 0.01 & 0.3 \\ 0.2 & 0.99 & 0.3 \\ 0.7 & 0 & 0.4 \end{bmatrix}</script><p>马尔科夫矩阵要满足两条性质：①每个元素均为非负数；②每列的元素和为 1。马尔可夫矩阵主要应用在概率领域。将一个马尔可夫矩阵进行方幂运算得到的矩阵仍旧是马尔可夫矩阵。</p>
<p>当处理一个微分方程问题时，特征值 0 意味着得到一个稳态。当进行矩阵的方幂运算时，特征值给出稳态的条件包括：<br>①$\,\lambda_1 = 1\,$ 是特征值之一；<br>②其它特征值的绝对值都比 1 小，$\,|\lambda_i| \lt 1\,$。</p>
<p>证明性质①：上面的例子代入 $\,\lambda = 1\,$，得到 $\, A - 1I= \begin{bmatrix} -0.9 &amp; 0.01 &amp; 0.3 \\ 0.2 &amp; -0.01 &amp; 0.3 \\ 0.7 &amp; 0 &amp; -0.6 \end{bmatrix} \,$，每一列元素之和为 0，这时候行向量相加的结构就是 0 向量，因此行向量线性相关，矩阵为奇异矩阵。矩阵 A 有特征向量在 A-I 的零空间中，其对应的特征值为 1。可以说<strong>每列的元素和为 1 这个性质决定了其有特征值 1 这个性质</strong>。</p>
<p>判断次幂运算的收敛性：之前差分方程中我们接触过 $\, u_k = A^ku_0 = c_1{\lambda}_1^kx_1 + c_2{\lambda}_2^kx_2 + \cdots + c_n{\lambda}_n^kx_n \,$，可以看做矩阵次幂运算的问题。根据马尔科夫矩阵的特点，$\,\lambda_1 = 1\,$，其余 $\,|\lambda_i| \lt 1\,$，所以最后次幂运算会收敛于 $\,u_0\,$ 中的 $\,c_1x_1\,$ 部分，这就是其稳态性质：马尔科夫矩阵中，若其特征值 1 所对应的特征向量的元素全为正，则初始值 $\,u_0\,$ 是正的，那么稳态也是正值。</p>
<hr>
<p>对转置矩阵特征值的补充：由之前介绍过的行列式性质十，转置矩阵与原矩阵行列式值相同，具体这里应用到 A-λi 这个方程上，得到：$\,|A- \lambda i| = |(A- \lambda i)^T| = |A^T - \lambda i|\,$。即 $\,|A- \lambda i| = 0\,$ 时，$\,|A^T - \lambda i|\,$ 也是 0，它们的特征值是一样的，但是它们的特征向量并不一样，因为根本不属于 A 的同一个空间中。</p>
<h2 id="马尔科夫矩阵的应用"><a href="#马尔科夫矩阵的应用" class="headerlink" title="马尔科夫矩阵的应用"></a>马尔科夫矩阵的应用</h2><p>我们用马尔可夫矩阵来研究加州和麻省的人口流动问题，矩阵 A 表示，一年后发生了人口的迁移。矩阵的四个元素相应表示的是留下和迁出的概率，在这个过程中总人口数保持不变。这里有个严格的限制：那就是马尔科夫矩阵不变（即每次变动的概率一样）。</p>
<script type="math/tex; mode=display">\begin{bmatrix} u_{Cal} \\ u_{Mass} \end{bmatrix}_{t = k + 1} = \begin{bmatrix} .9 & .2 \\ .1 & .8 \end{bmatrix} \begin{bmatrix} u_{Cal} \\ u_{Mass} \end{bmatrix}_{t = k}</script><p>方程中 u 的分量分别代表加利福尼亚州和马萨诸塞州的人口，矩阵中的每一列中元素代表着人口去留比例，比如第一列 0.9 表示留在加州的人口占加州人口的 90%，而 10% 进入麻省，第二列中由麻省进入加州的人口占麻省的 20%，而 80% 选择留在麻省。</p>
<p>假定初始状态为：</p>
<script type="math/tex; mode=display">\begin{bmatrix} u_{Cal} \\ u_{Mass} \end{bmatrix}_0 = \begin{bmatrix} 0 \\ 1000 \end{bmatrix}</script><p>则经过一次迁徙：</p>
<script type="math/tex; mode=display">\begin{bmatrix} u_{Cal} \\ u_{Mass} \end{bmatrix}_1 = \begin{bmatrix} .9 & .2 \\ .1 & .8 \end{bmatrix} \begin{bmatrix} 0 \\ 1000 \end{bmatrix} = \begin{bmatrix} 200 \\ 800 \end{bmatrix}</script><p>计算该马尔科夫矩阵特征值为 1 和 0.7。对应特征向量为 $\,\begin{bmatrix} 2 \\ 1 \end{bmatrix}\,$，$\,\begin{bmatrix} -1 \\ 1 \end{bmatrix}\,$。通解为：</p>
<script type="math/tex; mode=display">u_k = c_1 \begin{bmatrix} 2 \\ 1 \end{bmatrix} + c_2 (0.7)^k \begin{bmatrix} -1 \\ 1 \end{bmatrix}</script><p>只有 $\,\begin{bmatrix} 2 \\ 1 \end{bmatrix}\,$ 会反映最后稳态时的人口分布状况。</p>
<h2 id="傅里叶级数"><a href="#傅里叶级数" class="headerlink" title="傅里叶级数"></a>傅里叶级数</h2><h3 id="前提基础"><a href="#前提基础" class="headerlink" title="前提基础"></a>前提基础</h3><p>假定有一组 n 个标准正交向量 $\,q_1, q_2, \cdots, q_n\,$，它们是 n 维空间一组完整基。那么此空间中，任意向量 v 可由这组基的线性组合表示：  </p>
<script type="math/tex; mode=display">v = x_1q_1 + x_2q_2 + \cdots + x_nq_n</script><p>即 $\, v = Qx \,$ -&gt; $\, x = Q^{-1}v \,$</p>
<p>由于 Q 是正交阵，之前介绍过有 $\,Q^{-1} = Q^T\,$，即 $\, x = Q^{T}v \,$。则分量公式为 $\,x_i = q_i^T v\,$。</p>
<h3 id="傅里叶级数-1"><a href="#傅里叶级数-1" class="headerlink" title="傅里叶级数"></a>傅里叶级数</h3><p>傅里叶级数也是在上面的标准正交的概念上构建的。我们可以对任意函数做傅里叶展开，得到表达式：  </p>
<script type="math/tex; mode=display">f(x) = a_0 + a_1cosx + b_1sinx + a_2cos2x + b_2sin2x + \cdots</script><p>傅里叶级数作用在函数空间上，用函数 f(x) 来代替向量 v，也就是使用正交函数来代替原本上面介绍的标准正交基，与之前的有限个标准正交向量组成的正交矩阵不同，这个空间是无限维，它的一组基是 1，cosx，sinx，cos2x，sin2x……。而傅里叶级数成立的原因即是：这些基是正交的。</p>
<p>①函数空间下的“正交”：<br>我们知道，对于向量的点积为：  </p>
<script type="math/tex; mode=display">v^Tw = v_1w_1 + \cdots + v_nw_n</script><p>在这里，向量可以看做是离散的，但是上面给出的函数，它们在其定义域上是连续的，那么对于两个连续函数而言，其内积是什么？对比上面的向量内积的形式，对于函数而言，与之最相似的情况就是在每个 x 值上的 f(x)·g(x)，而连续情况对应的就是对其进行积分：  </p>
<script type="math/tex; mode=display">f^Tg = \int_0^{2 \pi} f(x)g(x) dx</script><p>计算基 sinx 和 cosx 的点积可以验证其正交性：</p>
<script type="math/tex; mode=display">\int_0^{2 \pi} sinx cosx dx = \frac {1} {2}(sin2x)^2 |^{2 \pi}_0 = 0</script><p>接下来解决系数的求解问题，以 $\,a_1\,$ 为例，与之前讲过的向量求解是类似的，利用正交基，直接将向量与正交基点乘来求各分量，这里将函数 f（x）与 cosx 作内积，所以就可以得到：</p>
<script type="math/tex; mode=display">\begin{align*} \int_0^{2 \pi} f(x) cosx dx &= \int_0^{2 \pi} (a_0 + a_1cosx + b_1sinx + a_2cos2x + b_2sin2x + \cdots)cosx dx \\ &= 0 + \int_0^{2 \pi} a_1 cos^2x dx+ 0 + 0 + \cdots \\ &= a_1 \pi \end{align*}</script><p>可以得到 $\,a_1 = \frac {1} {\pi} \int_0^{2\pi} f(x) cosx dx\,$，同理可以求得其它参数。</p>
<h1 id="第二十五课-复习二"><a href="#第二十五课-复习二" class="headerlink" title="第二十五课 复习二"></a>第二十五课 复习二</h1><h2 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h2><p><strong>【例一】</strong>：$\,a = \begin{bmatrix} 2 \\ 1 \\ 2 \end{bmatrix}\,$<br>①求投影到向量 a 方向的投影矩阵 P。</p>
<p>解：$\,P = A(A^TA)^{-1}A^T\,$，这里 a 是向量，因此 $\,P = \cfrac {aa^T} {a^Ta} = \cfrac {1} {9} \begin{bmatrix} 4 &amp; 2 &amp; 4 \\ 2 &amp; 1 &amp; 2 \\ 4 &amp; 2 &amp; 4 \end{bmatrix}\,$</p>
<p>②求矩阵 P 的秩、特征值、特征向量。</p>
<p>解：P 显然是一个不可逆矩阵，第一列，第三列均是第二列的两倍。所以这个矩阵 P 秩为 1，列空间为 1 维。矩阵的秩为 1，因此存在重特征值 0，再从矩阵的迹可以得到另一个特征值为 1。因为矩阵 P 为投影矩阵，在投影空间中的向量就是对应特征值 1 的特征向量，因此 a 就是对应的特征向量。</p>
<p>③将矩阵 P 引入差分方程：若有 $\,u_{k + 1} = Pu_k\,$，且有初值 $\,u_0 = \begin{bmatrix} 9 \\ 9 \\ 0 \end{bmatrix}\,$，求 $\,u_k\,$。</p>
<p>解：重复将一个向量投影到一条直线，从第二次开始投影结果即不发生变化，即：  </p>
<script type="math/tex; mode=display">u_{k + 1} = P^ku_0 = Pu_0 =  a \cfrac {a^Tu_0} {a^Ta} = 3a = \begin{bmatrix} 6 \\ 3 \\ 6 \end{bmatrix}</script><p>若 P 矩阵不是投影矩阵时，我们是使用特征值特征向量展开来求解的：</p>
<script type="math/tex; mode=display">u_0 = c_1x_1 + c_2x_2 + \cdots +  c_nx_n</script><script type="math/tex; mode=display">u_k = A^ku_0 = c_1\lambda_1^kx_1 + c_2\lambda_2^kx_2 + \cdots +  c_n\lambda_n^kx_n</script><p>对于投影矩阵而言，$\,\lambda_1 = 1, \lambda_2 = \lambda_3 = 0\,$</p>
<p><strong>【例二】</strong>：给定一组点（1, 4）（2, 5）（3, 8），尝试将其拟合到一条过原点的直线上：</p>
<p>解：先设直线 y = Dt，即 $\,\begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}D = \begin{bmatrix} 4 \\ 5 \\ 8 \end{bmatrix}\,$，我们求解的问题就是求方程的最优解 $\,\hat D\,$。$\,A^TA\hat D = A^Tb\,$。</p>
<p>解得 $\,\hat D = 19/7\,$。</p>
<p><strong>【例三】</strong>：向量 $\,a_1 = \begin{bmatrix} 1 \\ 2 \\ 3 \end{bmatrix}\,$ 和 $\,a_2 = \begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix}\,$ 确定了一个平面，找到该平面的一组正交基。</p>
<p>解：应用 Gram-Shmidt 正交化方法。取 $\,a_1\,$ 为第一个方向，找出垂直于该方向的向量  B。策略就是在 $\,a_2\,$ 中减掉它在 $\,a_1\,$ 方向上的分量，得到完全垂直于 $\,a_1\,$ 的部分：</p>
<script type="math/tex; mode=display">B = a_2 - \cfrac {a_1^Ta_2} {a_1^Ta_1} a_1 = \begin{bmatrix} 4/7 \\ 1/7 \\ -2/7 \end{bmatrix}</script><p><strong>【例四】</strong>：已知一个 4 阶方阵 A 具有特征值 $\,\lambda_1, \lambda_2, \lambda_3, \lambda_4\,$<br>①特征值需要满足什么条件才能保证 A 为可逆矩阵。</p>
<p>当且仅当矩阵的特征值均不为 0 的时候，A 为可逆矩阵。若有特征值 0 存在，则矩阵零空间有非零向量，矩阵不可逆。</p>
<p>②求逆矩阵行列式的值。</p>
<p>根据 $\,|A||A^{-1}| = 1\,$ 以及特征值之积为 A 矩阵行列式的值这两个定理，可知：</p>
<script type="math/tex; mode=display">|A^{-1}| = \cfrac {1} {\lambda_1\lambda_2\lambda_3\lambda_4}</script><p>③求 A+I 的迹。</p>
<p>矩阵的迹等于其特征值的和，A+I 的特征值为 $\,\lambda_1 + 1,\lambda_2 + 1,\lambda_3 + 1,\lambda_4 + 1\,$，则该矩阵的迹为 $\,\lambda_1 + \lambda_2 + \lambda_3 + \lambda_4 + 4\,$。</p>
<p><strong>【例五】</strong>：已知三对角矩阵：$\,A_4 = \begin{bmatrix} 1 &amp; 1 &amp; 0 &amp; 0 \\ 1 &amp; 1 &amp; 1 &amp; 0 \\ 0 &amp; 1 &amp; 1 &amp; 1 \\ 0 &amp; 0 &amp; 1 &amp; 1 \end{bmatrix}\,$，求 $\,A_n\,$ 的行列式 $\,D_n\,$。</p>
<p>利用代数余子式的知识，类比于此类矩阵在四阶时的特征，不难得到：$\,D_n = D_{n - 1} - D_{n - 2}\,$。</p>
<p>按照递归方程构造 2 阶线性方程：$\,\begin{bmatrix} D_n \\ D_{n-1} \end{bmatrix} = \begin{bmatrix} 1 &amp; -1 \\ 1 &amp; 0 \end{bmatrix} \begin{bmatrix} D_{n-1} \\ D_{n-2} \end{bmatrix}\,$，求解矩阵的特征值可得：$\,\lambda = \cfrac {1 \pm \sqrt 3 i} {2}\,$，这两个特征值，发现其模均为 1，在复平面上表示位于单位圆上的两个点。</p>
<p>由欧拉公式：$\,e^{i\theta} = cos\theta + isin\theta\,$，还可以求得特征值为 $\,e^{\cfrac {\pi} {3} i}\,$、$\,e^{\cfrac {-\pi} {3} i}\,$</p>
<p>可以看到 $\,\lambda_1^6 = \lambda_2^6 = 1\,$，矩阵经六次变换变为单位阵。该序列既不发散也不收敛，数列以 6 次为重复周期不停循环，1, 0, -1, 0, 1, 1。</p>
<p><strong>【例六】</strong>：有一组对称矩阵：  </p>
<script type="math/tex; mode=display">A_2 = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix}, A_3 = \begin{bmatrix} 0 & 1 & 0 \\ 1 & 0 & 2 \\ 0 & 2 & 0 \end{bmatrix}, A_4 = \begin{bmatrix} 0 & 1 & 0 & 0 \\ 1 & 0 & 2 & 0 \\ 0 & 2 & 0 & 3 \\ 0 & 0 & 3 & 0 \end{bmatrix}</script><p>①找到投影到矩阵 $\,A_3\,$ 列空间的投影矩阵 P：  </p>
<p>解：矩阵 $\,A_3\,$ 为奇异阵，其第 3 列列向量为第 1 列的 3 倍，而第 1, 2 列线性无关，因此其列空间为一个平面，取其前两列列向量组成矩阵 A，则有 $\,P = A(A^TA)^{-1}A^T = \begin{bmatrix} 1/5 &amp; 0 &amp; 2/5 \\ 0 &amp; 1 &amp; 0 \\ 2/5 &amp; 0 &amp; 4/5 \end{bmatrix}\,$。可以通过将矩阵 $\,A_3\,$ 的列向量乘以投影矩阵来验证这一结果，在平面内的向量投影后应该不发生变化。</p>
<p>②求 $\,A_3\,$ 的特征值和特征向量。  </p>
<script type="math/tex; mode=display">det(A_3 - \lambda I) = \begin{vmatrix} -\lambda & 1 & 0 \\ 1 & -\lambda & 2 \\ 0 & 2 & -\lambda \end{vmatrix} = -\lambda^3 + 5\lambda = 0</script><p>解得三个特征值，$\,\lambda_1 = 0, \lambda_2 = \sqrt 5, \lambda_3 = -\sqrt 5\,$。特征向量 $\, x_1 = \begin{bmatrix} -2 \\ 0 \\ 1 \end{bmatrix}\,$，$\, x_2 = \begin{bmatrix} 1 \\ - \sqrt 5 \\ 2 \end{bmatrix}\,$，$\, x_3 = \begin{bmatrix} 1 \\ \sqrt 5 \\ 2 \end{bmatrix}\,$</p>
<p>③求投影到 $\,A_4\,$ 列空间的投影矩阵。<br>因为 $\,A_4\,$ 为可逆矩阵，所以它的列空间就是整个 R(4) 空间，其投影矩阵即为单位阵 I，因为投向 R(4) 空间不影响向量本身。可逆矩阵的证明可以采用求行列式的办法，用代数余子式展开可得 $\,det(A_4) = 9\,$。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://ybniaobu.github.io">鸟布</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://ybniaobu.github.io/2024/02/18/2024-02-18-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%802/">https://ybniaobu.github.io/2024/02/18/2024-02-18-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%802/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://ybniaobu.github.io" target="_blank">鸟布的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/">游戏开发</a><a class="post-meta__tags" href="/tags/%E6%95%B0%E5%AD%A6/">数学</a><a class="post-meta__tags" href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">线性代数</a></div><div class="post_share"><div class="social-share" data-image="https://s2.loli.net/2024/02/18/6rKVn5pm3sXlxS8.gif" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/images/wechat.png" target="_blank"><img class="post-qr-code-img" src="/images/wechat.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/images/alipay.png" target="_blank"><img class="post-qr-code-img" src="/images/alipay.png" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/02/22/2024-02-22-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%803/" title="MIT 线性代数公开课笔记（三）"><img class="cover" src="https://s2.loli.net/2024/02/18/NjAQJ5diwBHTKzc.gif" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">MIT 线性代数公开课笔记（三）</div></div></a></div><div class="next-post pull-right"><a href="/2024/02/05/2024-02-05-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%801/" title="MIT 线性代数公开课笔记（一）"><img class="cover" src="https://s2.loli.net/2024/03/20/wpVnygJlIjor2Rb.gif" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">MIT 线性代数公开课笔记（一）</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/02/05/2024-02-05-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%801/" title="MIT 线性代数公开课笔记（一）"><img class="cover" src="https://s2.loli.net/2024/03/20/wpVnygJlIjor2Rb.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-05</div><div class="title">MIT 线性代数公开课笔记（一）</div></div></a></div><div><a href="/2024/02/22/2024-02-22-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%803/" title="MIT 线性代数公开课笔记（三）"><img class="cover" src="https://s2.loli.net/2024/02/18/NjAQJ5diwBHTKzc.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-22</div><div class="title">MIT 线性代数公开课笔记（三）</div></div></a></div><div><a href="/2023/10/13/2023-10-13-UnityShader2/" title="《Unity Shader入门精要》读书笔记（二）"><img class="cover" src="https://s2.loli.net/2023/10/15/RZftaNSscWoLH1u.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-13</div><div class="title">《Unity Shader入门精要》读书笔记（二）</div></div></a></div><div><a href="/2023/11/22/2023-11-22-UnityShader3/" title="《Unity Shader入门精要》读书笔记（三）"><img class="cover" src="https://s2.loli.net/2023/11/23/L3ts4WnThMlDN9d.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-22</div><div class="title">《Unity Shader入门精要》读书笔记（三）</div></div></a></div><div><a href="/2023/07/09/2023-07-09-Unity%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%9D%82%E8%AE%B0/" title="Unity基础"><img class="cover" src="https://s2.loli.net/2023/09/19/zXfAWqLZlxQwdU1.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-07-09</div><div class="title">Unity基础</div></div></a></div><div><a href="/2023/12/30/2023-12-30-UnityShader5/" title="《Unity Shader入门精要》读书笔记（五）"><img class="cover" src="https://s2.loli.net/2023/12/30/hc2s7BS45l1wUdQ.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-12-30</div><div class="title">《Unity Shader入门精要》读书笔记（五）</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/images/wechat%20avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">鸟布</div><div class="author-info__description">教练，我想学技术</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">29</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://niaobu.notion.site/787824630ea6480e944c1ae5ae7f4792"><i class="fa-solid fa-book"></i><span>My Notion</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ybniaobu/ybniaobu.github.io" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:niaobubob@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">为了蒂法！！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%8D%81%E5%9B%9B%E8%AF%BE-%E6%AD%A3%E4%BA%A4%E5%90%91%E9%87%8F%E4%B8%8E%E6%AD%A3%E4%BA%A4%E5%AD%90%E7%A9%BA%E9%97%B4"><span class="toc-number">1.</span> <span class="toc-text">第十四课 正交向量与正交子空间</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%91%E9%87%8F%E6%AD%A3%E4%BA%A4"><span class="toc-number">1.1.</span> <span class="toc-text">向量正交</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%90%E7%A9%BA%E9%97%B4%E6%AD%A3%E4%BA%A4"><span class="toc-number">1.2.</span> <span class="toc-text">子空间正交</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%B6%E7%A9%BA%E9%97%B4%E4%B8%8E%E8%A1%8C%E7%A9%BA%E9%97%B4%E7%9A%84%E6%AD%A3%E4%BA%A4%E5%85%B3%E7%B3%BB"><span class="toc-number">1.3.</span> <span class="toc-text">零空间与行空间的正交关系</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%97%A0%E8%A7%A3%E6%96%B9%E7%A8%8B%E7%9A%84%E6%9C%80%E4%BC%98%E8%A7%A3"><span class="toc-number">1.4.</span> <span class="toc-text">无解方程的最优解</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%8D%81%E4%BA%94%E8%AF%BE-%E5%AD%90%E7%A9%BA%E9%97%B4%E6%8A%95%E5%BD%B1"><span class="toc-number">2.</span> <span class="toc-text">第十五课 子空间投影</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%91%E9%87%8F%E6%8A%95%E5%BD%B1"><span class="toc-number">2.1.</span> <span class="toc-text">向量投影</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8A%95%E5%BD%B1%E7%9F%A9%E9%98%B5"><span class="toc-number">2.2.</span> <span class="toc-text">投影矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Why-Project"><span class="toc-number">2.3.</span> <span class="toc-text">Why Project</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%B3%E9%9D%A2%E6%8A%95%E5%BD%B1"><span class="toc-number">2.4.</span> <span class="toc-text">平面投影</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95-Least-Squares-%E5%88%9D%E6%B6%89"><span class="toc-number">2.5.</span> <span class="toc-text">最小二乘法 Least Squares 初涉</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%8D%81%E5%85%AD%E8%AF%BE-%E6%8A%95%E5%BD%B1%E7%9F%A9%E9%98%B5%E5%92%8C%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95"><span class="toc-number">3.</span> <span class="toc-text">第十六课 投影矩阵和最小二乘法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8A%95%E5%BD%B1%E7%9F%A9%E9%98%B5%E5%9B%9E%E9%A1%BE"><span class="toc-number">3.1.</span> <span class="toc-text">投影矩阵回顾</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95"><span class="toc-number">3.2.</span> <span class="toc-text">最小二乘法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5-A-TA"><span class="toc-number">3.3.</span> <span class="toc-text">矩阵 $\,A^TA\,$</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%87%E5%87%86%E6%AD%A3%E4%BA%A4%E5%9F%BA"><span class="toc-number">3.4.</span> <span class="toc-text">标准正交基</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%8D%81%E4%B8%83%E8%AF%BE-%E6%AD%A3%E4%BA%A4%E7%9F%A9%E9%98%B5%E5%92%8C%E6%96%BD%E5%AF%86%E7%89%B9%E6%AD%A3%E4%BA%A4%E5%8C%96"><span class="toc-number">4.</span> <span class="toc-text">第十七课 正交矩阵和施密特正交化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%87%E5%87%86%E6%AD%A3%E4%BA%A4%E5%90%91%E9%87%8F-Orthonormal-vectors"><span class="toc-number">4.1.</span> <span class="toc-text">标准正交向量 Orthonormal vectors</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%87%E5%87%86%E6%AD%A3%E4%BA%A4%E7%9F%A9%E9%98%B5-Orthonormal-matrix"><span class="toc-number">4.2.</span> <span class="toc-text">标准正交矩阵 Orthonormal matrix</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%87%E5%87%86%E6%AD%A3%E4%BA%A4%E7%9F%A9%E9%98%B5%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="toc-number">4.3.</span> <span class="toc-text">标准正交矩阵的作用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%BD%E5%AF%86%E7%89%B9%E6%AD%A3%E4%BA%A4%E5%8C%96-Gram-Schmidt"><span class="toc-number">4.4.</span> <span class="toc-text">施密特正交化 Gram-Schmidt</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%8D%81%E5%85%AB%E8%AF%BE-%E8%A1%8C%E5%88%97%E5%BC%8F%E5%8F%8A%E5%85%B6%E6%80%A7%E8%B4%A8"><span class="toc-number">5.</span> <span class="toc-text">第十八课 行列式及其性质</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A1%8C%E5%88%97%E5%BC%8F-Determinants"><span class="toc-number">5.1.</span> <span class="toc-text">行列式 Determinants</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A1%8C%E5%88%97%E5%BC%8F%E7%9A%84%E6%80%A7%E8%B4%A8"><span class="toc-number">5.2.</span> <span class="toc-text">行列式的性质</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E5%8D%81%E4%B9%9D%E8%AF%BE-%E8%A1%8C%E5%88%97%E5%BC%8F%E5%85%AC%E5%BC%8F%E5%92%8C%E4%BB%A3%E6%95%B0%E4%BD%99%E5%AD%90%E5%BC%8F"><span class="toc-number">6.</span> <span class="toc-text">第十九课 行列式公式和代数余子式</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A1%8C%E5%88%97%E5%BC%8F%E5%85%AC%E5%BC%8F"><span class="toc-number">6.1.</span> <span class="toc-text">行列式公式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E6%95%B0%E4%BD%99%E5%AD%90%E5%BC%8F-Cofactor-formula"><span class="toc-number">6.2.</span> <span class="toc-text">代数余子式 Cofactor formula</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E5%8D%81%E8%AF%BE-%E5%85%8B%E8%8E%B1%E5%A7%86%E6%B3%95%E5%88%99%E3%80%81%E9%80%86%E7%9F%A9%E9%98%B5%E3%80%81%E4%BD%93%E7%A7%AF"><span class="toc-number">7.</span> <span class="toc-text">第二十课 克莱姆法则、逆矩阵、体积</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%86%E7%9F%A9%E9%98%B5%E5%85%AC%E5%BC%8F"><span class="toc-number">7.1.</span> <span class="toc-text">逆矩阵公式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%8B%E8%8E%B1%E5%A7%86%E6%B3%95%E5%88%99-Cramer%E2%80%99s-Rule"><span class="toc-number">7.2.</span> <span class="toc-text">克莱姆法则 Cramer’s Rule</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%93%E7%A7%AF"><span class="toc-number">7.3.</span> <span class="toc-text">体积</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E5%8D%81%E4%B8%80%E8%AF%BE-%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F"><span class="toc-number">8.</span> <span class="toc-text">第二十一课 特征值和特征向量</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%80%BC%E5%92%8C%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F"><span class="toc-number">8.1.</span> <span class="toc-text">特征值和特征向量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%80%BC%E6%B1%82%E8%A7%A3%E6%96%B9%E6%B3%95"><span class="toc-number">8.2.</span> <span class="toc-text">特征值求解方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%8D%E6%95%B0%E7%89%B9%E5%BE%81%E5%80%BC"><span class="toc-number">8.3.</span> <span class="toc-text">复数特征值</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E8%A7%92%E9%98%B5%E5%92%8C%E9%87%8D%E7%89%B9%E5%BE%81%E5%80%BC-Triangular-matrices-and-repeated-eigenvalues"><span class="toc-number">8.4.</span> <span class="toc-text">三角阵和重特征值 Triangular matrices and repeated eigenvalues</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E5%8D%81%E4%BA%8C%E8%AF%BE-%E5%AF%B9%E8%A7%92%E5%8C%96%E5%92%8C%E7%9F%A9%E9%98%B5%E7%9A%84%E5%B9%82"><span class="toc-number">9.</span> <span class="toc-text">第二十二课 对角化和矩阵的幂</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E5%AF%B9%E8%A7%92%E5%8C%96"><span class="toc-number">9.1.</span> <span class="toc-text">矩阵对角化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E5%B9%82%E8%BF%90%E7%AE%97"><span class="toc-number">9.2.</span> <span class="toc-text">矩阵幂运算</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%8D%E7%89%B9%E5%BE%81%E5%80%BC-Repeated-eigenvalues"><span class="toc-number">9.3.</span> <span class="toc-text">重特征值 Repeated eigenvalues</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B7%AE%E5%88%86%E6%96%B9%E7%A8%8B-Difference-equations"><span class="toc-number">9.4.</span> <span class="toc-text">差分方程 Difference equations</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E5%8D%81%E4%B8%89%E8%AF%BE-%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E5%92%8C%E7%9F%A9%E9%98%B5%E6%8C%87%E6%95%B0"><span class="toc-number">10.</span> <span class="toc-text">第二十三课 微分方程和矩阵指数</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B-Differential-equations"><span class="toc-number">10.1.</span> <span class="toc-text">微分方程 Differential equations</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E8%80%A6"><span class="toc-number">10.2.</span> <span class="toc-text">解耦</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E6%8C%87%E6%95%B0%E5%87%BD%E6%95%B0-e-At"><span class="toc-number">10.3.</span> <span class="toc-text">矩阵指数函数$\,e^{At}\,$</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E9%98%B6%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B"><span class="toc-number">10.4.</span> <span class="toc-text">二阶微分方程</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E5%8D%81%E5%9B%9B%E8%AF%BE-%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E7%9F%A9%E9%98%B5%E5%92%8C%E5%82%85%E9%87%8C%E5%8F%B6%E7%BA%A7%E6%95%B0"><span class="toc-number">11.</span> <span class="toc-text">第二十四课 马尔可夫矩阵和傅里叶级数</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E7%9F%A9%E9%98%B5"><span class="toc-number">11.1.</span> <span class="toc-text">马尔科夫矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E7%9F%A9%E9%98%B5%E7%9A%84%E5%BA%94%E7%94%A8"><span class="toc-number">11.2.</span> <span class="toc-text">马尔科夫矩阵的应用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%82%85%E9%87%8C%E5%8F%B6%E7%BA%A7%E6%95%B0"><span class="toc-number">11.3.</span> <span class="toc-text">傅里叶级数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8D%E6%8F%90%E5%9F%BA%E7%A1%80"><span class="toc-number">11.3.1.</span> <span class="toc-text">前提基础</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%82%85%E9%87%8C%E5%8F%B6%E7%BA%A7%E6%95%B0-1"><span class="toc-number">11.3.2.</span> <span class="toc-text">傅里叶级数</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E5%8D%81%E4%BA%94%E8%AF%BE-%E5%A4%8D%E4%B9%A0%E4%BA%8C"><span class="toc-number">12.</span> <span class="toc-text">第二十五课 复习二</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BE%8B%E9%A2%98"><span class="toc-number">12.1.</span> <span class="toc-text">例题</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/04/05/2024-04-05-GAMES_101_1/" title="GAMES101-图形学入门公开课笔记（一）"><img src="https://s2.loli.net/2024/04/05/bQhEat4gmx9UWIX.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="GAMES101-图形学入门公开课笔记（一）"/></a><div class="content"><a class="title" href="/2024/04/05/2024-04-05-GAMES_101_1/" title="GAMES101-图形学入门公开课笔记（一）">GAMES101-图形学入门公开课笔记（一）</a><time datetime="2024-04-05T11:16:20.000Z" title="发表于 2024-04-05 19:16:20">2024-04-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/03/26/2024-03-26-NPR_StarRail2/" title="基于星穹铁道的卡通渲染（二）"><img src="https://s2.loli.net/2024/03/26/kxdT3sE6wS9LXbp.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于星穹铁道的卡通渲染（二）"/></a><div class="content"><a class="title" href="/2024/03/26/2024-03-26-NPR_StarRail2/" title="基于星穹铁道的卡通渲染（二）">基于星穹铁道的卡通渲染（二）</a><time datetime="2024-03-26T07:25:22.000Z" title="发表于 2024-03-26 15:25:22">2024-03-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/03/20/2024-03-20-NPR_StarRail1/" title="基于星穹铁道的卡通渲染（一）"><img src="https://s2.loli.net/2024/03/26/dZTwsApi59CSUal.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于星穹铁道的卡通渲染（一）"/></a><div class="content"><a class="title" href="/2024/03/20/2024-03-20-NPR_StarRail1/" title="基于星穹铁道的卡通渲染（一）">基于星穹铁道的卡通渲染（一）</a><time datetime="2024-03-20T05:25:53.000Z" title="发表于 2024-03-20 13:25:53">2024-03-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/02/23/2024-02-23-URP%E5%9F%BA%E7%A1%80/" title="Unity URP 基础"><img src="https://s2.loli.net/2024/02/18/pMAzYioaFZEkS8I.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Unity URP 基础"/></a><div class="content"><a class="title" href="/2024/02/23/2024-02-23-URP%E5%9F%BA%E7%A1%80/" title="Unity URP 基础">Unity URP 基础</a><time datetime="2024-02-23T06:03:56.000Z" title="发表于 2024-02-23 14:03:56">2024-02-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/02/22/2024-02-22-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%803/" title="MIT 线性代数公开课笔记（三）"><img src="https://s2.loli.net/2024/02/18/NjAQJ5diwBHTKzc.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MIT 线性代数公开课笔记（三）"/></a><div class="content"><a class="title" href="/2024/02/22/2024-02-22-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%803/" title="MIT 线性代数公开课笔记（三）">MIT 线性代数公开课笔记（三）</a><time datetime="2024-02-22T05:56:08.000Z" title="发表于 2024-02-22 13:56:08">2024-02-22</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By 鸟布</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Your time is limited, so don't waste it living someone else's life.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>