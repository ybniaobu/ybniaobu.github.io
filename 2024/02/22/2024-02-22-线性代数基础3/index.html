<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>MIT 线性代数公开课笔记（三） | 鸟布的博客</title><meta name="author" content="鸟布"><meta name="copyright" content="鸟布"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="该笔记主要内容为对称矩阵；正定矩阵；相似矩阵；奇异值分解 SVD 等等。该笔记主要参考了 MLNLP 的关于该公开课的 GitHub 公开项目的笔记：https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;MLNLP-World&amp;#x2F;MIT-Linear-Algebra-Notes公开课 B 站 bv 号：BV16Z4"><link rel="shortcut icon" href="https://s2.loli.net/2022/09/08/Ygib4lfw6z1khnr.png"><link rel="canonical" href="https://ybniaobu.github.io/2024/02/22/2024-02-22-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%803/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 鸟布","link":"链接: ","source":"来源: 鸟布的博客","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'MIT 线性代数公开课笔记（三）',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-04-12 18:26:16'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/images/wechat%20avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">31</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-bars"></i><span> 目录</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/images/black.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="鸟布的博客"><span class="site-name">鸟布的博客</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-bars"></i><span> 目录</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">MIT 线性代数公开课笔记（三）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-02-22T05:56:08.000Z" title="发表于 2024-02-22 13:56:08">2024-02-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-04-12T10:26:16.601Z" title="更新于 2024-04-12 18:26:16">2024-04-12</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E5%AD%A6/">数学</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E5%AD%A6/3d%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/">3d数学基础</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E5%AD%A6/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">线性代数</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">13.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>48分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="MIT 线性代数公开课笔记（三）"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote>
<p>该笔记主要内容为对称矩阵；正定矩阵；相似矩阵；奇异值分解 SVD 等等。<br>该笔记主要参考了 MLNLP 的关于该公开课的 GitHub 公开项目的笔记：<a target="_blank" rel="noopener" href="https://github.com/MLNLP-World/MIT-Linear-Algebra-Notes">https://github.com/MLNLP-World/MIT-Linear-Algebra-Notes</a><br>公开课 B 站 bv 号：BV16Z4y1U7oU</p>
</blockquote>
<h1 id="第二十六课-对称矩阵和正定性"><a href="#第二十六课-对称矩阵和正定性" class="headerlink" title="第二十六课 对称矩阵和正定性"></a>第二十六课 对称矩阵和正定性</h1><p>本节从对称矩阵的特征值，特征向量入手，介绍对称矩阵的特殊性质。并引出正定矩阵的内容。</p>
<h2 id="对称矩阵"><a href="#对称矩阵" class="headerlink" title="对称矩阵"></a>对称矩阵</h2><p>对称矩阵 A 的性质如下：<br>①$\,A = A^T\,$;<br>②特征值为实数，有正交的特征向量。这里指的是，可以选出一套完全正交的特征向量（例如在重特征值条件下，可能存在一个平面内向量都可以作为特征向量）。</p>
<h2 id="对称矩阵的分解"><a href="#对称矩阵的分解" class="headerlink" title="对称矩阵的分解"></a>对称矩阵的分解</h2><p>如果某矩阵 A 具有 n 个线性无关的特征向量，可以对角化得到 $\,A = S \Lambda S^{-1}\,$；</p>
<p>而对于对称矩阵 A，因其特征向量正交，并且可以将其长度单位化，故可以对角化得到 $\,A = Q \Lambda Q^{-1} = Q \Lambda Q^{T}\,$。其中 Q 为正交矩阵，列向量为标准正交基。这个公式本身还显示了矩阵的对称性：$\,(Q \Lambda Q^{T})^T = Q \Lambda Q^{T}\,$。</p>
<p>给定一个对称矩阵，我们就可以将其分解成上面的这种形式。这在力学上被称为 <strong>“主轴定理”</strong>，它意味着如果给定某种材料，在合适的轴上来看，它就会变成对角化的，方向就不会重复。而在数学上，这被称为 <strong>“谱定理” spectral theorem</strong>。<strong>谱 Spectrum</strong> 即矩阵的特征值的集合。</p>
<h2 id="对称矩阵的实特征值"><a href="#对称矩阵的实特征值" class="headerlink" title="对称矩阵的实特征值"></a>对称矩阵的实特征值</h2><p>之前介绍的旋转矩阵，其中有的对应值会造成特征值为虚数的情况，但是对于对称矩阵来说，这种情况是不会发生的，即：对称矩阵特征值均为实数。</p>
<p>对称矩阵 A 具有特征值 $\,\lambda\,$ 和特征向量 x，则有 $\,Ax = \lambda x\,$。若特征值为复数，则其共轭复数满足 $\,A \overline x = \overline \lambda \overline x\,$。两侧转置，则有：$\,\overline x^T A^T = \overline x^T \overline \lambda\,$。两侧同乘 x，则：$\,\overline x^T A^T x = \overline x^T \overline \lambda x\,$。因为矩阵为对称矩阵，则有：$\,\overline x^T \lambda x = \overline x^T \overline \lambda x\,$，若 $\,\overline x^T x \neq 0 \,$，则有 $\,\lambda = \overline\lambda\,$，这就证明了特征值是一个实数。</p>
<p>因为 $\,\overline x\,$ 为 x 的共轭，因此两者点积得到的是 x 中的每一分量与其共轭复数的乘积之和，即复向量 x 之模，当且仅当 x = 0 时，其模为 0。而对称矩阵的特征向量 x 不是零向量，那么 $\,\overline x^T x = 0 \,$ 情况不存在。</p>
<hr>
<p>当确认矩阵特征值为实数后，下一个要考虑的问题就是它是正还是负数，因为这影响着微分方程中体系的稳定与否。但是对于大型矩阵通过计算 $\,|A - \lambda I| = 0\,$ 得到特征值进行判定难以实现，即使用 MATLAB 求解结果也不一定可靠，但 MATLAB 可以得到矩阵的主元。因为对称矩阵具有如下特殊性质：<br>①<strong>对称矩阵的主元正负个数与特征值的正负个数对应一致。</strong><br>正主元个数 = 正特征值个数<br>负主元个数 = 负特征值个数<br>②<strong>对称矩阵的主元的乘积等于特征值的乘积</strong>（它们都等于矩阵行列式的值） </p>
<h2 id="对称矩阵的另一种理解"><a href="#对称矩阵的另一种理解" class="headerlink" title="对称矩阵的另一种理解"></a>对称矩阵的另一种理解</h2><p>对于对称矩阵，$\,A = Q \Lambda Q^{-1} = Q \Lambda Q^{T}\,$，可以写作：  </p>
<script type="math/tex; mode=display">\begin{align*} A = Q \Lambda Q^{-1} &= \begin{bmatrix} q_1 & q_2 & \cdots & q_n \end{bmatrix} \begin{bmatrix} \lambda_1 &  &  & \\ & \lambda_2 &  & \\ &  & \cdots & \\ &  &  & \lambda_n \end{bmatrix} \begin{bmatrix} q_1^T \\ q_2^T \\ \cdots \\ q_n^T \end{bmatrix} \\ &= \lambda_1q_1q_1^T + \lambda_2q_2q_2^T + \cdots + \lambda_nq_nq_n^T \end{align*}</script><p>矩阵 $\,q_kq_k^T\,$ 是朝向向量 $\,q_k\,$ 的投影矩阵，所以<strong>每一个对称矩阵都是正交投影矩阵的线性组合</strong>。这是理解谱定理的另一种方法。</p>
<h2 id="正定矩阵简介"><a href="#正定矩阵简介" class="headerlink" title="正定矩阵简介"></a>正定矩阵简介</h2><p>所谓<strong>正定矩阵 positive definite matrix</strong> 就是一类对称矩阵，满足：<br>①所有的特征值是正数；<br>②所有主元为正；<br>③所有的子行列式都为正。</p>
<p>子行列式概念：从原行列式左上角开始依次划分出 1x1 的一块，2x2 的一块，…得到的这些子块对应的行列式就称之为“子行列式”。</p>
<p>例如：矩阵 $\,A = \begin{bmatrix} 5 &amp; 2 \\ 2 &amp; 3 \end{bmatrix}\,$</p>
<p>对该矩阵消元，可求得其主元为：5、11/5 皆为正。而且该矩阵是对称矩阵，所以它也是正定矩阵。同时，我们计算它的特征值可以得到：$\, \lambda = 4 \pm \sqrt{5} \,$（同主元，皆为正）。所以正定矩阵的行列式值是正数，但是这里要注意，行列式为正数的矩阵不一定都是正定矩阵，要满足“所有的子行列式都为正”才可以。反例：$\,\begin{bmatrix} -1 &amp; 0 \\ 0 &amp; -3 \end{bmatrix}\,$</p>
<h1 id="第二十七课-复矩阵，快速傅里叶变换"><a href="#第二十七课-复矩阵，快速傅里叶变换" class="headerlink" title="第二十七课 复矩阵，快速傅里叶变换"></a>第二十七课 复矩阵，快速傅里叶变换</h1><p>实矩阵也可能有复特征值，因此无法避免在矩阵运算中碰到复数，本讲学习处理复数矩阵和复向量。</p>
<p>最重要的复矩阵是傅里叶矩阵，它用于傅里叶变换。而对于大数据处理快速傅里叶变换（Fast Fourier Transform，FFT）显得更为重要，它将矩阵乘法的运算次数从 $\,n^2\,$ 次降至 $\,nlog_2n\,$ 次。</p>
<h2 id="复向量"><a href="#复向量" class="headerlink" title="复向量"></a>复向量</h2><p>如果向量中有分量是虚数的话，很明显我们无法再用普通的公式计算长度和内积。比如：$\,\begin{bmatrix} 1 \\ i \end{bmatrix}\,$，按照我们以前的计算会得到 $\,\begin{bmatrix} 1 &amp; i \end{bmatrix} \begin{bmatrix} 1 \\ i \end{bmatrix} = 0\,$，即长度就是 0。但是很明显 $\,\begin{bmatrix} 1 \\ i \end{bmatrix}\,$ 这个向量模长为 $\,\sqrt 2\,$，这就造成了谬误。在这里我们给出复向量的长度与内积计算方法：  </p>
<p>对于复数向量 $\, \begin{bmatrix} z_1 \\ z_2 \\ z_3 \\ \vdots \\ z_n\end{bmatrix} \in C^n \,$，定义 $\, |z|^2 = z^Hz = \overline z^T z\,$，即<strong>先将分量取共轭 Conjugate，再转置相乘</strong>。与之相似，向量内积的定义也变为 $\,yx = y^Hx = \overline y^T x\,$。因此向量 $\,\begin{bmatrix} 1 \\ i \end{bmatrix}\,$ 的模长的平方就等于 $\,\begin{bmatrix} 1 &amp; -i \end{bmatrix} \begin{bmatrix} 1 \\ i \end{bmatrix} = 2\,$。</p>
<h2 id="复矩阵"><a href="#复矩阵" class="headerlink" title="复矩阵"></a>复矩阵</h2><p>在实矩阵中，$\, A^T = A \,$，则 A 为对称阵。而在复矩阵中，这并不成立，在复矩阵中取共轭与取转置往往是同步的。所以，复对称矩阵定义为：若 $\, \overline A^T = A \,$，则 A 为对称阵。则复矩阵 A 的特征值为实数。这种复矩阵被称为<strong>埃尔米特矩阵 Hermitian matrixes</strong>，又译作“厄米特矩阵”或者“厄米矩阵”。转置共轭记作 $\, A^H = \overline A^T \,$。</p>
<p>例如 $\, \begin{bmatrix} 2 &amp; 3 + i \\ 3 - i &amp; 5 \end{bmatrix} \,$，主对角线上为实数，而沿主对角线对称的两个元素共轭。它具有实数特征值和正交的特征向量。</p>
<p>此处向量标准正交的意思是 $\, \overline q_j^T q_k = \begin{cases} 0 (j \neq k)\\ 1(j = k) \end{cases} \,$。用 n 个标准正交的复向量作为列向量可以构造一个矩阵 Q，则有 $\,Q^TQ = I = Q^HQ\,$。这个复空间的正交矩阵称为酉矩阵 unitary matrix。</p>
<h2 id="傅里叶矩阵"><a href="#傅里叶矩阵" class="headerlink" title="傅里叶矩阵"></a>傅里叶矩阵</h2><p>傅里叶级数是将周期函数或者信号变换为不同频率的三角函数的和函数： </p>
<script type="math/tex; mode=display">f(x) = a_0 + a_1cosx + b_1sinx + a_2cos2x + b_2sin2x + \cdots</script><p>在电子工程或者计算机科学中，矩阵的行和列从第 0 行和第 0 列开始计数，最后到第 n-1 行和第 n-1 列。我们在讨论傅里叶矩阵的时候遵从这种习惯。</p>
<p>傅里叶矩阵：  </p>
<script type="math/tex; mode=display">F_n = \begin{bmatrix} 1 & 1 & 1 & \cdots & 1 \\ 1 & \omega & \omega^2 & \cdots & \omega^{n-1} \\ 1 & \omega^2 & \omega^4 & \cdots & \omega^{2(n-1)} \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ 1 & \omega^{n-1} & \omega^{2(n-1)} & \cdots & \omega^{(n-1)^2} \end{bmatrix}</script><p>其中 $\,\omega^n = 1\,$，$\,\omega = e^{i2\pi/n} = cos(2\pi/n) + isin(2\pi/n)\,$。ω 就反映在复数坐标系的圆上，其中的 n 就表示将这个圆分成几部分。当 n = 4 时，$\,\omega^4 = 1\,$，$\,\omega = e^{i2\pi/4} = i\,$。</p>
<script type="math/tex; mode=display">F_4 = \begin{bmatrix} 1 & 1 & 1 & 1 \\ 1 & i & i^2 & i^3 \\ 1 & i^2 & i^4 & i^6 \\ 1 & i^3 & i^6 & i^9 \end{bmatrix} = \begin{bmatrix} 1 & 1 & 1 & 1 \\ 1 & i & -1 & -i \\ 1 & -1 & 1 & -1 \\ 1 & -i & -1 & i \end{bmatrix}</script><p>从矩阵可以得到一个四点（离散的）傅里叶变换，它的逆矩阵就是反傅里叶变换。逆矩阵很容易计算，因为傅里叶矩阵列向量正交，得到：$\,F_4^HF_4 = 4\,$。将 $\,F_4\,$ 前乘上 1/2，作为新的 $\,F_4’\,$，然后 $\,F_4’^HF_4’ = I\,$，即新的 $\,F_4’\,$ 的逆矩阵为 $\,F_4’^H\,$。</p>
<h2 id="快速傅里叶变换"><a href="#快速傅里叶变换" class="headerlink" title="快速傅里叶变换"></a>快速傅里叶变换</h2><p>对于 64 阶傅里叶矩阵 $\, F_{64} \,$ 中的 $\, \omega_{64} \,$ 与 32 阶傅里叶矩阵 $\, F_{32} \,$ 的 $\, \omega_{32} \,$ 相比，幅角是其一半，$\,(\omega_{64})^2 = \omega_{32}\,$。可以从分块矩阵运算找到两者的联系：  </p>
<script type="math/tex; mode=display">F_{64} = \begin{bmatrix} I & D \\ I & -D \end{bmatrix} \begin{bmatrix} F_{32} & 0 \\ 0 & F_{32} \end{bmatrix} P</script><p>其中 P 是置换矩阵，作用是将奇偶行分开，例如 4 维时，置换矩阵 $\,P = \begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix}\,$ 。而 D 为对角矩阵，$\,D = \begin{bmatrix} 1 &amp; &amp; &amp; &amp; \\ &amp; \omega &amp; &amp; &amp; \\ &amp; &amp; \omega^2 &amp; &amp; \\ &amp; &amp; &amp; \cdots &amp; \\ &amp; &amp; &amp; &amp; \omega^{31} \end{bmatrix}\,$，</p>
<p>计算 64 阶傅里叶变换（傅里叶矩阵乘以向量）的计算量是 64 x 64，而等式右侧的计算量是 2 x 32 x 32（两个 32 阶）再加上一些修正项，修正项主要来自于与对角矩阵 D 的乘法，大约为 32 次。继续对 F32 进行分解，计算的运算量再一次下降变为 2(2 x 16 x 16 + 16) + 32。分解到最后，仅剩修正项的运算，$\,32 \times log_264\,$。对于 n 阶矩阵，即将 $\,n^2\,$ 次计算降至 $\,n/2 \times log_2n\,$ 次。</p>
<h1 id="第二十八课-正定矩阵和最小值"><a href="#第二十八课-正定矩阵和最小值" class="headerlink" title="第二十八课 正定矩阵和最小值"></a>第二十八课 正定矩阵和最小值</h1><p>本节将正定矩阵和主元，行列式，特征值等联系起来，并通过正定矩阵判据式引出矩阵与函数之间的关系。</p>
<h2 id="正定矩阵"><a href="#正定矩阵" class="headerlink" title="正定矩阵"></a>正定矩阵</h2><p>给定一个 2 × 2 的对称矩阵 $\,A = \begin{bmatrix} a &amp; b \\ b &amp; c \end{bmatrix}\,$，有四个途径判定矩阵是否正定矩阵：<br>①特征值皆为正数：$\,\lambda_1 &gt; 0\,$，$\,\lambda_2 &gt; 0\,$；<br>②行列式（所有子行列式）均为正值：$\,a &gt; 0\,$，$\,ac - b^2 &gt; 0\,$；<br>③主元均为正数：$\,a &gt; 0\,$，$\,\cfrac{ac - b^2} {a} &gt; 0\,$；<br>④判据式 $\,x^TAx &gt; 0\,$，x = 0 除外。这就是正定性的定义，第 1 到 3 条都是用来验证这个的。</p>
<hr>
<p>设矩阵 $\,A = \begin{bmatrix} 2 &amp; 6 \\ 6 &amp; y \end{bmatrix}\,$。从判断方法来看，矩阵为正定阵的条件是 2y - 36 &gt; 0，即 y &gt; 18。</p>
<p>而 y = 18 时，矩阵 $\,\begin{bmatrix} 2 &amp; 6 \\ 6 &amp; 18 \end{bmatrix}\,$ 正好处在判定为正定矩阵的临界点上，称之为<strong>半正定 positive semidefinite</strong> 矩阵，它是奇异矩阵，只有一个主元，而行列式为 0，特征值为 0，20 都大于等于 0。</p>
<h2 id="判据式"><a href="#判据式" class="headerlink" title="判据式"></a>判据式</h2><p>再来看判据式 $\,x^TAx\,$：</p>
<script type="math/tex; mode=display">x^TAx = \begin{bmatrix} x_1 & x_2 \end{bmatrix} \begin{bmatrix} 2 & 6 \\ 6 & 18 \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} = 2x_1^2 + 12x_1x_2 + 18x_2^2</script><p>对应的 $\,x_1^2, x_1x_2, x_2^2\,$ 前的系数分别为 $\,\begin{bmatrix} a &amp; b \\ b &amp; c \end{bmatrix}\,$ 中的 a，2b，c。</p>
<p>这就是<strong>二次型</strong>，而所谓判定 A 是不是正定矩阵，也就是判别式 $\,x^TAx\,$ 所构造出的类似于 $\,2x_1^2 + 12x_1x_2 + 18x_2^2\,$ 的二次型是不是恒大于 0。对于本例中来说，它显然不是恒正的，因为在某种取值中，其结果可以为 0。</p>
<p>这表明了 A 为半正定时，其对应二次型会在某种情况下得到 0，那么 A 不是正定时，其对应的判别式会呈现出一种什么样的状态呢？</p>
<p>如果将矩阵变为 $\,\begin{bmatrix} 2 &amp; 6 \\ 6 &amp; 7 \end{bmatrix}\,$，二次型为 $\,f(x,y) = 2x^2 + 12xy + 7y^2\,$，从几何图像上看没有最小值点，在原点处有一鞍点。鞍点在某个方向上看是极大值点，在另一方向上是极小值点，实际上最佳观测角度是特征向量的方向。</p>
<p>如果将矩阵变为 $\,\begin{bmatrix} 2 &amp; 6 \\ 6 &amp; 20 \end{bmatrix}\,$，主元为正；特征值之积为行列式的值 4，特征值和为矩阵的迹 22，因此特征值为正；子行列式均为正。矩阵为正定矩阵。其二次型 $\,f(x,y) = 2x^2 + 12xy + 20y^2\,$ 图像最小值点为原点，一阶偏导数为 0，二阶偏导数为正。</p>
<div  align="center">  
<img src="https://s2.loli.net/2024/04/08/6uqwar1JFvMmZIi.png" width = "70%" height = "70%" alt="图12 - 两个二次型双曲面函数"/>
</div>

<div  align="center">  
<img src="https://s2.loli.net/2024/04/08/xymIShuNK5nsJoq.png" width = "60%" height = "60%" alt="图13 - 二次型函数图像"/>
</div>

<p>微积分中判定最小值点的判据：一阶导数等于零，二阶导数为正；而在线性代数中，我们判断是否有最小值是通过判断二阶导数矩阵是否为正定，这是正定矩阵的用法之一，将数字转化为矩阵。</p>
<hr>
<p>对于二次型我们可以用配方的办法来验证其是否具有最小值：</p>
<script type="math/tex; mode=display">f(x,y) = 2x^2 + 12xy + 20y^2 = 2(x+3y)^2 + 2y^2</script><p>配方使得 $\,x^2\,$ 的系数和交叉项 $\,xy\,$ 的系数配合形成完全平方的形式，这时候交叉项的 $\,y^2\,$ 的系数正好是 18，即判定正定的临界点。如果实际的系数 d 大于 18，则还剩余 $\,(d - 18)y^2\,$，二次型在原点之外一定大于零，若小于 18 则二次型可以小于等于 0。而如果我们用 f = 1 这个平面来截这个曲线，则上面的 f(x,y) 截得的就是椭圆。而对于双曲面进行切割就得到双曲线。</p>
<p>另外，配方法反映在线代中就是消元：</p>
<script type="math/tex; mode=display">\begin{bmatrix} 2 & 6 \\ 6 & 20 \end{bmatrix} = \begin{bmatrix} 1 & 0 \\ 3 & 1 \end{bmatrix} \begin{bmatrix} 2 & 6 \\ 0 & 2 \end{bmatrix}</script><p>主元就是平方项系数，L 矩阵中的行操作数 $\,l_{21}\,$ 就是配方项内 y 的系数。因此这就是为什么主元为正，则矩阵为正定矩阵，因为主元是每一个完全平方项的系数。正定 -&gt; 主元为正 -&gt; 二次型平方项外系数为正 -&gt; 图像朝上 -&gt; 原点为最小值点。</p>
<p>此理论可推广到 n 维。同样，在微积分中我们学习二阶偏导数极值时的 $\,f_{xx}\,$，$\,f_{yy}\,$ 与 $\,f_{xy}^2\,$ 之间的关系也可以反映到矩阵的正定判断上，即矩阵 $\, \begin{bmatrix} f_{xx} &amp; f_{xy} \\ f_{yx} &amp; f_{yy} \end{bmatrix} \,$，这就是二阶导数矩阵。矩阵对称代表交叉二阶偏导数与求导顺序无关，即 $\,f_{xy} = f_{yx}\,$。在微积分中我们学到的判据 $\,f_{xx}f_{yy} &gt; f_{xy}^2\,$，和二阶矩阵判定正定是等价的。</p>
<hr>
<p>例：矩阵 $\,A = \begin{bmatrix} 2 &amp; -1 &amp; 0 \\ -1 &amp; 2 &amp; -1 \\ 0 &amp; -1 &amp; 2 \end{bmatrix}\,$，其二次型为 $\,x^TAx = 2x_1^2 + 2x_2^2 + 2x_3^2 - 2x_1x_2 - 2x_2x_3 \,$</p>
<p>这是一个四维的图像，如果用 f = 1 切割图像，则得到一个椭球体，三个特征值不同，因此椭球的三个长轴长度不同。三个轴的方向就是特征向量的方向，轴长度就是特征值，矩阵的分解 $\,A = Q \Lambda Q^T\,$ 很好的说明了这件事，这就是所谓的“主轴定理”。</p>
<h1 id="第二十九课-相似矩阵和若尔当标准型"><a href="#第二十九课-相似矩阵和若尔当标准型" class="headerlink" title="第二十九课 相似矩阵和若尔当标准型"></a>第二十九课 相似矩阵和若尔当标准型</h1><h2 id="正定矩阵补充"><a href="#正定矩阵补充" class="headerlink" title="正定矩阵补充"></a>正定矩阵补充</h2><p>正定矩阵来自于最小二乘问题。有大量的实际问题用到了长方形矩阵，而最小二乘问题中用到了长方形矩阵的积 $\,A^TA\,$，它是正定矩阵。</p>
<p>正定矩阵 $\,A\,$ 是对称矩阵，它的逆矩阵 $\,A^{-1}\,$ 也是正定矩阵，逆矩阵的特征值是原矩阵的倒数，因此也都是正数。若矩阵 A 和 B 都是正定矩阵，则 A + B 也是正定矩阵：$\,x^TAx &gt; 0\,$，$\,x^TBx &gt; 0\,$，则有 $\,x^T(A + B)x &gt; 0\,$。</p>
<p>如果 A 是一个 m x n 长方形矩阵，则 $\,A^TA\,$ 是对称方阵。通过讨论 $\,x^T(A^TA)x\,$ 的正负可以确认它是正定矩阵：$\,x^T(A^TA)x\, = (Ax)^T(Ax) = |Ax|^2 \ge 0\,$，当且仅当 Ax = 0 时，表达式为 0。即当矩阵 A 的各列线性无关时，即矩阵为列满秩 r = n，A 的零空间只有零向量，即此条件下仅有零向量，满足 $\,x^T(A^TA)x = 0\,$。因此矩阵列满秩时，$\,A^TA\,$ 是正定矩阵。</p>
<h2 id="相似矩阵"><a href="#相似矩阵" class="headerlink" title="相似矩阵"></a>相似矩阵</h2><p>A 和 B 均是 n x n 方阵，若存在可逆矩阵 M，使得 $\,B = M^{-1}AM\,$，则 A 和 B 为<strong>相似矩阵 similar matrices</strong>。</p>
<p>若矩阵 A 具有 n 个线性无关的特征向量，我们知道可以对角化得到 $\,S^{-1}AS = \Lambda\,$，则 $\,A\,$ 相似于 $\,\Lambda\,$。但是与 A 相似的不只是这个对角阵，任取一对矩阵与矩阵的逆，就可以计算与 A 相似的矩阵，只不过 $\,\Lambda\,$ 是其中最简洁的一个。</p>
<p>例如，$\, A = \begin{bmatrix} 2 &amp; 1 \\ 1 &amp; 2 \end{bmatrix}\,$，则 $\, \Lambda = \begin{bmatrix} 3 &amp; 0 \\ 0 &amp; 1 \end{bmatrix}\,$，而若取另一 M，则有 $\, B = M^{-1}AM = \begin{bmatrix} 1 &amp; -4 \\ 0 &amp; 1 \end{bmatrix} \begin{bmatrix} 2 &amp; 1 \\ 1 &amp; 2 \end{bmatrix} \begin{bmatrix} 1 &amp; 4 \\ 0 &amp; 1 \end{bmatrix} = \begin{bmatrix} -2 &amp; -15 \\ 1 &amp; 6 \end{bmatrix} \,$</p>
<p>最终得到的这个矩阵 B 也与矩阵 A 相似。结论：<strong>相似矩阵特征值相同，其线性无关的特征向量数目也一样</strong>。</p>
<p>证明如下：<br>①首先矩阵 A 具有的特征值 $\,\lambda\,$，即存在特征向量 x 满足 $\,Ax = \lambda x\,$；<br>②由 $\,A = AI = AMM^{-1}\,$ 得到：$\,AMM^{-1}x = \lambda x\,$；<br>③同时左乘 $\,M^{-1}\,$ 得到 $\,M^{-1}AMM^{-1}x = M^{-1} \lambda x\,$；<br>④由 $\,B = M^{-1}AM\,$ 得到 $\,BM^{-1}x = \lambda M^{-1}x\,$。</p>
<p>即矩阵 B 具有特征值 $\,\lambda\,$，且特性向量为 $\,M^{-1}x\,$。</p>
<p>因此，相似矩阵具有相同的特征值，并且线性无关的特征向量的个数相同，但是特征向量往往不同。</p>
<h2 id="若尔当标准型"><a href="#若尔当标准型" class="headerlink" title="若尔当标准型"></a>若尔当标准型</h2><h3 id="重特征值的相似情况"><a href="#重特征值的相似情况" class="headerlink" title="重特征值的相似情况"></a>重特征值的相似情况</h3><p>如果矩阵有重特征值，则可能无法进行对角化。</p>
<p>例如，设 $\,\lambda_1 = \lambda_2 = 4\,$，具有此特征值的二阶矩阵可以被分为两类：<br>①第一类 $\,\begin{bmatrix} 4 &amp; 0 \\ 0 &amp; 4 \end{bmatrix}\,$ 只与自己相似。$\,M^{-1} \begin{bmatrix} 4 &amp; 0 \\ 0 &amp; 4 \end{bmatrix} M = 4 M^{-1}IM = \begin{bmatrix} 4 &amp; 0 \\ 0 &amp; 4 \end{bmatrix}\,$，这个矩阵的相似矩阵仅包含其自身。<br>②第二类包含其它所有的重特征值为 4 的矩阵：其中最简洁的是 $\,\begin{bmatrix} 4 &amp; 1 \\ 0 &amp; 4 \end{bmatrix}\,$，元素 1 的位置换上其它数值仍然是相似矩阵。这个最优形式称为<strong>若尔当标准型 Jordan form</strong>。而这一类矩阵不可以相似对角化，对于不能完成相似对角化的矩阵，可以完成近似的“对角化”转化为若尔当标准型进行处理。</p>
<h3 id="若尔当标准型-1"><a href="#若尔当标准型-1" class="headerlink" title="若尔当标准型"></a>若尔当标准型</h3><p>更复杂的情况，一个四阶矩阵具有重特征值 0，$\,\lambda_1 = \lambda_2 = \lambda_3 = \lambda_4 = 0\,$。</p>
<p>$\,A = \begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{bmatrix}\,$，它的秩为 2，因此其零空间的维数为 4 - 2 = 2，而零空间的向量就是矩阵的特征向量，满足 Ax = 0x，所以矩阵 A 只有两个特征向量。若尔当指出上对角线每增加一个 1，矩阵就减掉一个特征向量，本例中特征向量数为 4 - 2 = 2。</p>
<p>矩阵 $\,B = \begin{bmatrix} 0 &amp; 1 &amp; 7 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{bmatrix}\,$ 与矩阵 $\,A = \begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{bmatrix}\,$ 为相似矩阵。  </p>
<p>矩阵 $\,C = \begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{bmatrix}\,$ 与矩阵 $\,A = \begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{bmatrix}\,$ 并不是相似矩阵，两者具有不同的若尔当块。</p>
<p><strong>若尔当块</strong>：$\,J_i\,$ 表示 i 阶的若尔当块，它只有一个重复的特征值。满足形式：  </p>
<script type="math/tex; mode=display">J_i = \begin{bmatrix} \lambda_i & 1 & 0 & \cdots & 0 \\ 0 & \lambda_i & 1 & \cdots & 0 \\ 0 & 0 & \lambda_i & \cdots & 0 \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & 0 & \cdots & \lambda_i \end{bmatrix}</script><p>若尔当块的对角线上为重特征值 $\,\lambda_i\,$，上对角线为 1，其它位置的元素均为 0。每个若尔当块只有 1 个特征向量。若干个若尔当块可以拼成一个若尔当矩阵，形如下：  </p>
<script type="math/tex; mode=display">J = \begin{bmatrix} J_1 & 0 & \cdots & 0 \\ 0 & J_2 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & J_d \end{bmatrix}</script><p>两个矩阵若具有相同的特征值和特征向量个数，但是其若尔当块的尺寸不同，两者也并不是相似矩阵。如前述矩阵 A 与 C 并不相似。</p>
<p>若尔当理论：任意 n 阶矩阵 A 都与一个若尔当矩阵 J 相似。若尔当矩阵中的每一个若尔当块对应一个特征向量。若矩阵具有 n 个不同的特征向量，则可以对角化，此时其若尔当标准型 J 就是对角矩阵 $\,\Lambda\,$。若出现重特征值，则特征向量个数变少。</p>
<h1 id="第三十课-奇异值分解"><a href="#第三十课-奇异值分解" class="headerlink" title="第三十课 奇异值分解"></a>第三十课 奇异值分解</h1><p>本节介绍矩阵的奇异解分解，本质就是将行空间的一组正交基变换成列空间里的一组正交基。这是矩阵最终也是最好的分解，任意矩阵可分解为正交矩阵 $\,U\,$，对角阵 $\,\Sigma\,$ 和正交矩阵 $\,V\,$，即 $\,A = U \Sigma V^T\,$。如果矩阵 A 是正定矩阵，它的奇异值分解就是 $\,A = Q \Lambda Q^T\,$，因为矩阵为对称时，特性向量就是正交的。而对于可对角化的矩阵有 $\,A = S \Lambda S^{-1}\,$，但特征向量矩阵 S 并不是正交矩阵，而 SVD 中的 U 和 V 都是正交矩阵。</p>
<h2 id="奇异值分解"><a href="#奇异值分解" class="headerlink" title="奇异值分解"></a>奇异值分解</h2><h3 id="基变换"><a href="#基变换" class="headerlink" title="基变换"></a>基变换</h3><p><strong>奇异值分解 Singular value decomposition</strong> 简称 SVD，实现如下：对矩阵做奇异值分解，首先如下图，先在行空间中找一组正交基 $\,v_1, v_2, \cdots, v_i\,$，然后通过矩阵 A 对其进行线性变换，得到列空间中一组正交基 $\,u_1, u_2, \cdots, u_i\,$，即 $\,Av_i = \sigma_i u_i$。其中 $\,\sigma_i\,$ 是伸缩因子。</p>
<div  align="center">  
<img src="https://s2.loli.net/2024/04/10/kqgoxnGuJ54YwAZ.png" width = "70%" height = "70%" alt="图14 - 奇异值分解"/>
</div>

<p>Gram-Schmidt 正交化可以找出矩阵 A 行空间中的正交基，但是随便的一组正交基经过矩阵矩阵 A 变换得到的向量并不一定正交，因此满足此要求的行空间的正交基非常特殊。</p>
<h3 id="矩阵形式"><a href="#矩阵形式" class="headerlink" title="矩阵形式"></a>矩阵形式</h3><p>接下来将上述过程用矩阵形式表示出来：  </p>
<script type="math/tex; mode=display">\begin{align*} A \begin{bmatrix} v_1 & v_2 & \cdots & v_r \end{bmatrix} &= \begin{bmatrix} \sigma_1u_1 & \sigma_2v_2 & \cdots & \sigma_r v_r \end{bmatrix} \\ &= \begin{bmatrix} u_1 & u_2 & \cdots & u_r \end{bmatrix} \begin{bmatrix} \sigma_1 &  &  & \\ & \sigma_2 &  & \\ &  & \cdots & \\ &  &  & \sigma_r \end{bmatrix} \end{align*}</script><p>上述等式可以写为 $\,AV = U \Sigma\,$，对其进行简单变形：$\,A = U \Sigma V^{-1} = U \Sigma V^T\,$，因为 V 与 U 都是正交基构成的正交矩阵，转置即为逆。这个形式就是 SVD 分解，任意矩阵都可以被分解为这个形式，即两个正交矩阵 U, V 以及一个对角矩阵 $\,\Sigma\,$。</p>
<h3 id="计算方式"><a href="#计算方式" class="headerlink" title="计算方式"></a>计算方式</h3><p>但是在这种变形方式中，U 与 V 并不好同时寻找，我们考虑使用变形技巧来简化求解过程，想办法将 U 消去，利用 U 是正交阵的性质，如：</p>
<script type="math/tex; mode=display">A^TA = V\Sigma U^TU \Sigma V^T = V \Sigma^2 V^T</script><p>上式其实就是正定矩阵 $\,A^TA\,$ 的正交分解，$\,v_i\,$ 就是矩阵 $\,A^TA\,$ 的特征向量，$\,\sigma_i^2\,$ 就是矩阵 $\,A^TA\,$ 的特征值。用同样的办法也可以求得 U，它的列向量就是矩阵 $\,AA^T\,$ 的特征向量。</p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>示例一：矩阵 $\,A = \begin{bmatrix} 4 &amp; 4 \\ -3 &amp; 3 \end{bmatrix}\,$</p>
<script type="math/tex; mode=display">A^TA = \begin{bmatrix} 25 & 7 \\ 7 & 25 \end{bmatrix}</script><p>对应求其特征值，特征向量，并将特征向量标准化：  </p>
<script type="math/tex; mode=display">\lambda_1 = \sigma_1^2 = 32, x_1 = \begin{bmatrix} 1 / \sqrt 2 \\ 1 / \sqrt 2 \end{bmatrix}</script><script type="math/tex; mode=display">\lambda_2 = \sigma_2^2 = 18, x_2 = \begin{bmatrix} 1 / \sqrt 2 \\ -1 / \sqrt 2 \end{bmatrix}</script><p>接下来，我们来求 $\,AA^T\,$ 来确定 U：  </p>
<script type="math/tex; mode=display">AA^T = \begin{bmatrix} 32 & 0 \\ 0 & 18 \end{bmatrix}</script><p>其对应的特征值与特征向量为：</p>
<script type="math/tex; mode=display">\lambda_1 = \sigma_1^2 = 32, x_1 = \begin{bmatrix} 1 \\ 0 \end{bmatrix}</script><script type="math/tex; mode=display">\lambda_2 = \sigma_2^2 = 18, x_2 = \begin{bmatrix} 0 \\ 1 \end{bmatrix}</script><p>这里得到的特征值与之前的是一样的。事实上，存在性质：BA 与 AB 的特征值相同。</p>
<p>完成了各个矩阵求解的工作，将矩阵 V 和 U 代入之前提到的分解式：$\,A = U \Sigma V^{-1} = U \Sigma V^T = \begin{bmatrix} 4 &amp; 4 \\ 3 &amp; -3 \end{bmatrix}\,$。但之前的矩阵是 $\,\begin{bmatrix} 4 &amp; 4 \\ -3 &amp; 3 \end{bmatrix}\,$，这是因为确定特征向量的过程中，特征向量反向仍然符合要求，通过现在的方法无法确认向量的符号，但是一旦我们确认 v 的方向之后，u 的方向也就随之确定。u 和 v 之间的符号联系在进行 $\,AA^T\,$ 的计算时被切断了，而用 $\,AV = U \Sigma\,$ 可以避免此问题。</p>
<hr>
<p>示例二：奇异阵 $\,A = \begin{bmatrix} 4 &amp; 3 \\ 8 &amp; 6 \end{bmatrix}\,$</p>
<p>易知 A 秩为 1，对应的行空间是一条直线，即（4,3）的倍数，零空间是与之垂直的一条直线。而同时，A 对应的列空间也是一条直线，即（4,8）的倍数，左零空间是与之垂直的一条直线。 </p>
<p>于是，由奇异值分解式的意义，行空间方向上的基：$\,v_1 = \begin{bmatrix} 0.8 \\ 0.6 \end{bmatrix}\,$，零空间方向上的基：$\,v_2 = \begin{bmatrix} 0.6 \\ -0.8 \end{bmatrix}\,$。列空间方向：$\,u_1 = 1/ \sqrt 5 \begin{bmatrix} 1 \\ 2 \end{bmatrix} \,$，左零空间方向：$\,u_2 = 1/ \sqrt 5 \begin{bmatrix} 2 \\ -1 \end{bmatrix} \,$。我们要寻找的 SVD，就是一种转换方式，将行空间与零空间上的基转换为列空间与左零空间上的基。</p>
<p>接下来代入 $\,A^TA\,$ 很容易求得 $\,\lambda_1 = \sigma_1^2 = 125\,$，$\,\lambda_2 = \sigma_2^2 = 0\,$，最后代入 $\,A = U \Sigma V^T\,$ 即可。</p>
<hr>
<p>总结：回忆这个奇异值分解的过程，我们所做的就是在线性代数的四个子空间中选出合适的基。</p>
<p>从 $\,v_1\,$ 到 $\,v_r\,$ 是矩阵行空间的标准正交基；<br>从 $\,u_1\,$ 到 $\,u_r\,$ 是矩阵行空间的标准正交基；<br>从 $\,v_{r+1}\,$ 到 $\,v_n\,$ 是矩阵行空间的标准正交基；<br>从 $\,u_{r+1}\,$ 到 $\,u_n\,$ 是矩阵行空间的标准正交基；  </p>
<p>SVD 很重要，与最小二乘法也有一定的联系。其实 SVD 的用处远不止我们介绍的这些而已。它还可以减小一些计算量，进行图像变换等。</p>
<div  align="center">  
<img src="https://s2.loli.net/2024/04/10/zKQcCyua1AlErNB.png" width = "70%" height = "70%" alt="图15 - 图为 G.Strang 给出的二阶方阵 SVD 的几何意义"/>
</div>


<h1 id="第三十一课-线性变换及对应矩阵"><a href="#第三十一课-线性变换及对应矩阵" class="headerlink" title="第三十一课 线性变换及对应矩阵"></a>第三十一课 线性变换及对应矩阵</h1><h2 id="线性变换"><a href="#线性变换" class="headerlink" title="线性变换"></a>线性变换</h2><p>首先直接给出线性变换满足的条件，对于任意向量 v，w 和标量 c：<br>①$\,T(v + w) = T(v) + T(w)\,$<br>②$\,T(cv) = cT(v)\,$（由此有：$\,T(0) = 0\,$）</p>
<p>将上面两个式子联系起来，即任何一个线性组合的线性变换等同于 T(v) 和 T(w) 的同样的线性组合：</p>
<script type="math/tex; mode=display">T(cv + dw) = cT(v) + dT(w)</script><p>T 可以理解为一种函数，有输入，有输出。例如投影，其输入就是一个向量，输出则是向量在直线上的投影。而投影本身就是一种线性变换，满足线性变换的两条性质。</p>
<h2 id="举例说明"><a href="#举例说明" class="headerlink" title="举例说明"></a>举例说明</h2><p>①平面平移：假如将整个平面都沿着某一方向平移 $\,v_0\,$，这是一个线性变换吗？</p>
<p>答：假设我们将向量 v 长度增加一倍，变换之后的向量显然不是原向量变换结果 T（v）的两倍。甚至这个变换连最基本的 T(0) = 0 都不满足。</p>
<p>②求长度 T(v) = |v|，是一个线性变换吗？</p>
<p>答：对于零向量而言 T(0) = 0，如果向量翻倍，它的长度也翻倍，没错。但是如果乘的是负数的话，这个变换就不满足数乘的性质了，即 $\,T(-v) \neq -T(v)\,$。故这不是线性变换。</p>
<p>③对于平面内的任意向量，将其逆时针旋转 45 度得到一个新的向量。</p>
<p>答：这满足上面的两条性质。旋转后相加或数乘对线性变换运算无影响。所以这个操作 T 是线性变换。</p>
<p>④给定线性变换：T(v) = Av</p>
<p>答：矩阵乘法是一个线性变换。满足 A(v+w) = A(v) + A(w)；A(cv) = cA(v)。所以理解线性变换的本质就是确定它背后的矩阵。</p>
<p>⑤对某一线性变换 T：R3 -&gt; R2，输入一个三维向量而输出是一个二维向量。变成矩阵的形式 T(v) = Av，则矩阵 A 是一个 2 × 3 矩阵。</p>
<h2 id="线性变换的基向量与坐标"><a href="#线性变换的基向量与坐标" class="headerlink" title="线性变换的基向量与坐标"></a>线性变换的基向量与坐标</h2><p>由于对于向量空间而言，所有向量都可以表示为基向量的线性组合。所以任意的向量的线性变换都可以用基向量的线性变换的结果进行表示：  </p>
<p>假设 $\,v = c_1v_1 + c_2v_2 + \cdots + c_nv_n\,$，则有 $\,T(v) = c_1T(v_1) + c_2T(v_2) + \cdots + c_nT(v_n)\,$</p>
<p>在笛卡尔坐标系下。坐标就是 x，y，这实际上是取坐标轴上的一组单位向量作为基向量的结果。</p>
<p>如果用矩阵 A 来表示线性变换 $\,T(R^n \to R^m)\,$。T 表示从 n 维空间到 m 维空间的变换。我们需要两组基：输入空间的一组基和输出空间的一组基，来分别确认输入向量与输出向量的坐标。设 v1，v2 … vn 为输入空间的基，而 w1，w2 … wm 为输出空间的基，用矩阵来表示线性变换就是将向量的坐标乘以矩阵得到它在输出空间的坐标。</p>
<hr>
<p>例如投影：  </p>
<p>将二维平面内的向量投影到一条直线，选择输入空间的基向量为 $\,v_1\,$，$\,v_2\,$，其中 $\,v_1\,$ 是沿着投影方向的向量，$\,v_2\,$ 是垂直于投影方向的向量，而输出空间的基选择为 $\,w_1 = v_1\,$，$\,w_2 = v_2\,$，这里的变换是从平面到平面，所以输入向量与输出向量共用一组基。</p>
<p>对于投影而言，$\,T(v_1) = v_1\,$，$\,T(v_2) = 0\,$，于是，对于一个输入向量 $\,v(c_1,c_2)\,$ 而言，得到的输出向量就是 $\,(c_1, 0)\,$。</p>
<p>把这变换过程描述为矩阵形式：$\,A = \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 0 \end{bmatrix}\,$，输入 $\,\begin{bmatrix} c_1 \\ c_2 \end{bmatrix}\,$ 得到 $\, \begin{bmatrix} 1 &amp; 0 \\ 0 &amp; 0 \end{bmatrix} \begin{bmatrix} c_1 \\ c_2 \end{bmatrix} = \begin{bmatrix} c_1 \\ 0 \end{bmatrix} \,$</p>
<p>回顾这个例子：选取的基一组与直线同向，一组与直线垂直垂直。之前介绍投影时说过，它们实际上都是投影的特征向量。所以得到的矩阵 A 是一个对角阵，对角线上都是特征值。这就证明了结论：<strong>如果以特征向量为基，可以得到线性变换的矩阵 A 是对角阵 $\,\Lambda\,$，对角线上都是特征值</strong>。</p>
<p>而如果我们以标准坐标为基，即 $\,w_1 = v_1 = \begin{bmatrix} 1 \\ 0 \end{bmatrix}\,$，$\,w_2 = v_2 = \begin{bmatrix} 0 \\ 1 \end{bmatrix}\,$。对应的投影矩阵就是之前学到的投影矩阵 $\,P = \cfrac {aa^T} {a^Ta}\,$。对于投影到斜率 45 度的直线，$\,P = \begin{bmatrix} 1/2 &amp; 1/2 \\ 1/2 &amp; 1/2 \end{bmatrix}\,$。</p>
<h2 id="如何确定矩阵-A"><a href="#如何确定矩阵-A" class="headerlink" title="如何确定矩阵 A"></a>如何确定矩阵 A</h2><p>矩阵 A 的列实际上是描述输入原空间的基向量得到的列空间线性组合的系数，$\,v_1,v_2,\cdots,v_n\,$ 来自 $\,R^n\,$ 空间的一组基，$\,w_1,w_2,\cdots,w_n\,$ 来自 $\,R^m\,$ 空间的一组基：</p>
<script type="math/tex; mode=display">T(v_1) = a_{11}w_1 + a_{21}w_2 + \cdots + a_{m1}w_m</script><script type="math/tex; mode=display">T(v_2) = a_{12}w_1 + a_{22}w_2 + \cdots + a_{m2}w_m</script><script type="math/tex; mode=display">...</script><p>其中 a 表示 A 矩阵中对应位置的元素。也就是说，计算 A 矩阵的方法是：选取基向量 $\,v_1,v_2,\cdots,v_n\,$。通过线性变换得到输出向量 $\,T(v_1),T(v_2),\cdots\,$。在输出空间里，$\,T(v_i)\,$ 就是输出基的线性组合 $\,a_{11}w_1 + a_{21}w_2 + \cdots + a_{m1}w_m\,$，这个线性组合的系数就是矩阵 A 的第 i 列。</p>
<p>通过这种方式得到的矩阵 A，如果给定输入坐标，就有：A(输入的坐标) = 输出坐标。</p>
<hr>
<p>介绍一个特别的线性变换：求导，$\,T = \cfrac {d} {dx}\,$</p>
<p>输入：$\,c_1 + c_2x + c_3x^2\,$，基：$\,1, x, x^2\,$<br>输出：$\,c_2 + 2c_3x\,$，基：$\,1, x\,$</p>
<p>这是一个 T：R3 -&gt; R2 的线性变化：  </p>
<p>矩阵 A 满足：$\,A \begin{bmatrix} c_1 \\ c_2 \\ c_3 \end{bmatrix} = \begin{bmatrix} c_2 \\ 2c_3 \end{bmatrix}\,$，可求得矩阵$\,A = \begin{bmatrix} 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 2 \end{bmatrix} \,$。</p>
<p>更普遍的来讲，矩阵的逆矩阵就是线性变换的逆变换，矩阵的乘积就是线性变换的乘积，矩阵乘法源自于线性变换。</p>
<h1 id="第三十二课-基变换和图像压缩"><a href="#第三十二课-基变换和图像压缩" class="headerlink" title="第三十二课 基变换和图像压缩"></a>第三十二课 基变换和图像压缩</h1><p>本讲介绍基变换，选择合适的基向量会给计算制造便利。基变换的一个重要应用就是压缩，图像、影像、音频和其它一些数据都会因为基变换而得到更高效的压缩储存。</p>
<h2 id="图像压缩"><a href="#图像压缩" class="headerlink" title="图像压缩"></a>图像压缩</h2><p>本讲涉及的压缩过程是有损压缩。例如一幅像素是 512x512 的静态黑白图像，图像用一个向量来表示，向量的分量 $\,x_i\,$ 表示像素的灰度，变化范围 $\,0 \le x_i \le 255\,$，占 8 bits。该向量属于 $\,R^n\,$ 空间，n = 512 x 512。如果是彩色图像长度就是三倍，就是 3 x 512 x 512。因为我们需要三个值来代表颜色。</p>
<p>图像的标准压缩方式为 JPEG（联合图像专家组 Joint Photographic Experts Group）。图像压缩的本质就是基变换。</p>
<p>压缩前图像采用的基向量是标准基。但是在图像中离得很近的区域，颜色是非常接近的，比如教学视频中黑板的一个区域，这些区域像素的灰度值很接近，但是用标准基来存储并没有利用上这一特点，这就给了我们压缩的空间。</p>
<p>标准基就是 $\,\begin{bmatrix} 1 \\ 0 \\ \vdots \\ 0 \end{bmatrix}\,$，$\,\begin{bmatrix} 0 \\ 1 \\ \vdots \\ 0 \end{bmatrix}\,$，…，$\,\begin{bmatrix} 0 \\ 0 \\ \vdots \\ 1 \end{bmatrix}\,$。而对于灰度很接近的情况，$\,\begin{bmatrix} 1 \\ 1 \\ \vdots \\ 1 \end{bmatrix}\,$ 是一个很好的基，代表低频信号，频率为 0，平滑，在图像压缩后经常会存在，因为其系数通常很大，，在一组基中有一个这样的向量能解决很大的问题，可以处理像素灰度接近一致的情况。</p>
<p>但图像不是灰度完全一致的，因此接下来的问题是跟它相配合的基要选择哪些。极端的情况包括选择 $\,\begin{bmatrix} +1 \\ -1 \\ +1 \\\vdots \end{bmatrix}\,$，它可以给出类似国际象棋盘那种黑白相间的状态（最高频信号，噪音、扰动……在图像压缩后很少存在）。</p>
<h2 id="傅里叶基"><a href="#傅里叶基" class="headerlink" title="傅里叶基"></a>傅里叶基</h2><p>JPEG 处理图像压缩的方法就是先将图像分块，在使用傅里叶基进行处理，最后进行压缩。</p>
<p>首先将 512 x 512 的区域划分为 8 x 8 的区块，每个区域中有 64 个元素，再使用傅里叶基进行变换。</p>
<p>8 x 8 的图像傅里叶基如下：  </p>
<script type="math/tex; mode=display">\begin{bmatrix} 1 \\ 1 \\ 1 \\ 1 \\ 1 \\ 1 \\ 1 \\ 1 \end{bmatrix},\begin{bmatrix} 1 \\ w \\ w^2 \\ w^3 \\ w^4 \\ w^5 \\ w^6 \\ w^7 \end{bmatrix},\begin{bmatrix} 1 \\ w^2 \\ w^4 \\ w^6 \\ w^8 \\ w^{10} \\ w^{12} \\ w^{14} \end{bmatrix},\cdots,\begin{bmatrix} 1 \\ w^7 \\ w^{14} \\ w^{21} \\ w^{28} \\ w^{35} \\ w^{42} \\ w^{49} \end{bmatrix}</script><p>整个处理流程如下图：</p>
<div  align="center">  
<img src="https://s2.loli.net/2024/04/11/qujSCz4mYZohyEJ.png" width = "70%" height = "70%" alt="图16 - JPEG 压缩流程"/>
</div>

<p>首先对输入的信号 x，从标准基变换为傅里叶基，得到系数 c，这一步是无损的过程。之后设置阀值进行压缩，超过阀值的认定为肉眼无法分辨的信号。在数学上表现为某些基向量的系数很小，这部分可以丢弃，随之得到新的系数 $\,\hat c\,$。将新的系数赋值在傅里叶基上求和得到 $\,\hat x = \sum {\hat c_i v_i}\,$。此时求和项已经不是 64 项，可能只剩下两三项，这就是压缩。</p>
<p>视频文件可以视为图像的序列，一幅一幅进行图像压缩即可。但这样做没有利用好视频的性质，因为视频是连续的，一幅图像和下一幅图像非常接近，因此可以存储一幅基础图像，随后只存储下一幅图像对它的修正部分。</p>
<h2 id="小波-Wavelets"><a href="#小波-Wavelets" class="headerlink" title="小波 Wavelets"></a>小波 Wavelets</h2><p>下面介绍另一组和傅里叶竞争的基向量，小波，在 8 x 8 的情况下，其基为：</p>
<script type="math/tex; mode=display">\begin{bmatrix} 1 \\ 1 \\ 1 \\ 1 \\ 1 \\ 1 \\ 1 \\ 1 \end{bmatrix},\begin{bmatrix} 1 \\ 1 \\ 1 \\ 1 \\ -1 \\ -1 \\ -1 \\ -1 \end{bmatrix},\begin{bmatrix} 1 \\ 1 \\ -1 \\ -1 \\ 0 \\ 0 \\ 0 \\ 0 \end{bmatrix}, \begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \\ 1 \\ 1 \\ -1 \\ -1 \end{bmatrix}, \begin{bmatrix} 1 \\ -1 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},\begin{bmatrix} 0 \\ 0 \\ 1 \\ -1 \\ 0 \\ 0 \\ 0 \\ 0 \end{bmatrix},\begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \\ 1 \\ -1 \\ 0 \\ 0 \end{bmatrix}, \begin{bmatrix} 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 1 \\ -1 \end{bmatrix}</script><p>这个只是一个小波选择，还有很多种更多精细的选择，这一组基中有太多从 +1 跳转到 -1 的变化。线性代数要做的基变换，就是将标准基下的向量 p 表示为小波基的线性组合，求出线性组合的参数 c 满足 $\,p = c_1w_1 + c_2w_2 + \cdots + c_8w_8\,$，即 $\,p = Wc\,$。W 即以小波基向量为列向量的小波矩阵，因此有 $\,c = W^{-1}p\,$</p>
<p>好的基向量组要求：第一，可以快速求逆矩阵，例如快速傅里叶变换，这里也存在快速小波变换，因为小波矩阵列向量正交，因此可以转置得到逆矩阵；第二，要少量基向量就可以近似信号，可压缩的比例就比较高。</p>
<h2 id="基变换-1"><a href="#基变换-1" class="headerlink" title="基变换"></a>基变换</h2><p>W 的列向量是新的基向量。x 是旧基下的一个向量，而 c 是新基下的对应得到的向量，则：  </p>
<script type="math/tex; mode=display">x = Wc</script><p>已知一个线性变换 T：R8 -&gt; R8。当使用空间的一组基 v1，v2 … v8 时，线性变换对应的矩阵为 A；当使用一组新的基 u1，u2 … u8 时，线性变换对应的矩阵为矩阵 B。两个矩阵对应的是同一个线性变换，只是使用了不同的基向量。那么 A 和 B 为相似矩阵，即 $\,B = M^{-1}AM\,$，M 是基变换矩阵。</p>
<p>如果我们使用的基向量就是特征向量 $\,T(v_i) = \lambda_i v_i\,$，矩阵 A 就变成对角阵 $\,\Lambda\,$。找出特征向量是压缩最理想的结果，但是找出图像的特征向量代价太大，因此我们找到代价小但是接近理想状态的基向量（例如小波基）进行基变换，完成压缩过程。</p>
<h1 id="第三十三课-复习三"><a href="#第三十三课-复习三" class="headerlink" title="第三十三课 复习三"></a>第三十三课 复习三</h1><h2 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h2><p>从对称矩阵开始，对称矩阵特征值永远为实数。并且总存在足够的特征向量实现矩阵的对角化 $\,A = Q \Lambda Q^T\,$，然后引出正定矩阵的概念。</p>
<p>之后还介绍了相似矩阵 $\,B = M^{-1}AM\,$，两矩阵具有相同的特征值，但是特征向量不同。</p>
<p>最后介绍了奇异值分解 SVD，$\,A = U \Sigma V^T\,$。</p>
<h2 id="例题"><a href="#例题" class="headerlink" title="例题"></a>例题</h2><p>例题一：解微分方程 $\,\cfrac {du} {dt} = Au = \begin{bmatrix} 0 &amp; -1 &amp; 0 \\ 1 &amp; 0 &amp; -1 \\ 0 &amp; 1 &amp; 0 \end{bmatrix}u\,$</p>
<p>①求通解 $\,u(t) = c_1e^{\lambda_1t}x_1 + c_2e^{\lambda_2t}x_2 + c_3e^{\lambda_3t}x_3\,$</p>
<p>首先求出矩阵的特征值，矩阵为奇异矩阵，因此具有一个特征值 0。矩阵为反对称矩阵，因此特征值为纯虚数。</p>
<script type="math/tex; mode=display">|A - \lambda I| = \begin{bmatrix} -\lambda & -1 & 0 \\ 1 & -\lambda & -1 \\ 0 & 1 & -\lambda \end{bmatrix} = -\lambda^3 - 2\lambda = 0</script><p>解得 $\,\lambda_1 = 0, \lambda_2 = \sqrt2 i, \lambda_3 = -\sqrt2 i\,$，则通解形式为 $\,u(t) = c_1x_1 + c_2e^{\sqrt2 it}x_2 + c_3e^{-\sqrt2 it}x_3\,$，解既不发散也不收敛，纯虚数特征值使得解的分量始终在单位圆上循环。</p>
<p>②解为周期性函数，何时返回初值？</p>
<p>因为 $\,e^0 = e^{2 \pi i} = 1\,$，即当 $\,\sqrt 2 i t = 2 \pi i\,$ 时返回初值，即 $\,t = \sqrt 2 \pi\,$。</p>
<p>③求出两个特征向量，证明其正交？</p>
<p>满足 $\,A^TA = AA^T\,$ 的矩阵具有正交的特征向量。对称和反对称矩阵都具有正交的特征向量。正交矩阵也符合此要求。将特征值代入，求得 $\,x_1 = \begin{bmatrix} 1 \\ 0 \\ 1 \end{bmatrix}, x_2 = \begin{bmatrix} -1 \\ \sqrt2 i \\ 1 \end{bmatrix}, x_1 = \begin{bmatrix} 1 \\ \sqrt2 i \\ -1 \end{bmatrix}\,$。可以用内积验证其正交性，要注意对复向量取内积要做共轭。</p>
<p>④微分方程的解写成矩阵指数形式为 $\,u(t) = e^{At}u(0)\,$，如何计算 $\,e^{At}\,$?</p>
<p>若有 $\,A = S \Lambda S^{-1}\,$，则有 $\,e^{At} = Se^{\Lambda t} S^{-1}\,$</p>
<p>因为这里的 A 满足 $\,A^TA = AA^T\,$，所以求得的特征向量是正交的，必然线性无关，直接代入即可。</p>
<hr>
<p>例题二：已知一个 3 x 3 矩阵 A 具有特征值 $\,\lambda_1 = 0,\lambda_2 = c,\lambda_3 = 2\,$。对应特征向量为 $\,x_1 = \begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix}, x_2 = \begin{bmatrix} 1 \\ -1 \\ 0 \end{bmatrix}, x_3 = \begin{bmatrix} 1 \\ 1 \\ -2 \end{bmatrix}\,$</p>
<p>①求 c 为何值时，这个矩阵 A 可以被对角化？</p>
<p>事实上，对于所有的 c 都可以对角化。因为这三个特征向量是相互正交的，所以这个矩阵具有三个线性无关的特征向量，可以构成 S，可以对角化。</p>
<p>②c 取何值时，矩阵对称？</p>
<p>对称阵的特征值都是实数，所以 c 取实数。</p>
<p>③c 取何值时，得到正定矩阵？</p>
<p>有一个特征值为 0，矩阵不可能正定。c 为实数且 c &gt;= 0 时，矩阵半正定。</p>
<p>④此矩阵可能是马尔可夫矩阵吗？</p>
<p>不可能，因为马尔科夫矩阵最大特征值为 1，但是这里有一个特征值大于 1。</p>
<p>⑤矩阵可能是一个投影矩阵的两倍吗？即 $\,P = 1/2 A\,$?</p>
<p>投影矩阵的特征值为 1 或者 0，所以当 c = 0 或者 2 时。</p>
<hr>
<p>例题三：对于矩阵 A 可做奇异值分解 $\,A = U \Sigma V^T\,$，已知 $\,\Sigma = \begin{bmatrix} 3 &amp; 0 \\ 0 &amp; 2 \end{bmatrix}\,$，并且矩阵 U 和 V 均为 2 列。</p>
<p>①对于矩阵 A 我们知道些什么？</p>
<p>矩阵 A 为二阶可逆矩阵。</p>
<p>②如果 $\,\Sigma = \begin{bmatrix} 3 &amp; 0 \\ 0 &amp; -5 \end{bmatrix}\,$？</p>
<p>不可能，因为奇异值分解要求奇异值大于 0。</p>
<p>③如果 $\,\Sigma = \begin{bmatrix} 3 &amp; 0 \\ 0 &amp; 0 \end{bmatrix}\,$？</p>
<p>矩阵为奇异阵，秩为 1，零空间的维数为 1。四个子空间由 U 和 V 的列向量张成。例如 v2 就在矩阵的零空间中。</p>
<hr>
<p>例题四：已知矩阵 A 对称且正交，回答下列问题。</p>
<p>①它的特征值可以等于什么？</p>
<p>对称矩阵的特征值为实数，正交矩阵的特征值的绝对值为 1。因此矩阵的特征值为 +1 或者 -1。</p>
<p>②矩阵 A 是否为正定矩阵？</p>
<p>特征值可以是 -1，非正定。</p>
<p>③这样的矩阵一定没有重特征值吗？</p>
<p>不一定，这个如果是 3x3 的矩阵，特征值只有两种选择，这时就有重复的特征值了。</p>
<p>④矩阵 A 可对角化么？</p>
<p>所有的对称矩阵和所有的正交矩阵都可对角化。</p>
<p>⑤矩阵 A 可逆么？</p>
<p>正交矩阵都可逆。</p>
<p>⑥证明 $\, P = 1/2 (A + I)\,$ 是投影矩阵</p>
<p>$\, P^2 = (1/2 (A + I))^2 = 1/4(A^2 + 2A + I)\,$。其中 $\,A^2 = A^TA = I\,$，所以 $\,P^2 = 1/2(A + I) = P\,$，因此它可以是投影矩阵。此外 1/2(A + I) 的特征值为 1 或者 0，并且是对称矩阵，这亦可证明它是投影矩阵。</p>
<h1 id="第三十四课-左右逆和伪逆"><a href="#第三十四课-左右逆和伪逆" class="headerlink" title="第三十四课 左右逆和伪逆"></a>第三十四课 左右逆和伪逆</h1><h2 id="两侧逆矩阵"><a href="#两侧逆矩阵" class="headerlink" title="两侧逆矩阵"></a>两侧逆矩阵</h2><p>即满秩逆矩阵，对于 m × n 的矩阵 A，若秩 r = m = n，则 A 为满秩矩阵，即有逆矩阵 $\,A^{-1}\,$，使 $\,AA^{-1} = A^{-1}A = I\,$</p>
<h2 id="左逆矩阵"><a href="#左逆矩阵" class="headerlink" title="左逆矩阵"></a>左逆矩阵</h2><p>对于 m × n 的矩阵 A，如果 A 列满秩，即 r = n &lt; m，列向量之间线性无关，而行向量不一定，此时矩阵零空间中只有零向量。此时方程 Ax = b 无解或者有唯一解。</p>
<p>对于 A 来说，$\,A^TA\,$ 很明显是个 n × n 对称矩阵，而且满秩。所以 $\,A^TA\,$ 是可逆的，即 $\,(A^TA)^{-1}A^TA = I\,$。如果看 A 左侧为一个整体，那么可以称 $\,A_{left}^{-1} = (A^TA)^{-1}A^T\,$ 为 A 的左逆矩阵。$\,A_{left}^{-1}\,$ 为 n × m 的矩阵。</p>
<h2 id="右逆矩阵"><a href="#右逆矩阵" class="headerlink" title="右逆矩阵"></a>右逆矩阵</h2><p>对于 m × n 的矩阵 A，如果 A 行满秩，即 r = m &lt; n，行向量之间线性无关，则矩阵的左零空间只有零向量。A 的零空间维数为 n - m，因此有 n - m 个自由变量，n 大于 m 时，方程 Ax = b 有无穷多解。</p>
<p>类比左逆，$\,AA^T(AA^T)^{-1} = I\,$，则 $\,A_{right}^{-1} = A^T(AA^T)^{-1}\,$</p>
<hr>
<p>通常情况下右乘左逆矩阵得不到单位阵，$\,AA_{left}^{-1} = A(A^TA)^{-1}A^T = P\,$，这是列空间的投影矩阵。仅在 m = n 的条件下，$\,AA_{left}^{-1} = I\,$。一个长方形矩阵 A 不可能有两侧逆，因为 $\,A\,$ 或 $\,A^T\,$ 总有一个零空间的维数不是 0。</p>
<p>同样的，左乘右逆矩阵得到的是 $\,A_{right}^{-1}A = A^T(AA^T)^{-1}A\,$，这是向行空间投影的矩阵。</p>
<p>注：满秩情况，两侧零空间都没了；列满秩情况，零空间没了；行满秩情况，左零空间没了</p>
<h2 id="伪逆矩阵-Pseudo-inverse"><a href="#伪逆矩阵-Pseudo-inverse" class="headerlink" title="伪逆矩阵 Pseudo-inverse"></a>伪逆矩阵 Pseudo-inverse</h2><p>可逆矩阵的零空间和左零空间只有零向量。列满秩的矩阵的零空间只有零向量，行满秩的矩阵的左零空间只有零向量。但对于不满秩的矩阵，其两个零空间均存在，这就使得它取不到逆矩阵。</p>
<p>逆矩阵的作用可以看作是原矩阵的逆操作，但是矩阵 A 对其零空间中向量操作后变为 0，这时没有逆操作能够恢复这一过程，所以带有零空间就不能取逆矩阵。</p>
<p>观察不满秩矩阵 A 的四个子空间，如下图，其行空间和列空间的维数相等，均为 r。在其行空间中的向量 x 经过矩阵 A 操作后，变为列空间中的向量 Ax。而 x 与 Ax 为对应的关系。如果将矩阵 A 限制在行空间和列空间上，它是个可逆矩阵，此时 A 的逆矩阵就是所谓的“伪逆矩阵 $\,A^+\,$”</p>
<div  align="center">  
<img src="https://s2.loli.net/2024/04/12/MNrpFHXD5VeoAcz.png" width = "70%" height = "70%" alt="图17 - 伪逆"/>
</div>

<p>问题的关键就是一一对应关系，即对于行空间中的向量 $\,x \neq y\,$，其通过矩阵 A 映射到列空间得到的向量 $\,Ax \neq Ay\,$。</p>
<p>证明：若行空间中存在向量 y 与向量 x 在列空间中对应的向量相同，则有 Ax - Ay = 0，即 A(x-y) = 0，则 x - y 为矩阵 A 零空间中的向量，但矩阵的行空间对线性运算封闭，因此 x - y 为行空间中的向量，因两个子空间正交，所以有 x - y = 0，即 x 与 y 相同。因此行空间与列空间中的向量为一一对应。</p>
<p>统计学家非常需要伪逆矩阵，因为他们要做很多最小二乘法进行线性回归的问题。如果矩阵不满秩，则矩阵 $\,A^TA\,$ 为不可逆，所以无法用之前的办法解决，此时要用到伪逆矩阵。</p>
<h2 id="伪逆求解"><a href="#伪逆求解" class="headerlink" title="伪逆求解"></a>伪逆求解</h2><p>求伪逆矩阵 $\,A^+\,$ 的一个方法是利用奇异值分解 $\,A = U \Sigma V^T\,$，其中对角阵 $\,\Sigma\,$ 是由矩阵奇异值排列在对角线上构成的 m x n 矩阵，其秩为 r。则伪逆矩阵 $\,A^+\,$ 为 n x m 矩阵，矩阵的秩也为 r。</p>
<script type="math/tex; mode=display">\Sigma = \begin{bmatrix} \sigma_1 &  &  & \\ & \sigma_2 &  & \\ &  & \cdots & \\ &  &  & \sigma_r \end{bmatrix}</script><p>$\,\Sigma\,$ 的伪逆 $\,\Sigma^+\,$ 为：  </p>
<script type="math/tex; mode=display">\Sigma^+ = \begin{bmatrix} 1/\sigma_1 &  &  & \\ & 1/\sigma_2 &  & \\ &  & \cdots & \\ &  &  & 1/\sigma_r \end{bmatrix}</script><p>计算得到的 $\,\Sigma\Sigma^+\,$ 与 $\,\Sigma^+\Sigma\,$ 不同，一个是 n × n 矩阵，另一个是 m × m。这两个都是 $\,\Sigma\,$ 的投影矩阵，一个投影到行空间，一个投影到列空间。</p>
<p>介绍完了 $\,\Sigma\,$ 的伪逆求法，那么 A 本身的伪逆就好求了：$\,A^+ = V \Sigma^+ U^T\,$。</p>
<h1 id="第三十五课-总复习"><a href="#第三十五课-总复习" class="headerlink" title="第三十五课 总复习"></a>第三十五课 总复习</h1><h2 id="例题-1"><a href="#例题-1" class="headerlink" title="例题"></a>例题</h2><p>【例 1】已知 $\,Ax = \begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix}\,$ 无解， $\,Ax = \begin{bmatrix} 0 \\ 1 \\ 0 \end{bmatrix}\,$ 有一个解。</p>
<p>①A 是一个 m x n 的矩阵，秩为 r，试求解 m，n，r 这三个未知量间的关系。</p>
<p>m = 3。第一个无解说明 r 小于 m，第二个方程仅有一解说明矩阵零空间只有零向量，所以 r = n。例如 $\,A = \begin{bmatrix} 0 \\ 1 \\ 0 \end{bmatrix}\,$ 或者 $\,A = \begin{bmatrix} 0 &amp; 0 \\ 1 &amp; 0 \\ 0 &amp; 1 \end{bmatrix}\,$</p>
<p>②$\,det(A^TA) = det(AA^T)\,$ 是否成立？</p>
<p>不成立，由后面两问知上述两个矩阵分别是可逆和不可逆的矩阵：这两个行列式的值一个为 0，一个不为零，故二者不相等。如果 A 是方阵，那么上面的等式就是成立的。</p>
<p>③$\,A^TA\,$ 是否可逆？</p>
<p>可逆，这判断不需要实际算出矩阵这里，因为 r = n，列满秩。此时矩阵 A 各列线性无关，矩阵可逆。</p>
<p>④$\,AA^T\,$ 是否正定？</p>
<p>否，不满秩，不可能是正定矩阵。</p>
<p>⑤求证：对于方程 $\,A^Ty = c\,$（c 为任意向量）至少有一解</p>
<p>矩阵 A 行满秩，r = n &lt; m ，故该方程有无穷多解。</p>
<hr>
<p>【例 2】已知 $\,A = \begin{bmatrix} v_1 &amp; v_2 &amp; v_3 \end{bmatrix}\,$</p>
<p>①解方程：求解 $\,Ax = v_1 - v_2 + v_3\,$</p>
<p>显然 $\,x = \begin{bmatrix} 1 \\ -1 \\ 1 \end{bmatrix}\,$</p>
<p>②若 $\,v_1 - v_2 + v_3 = 0\,$，那么解是否唯一？</p>
<p>列向量线性相关，零空间有非零向量，Ax = 0 解不唯一。</p>
<p>③若 $\,v_1, v_2, v_3\,$ 为标准正交，求 $\,v_1, v_2\,$ 线性组合距离 $\,v_3\,$ 最近？</p>
<p>原点。</p>
<hr>
<p>【例 3】已知一个马尔科夫矩阵 $\,A = \begin{bmatrix} 0.2 &amp; 0.4 &amp; 0.3 \\ 0.4 &amp; 0.2 &amp; 0.3 \\ 0.4 &amp; 0.4 &amp; 0.4 \end{bmatrix}\,$</p>
<p>①求其特征值？</p>
<p>首先观察到矩阵 A，发现 A 不可逆，三列线性相关。故 A 有一个特征值为 0，另外，这是一个马尔科夫矩阵，因此有一个特征值为 1，另外矩阵的迹为 0.8，故第三个特征值为 -0.2。</p>
<p>②设 $\,u_0 = \begin{bmatrix} 0 \\ 10 \\ 0 \end{bmatrix}\,$，$\,u_k = A^ku_0\,$，当 k 趋近于无穷时的状态？</p>
<p>$\,u_k = c_1\lambda_1^kx_1 + c_2\lambda_2^kx_2 + c_3\lambda_3^kx_3\,$。代入特征值可知，当 k 趋近于无穷时，只剩下 $\,c_2x_2\,$。根据特征值求解特征向量，得到 $\,x_2 = \begin{bmatrix} 3 \\ 3 \\ 4 \end{bmatrix}\,$，即最终的分配比例为 3:3:4。</p>
<hr>
<p>【例 4】求解各个满足性质的二阶矩阵</p>
<p>①将向量投影到 $\,a = \begin{bmatrix} 4 \\ -3 \end{bmatrix}\,$ 所在直线的矩阵 P</p>
<p>直接代入投影矩阵公式即可：$\,a = \cfrac {a a^T} {a^T a}\,$</p>
<p>②矩阵的特征值和对应的特征向量分别是：0，3；$\,\begin{bmatrix} 1 \\ 2 \end{bmatrix}, \begin{bmatrix} 2 \\ 1 \end{bmatrix}\,$</p>
<p>两个特征向量线性无关，直接套用对角化公式：$\,A = S \Lambda S^{-1}\,$</p>
<p>③给出一个矩阵 A，不能分解成 $\,B^TB\,$ 的形式</p>
<p>$\,B^TB\,$ 是对称的，故我们只要给出一个非对称的矩阵即可。</p>
<p>④给出一个矩阵，有正交的特征向量，但不是对称的</p>
<p>反对称矩阵或者在复数域上有正交特征向量的其它矩阵。</p>
<hr>
<p>【例 5】在最小二乘的范畴内讨论问题。给定 Ax = b 形式：  </p>
<script type="math/tex; mode=display">\begin{bmatrix} 1 & 0 \\ 1 & 1 \\ 1 & 2 \end{bmatrix} \begin{bmatrix} \hat C \\ \hat D \end{bmatrix} = \begin{bmatrix} 3 \\ 4 \\ 1 \end{bmatrix}, \begin{bmatrix} \hat C \\ \hat D \end{bmatrix} = \begin{bmatrix} 11/3 \\ -1 \end{bmatrix}</script><p>①求 b 到 A 的列空间的投影 p</p>
<p>由最小二乘的意义，这里的投影就是将 $\,\begin{bmatrix} \hat C \\ \hat D \end{bmatrix} = \begin{bmatrix} 11/3 \\ -1 \end{bmatrix}\,$ 代入得到 $\,p = \begin{bmatrix} 1 &amp; 0 \\ 1 &amp; 1 \\ 1 &amp; 2 \end{bmatrix} \begin{bmatrix} 11/3 \\ -1 \end{bmatrix} = \begin{bmatrix} 11/3 \\ 8/3 \\ 5/3 \end{bmatrix}\,$</p>
<p>②找出另一个非零向量 b 使得最小二乘的结果是 0，就是将问题变为：寻找 $\,\begin{bmatrix} 1 &amp; 0 \\ 1 &amp; 1 \\ 1 &amp; 2 \end{bmatrix} \begin{bmatrix} \hat C \\ \hat D \end{bmatrix} = b\,$ 中的 b，使得 $\,\begin{bmatrix} \hat C \\ \hat D \end{bmatrix} = 0\,$</p>
<p>b 要与系数矩阵的列空间正交，才会使得最优解为 0。解得 $\,b = \begin{bmatrix} 1 \\ -2 \\ 1 \end{bmatrix}\,$。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://ybniaobu.github.io">鸟布</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://ybniaobu.github.io/2024/02/22/2024-02-22-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%803/">https://ybniaobu.github.io/2024/02/22/2024-02-22-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%803/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://ybniaobu.github.io" target="_blank">鸟布的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/">游戏开发</a><a class="post-meta__tags" href="/tags/%E6%95%B0%E5%AD%A6/">数学</a><a class="post-meta__tags" href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/">线性代数</a></div><div class="post_share"><div class="social-share" data-image="https://s2.loli.net/2024/02/18/NjAQJ5diwBHTKzc.gif" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/images/wechat.png" target="_blank"><img class="post-qr-code-img" src="/images/wechat.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/images/alipay.png" target="_blank"><img class="post-qr-code-img" src="/images/alipay.png" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/02/23/2024-02-23-URP%E5%9F%BA%E7%A1%80/" title="Unity URP 基础"><img class="cover" src="https://s2.loli.net/2024/02/18/pMAzYioaFZEkS8I.gif" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Unity URP 基础</div></div></a></div><div class="next-post pull-right"><a href="/2024/02/18/2024-02-18-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%802/" title="MIT 线性代数公开课笔记（二）"><img class="cover" src="https://s2.loli.net/2024/02/18/6rKVn5pm3sXlxS8.gif" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">MIT 线性代数公开课笔记（二）</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/02/05/2024-02-05-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%801/" title="MIT 线性代数公开课笔记（一）"><img class="cover" src="https://s2.loli.net/2024/03/20/wpVnygJlIjor2Rb.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-05</div><div class="title">MIT 线性代数公开课笔记（一）</div></div></a></div><div><a href="/2024/02/18/2024-02-18-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%802/" title="MIT 线性代数公开课笔记（二）"><img class="cover" src="https://s2.loli.net/2024/02/18/6rKVn5pm3sXlxS8.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-18</div><div class="title">MIT 线性代数公开课笔记（二）</div></div></a></div><div><a href="/2023/07/09/2023-07-09-Unity%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%9D%82%E8%AE%B0/" title="Unity基础"><img class="cover" src="https://s2.loli.net/2023/09/19/zXfAWqLZlxQwdU1.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-07-09</div><div class="title">Unity基础</div></div></a></div><div><a href="/2023/09/15/2023-09-15-UnityShader1/" title="《Unity Shader入门精要》读书笔记（一）"><img class="cover" src="https://s2.loli.net/2023/09/19/cDvdURBPhjwkOsY.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-15</div><div class="title">《Unity Shader入门精要》读书笔记（一）</div></div></a></div><div><a href="/2023/11/22/2023-11-22-UnityShader3/" title="《Unity Shader入门精要》读书笔记（三）"><img class="cover" src="https://s2.loli.net/2023/11/23/L3ts4WnThMlDN9d.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-22</div><div class="title">《Unity Shader入门精要》读书笔记（三）</div></div></a></div><div><a href="/2023/10/13/2023-10-13-UnityShader2/" title="《Unity Shader入门精要》读书笔记（二）"><img class="cover" src="https://s2.loli.net/2023/10/15/RZftaNSscWoLH1u.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-13</div><div class="title">《Unity Shader入门精要》读书笔记（二）</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/images/wechat%20avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">鸟布</div><div class="author-info__description">教练，我想学技术</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">31</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://niaobu.notion.site/787824630ea6480e944c1ae5ae7f4792"><i class="fa-solid fa-book"></i><span>My Notion</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ybniaobu/ybniaobu.github.io" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:niaobubob@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">为了蒂法！！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E5%8D%81%E5%85%AD%E8%AF%BE-%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E5%92%8C%E6%AD%A3%E5%AE%9A%E6%80%A7"><span class="toc-number">1.</span> <span class="toc-text">第二十六课 对称矩阵和正定性</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5"><span class="toc-number">1.1.</span> <span class="toc-text">对称矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E5%88%86%E8%A7%A3"><span class="toc-number">1.2.</span> <span class="toc-text">对称矩阵的分解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E5%AE%9E%E7%89%B9%E5%BE%81%E5%80%BC"><span class="toc-number">1.3.</span> <span class="toc-text">对称矩阵的实特征值</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84%E5%8F%A6%E4%B8%80%E7%A7%8D%E7%90%86%E8%A7%A3"><span class="toc-number">1.4.</span> <span class="toc-text">对称矩阵的另一种理解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5%E7%AE%80%E4%BB%8B"><span class="toc-number">1.5.</span> <span class="toc-text">正定矩阵简介</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E5%8D%81%E4%B8%83%E8%AF%BE-%E5%A4%8D%E7%9F%A9%E9%98%B5%EF%BC%8C%E5%BF%AB%E9%80%9F%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2"><span class="toc-number">2.</span> <span class="toc-text">第二十七课 复矩阵，快速傅里叶变换</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%8D%E5%90%91%E9%87%8F"><span class="toc-number">2.1.</span> <span class="toc-text">复向量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%8D%E7%9F%A9%E9%98%B5"><span class="toc-number">2.2.</span> <span class="toc-text">复矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%82%85%E9%87%8C%E5%8F%B6%E7%9F%A9%E9%98%B5"><span class="toc-number">2.3.</span> <span class="toc-text">傅里叶矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BF%AB%E9%80%9F%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2"><span class="toc-number">2.4.</span> <span class="toc-text">快速傅里叶变换</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E5%8D%81%E5%85%AB%E8%AF%BE-%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5%E5%92%8C%E6%9C%80%E5%B0%8F%E5%80%BC"><span class="toc-number">3.</span> <span class="toc-text">第二十八课 正定矩阵和最小值</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5"><span class="toc-number">3.1.</span> <span class="toc-text">正定矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%A4%E6%8D%AE%E5%BC%8F"><span class="toc-number">3.2.</span> <span class="toc-text">判据式</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E5%8D%81%E4%B9%9D%E8%AF%BE-%E7%9B%B8%E4%BC%BC%E7%9F%A9%E9%98%B5%E5%92%8C%E8%8B%A5%E5%B0%94%E5%BD%93%E6%A0%87%E5%87%86%E5%9E%8B"><span class="toc-number">4.</span> <span class="toc-text">第二十九课 相似矩阵和若尔当标准型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E5%AE%9A%E7%9F%A9%E9%98%B5%E8%A1%A5%E5%85%85"><span class="toc-number">4.1.</span> <span class="toc-text">正定矩阵补充</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B8%E4%BC%BC%E7%9F%A9%E9%98%B5"><span class="toc-number">4.2.</span> <span class="toc-text">相似矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%8B%A5%E5%B0%94%E5%BD%93%E6%A0%87%E5%87%86%E5%9E%8B"><span class="toc-number">4.3.</span> <span class="toc-text">若尔当标准型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%8D%E7%89%B9%E5%BE%81%E5%80%BC%E7%9A%84%E7%9B%B8%E4%BC%BC%E6%83%85%E5%86%B5"><span class="toc-number">4.3.1.</span> <span class="toc-text">重特征值的相似情况</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%8B%A5%E5%B0%94%E5%BD%93%E6%A0%87%E5%87%86%E5%9E%8B-1"><span class="toc-number">4.3.2.</span> <span class="toc-text">若尔当标准型</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E5%8D%81%E8%AF%BE-%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3"><span class="toc-number">5.</span> <span class="toc-text">第三十课 奇异值分解</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3"><span class="toc-number">5.1.</span> <span class="toc-text">奇异值分解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E5%8F%98%E6%8D%A2"><span class="toc-number">5.1.1.</span> <span class="toc-text">基变换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E5%BD%A2%E5%BC%8F"><span class="toc-number">5.1.2.</span> <span class="toc-text">矩阵形式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F"><span class="toc-number">5.1.3.</span> <span class="toc-text">计算方式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B"><span class="toc-number">5.2.</span> <span class="toc-text">示例</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E5%8D%81%E4%B8%80%E8%AF%BE-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E5%8F%8A%E5%AF%B9%E5%BA%94%E7%9F%A9%E9%98%B5"><span class="toc-number">6.</span> <span class="toc-text">第三十一课 线性变换及对应矩阵</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2"><span class="toc-number">6.1.</span> <span class="toc-text">线性变换</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BE%E4%BE%8B%E8%AF%B4%E6%98%8E"><span class="toc-number">6.2.</span> <span class="toc-text">举例说明</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E7%9A%84%E5%9F%BA%E5%90%91%E9%87%8F%E4%B8%8E%E5%9D%90%E6%A0%87"><span class="toc-number">6.3.</span> <span class="toc-text">线性变换的基向量与坐标</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E7%A1%AE%E5%AE%9A%E7%9F%A9%E9%98%B5-A"><span class="toc-number">6.4.</span> <span class="toc-text">如何确定矩阵 A</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E5%8D%81%E4%BA%8C%E8%AF%BE-%E5%9F%BA%E5%8F%98%E6%8D%A2%E5%92%8C%E5%9B%BE%E5%83%8F%E5%8E%8B%E7%BC%A9"><span class="toc-number">7.</span> <span class="toc-text">第三十二课 基变换和图像压缩</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%BE%E5%83%8F%E5%8E%8B%E7%BC%A9"><span class="toc-number">7.1.</span> <span class="toc-text">图像压缩</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%82%85%E9%87%8C%E5%8F%B6%E5%9F%BA"><span class="toc-number">7.2.</span> <span class="toc-text">傅里叶基</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E6%B3%A2-Wavelets"><span class="toc-number">7.3.</span> <span class="toc-text">小波 Wavelets</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E5%8F%98%E6%8D%A2-1"><span class="toc-number">7.4.</span> <span class="toc-text">基变换</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E5%8D%81%E4%B8%89%E8%AF%BE-%E5%A4%8D%E4%B9%A0%E4%B8%89"><span class="toc-number">8.</span> <span class="toc-text">第三十三课 复习三</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9E%E9%A1%BE"><span class="toc-number">8.1.</span> <span class="toc-text">回顾</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BE%8B%E9%A2%98"><span class="toc-number">8.2.</span> <span class="toc-text">例题</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E5%8D%81%E5%9B%9B%E8%AF%BE-%E5%B7%A6%E5%8F%B3%E9%80%86%E5%92%8C%E4%BC%AA%E9%80%86"><span class="toc-number">9.</span> <span class="toc-text">第三十四课 左右逆和伪逆</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%A4%E4%BE%A7%E9%80%86%E7%9F%A9%E9%98%B5"><span class="toc-number">9.1.</span> <span class="toc-text">两侧逆矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B7%A6%E9%80%86%E7%9F%A9%E9%98%B5"><span class="toc-number">9.2.</span> <span class="toc-text">左逆矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%B3%E9%80%86%E7%9F%A9%E9%98%B5"><span class="toc-number">9.3.</span> <span class="toc-text">右逆矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%AA%E9%80%86%E7%9F%A9%E9%98%B5-Pseudo-inverse"><span class="toc-number">9.4.</span> <span class="toc-text">伪逆矩阵 Pseudo-inverse</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%AA%E9%80%86%E6%B1%82%E8%A7%A3"><span class="toc-number">9.5.</span> <span class="toc-text">伪逆求解</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E5%8D%81%E4%BA%94%E8%AF%BE-%E6%80%BB%E5%A4%8D%E4%B9%A0"><span class="toc-number">10.</span> <span class="toc-text">第三十五课 总复习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BE%8B%E9%A2%98-1"><span class="toc-number">10.1.</span> <span class="toc-text">例题</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/05/21/2024-05-21-PBR_Theory1/" title="PBR 理论基础（一）"><img src="https://s2.loli.net/2024/05/21/6QnAbYhwJX4Bavl.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="PBR 理论基础（一）"/></a><div class="content"><a class="title" href="/2024/05/21/2024-05-21-PBR_Theory1/" title="PBR 理论基础（一）">PBR 理论基础（一）</a><time datetime="2024-05-21T06:20:48.000Z" title="发表于 2024-05-21 14:20:48">2024-05-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/04/23/2024-04-23-GAMES_101_2/" title="GAMES101-图形学入门公开课笔记（二）"><img src="https://s2.loli.net/2024/04/23/AnT1Gf8cdqDa69b.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="GAMES101-图形学入门公开课笔记（二）"/></a><div class="content"><a class="title" href="/2024/04/23/2024-04-23-GAMES_101_2/" title="GAMES101-图形学入门公开课笔记（二）">GAMES101-图形学入门公开课笔记（二）</a><time datetime="2024-04-23T13:53:41.000Z" title="发表于 2024-04-23 21:53:41">2024-04-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/04/05/2024-04-05-GAMES_101_1/" title="GAMES101-图形学入门公开课笔记（一）"><img src="https://s2.loli.net/2024/04/05/bQhEat4gmx9UWIX.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="GAMES101-图形学入门公开课笔记（一）"/></a><div class="content"><a class="title" href="/2024/04/05/2024-04-05-GAMES_101_1/" title="GAMES101-图形学入门公开课笔记（一）">GAMES101-图形学入门公开课笔记（一）</a><time datetime="2024-04-05T11:16:20.000Z" title="发表于 2024-04-05 19:16:20">2024-04-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/03/26/2024-03-26-NPR_StarRail2/" title="基于星穹铁道的卡通渲染（二）"><img src="https://s2.loli.net/2024/03/26/kxdT3sE6wS9LXbp.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于星穹铁道的卡通渲染（二）"/></a><div class="content"><a class="title" href="/2024/03/26/2024-03-26-NPR_StarRail2/" title="基于星穹铁道的卡通渲染（二）">基于星穹铁道的卡通渲染（二）</a><time datetime="2024-03-26T07:25:22.000Z" title="发表于 2024-03-26 15:25:22">2024-03-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/03/20/2024-03-20-NPR_StarRail1/" title="基于星穹铁道的卡通渲染（一）"><img src="https://s2.loli.net/2024/03/26/dZTwsApi59CSUal.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="基于星穹铁道的卡通渲染（一）"/></a><div class="content"><a class="title" href="/2024/03/20/2024-03-20-NPR_StarRail1/" title="基于星穹铁道的卡通渲染（一）">基于星穹铁道的卡通渲染（一）</a><time datetime="2024-03-20T05:25:53.000Z" title="发表于 2024-03-20 13:25:53">2024-03-20</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By 鸟布</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Your time is limited, so don't waste it living someone else's life.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>