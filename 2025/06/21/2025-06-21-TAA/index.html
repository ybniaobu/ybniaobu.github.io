<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Temporal Anti-Aliasing (TAA) | 鸟布的博客</title><meta name="author" content="鸟布"><meta name="copyright" content="鸟布"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本文章主要内容有 TAA 基本原理和实现，包括 Jitter、History Blending、Reprojection、Color Clamping、Weighted Blending Factor、Depth Dilation、Filter 等步骤；以及在 Unity 实现 Object Mot"><link rel="shortcut icon" href="https://s2.loli.net/2022/09/08/Ygib4lfw6z1khnr.png"><link rel="canonical" href="https://ybniaobu.github.io/2025/06/21/2025-06-21-TAA/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 鸟布","link":"链接: ","source":"来源: 鸟布的博客","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Temporal Anti-Aliasing (TAA)',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-07-31 21:49:12'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/images/wechat%20avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">47</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-bars"></i><span> 目录</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/images/black.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="鸟布的博客"><span class="site-name">鸟布的博客</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-bars"></i><span> 目录</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Temporal Anti-Aliasing (TAA)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-06-21T11:43:03.000Z" title="发表于 2025-06-21 19:43:03">2025-06-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-31T13:49:12.822Z" title="更新于 2025-07-31 21:49:12">2025-07-31</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/unity/">unity</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/">图形学</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/unity/pipeline/">pipeline</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">17.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>63分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Temporal Anti-Aliasing (TAA)"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote>
<p>本来是想先实现 SSGI 或者 SSR 的，但是研究着研究着，就发现 SSGI 或 SSR 的思想都有些许依赖于 SSAO 相关技术算法（SSAO、SSDO、HBAO、GTAO 等等），然后就想着要不先实现 SSAO，但是研究着研究着，又发现 SSAO 等相关随机技术（<strong>Stochastic Algorithms</strong>）跟 PCSS 一样较为依赖于降噪技术，降噪技术又可以分为<strong>空间滤波 Spatial Filter</strong> 以及<strong>时间滤波 Temporal Filter</strong>。所以为了打好基础，最终决定先实现 <strong>Temporal Anti-Aliasing (TAA)</strong>，对<strong>抖动 jitter</strong> 有个更深入的理解后，再进入全局光照的实现，顺便也能优化一下 PCSS。</p>
<p>本篇文章具体实现是在 Unity 当中，主要参考了以下几篇文章或演讲或 PPT（加粗的文章更综合地介绍了 TAA 技术，建议优先观看）：<br>① High Quality Temporal Supersampling（SIGGRAPH 2014）：<a target="_blank" rel="noopener" href="https://advances.realtimerendering.com/s2014/#_HIGH-QUALITY_TEMPORAL_SUPERSAMPLING">https://advances.realtimerendering.com/s2014/#_HIGH-QUALITY_TEMPORAL_SUPERSAMPLING</a> or <a target="_blank" rel="noopener" href="https://de45xmedrsdbp.cloudfront.net/Resources/files/TemporalAA_small-59732822.pdf">https://de45xmedrsdbp.cloudfront.net/Resources/files/TemporalAA_small-59732822.pdf</a> ；<br>② <strong>A Survey of Temporal Antialiasing Techniques</strong> ：<a target="_blank" rel="noopener" href="https://research.nvidia.com/labs/rtr/publication/yang2020survey/">https://research.nvidia.com/labs/rtr/publication/yang2020survey/</a> ；<br>③ <strong>Temporal AA and the Quest for the Holy Trail</strong> ：<a target="_blank" rel="noopener" href="https://www.elopezr.com/temporal-aa-and-the-quest-for-the-holy-trail/">https://www.elopezr.com/temporal-aa-and-the-quest-for-the-holy-trail/</a> ；<br>④ Temporal Reprojection Anti-Aliasing in INSIDE（GDC 2016）：<a target="_blank" rel="noopener" href="https://www.gdcvault.com/play/1022970/Temporal-Reprojection-Anti-Aliasing-in">https://www.gdcvault.com/play/1022970/Temporal-Reprojection-Anti-Aliasing-in</a> ；<br>⑤ An Excursion in Temporal Supersampling（GDC 2016）：<a target="_blank" rel="noopener" href="https://developer.download.nvidia.com/gameworks/events/GDC2016/msalvi_temporal_supersampling.pdf">https://developer.download.nvidia.com/gameworks/events/GDC2016/msalvi_temporal_supersampling.pdf</a> ；<br>⑥ Temporal Antialiasing in Uncharted 4（SIGGRAPH 2016）：<a target="_blank" rel="noopener" href="https://advances.realtimerendering.com/s2016/">https://advances.realtimerendering.com/s2016/</a> ；<br>⑦ Temporal Antialiasing Starter Pack ：<a target="_blank" rel="noopener" href="https://alextardif.com/TAA.html">https://alextardif.com/TAA.html</a> ；<br>⑧ Temporal Anti Aliasing – Step by Step ：<a target="_blank" rel="noopener" href="https://ziyadbarakat.wordpress.com/2020/07/28/temporal-anti-aliasing-step-by-step/">https://ziyadbarakat.wordpress.com/2020/07/28/temporal-anti-aliasing-step-by-step/</a> ；<br>⑨ Adaptive Temporal Antialiasing ：<a target="_blank" rel="noopener" href="https://research.nvidia.com/publication/2018-08_adaptive-temporal-antialiasing">https://research.nvidia.com/publication/2018-08_adaptive-temporal-antialiasing</a> ；<br>⑩ Rendering The Alternate History of The Order 1886（SIGGRAPH 2015）：<a target="_blank" rel="noopener" href="https://advances.realtimerendering.com/s2015/#_REFLECTION_SYSTEM_IN">https://advances.realtimerendering.com/s2015/#_REFLECTION_SYSTEM_IN</a> 。</p>
</blockquote>
<h1 id="TAA-原理及流程简单介绍"><a href="#TAA-原理及流程简单介绍" class="headerlink" title="TAA 原理及流程简单介绍"></a>TAA 原理及流程简单介绍</h1><p><strong>时域抗锯齿 Temporal Anti-Aliasing (TAA)</strong> 用一句话概括可以说是使用了历史帧中的<strong>子/次/亚像素 subpixel</strong> 进行累计从而更有效地实现<strong>超采样抗锯齿 Supersampling Anti-Aliasing (SSAA)</strong>。相对于 SSAA 或 MSAA 来说，TAA 有效地将一个像素多次采样分摊到了连续的几帧当中，即以一个像素一次采样的代价实现了超采样抗锯齿。与此同时，单帧光栅化单像素采样，实际上会“损失”一些亚像素信息的，而 TAA 通过抖动在历史帧中解析出单帧光栅化以及单像素采样中丢失的亚像素信息，从而能够更好地解决<strong>几何锯齿 Geometric Aliasing</strong>（几何光栅化锯齿） 和<strong>着色锯齿 Shading Aliasing</strong>（渲染锯齿），也相对来说增加了基于时序的稳定性。特别是当物体或相机移动时，图元边缘相对于采样点的位置不断变化，导致边缘像素的覆盖率计算结果不断变化，使得边缘像素的颜色在帧与帧之间发生微妙的、高频的亮度变化，而历史帧的混合可以减少这种不稳定性。虽然由于每帧的抖动，会让我们误以为更加不稳定，但实际上可以通过些许 trick 来减少感知上的闪烁问题，从而达到其他后处理抗锯齿技术（诸如形态抗锯齿）无法达到的基于时序的稳定性。这也引出了 TAA 的两大难题：<strong>鬼影 ghost</strong> 问题和<strong>闪烁 flicker</strong> 问题，我们在后面重点解决这两个问题。</p>
<p>TAA 大致流程如下所示：<br>①首先对摄像机进行<strong>抖动 jitter</strong>，这样子每一帧采样的是一个基于中心位置的被抖动过后的随机位置采样点，将当前帧采样颜色和历史颜色进行混合得到 TAA Target 贴图，后处理后输出。与此同时，将 TAA Target 复制为 TAA History/Accumulation 贴图，将累计的历史颜色信息用于下一帧进行混合；<br>②由于相机或物体会进行移动，所以采样历史帧（TAA History）时，不能使用当前的 uv 值，否则采样到的颜色会不是当前像素点或物体的历史颜色信息。这就需要使用上一帧的矩阵进行<strong>重投影 Reprojection</strong> 计算出<strong>运动向量 Motion Vector</strong>，从而还原出当前像素在上一帧的屏幕位置。Motion Vector 又分为 <strong>Camera Motion Vector</strong> 和 <strong>Object Motion Vector</strong>，后面会详细说明；<br>③由于运动时遮挡的变化，或者超出屏幕范围，又或者是灯光的变化，会让我们采样到跟当前帧不匹配的历史颜色信息，从而产生鬼影现象。因此我们需要<strong>验证 Validate</strong> 或<strong>矫正 rectify</strong> 历史信息，以防止鬼影现象的产生；<br>④最后是解决闪烁问题。鬼影和闪烁问题是 TAA 的两大顽疾，而且这两顽疾几乎很难同时解决。防止鬼影现象产生，往往会加剧闪烁现象，解决了闪烁问题，鬼影可能又会回来。</p>
<div align="center">  
<img src="https://s2.loli.net/2025/07/06/HCp3vjaQ4tswEUq.png" width = "60%" height = "60%" alt="图1 - TAA 基本流程"/>
</div>

<p>下面就开始介绍具体的实现方式，我们先处理静态场景的情形，即摄像机和物体都不运动：</p>
<h1 id="累计历史样本"><a href="#累计历史样本" class="headerlink" title="累计历史样本"></a>累计历史样本</h1><h2 id="抖动-Jitter"><a href="#抖动-Jitter" class="headerlink" title="抖动 Jitter"></a>抖动 Jitter</h2><p>由于我们要对一个像素内的多个<strong>子像素 subpixel</strong> 进行采样，故我们需要对采样点的位置进行偏移，即<strong>抖动 Jitter</strong>，通常情况下会使用低差异序列中的 Halton 序列，从而实现更好的抗锯齿效果。UE4 默认使用了 Halton 序列的前 8 个样本，Playdead Studios 工作室（《INSIDE》、《地狱边境》的制作厂商）在 GDC 2016 的分享中有提到使用前 16 个样本可以产生更好的效果，我也采用了这个方式。Halton 序列等低差异序列的生成就不在这里赘述了，详见《Physically Based Rendering: From Theory To Implementation》中的第八章 Sampling and Reconstruction 的第六节 <a target="_blank" rel="noopener" href="https://www.pbr-book.org/4ed/Sampling_and_Reconstruction/Halton_Sampler">Halton Sampler</a> 。</p>
<div align="center">  
<img src="https://s2.loli.net/2025/07/06/Fr3pSCQuLM2fJWl.jpg" width = "50%" height = "50%" alt="图2 - Halton Squence"/>
</div>

<p>对采样点进行偏移的方式通常是修改相机的投影矩阵，只需修改矩阵中的两个变量即可：  </p>
<pre><code>ProjectionMatrix[0][2] += ( OffsetX * 2.0f – 1.0f ) / FrameBufferSize.Width;
ProjectionMatrix[1][2] += ( OffsetY * 2.0f – 1.0f ) / FrameBufferSize.Height;
</code></pre><p>至于为什么要对 offset 乘 2 减 1 的原因是，Halton 序列即 offset 的范围是在 (0, 1)，我们希望采样点偏移的范围是在一个像素内，即在 (-0.5, 0.5) 之间，需要对 Halton 序列减去 0.5。又因为齐次除法后得到的 NDC 坐标的 x、y 分量都在 [-1, 1] 之间，而得到 uv 值在 (0, 1) 之间，故需要乘以 2 消除缩放影响。具体推导如下，假设 jitter 在 (-0.5, 0.5) 之间：  </p>
<script type="math/tex; mode=display">P'_{clip} = M_{persp}P_{view} = \begin{bmatrix} A & 0 & 2 \times jitter.x / width & 0 \\ 0 & B & 2 \times jitter.y / height & 0 \\ 0 & 0 & C & D \\ 0 & 0 & 1\,or\, -1 & 0 \end{bmatrix} \begin{bmatrix} x \\ y \\ z \\ 1 \end{bmatrix} = \begin{bmatrix} Ax + 2 \times jitter.x / width \times z \\ By + 2 \times jitter.y / height \times z \\ ... \\ ... \end{bmatrix}</script><script type="math/tex; mode=display">P'_{NDC} = \left[ \cfrac {A}{z}x + \cfrac {2 \times jitter.x}{width} , \cfrac {B}{z}y + \cfrac {2 \times jitter.y}{height} , ..., ... \right]</script><script type="math/tex; mode=display">P'_{ScreenUV} = \left[ \cfrac {A}{2z}x + \cfrac {jitter.x}{width} + 0.5 , \cfrac {B}{2z}y + \cfrac {jitter.y}{height} + 0.5 \right]</script><p>要注意，原 ScreenUV 为 $\, \left[ \cfrac {A}{2z}x + 0.5, \cfrac {B}{2z}y + 0.5 \right] \,$，故偏移了 $\, \left[ \cfrac {jitter.x}{width}, \cfrac {jitter.y}{height} \right] \,$，符合我们的要求。注意上面推导的是透视投影的情况，正交投影则需改变第一行第四位，以及第二行第四位，即 [0][3] 和 [1][3] ：</p>
<script type="math/tex; mode=display">P'_{clip} = M_{ortho}P_{view} = \begin{bmatrix} A & 0 & 0 & 2 \times jitter.x / width \\ 0 & B & 0 & 2 \times jitter.y / height \\ 0 & 0 & C & D \\ 0 & 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} x \\ y \\ z \\ 1 \end{bmatrix} = \begin{bmatrix} Ax + 2 \times jitter.x / width \\ By + 2 \times jitter.y / height \\ ... \\ ... \end{bmatrix}</script><script type="math/tex; mode=display">P'_{ScreenUV} = \left[ \cfrac {A}{2}x + \cfrac {jitter.x}{width} + 0.5 , \cfrac {B}{2}y + \cfrac {jitter.y}{height} + 0.5 \right]</script><p>为了方便控制偏移距离，可以给 jitter 乘以一个 jitterScale 参数，用于控制偏移的范围。得到修改的矩阵后，只需调用 <code>CommandBuffer.SetViewProjectionMatrices()</code> 即可实现抖动了，我用了一张金属度比较高的图片，方便观察闪烁现象：  </p>
<div align="center">  
<img src="https://s2.loli.net/2025/07/08/Hl3VvTNDFPCQh7n.gif" width = "512" height = "512" alt="图3 - Jitter"/>
</div>

<h2 id="Exponential-Blending"><a href="#Exponential-Blending" class="headerlink" title="Exponential Blending"></a>Exponential Blending</h2><p>接下来就是将当前帧与历史帧进行混合了，直接混合所有历史帧肯定是不现实的，因为我们没法存储所有历史数据。绝大多数 TAA 的实现采用了类似递归的方式，将所有历史帧的累加结果存储到一张贴图当作，即 TAA History/Accumulation Texture，并采用了以下公式进行混合：  </p>
<script type="math/tex; mode=display">f_n(p) = \alpha \cdot s_n(p) + (1 - \alpha) \cdot f_{n-1} (\pi(p))</script><p>其中 $\,f_n(p)\,$ 是第 n 帧的输出颜色，$\,\alpha\,$ 是混合系数，$\,s_n(p)\,$ 是当前帧颜色，$\,f_{n-1} (\pi(p))\,$ 是经过重投影后的累计历史帧。重投影后面再考虑，这里先考虑静态场景。在这个公式下，历史帧会被不断累计，当然随着时间的流逝，单一历史帧的影响会被无限缩小。</p>
<div align="center">  
<img src="https://s2.loli.net/2025/07/08/ANXvRKOwUabtjDl.jpg" width = "45%" height = "45%" alt="图4 - 单一历史帧随着帧数增加所占的比例变化"/>
</div>

<p>越老的历史帧所占的比例越来越小，在大部分情况下是很好的选择，因为场景肯定会变化，大概率老的历史帧的颜色已经不在屏幕上了，但是从最小化方差的角度来看，上述选择只能算次优解。下面的表格揭示了不同帧数下，不同 $\,\alpha\,$ 对应的有效累计样本数：  </p>
<div align="center">  
<img src="https://s2.loli.net/2025/07/08/YNvzT4HPkb29eK6.jpg" width = "45%" height = "45%" alt="图5 - 在 α = 0.1 的情况下，经过 5 帧相当于 1 个像素采样了 2 个样本；经过 10 帧，相当于 5 个样本；经过 15 帧，相当于 10 个样本；经过无限帧，相当于 19 个有效样本"/>
</div>

<p>$\,\alpha\,$ 的值，通常的选择是 0.1。可以看到对于无限帧的情况，相当于 19x SSAA，效果还是相当不错的。在 Unity RenderGraph 创建持久化的 RT，即 TAA History，以及临时资源 TAA Target 并绘制的 C# 代码，这里就不展示了，就说一下大致流程，创建好了 TAA History 和 TAA Target 后，将 Color Attachment 作为当前帧的输入纹理，将 TAA History 作为历史帧的输入纹理，使用 Shader 或 Compute Shader 绘制出 TAA Target 后，作为 post processing 的输入纹理。与此同时，将 TAA Target 复制给 TAA History 以便下一帧使用。TAA Shader 目前的混合代码如下（我的 blend factor 是乘在 history 上的，故是 0.9）：  </p>
<pre><code>TEXTURE2D(_TAAHistory);
float4 _TAAParams; // x: history blend factor

float4 TAAFrag(Varyings IN) : SV_TARGET
&#123;
    float3 history = LOAD_TEXTURE2D_LOD(_TAAHistory, IN.positionHCS.xy, 0).xyz;
    float3 current = LOAD_TEXTURE2D_LOD(_BlitTexture, IN.positionHCS.xy, 0).xyz;
    float3 color = lerp(current, history, _TAAParams.x);
    return float4(color, 1.0);
&#125;
</code></pre><p>混合效果如下，为了方便观察高光闪烁问题，我又在机器人旁边加了盏红灯：  </p>
<table><tr>
<td><img src='https://s2.loli.net/2025/07/08/JTbiFsuX9qG4Eeh.gif' width="512" alt="图6 - TAA (After Simple Exponential Blending)"></td>
<td><img src='https://s2.loli.net/2025/07/08/BonNJtUQaAZOPx9.gif' width="512" alt="图7 - NoAA"></td>
</tr></table>

<p>可以很明显地感受到抗锯齿的效果，但也能明显地感受到闪烁问题。还有一点是，上图中可能会感觉到在 TAA 下会损失一些贴图细节，这是因为上图分辨率较小，只有 512 × 512，分辨率越高，这些现象越能得到缓解，对于现在普遍的 2k 与 4k 屏幕，这个问题不明显。</p>
<p>图 6 中的闪烁问题我们暂时先放着，后面再详细讨论，我们先来看看若将摄像机进行移动，图 6 会变为什么样子：  </p>
<div align="center">  
<img src="https://s2.loli.net/2025/07/09/AktR52mKGpsdqIQ.gif" width = "512" height = "512" alt="图8 - 鬼影 Ghost 现象"/>
</div>

<p>上图只移动了摄像机，没移动物体，可以看到传说中的鬼影问题了。这下就集齐了 TAA 的两大问题：闪烁和鬼影。闪烁问题无论静态动态都存在，动态情况下会加剧闪烁问题，而鬼影只在动态场景存在，下面我们先来处理鬼影现象。</p>
<h2 id="重投影-Reprojection"><a href="#重投影-Reprojection" class="headerlink" title="重投影 Reprojection"></a>重投影 Reprojection</h2><p>鬼影现象的产生原因很简单，相机或物体的移动导致了颜色信息的位置发生了变化，而我们还在采样原来的位置。所以我们很容易可以想到，通过计算屏幕像素每帧的坐标变化，即计算<strong>运动向量 Motion Vector</strong>，来找到像素移动前的屏幕坐标进行采样就可以解决鬼影问题。之前有提到过 Motion Vector 分为 <strong>Camera Motion Vector</strong> 和 <strong>Object Motion Vector</strong>，因为 Object Motion Vector 的实现在工程上相对麻烦一点（Unity 有一些历史遗留问题），我们先来解决只有摄像机移动的动态情形，即 Camera Motion Vector 的情形，至于物体的移动，等闪烁和鬼影解决得差不多了之后会专门讲解。</p>
<p>计算 Camera Motion Vector 的方法也不难，步骤如下：<br>①通过 Camera Depth Texture 获取当前像素点的深度，通过深度还原出像素点的 clip space 坐标；<br>②将 clip space 通过 view-projection 的逆矩阵，反向投影至世界坐标。因为只有相机在运动，物体的世界坐标是不会变的；<br>③使用上一帧的 view-projection 矩阵，投影至上一帧的屏幕 uv 坐标，与当前帧的屏幕 uv 坐标相减得到 Camera Motion Vector。<br>（注意上述方法只能计算 Camera Motion Vector，Object Motion Vector 还涉及到 MVP 矩阵的 M 的变化或者顶点在模型空间的变化。）</p>
<p>Camera Motion Vector 可以直接在 TAA 的 Shader 里计算，也可以存储在一张 RT（只需要 RG 通道就可以，因为精度很重要，常规的做法是两通道都 16 bit）里并在 TAA 里采样，我这里是开了一张 RT 存储的。如果后面没有使用 Camera Motion Vector 的后处理效果，比如动态模糊，并且 TAA 只打算使用 Camera Motion Vector，不使用 Object Motion Vector，那么就没必要多开张 RT。</p>
<h3 id="记录上一帧-VP-矩阵"><a href="#记录上一帧-VP-矩阵" class="headerlink" title="记录上一帧 VP 矩阵"></a>记录上一帧 VP 矩阵</h3><p>这里顺便提一下 Unity 工程上的问题，以下计算 Camera Motion Vector 需要使用的矩阵 shader 参数，Unity 的 Built-in Engine 不会自动上传：  </p>
<pre><code>float4x4 unity_MatrixInvP;
float4x4 unity_MatrixInvVP;
float4x4 _PrevViewProjMatrix; // non-jittered.
float4x4 _NonJitteredViewProjMatrix; // non-jittered.
</code></pre><p>因为我看 URP 将上述参数放在了 UnityInput.hlsl 里面，我还以为 Unity 的 Built-in Engine 会自动上传，但是使用这些参数，会发现它们都是单位矩阵。所以 UnityInput.hlsl 里的参数，哪些会被 Built-in Engine 自动上传，哪些不会，还得自己测试一下。最后上述这些参数，还得我们自己上传，首先找个地方保留住这一帧和上一帧的各种矩阵，然后根据它们计算相关参数，代码大致如下：  </p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="built_in">bool</span> isProjectionMatrixFlipped = SystemInfo.graphicsUVStartsAtTop;</span><br><span class="line"></span><br><span class="line">Matrix4x4 viewMatrix = yCamera.perCameraData.viewMatrix;</span><br><span class="line">Matrix4x4 inverseViewMatrix = viewMatrix.inverse;</span><br><span class="line">Matrix4x4 gpuProjectionMatrix = GL.GetGPUProjectionMatrix(yCamera.perCameraData.jitteredProjectionMatrix, isProjectionMatrixFlipped);</span><br><span class="line">Matrix4x4 inverseProjectionMatrix = gpuProjectionMatrix.inverse;</span><br><span class="line">Matrix4x4 gpuNonJitterProjectionMatrix = GL.GetGPUProjectionMatrix(yCamera.perCameraData.projectionMatrix, isProjectionMatrixFlipped);</span><br><span class="line">Matrix4x4 nonJitterInverseProjectionMatrix = gpuNonJitterProjectionMatrix.inverse;</span><br><span class="line"></span><br><span class="line">Matrix4x4 inverseViewProjectionMatrix = inverseViewMatrix * inverseProjectionMatrix;</span><br><span class="line">Matrix4x4 nonJitterViewProjectionMatrix = gpuNonJitterProjectionMatrix * viewMatrix;</span><br><span class="line">Matrix4x4 nonJitterInverseViewProjectionMatrix = inverseViewMatrix * nonJitterInverseProjectionMatrix;</span><br><span class="line"></span><br><span class="line">Matrix4x4 previousViewMatrix = yCamera.perCameraData.previousViewMatrix;</span><br><span class="line">Matrix4x4 previousInverseViewMatrix = previousViewMatrix.inverse;</span><br><span class="line">Matrix4x4 previousGPUProjectionMatrix = GL.GetGPUProjectionMatrix(yCamera.perCameraData.previousJitteredProjectionMatrix, isProjectionMatrixFlipped);</span><br><span class="line">Matrix4x4 previousInverseProjectionMatrix = previousGPUProjectionMatrix.inverse;</span><br><span class="line">Matrix4x4 previousGPUNonJitterProjectionMatrix = GL.GetGPUProjectionMatrix(yCamera.perCameraData.previousProjectionMatrix, isProjectionMatrixFlipped);</span><br><span class="line">Matrix4x4 previousNonJitterInverseProjectionMatrix = previousGPUNonJitterProjectionMatrix.inverse;</span><br><span class="line"></span><br><span class="line">Matrix4x4 previousViewProjectionMatrix = previousGPUProjectionMatrix * previousViewMatrix;</span><br><span class="line">Matrix4x4 previousInverseViewProjectionMatrix = previousInverseViewMatrix * previousInverseProjectionMatrix;</span><br><span class="line">Matrix4x4 previousNonJitterViewProjectionMatrix = previousGPUNonJitterProjectionMatrix * previousViewMatrix;</span><br><span class="line">Matrix4x4 previousNonJitterInverseViewProjectionMatrix = previousInverseViewMatrix * previousNonJitterInverseProjectionMatrix;</span><br><span class="line"></span><br><span class="line">cmd.SetGlobalMatrix(YPipelineShaderIDs.k_InverseProjectionMatrixID, inverseProjectionMatrix);</span><br><span class="line">cmd.SetGlobalMatrix(YPipelineShaderIDs.k_InverseViewProjectionMatrixID, inverseViewProjectionMatrix);</span><br><span class="line">cmd.SetGlobalMatrix(YPipelineShaderIDs.k_NonJitteredViewProjectionMatrixID, nonJitterViewProjectionMatrix);</span><br><span class="line">cmd.SetGlobalMatrix(YPipelineShaderIDs.k_NonJitteredInverseViewProjectionMatrixID, nonJitterInverseViewProjectionMatrix);</span><br><span class="line">cmd.SetGlobalMatrix(YPipelineShaderIDs.k_PreviousViewProjectionMatrixID, previousViewProjectionMatrix);</span><br><span class="line">cmd.SetGlobalMatrix(YPipelineShaderIDs.k_PreviousInverseViewProjectionMatrixID, previousInverseViewProjectionMatrix);</span><br><span class="line">cmd.SetGlobalMatrix(YPipelineShaderIDs.k_NonJitteredPreviousViewProjectionMatrixID, previousNonJitterViewProjectionMatrix);</span><br><span class="line">cmd.SetGlobalMatrix(YPipelineShaderIDs.k_NonJitteredPreviousInverseViewProjectionMatrixID, previousNonJitterInverseViewProjectionMatrix);</span><br></pre></td></tr></table></figure>
<p>上面代码中要注意一下的是 <code>GL.GetGPUProjectionMatrix</code> 这个 API，从 <code>camera.projectionMatrix</code> 获取到投影矩阵是 OpenGL 习惯下的矩阵，我们需要根据不同平台转换成不同的习惯下的投影矩阵，所幸 <code>GL.GetGPUProjectionMatrix</code> 可以帮我们完成这件事情。另外一点要注意的是矩阵的乘法顺序，就不再赘述了。</p>
<h3 id="Camera-Motion-Vector-Shader"><a href="#Camera-Motion-Vector-Shader" class="headerlink" title="Camera Motion Vector Shader"></a>Camera Motion Vector Shader</h3><p>拿到矩阵后，就可以计算 Camera Motion Vector 了，Shader 代码如下：  </p>
<blockquote>
<p>在 DirectX 平台下，只要将 <code>GL.GetGPUProjectionMatrix()</code> 设置为 true，Unity 会将 Projection Matrix 的 y 轴翻转，这样子经过视口变换（uv 的 v 再次翻转），就统一了 OpenGL 下和 DirectX 下的 uv 了（即原点在左下角），这也是普通的 Unity Shader 中我们不用关心 uv 原点的位置的原因。但是直接绘制 RT 的 Shader 就不同了，因为此时的 uv 和 positionHCS 是我们生成的，而不是通过 Projection Matrix 计算而得，所以之前在顶点着色器中，将 uv 的 v 轴手动翻转了，positionHCS 无需手动翻转是因为视口变换会翻转。所以下面计算 Camera Motion Vector 要特别注意 uv 的方向。</p>
</blockquote>
<pre><code>float4 GetNDCFromUVAndDepth(float2 uv, float depth)
&#123;
    #if UNITY_UV_STARTS_AT_TOP
        uv.y = 1.0f - uv.y;
    #else
        depth = 2.0 * depth - 1.0;
    #endif

    return float4(2.0 * uv - 1.0, depth, 1.0);
&#125;

float3 TransformNDCToWorld(float4 NDC, float4x4 invViewProjMatrix)
&#123;
    float4 positionHWS = mul(invViewProjMatrix, NDC);
    return positionHWS.xyz / positionHWS.w;
&#125;

float4 CameraMotionVectorFrag(Varyings IN) : SV_TARGET
&#123;
    float depth = LOAD_TEXTURE2D_LOD(_CameraDepthTexture, IN.positionHCS.xy, 0).r;
    float4 NDC = GetNDCFromUVAndDepth(IN.uv, depth);
    float3 currentPositionWS = TransformNDCToWorld(NDC, UNITY_MATRIX_I_VP);

    float4 currentPositionCS = mul(UNITY_MATRIX_NONJITTERED_VP, float4(currentPositionWS.xyz, 1.0));
    float4 previousPositionCS = mul(UNITY_PREV_MATRIX_NONJITTERED_VP, float4(currentPositionWS.xyz, 1.0));

    float2 currentPositionNDC = currentPositionCS.xy * rcp(currentPositionCS.w);
    float2 previousPositionNDC = previousPositionCS.xy * rcp(previousPositionCS.w);

    float2 velocity = currentPositionNDC - previousPositionNDC;

    #if UNITY_UV_STARTS_AT_TOP
    velocity.y = -velocity.y;
    #endif

    velocity *= 0.5;

    return float4(velocity, 0,0);
&#125;
</code></pre><p>另外要注意的是，计算 Camera Motion Vector 的时候要去除掉 jitter 的影响，否则得到的 Motion Vector 是不对的，使用了会导致画面糊，所以上面计算时，使用了 <code>NONJITTERED_VP</code> 矩阵。然后在 TAA Shader 采样时，减去 Motion Vector：  </p>
<pre><code>float4 TAAFrag(Varyings IN) : SV_TARGET
&#123;
    float2 velocity = LOAD_TEXTURE2D_LOD(_CameraMotionVectorTexture, IN.positionHCS.xy, 0).rg;

    float3 history = SAMPLE_TEXTURE2D_LOD(_TAAHistory, sampler_LinearClamp, IN.uv - velocity, 0).xyz;
    float3 current = LOAD_TEXTURE2D_LOD(_BlitTexture, IN.positionHCS.xy, 0).xyz;

    float3 color = lerp(current, history, _TAAParams.x);
    return float4(color, 1.0);
&#125;
</code></pre><p>注意，采样 history 时，因为要减去 velocity，得到的新 uv 值不会正好在像素中心，此时若使用 load 或者 point 采样不合理，效果也不好，会出现涂抹 smear 感，建议使用 linear 采样。但是使用 linear 采样，又会造成模糊感，这也是一个较为重要的优化地方，在其他优化技术的 History Filter 小节中会详细介绍，目前为止的效果如下：  </p>
<blockquote>
<p>在后处理中，因为我们是绘制全屏三角形，设置了 3 个顶点 uv 值为 (0, 0)、(2, 0)、(0, 2)，当 uv 通过光栅化插值时，uv 会天然满足精确对应到纹素中心，此时和 SV_POSITION 语义的 xy 分量是对齐的，都代表纹素中心，只不过 SV_POSITION 是像素坐标。如果采样在纹素中心，此时 linear 和 point 采样得到的结果会是一样的。</p>
</blockquote>
<div align="center">  
<img src="https://s2.loli.net/2025/07/10/Xgvw4oALqMxWShn.gif" width = "512" height = "512" alt="图9 - After Camera Motion Vector"/>
</div>

<p>可以看到，虽然可以看清物体了，但是还是有鬼影现象，这是由于场景中的遮挡关系发生了变化。比如上图中，在这一帧中，机器人的位置可以拿到 Motion Vector 得到上一帧中机器人的颜色进行混合，但是机器人右上位置的像素，在上一帧中被机器人遮挡，在这一帧中没被机器人遮挡，同时 Motion Vector 也为 0，那么这些像素就会混合到上一帧中机器人的颜色，从而导致鬼影。所以 Camera Motion Vector 只能消除一部分的鬼影。当然鬼影现象还会因为其他因素引起，比如灯光的变化等等，这就需要我们去验证历史数据，拒绝不能使用的历史数据。</p>
<h1 id="验证历史样本"><a href="#验证历史样本" class="headerlink" title="验证历史样本"></a>验证历史样本</h1><p>那么如何验证历史样本呢？一般来说，有两类验证历史样本可信度的信息，即<strong>几何信息 geometry data</strong> 和<strong>颜色信息 color data</strong>。几何信息包括物体深度、速度以及 object ID 等等。使用几何信息拒绝历史样本相对于颜色信息来说没有那么 Robust，因为无法处理诸如灯光变化、影子变化等等颜色变化所产生的鬼影问题，所以这里主要详细介绍 Color Rejection，Color Rejection 可以说是 TAA 离开不了的一环。Geometry Rejection 的相关方法在下面只大致介绍一下思路。</p>
<h2 id="Color-Rejection-Rectification"><a href="#Color-Rejection-Rectification" class="headerlink" title="Color Rejection/Rectification"></a>Color Rejection/Rectification</h2><h3 id="Color-Clamping"><a href="#Color-Clamping" class="headerlink" title="Color Clamping"></a>Color Clamping</h3><p>Color Clamping 假设采样点周围样本对于 TAA 累计过程是有效的，历史样本如果跟当前帧样本出现较大偏差，那么历史样本就应该被拒绝。但相较于直接拒绝历史样本，Color Clamping 选择将历史样本钳制到当前帧样本周围 5 个样本或 9 个样本组成的 AABB 包围盒中：  </p>
<pre><code>float4 TAAFrag(Varyings IN) : SV_TARGET
&#123;
    float2 velocity = LOAD_TEXTURE2D_LOD(_CameraMotionVectorTexture, IN.positionHCS.xy, 0).rg;
    float3 history = SAMPLE_TEXTURE2D_LOD(_TAAHistory, sampler_LinearClamp, IN.uv - velocity, 0).xyz;

    float3 current = LOAD_TEXTURE2D_LOD(_BlitTexture, IN.positionHCS.xy, 0).xyz;

    float3 N = LoadOffset(_BlitTexture, IN.positionHCS.xy, int2(0, 1)).xyz;
    float3 E = LoadOffset(_BlitTexture, IN.positionHCS.xy, int2(1, 0)).xyz;
    float3 S = LoadOffset(_BlitTexture, IN.positionHCS.xy, int2(0, -1)).xyz;
    float3 W = LoadOffset(_BlitTexture, IN.positionHCS.xy, int2(-1, 0)).xyz;
    #if _TAA_SAMPLE_3X3
    float3 NW = LoadOffset(_BlitTexture, IN.positionHCS.xy, int2(-1, 1)).xyz;
    float3 NE = LoadOffset(_BlitTexture, IN.positionHCS.xy, int2(1, 1)).xyz;
    float3 SW = LoadOffset(_BlitTexture, IN.positionHCS.xy, int2(-1, -1)).xyz;
    float3 SE = LoadOffset(_BlitTexture, IN.positionHCS.xy, int2(1, -1)).xyz;
    #endif

    float3 min = min(current, min(N, min(E, min(S, W))));
    float3 max = max(current, max(N, max(E, max(S, W))));
    #if _TAA_SAMPLE_3X3
    min = min(min, min(NW, min(NE, min(SW, SE))));
    max = max(max, max(NW, max(NE, max(SW, SE))));
    #endif

    history = clamp(history, min, max);
    float3 color = lerp(current, history, _TAAParams.x);
    return float4(color, 1.0);
&#125;
</code></pre><p>由于临近采样点的亮度变化可能会很大，这会导致 AABB 包围盒很大，从而重现鬼影现象。Epic Games 的 Karis 在 SIGGRAPH 2014 的演讲 <a target="_blank" rel="noopener" href="https://de45xmedrsdbp.cloudfront.net/Resources/files/TemporalAA_small-59732822.pdf">High Quality Temporal Supersampling</a> 有提到使用 <strong>YCoCg</strong> 色彩空间可以使 AABB 包围盒更加紧致，因为它将颜色的色度 Chroma（即 Co, Cg 通道）从亮度（Y 通道）分离了出来，而亮度往往占据颜色差值的主导地位。</p>
<blockquote>
<p>YCoCg 色彩空间包含 Y、Co、Cg 三个通道，分别对应亮度、绿色色度（chrominance green）和橙色色度（chrominance orange）。  </p>
</blockquote>
<p>YCoCg 到 RGB 的转换是线性变换，代码如下：  </p>
<pre><code>float3 RGB2YCoCg(float3 rgb) &#123;
    return float3(
            rgb.x/4.0 + rgb.y/2.0 + rgb.z/4.0,
            rgb.x/2.0 - rgb.z/2.0,
            -rgb.x/4.0 + rgb.y/2.0 - rgb.z/4.0);
&#125;

float3 YCoCg2RGB(float3 YCoCg) &#123;
    return float3(
            YCoCg.x + YCoCg.y - YCoCg.z,
            YCoCg.x + YCoCg.z,
            YCoCg.x - YCoCg.y - YCoCg.z);
&#125;
</code></pre><p>最后 YCoCg 色彩空间下的 3X3 的 9 个样本的 Color Clamping 的结果如下：  </p>
<div align="center">  
<img src="https://s2.loli.net/2025/07/11/3IAFVrQbg6X4ZtE.gif" width = "512" height = "512" alt="图10 - After Color Clamping"/>
</div>

<p>其实这样子 TAA 已经勉强成形了，后面的技术的目的都是进一步优化 TAA 以减少鬼影和闪烁问题。</p>
<h3 id="Color-Clipping"><a href="#Color-Clipping" class="headerlink" title="Color Clipping"></a>Color Clipping</h3><p>Color Clipping 可以说是 Color Clamping 的进阶版本，用一张图可以概括它们的区别：  </p>
<div align="center">  
<img src="https://s2.loli.net/2025/07/11/Nq6mJQIWw2z3clg.jpg" width = "30%" height = "30%" alt="图11 - AABB clipping and clamping"/>
</div>

<p>我在网上找到有两种 Color Clipping 的实现方法，一种是 UE4 中的实现，一种是 <a target="_blank" rel="noopener" href="https://github.com/playdeadgames/temporal/blob/4795aa0007d464371abe60b7b28a1cf893a4e349/Assets/Shaders/TemporalReprojection.shader">Playdead</a> 的实现（它在 GDC 2016 的演讲：<a target="_blank" rel="noopener" href="https://www.gdcvault.com/play/1022970/Temporal-Reprojection-Anti-Aliasing-in">Temporal Reprojection Antialiasing in INSIDE</a>）。UE4 的实现我没在网上找到具体的来源，虽然是开源的，但是登录 Github 还要 Epic 账号才能查看，比较麻烦，而且网上也有很多人已经将这些代码摘抄下来了。Unity 的 <a target="_blank" rel="noopener" href="https://github.com/Unity-Technologies/Graphics/blob/master/Packages/com.unity.render-pipelines.high-definition/Runtime/PostProcessing/Shaders/TemporalAntialiasing.hlsl">HDRP</a> 里面这两种实现也都有，可以直接查看。</p>
<h4 id="Playdead-的-Clip-to-AABB-Center"><a href="#Playdead-的-Clip-to-AABB-Center" class="headerlink" title="Playdead 的 Clip to AABB Center"></a>Playdead 的 Clip to AABB Center</h4><p>Playdead 分享的库中的源代码如下：  </p>
<pre><code>float4 clip_aabb(float3 aabb_min, float3 aabb_max, float4 p, float4 q)
&#123;
    // note: only clips towards aabb center (but fast!)
    float3 p_clip = 0.5 * (aabb_max + aabb_min);
    float3 e_clip = 0.5 * (aabb_max - aabb_min) + FLT_EPS;

    float4 v_clip = q - float4(p_clip, p.w);
    float3 v_unit = v_clip.xyz / e_clip;
    float3 a_unit = abs(v_unit);
    float ma_unit = max(a_unit.x, max(a_unit.y, a_unit.z));

    if (ma_unit &gt; 1.0)
        return float4(p_clip, p.w) + v_clip / ma_unit;
    else
        return q;// point inside aabb
&#125;
</code></pre><p>其中 q 是 history，这个 p 不用管它，影响不到颜色。Playdead 的命名很难看懂，p_clip 就是 AABB center，e_clip 就是 AABB extent，FLT_EPS 是最小浮点数，防止除 0 的。v_clip 就是 history 到 AABB center 的距离（或向量），v_unit 就是 history 到 AABB center 的距离除以 AABB 边缘到 AABB center 的距离，它是一个距离倍数。只要这个距离倍数有一个分量大于 1 了，则认为需要 Clip，重新计算 history，计算方式为 AABB center 加上使用最大距离倍数缩放后的 v_clip。可以看到该方法是从 AABB center 出发的 Clip，因此我觉得从逻辑上来说，效果应该是不如 UE4 的实现的，我实际使用下来发现也确实如此，效果如下：  </p>
<div align="center">  
<img src="https://s2.loli.net/2025/07/11/1FzUWbOJwC7LRrd.gif" width = "512" height = "512" alt="图12 - Clip to AABB Center"/>
</div>

<h4 id="UE4-的-Clip-to-Filtered-Color"><a href="#UE4-的-Clip-to-Filtered-Color" class="headerlink" title="UE4 的 Clip to Filtered Color"></a>UE4 的 Clip to Filtered Color</h4><p>我在网上找到不同人摘抄的这段 UE4 的代码，计算方式可能略有不同，但逻辑都是一样的，跟 Unity HDRP 里的也差不多：  </p>
<pre><code>float3 ClipToFiltered(float3 NeighborMin, float3 NeighborMax, float3 Filtered, float3 History)
&#123;
    float3 BoxMin = NeighborMin;
    float3 BoxMax = NeighborMax;

    float3 RayOrigin = History;
    float3 RayDir = Filtered - History;
    RayDir = abs(RayDir) &lt; (1.0/65536.0) ? (1.0/65536.0) : RayDir;
    float3 InvDir = rcp(RayDir);

    float3 MaxIntersect = (BoxMax - RayOrigin) * InvDir;
    float3 MinIntersect = (BoxMin - RayOrigin) * InvDir;
    float3 EnterIntersect = min(MinIntersect, MaxIntersect);
    float ClipBlend = max3(EnterIntersect.x, EnterIntersect.y, EnterIntersect.z);
    ClipBlend = saturate(ClipBlend);
    return lerp(history, filtered, ClipBlend);
&#125;
</code></pre><p>上述代码和 playdead 的主要区别是使用了预过滤的当前帧中间颜色值，即 Filtered，而非 AABB 中心。它主要计算了三个方向，min 到 history 的方向、max 到 history 的方向、filtered color 到 history 的方向。MaxIntersect 就是 max 到 history 的方向所占 filtered color 到 history 的方向的比例，MinIntersect 同理，经过一次 min 一次 max 得到在 filtered color 和 history 的混合比例，混合后作为新的 history color。</p>
<p>理论上要使用 filtered color，我这里的展示是用了没过滤的中间颜色值替代的，预过滤在其他优化技术中详细说明，预过滤是一个抑制闪烁的有效方法，现在效果如下（展示的 gif 和上面的效果也感受不出太大区别，但是我在其他场景测试后能感受出这个方法的闪烁会更少一些，鬼影没怎么看出区别）：  </p>
<div align="center">  
<img src="https://s2.loli.net/2025/07/11/YgpwKOy23VFnm5i.gif" width = "512" height = "512" alt="图13 - Clip to Filtered Color"/>
</div>

<h3 id="Variance-Clipping"><a href="#Variance-Clipping" class="headerlink" title="Variance Clipping"></a>Variance Clipping</h3><p>因为物体边缘的亮度变化往往较大，这会使 AABB 包围盒过大，导致物体边缘的抗锯齿效果不佳，特别是一些有较亮或较暗边缘的物体。为了解决这个问题，NVIDIA 在 GDC 2016 的演讲：<a target="_blank" rel="noopener" href="https://developer.download.nvidia.com/gameworks/events/GDC2016/msalvi_temporal_supersampling.pdf">An Excursion in Temporal Supersampling</a> ，提出了 <strong>Variance Clipping</strong> 的方法，它使用了平均数和标准差来定义 AABB 包围盒。（Variance Clipping 是建立 AABB 的一种方式，和 color clamp/clip 可以同时使用，只不过之前建立 AABB 使用的是 min max 方法。）</p>
<p>理论上最好的 clipping 应该是基于<strong>凸包 Convex Hull</strong> 的 clipping（凸包指做小能包含点集中所有的点的凸多边形），如下图所示：  </p>
<div align="center">  
<img src="https://s2.loli.net/2025/07/14/bDnzUpil6XxG8By.jpg" width = "40%" height = "40%" alt="图14 - Convex Hull"/>
</div>

<p>因为凸包相交计算非常昂贵，所以退而求其次，普遍选择的是 AABB 包围盒，但是 AABB Clip 到的颜色可能会离凸包的结果相差较远，从而导致鬼影现象。于是 NVIDIA 开发出了使用统计学方法的 AABB 包围盒来替代之前 min/max 方法下的 AABB 包围盒，以确保更紧致的包围盒。它使用标准正太分布（z 分布）的区间估计来建立 AABB 包围盒，公式如下：  </p>
<script type="math/tex; mode=display">\mu \pm \gamma \sigma</script><p>$\,\mu\,$ (mu) 代表颜色的平均数，$\,\sigma\,$ (sigma) 代表颜色的标准差 standard deviation，$\,\gamma\,$ (gamma) 则是临界值 Critical Value 或者称为标准差乘数 Standard Deviation Multiplier，NVIDIA 建议 $\,\gamma\,$ 在 [0.75, 1.25] 之间。代码大致如下（标准差使用 $\,\sigma = \sqrt {\sum{X^2}/N - (\sum X / N)^2}\,$ 计算）：  </p>
<pre><code>void VarianceNeighbourhood(in Neighbourhoods samples, out float3 neighborMin, out float3 neighborMax, float gamma = 1.25)
&#123;
    float3 m1 = 0;
    float3 m2 = 0;
    for (int i = 0; i &lt; NEIGHBOURHOOD_COUNT; i++)
    &#123;
        float3 sampleColor = samples[i];
        m1 += sampleColor;
        m2 += sampleColor * sampleColor;
    &#125;

    m1 *= rcp(NEIGHBOURHOOD_COUNT);
    m2 *= rcp(NEIGHBOURHOOD_COUNT);

    float3 sigma = sqrt(abs(m2 - m1 * m1)); // standard deviation
    neighborMin = m1 - gamma * sigma;
    neighborMax = m1 + gamma * sigma;
&#125;
</code></pre><p>上述代码还可以进一步修改，NVIDIA 的 PPT 中有提到说可以和 min/max 的 AABB 做 clamp，确保 variance 不会比 min/max 的更大，从而做到让 AABB 更小：  </p>
<pre><code>neighborMin = max(MinMaxAABB_Min, VarianceAABB_Min);
neighborMax = min(MinMaxAABB_Max, VarianceAABB_Max);
</code></pre><p>而 UE4 则防止了 variance AABB 比 filter color 还紧致：  </p>
<pre><code>NeighborMin = min(VarianceAABB_Min, FilteredColor);
NeighborMax = max(VarianceAABB_Max, FilteredColor);
</code></pre><p>Unity HDRP 还对 gamma 值（Standard Deviation Multiplier）进行了自适应动态处理，有兴趣可以去翻翻 HDRP 的 TAA，这里就不摘抄了。展示图片也不上传了，反正在劣质分辨率下也看不出来区别（我使用的图床免费情况最大只支持 5 M，/(ㄒoㄒ)/~~）。</p>
<h2 id="Geometry-Rejection"><a href="#Geometry-Rejection" class="headerlink" title="Geometry Rejection"></a>Geometry Rejection</h2><p>说明一下，Geometry Rejection 强调使用几何信息消除鬼影，实际上也可以使用几何信息进行判断来控制闪烁现象，所以要和下面其他优化技术中的 Adaptive Blending Factor 进行一定程度的区分。但本质上来说，将 $\,\alpha\,$ 增大或者直接设置为 1 ，从而拒绝历史消除鬼影，理论上来讲也属于自适应/动态 $\,\alpha\,$ 的范畴，闪烁和鬼影本就一体两面，只不过处理闪烁是将 $\,\alpha\,$ 减小。但是，这里为了方便理解，将这二者强行进行了区分，只讨论消除鬼影，减少闪烁后面再讲。</p>
<p>因为 Color Rejection/Rectification 并不能完全消除鬼影现象，因为它仍然保留了一部分历史信息，可以看后面展示的 gif 图，动态物体掠过的地方是可以看到一定鬼影现象的。但是若将 Color AABB 包围盒变得更紧致来减少鬼影，闪烁现象就会更加突出。这时候为了在不恶化闪烁问题的前提下，更好地解决鬼影问题，往往需要配合 Geometry Rejection 来进行判断，主要逻辑就是使用这一帧和上一帧的几何信息的差别来判断是否产生了<strong>遮挡 Occlusion</strong> 或<strong>遮挡去除 Disocclusion</strong>，Geometry Rejection 的主要方法有如下几种：  </p>
<p>①<strong>Depth Rejection</strong>：这个方法假设每帧之间的深度不会发生显著变化，深度变化较大的，则认为是发生了遮挡。要实现该方法，需要存储上一帧的深度纹理。如果深度发生显著变化，超过了一定的阈值，则增大 $\,\alpha\,$ 的值，或者直接设置为 1 放弃历史数据。这个方法可能比较适用于特殊的游戏，例如《这是我的战争》（This War of Mine）这样的 3d 横板游戏，因为镜头以平移为主，深度不会发生较大变化；或者枪械长期占据屏幕的第一人称射击游戏，因为枪械的深度不会发生显著变化，可以减少移动时因枪械产生的鬼影；或者俯视角游戏，镜头以平移旋转为主。</p>
<p>但可想而知，这个方法对于一般的 3d 游戏，由于会出现前后平移镜头，比如行走等等，相对来说没有这么好用。同时 Depth Rejection 可能会加剧静止状态下的闪烁问题，因为抖动是可能会造成像素点的深度发生变化的，即几何闪烁，后面闪烁优化小节会提到，所以判断 Depth Rejection 需要使用非常保守的阈值。</p>
<p>②<strong>Stencil Rejection</strong>：顽皮狗在 SIGGRAPH 2016 的演讲 <a target="_blank" rel="noopener" href="https://advances.realtimerendering.com/s2016/">Temporal Antialiasing in Uncharted 4</a> 有介绍这一方法的使用，大致意思就是对于一些主要渲染物体，比如人物，使用 Stencil Buffer 存储模板值，也要保留上一帧的 Stencil Buffer，进行比较，不同模板值的不是同一物体，此时只采样当前帧颜色，不混合历史帧。这个方法我觉得比较适用于屏幕长期占用着主要渲染物体的游戏，比如第三人称游戏、赛车游戏、第一人称射击游戏等等。</p>
<p>③<strong>Velocity Rejection</strong>：Velocity Rejection 可以有两种思路：思路一是类似于 Depth Rejection 的思路，但是比 Depth Rejection 更加健壮。可以通过 Alpha 通道存储基于速度长度的历史累计值，具体可以参考 CryEngine 3 在 SIGGRAPH 2011 的演讲 <a target="_blank" rel="noopener" href="https://www.iryoku.com/aacourse/downloads/13-Anti-Aliasing-Methods-in-CryENGINE-3.pdf">Anti-Aliasing Methods in CryEngine 3</a>。当然也可以直接持久化历史 motion vector 贴图，然后比较前一帧和这一帧之间的速度差，速度差较大，则拒绝历史，或增加 $\,\alpha\,$ 的值。</p>
<p>思路二是若不想额外存储上一帧的 motion vector 数据，则只使用这一帧的 motion vector 进行判断，速度越大，越增加 $\,\alpha\,$ 的值。但方法二肯定是不如方法一的，因为方法二没法处理一种鬼影现象，就是上一帧被运动物体遮挡，但这一帧没被遮挡的没有速度的像素，即<strong>遮挡去除 Disocclusion</strong> 产生的鬼影，遮挡或遮挡去除只要有速度差就有可能会发生。</p>
<p>我大致尝试了额外开一个 motion vector history 贴图，并且根据前后帧速度差修改 $\,\alpha\,$ 减少鬼影，只能说效果是有的，但是让我感觉不值得额外开一个贴图，追求极致效果可以这么做，我的代码大致如下（代码中的 blend factor 是乘在 history 上的）：  </p>
<pre><code>float historyVelocitySqr = dot(historyVelocity, historyVelocity);
float currentVelocitySqr = dot(currentVelocity, currentVelocity);
float velocityFactor = abs(historyVelocitySqr - currentVelocitySqr) / max(historyVelocitySqr, currentVelocitySqr);
blendFactor = lerp(blendFactor, 0, saturate(velocityFactor));
</code></pre><h1 id="其他优化技术"><a href="#其他优化技术" class="headerlink" title="其他优化技术"></a>其他优化技术</h1><h2 id="闪烁优化"><a href="#闪烁优化" class="headerlink" title="闪烁优化"></a>闪烁优化</h2><p>Color Rejection/Rectification 无法完全消除鬼影信息，同时也会在一定程度下增加闪烁问题的，即使是静止的状态，我这里就不展示 gif 了，可以自行开关 Color Rejection 感受一下。闪烁问题加剧的原因是历史的累计过程本来是可以吸收颜色差异，但是 Color Rejection/Rectification 在抖动的过程中有可能会错误地打破历史的累计，特别是一些具有较大颜色变化的边缘。</p>
<p>减少闪烁和减少鬼影的目标从某种程度上来说是相互矛盾的。从根源上来说，TAA 的 artifact 的产生原因可以分为两种：<strong>False Positives</strong>（有效的历史被无效）会导致模糊以及闪烁，<strong>False Negatives</strong>（无效的历史被有效）会导致鬼影。</p>
<p>想要在闪烁和鬼影现象寻求平衡，同时尽可能减少闪烁和鬼影现象并不是一件简单的任务。很多时候，由于不同项目的侧重点不同，需要根据项目需求和喜好选择使用不同的技术，同一个技术可能不适用某种类型游戏，但可能特别适用另一种类型。下面提及的 <strong>Luma Weighted Exponential Blending</strong> 和 <strong>Filter Current Color</strong> 主要解决的是闪烁现象，而 <strong>Dynamic/Adaptive Blending Factor</strong> 则会兼顾闪烁和鬼影现象，先从闪烁问题讲起。</p>
<p>闪烁问题又可以被分为<strong>高光闪烁</strong>（着色闪烁）和<strong>几何闪烁</strong>。高光闪烁可以理解为高光等在着色后由于抖动出现不连续的闪光点，产生的原因跟 bloom 闪烁类似，解决方法也一样；几何闪烁则是因为抖动后，光栅化后得到的像素点的几何内容是不确定的，特别是存在密集三角形的区域，比如树叶、栏杆等等，物体越远这个现象也会越明显。下面讲解时，我会专门说明该方法是处理哪一类闪烁问题的。另外，由于闪烁问题是跟<strong>帧率</strong>和<strong>分辨率</strong>相关的，帧率越高闪烁越不明显，分辨率越高闪烁越不明显，建议把帧率控制在 30、60 FPS 查看闪烁现象。</p>
<h3 id="Luma-Weighted-Exponential-Blending"><a href="#Luma-Weighted-Exponential-Blending" class="headerlink" title="Luma Weighted Exponential Blending"></a>Luma Weighted Exponential Blending</h3><p>这个方法主要解决的是高光闪烁问题，这里顺便讨论一下 TAA 在 Pipeline 的位置问题，上面将 TAA 放置在了所有后处理之前，即是在 HDR 线性空间下进行的。在这样的情况下，物体或相机移动，甚至静止状态下的抖动，都会导致物体的高光计算的剧烈变化，从而导致高光的闪烁问题。可能有人会说为什么不把 TAA 放在 Tone Mapping 之后，这样子就能解决高光闪烁问题。因为 bloom 或者 lens flare 效果可能会增大因高亮度颜色产生的 alias 问题，TAA 放在 Tone Mapping 之后的话 bloom 闪烁问题也会比较严重。还有一点是在 Tone Mapping 之前，相对来说更物理正确，因为 Tone Mapping 之前是线性空间，之后是非线性空间。但是的确 TAA 在 LDR 下的效果会比 HDR 下要好，这就产生了一个妥协的办法，即类似于 Bloom 中的解决方案，使用 Karis Average 来混合当前帧与历史帧从而缓解高光闪烁现象，如下：</p>
<script type="math/tex; mode=display">w(c) = \cfrac {1} {1 + Luminance(c)}</script><p>代码如下：  </p>
<pre><code>float3 LumaExponentialAccumulation(float3 history, float3 current, float blendFactor)
&#123;
    float historyLuma = Luminance(history);
    float currentLuma = Luminance(current);
    float historyLumaWeight = rcp(historyLuma + 1.0);
    float currentLumaWeight = rcp(currentLuma + 1.0);
    float weightSum = lerp(currentLumaWeight, historyLumaWeight, blendFactor);
    float3 blendColor = lerp(current * currentLumaWeight, history * historyLumaWeight, blendFactor);
    return blendColor / weightSum;
&#125;
</code></pre><p>上述方法的缺点就是会在一定程度上压制高亮度物体的亮度。还有一点要注意的是，不要对 YCoCg 空间下的颜色使用 <code>Luminance()</code> 函数，因为 YCoCg 的 Y 就是亮度，直接使用即可，否则会出现颜色问题。</p>
<h3 id="Filter-Current-Color"><a href="#Filter-Current-Color" class="headerlink" title="Filter Current Color"></a>Filter Current Color</h3><p>这个方法就是过滤当前帧的颜色，主要解决高光闪烁问题，也可以略微减少点几何闪烁问题，缺点就是会模糊，最好能配合额外的后处理锐化重建使用（推荐 Mitchell-Netravali Filter，据说比 Catmull-Rom 要好）。可以使用 Box Kernel 或 Gaussian Kernel 来进行模糊，但是不建议使用 Box Kernel，因为 Box Kernel 对锐化重建相对来说不太友好，并且相对来说也更模糊。为了更好地压制高光闪烁，可以在过滤计算权重时同时考虑亮度权重，即 Karis Average，下面是 Gaussian Kernel 的代码：  </p>
<pre><code>float3 GaussianFilterMiddleColor(in Neighbourhoods samples)
&#123;
    const float weights[9] = &#123; 4.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0 &#125;;
    float weightSum = 0;
    float3 filtered = 0;

    for (int i = 0; i &lt; NEIGHBOURHOOD_COUNT; i++)
    &#123;
        float lumaWeight = rcp(GetLuma(samples[i]) + 1.0) * weights[i];
        weightSum += lumaWeight;
        filtered += lumaWeight * samples[i];
    &#125;
    filtered *= rcp(weightSum);
    return filtered;
&#125;
</code></pre><p>由于会模糊，这个方法应该根据项目的美术要求来选择是否使用。觉得太模糊也可以选择 $\,\sigma\,$ 更小的高斯核，我自己测试下来 $\,\sigma\,$ 大概在 0.6 左右，在 1080 p 的近距离时也基本上看不出来模糊的感觉，但是能略微抑制闪烁现象。下图为实现了 Luma Weighted Exponential Blending 和对当前帧颜色进行了 Filter 后的效果，可以看到高光闪烁得到了很好的抑制，缺点就是高光颜色感觉变暗了：  </p>
<div align="center">  
<img src="https://s2.loli.net/2025/07/25/sdOp7mSIloRf9qW.gif" width = "512" height = "512" alt="图15 - Luma Weighted Exponential Blending 和 $\,\sigma\,$ 为 0.5 的 Gaussian Filter 后的效果"/>
</div>

<h3 id="Dynamic-Adaptive-Blending-Factor"><a href="#Dynamic-Adaptive-Blending-Factor" class="headerlink" title="Dynamic/Adaptive Blending Factor"></a>Dynamic/Adaptive Blending Factor</h3><p>自适应 $\,\alpha\,$ 逻辑跟 Geometry/Color Rejection 是类似的，只不过 Geometry/Color Rejection 强调拒绝历史解决鬼影现象，自适应 $\,\alpha\,$ 强调在解决鬼影和解决闪烁之间寻求平衡。具体思路其实很简单：就是当物体和相机移动，以及发生<strong>遮挡 Occlusion</strong> 或<strong>遮挡去除 Disocclusion</strong> 时，处理鬼影现象优先于处理闪烁现象（即增加 $\,\alpha\,$ 的值），特别高速移动的物体我们相对来说不太在乎是否闪烁，反正也看不出来；反之，当物体和相机静止时，处理闪烁现象优先于处理鬼影现象（即减小 $\,\alpha\,$ 的值），因为静止状态下闪烁极其碍眼，影响体验。那么如何判断物体或相机是否在移动，还是老样子，就是使用颜色信息以及几何信息进行判断。</p>
<p>由于在解决鬼影和解决闪烁之间寻求平衡真的非常困难，我在这里浪费了不少时间也没能取得一个特别让人满意的鱼与熊掌兼得的结果，所以下面的思路仅供抛砖引玉，之后还是要不断优化的。在下面我会讲几个我认为比较有效的方法。因为自适应 $\,\alpha\,$ 比较经验主义，里面会有很多魔法数字，所以代码仅供参考，对于不同项目不同需求需要对代码中的魔法数字做出适当调整。顺便提一句，特别建议去看动视在 Siggraph 2016 的演讲 <a target="_blank" rel="noopener" href="https://research.activision.com/publications/archives/filmic-smaasharp-morphological-and-temporal-antialiasing">Filmic SMAA: Sharp Morphological and Temporal Antialiasing</a> ，里面提到的 TAA 抗鬼影、闪烁的方法很全。</p>
<p>①<strong>Color Weighted Blending Factor</strong><br>简单来说 Color Weighted Blending Factor 就是使用颜色信息来判断是否产生了闪烁现象，是较为有效的抗几何和高光闪烁的方法，具体思路也有两种：<br>&emsp;&emsp; - <strong>Distance to clamp</strong>：这个是 Epic Games 在 SIGGRAPH 2014 的演讲 <a target="_blank" rel="noopener" href="https://de45xmedrsdbp.cloudfront.net/Resources/files/TemporalAA_small-59732822.pdf">High Quality Temporal Supersampling</a> 中提到的方法，具体思路就是 Reduce blend factor when history is near clamping，即对于刚刚发生 color clamping 的像素，减少 $\,\alpha\,$，可以在 Alpha 通道中累计发生 clamping 的帧与当前帧所间隔的帧数，根据帧数来决定减少 $\,\alpha\,$ 的程度。我没有实践过这个方法，据动视在 Siggraph 2016 的 PPT 所说是不如下面的基于颜色 Contrast 的判断的；<br>&emsp;&emsp; - <strong>Contrast Weighted Blending Factor</strong>：该方法通过判断颜色差异，即 contrast，来确定是否产生了闪烁，若产生了闪烁，则减少 $\,\alpha\,$ 的值。思路可以有两种，一种是 <strong>Temporal Contrast</strong>，一种是 <strong>Spatial Contrast</strong>。Temporal Contrast 通过像素当前帧和前一帧的像素颜色亮度差值，来判断是否产生了闪烁，可以选择在 Alpha 通道中累计这个差值，通过累计的 Temporal Contrast 确定减少的 $\,\alpha\,$ 值大小；Spatial Contrast 则在像素的 Neighbourhood 中，选择最大亮度像素和最小亮度像素相减得到 Contrast，并在 Alpha 通道中累计这个 Contrast。这两个思路我都尝试过，我感觉结果是大差不差的，当然不排除我代码没写好。下面展示我的 Spatial Contrast 的代码（代码中的 blendFactor 是 $\,1 - \alpha\,$，通常是 0.9 ~ 0.95。threshold 参考了 FXAA 的 Fixed Threshold 和 Relative Threshold 的数值）：  </p>
<pre><code>float GetContrastWeightedBlendFactor(float blendFactor, float minNeighbourLuma, float maxNeighbourLuma, float historyLuma, inout float accumulatedLumaContrast)
&#123;
    float lumaContrast = max(maxNeighbourLuma - minNeighbourLuma, 0);
    accumulatedLumaContrast = lerp(lumaContrast, accumulatedLumaContrast, 0.90);
    float threshold = max(0.0625, historyLuma * 0.125);
    float lumaFactor = saturate(accumulatedLumaContrast - threshold);
    blendFactor = lerp(blendFactor, 0.98, lumaFactor);
    return blendFactor;
&#125;
</code></pre><p>Color Weighted Blending Factor 无论基于哪种思路，都是会略微增加鬼影现象的，特别是基于颜色的鬼影，比如阴影的鬼影，因为阴影没有 Motion Vector，同时会由于 Contrast 被误判为闪烁。</p>
<blockquote>
<p>修改 $\,\alpha\,$ 的值的方式，无论怎么尝试，都只能做到略微缓解闪烁，其实最好的抗闪烁方式永远是取消 Color Clamping。静态场景中取消 Color Clamping 在上面的 Filter Current Color、Luma Weighted Exponential Blending 的加持下，其实几乎看不到闪烁问题了。所以我花了很多时间，尝试判断几何信息来确定像素是否在运动，比如保留上一帧的速度信息，当这一帧和上一帧速度都为 0 时，才取消 Color Clamping，有速度差时，拒绝历史，但是最终发现判断几何信息无法解决颜色变化产生鬼影，比如阴影。我把颜色鬼影问题、闪烁问题、几何鬼影问题称为 <strong>TAA 的不可能三角</strong>。  </p>
<p>我后来又在网上看到一个思路：比较这一帧与上一帧的深度差，若有深度差，且当前后两帧速度为 0 时，则认为是几何闪烁。这个思路看似可以绕过不可能三角，但我在实践中发现比较深度差并不是一个很好的方式，因为像素在抖动时就会产生深度差，所以判断闪烁的深度差阈值不能太低，但是对于远景的物体，比如水平地面的远处，像素抖动的深度差可能会非常大，这就会导致阈值很难设定的问题，设定太低闪烁问题是好了，但是颜色鬼影问题又会出现，设定太高闪烁问题又会出现。总之，还是绕不开不可能三角，我不否定我代码没写好的可能，但我确实没得到一个特别满意的结果。为此，我特别观察了几款游戏的 TAA，其实发现在 1080 P 下，基本上也都做不到我想要得到的那种特别满意的结果，所以其实可以不用太过于纠结 TAA 的这些副作用，其实多数玩家很可能都感受不到，我在接触 TAA 技术前也没有什么这类感觉。  </p>
<p>我估计之后在研究 <strong>Temporal Super Resolution (TSR)</strong> 或 <strong>FidelityFX Super Resolution (FSR)</strong> 等超分算法时，还是会遇到上述问题，到时候再回来研究，看看有没有更好的解决方案。但是我大致看了一圈，基本上说不使用 AI 技术，也基本没什么特别好的办法。</p>
</blockquote>
<p>②<strong>Velocity Weighted Blending Factor</strong><br>跟 Velocity Rejection 一样也是两种思路：<br>&emsp;&emsp; - 一是保留上一帧的速度，若上一帧和这一帧的速度都为 0，则认为像素在静止状态，此时减少 $\,\alpha\,$ 的值。但还是老样子，会误伤颜色鬼影问题，代码类似 Geometry Rejection 中的 Velocity Rejection；<br>&emsp;&emsp; - 二是直接使用当前帧的速度大小来调整 $\,\alpha\,$ 的值，这个方法其实是没法减少几何鬼影问题的，而且也会误伤颜色鬼影问题，只能略微减少运动物体的模糊感，代码大致如下（代码中的 blendFactor 是 $\,1 - \alpha\,$）：  </p>
<pre><code>float velocityLengthSqr = dot(velocity, velocity);
blendFactor = lerp(blendFactor + 0.025, 0, saturate(velocityLengthSqr * 10));
</code></pre><h2 id="重投影优化"><a href="#重投影优化" class="headerlink" title="重投影优化"></a>重投影优化</h2><p>由于 motion vector 没有被抗锯齿处理过，使用 motion vector 进行重投影时会间接引入锯齿，特别是移动物体的边缘会因此出现锯齿。一种常见的解决方案就是采样 motion vector 时放大靠前物体的边缘，称为 <strong>Depth Dilation</strong>。具体来说就是，使用周围几个像素点的最近深度的像素点的 motion vector 进行重投影，以此达到更加平滑的效果，代码如下：  </p>
<pre><code>float2 GetClosestDepthPixelCoord(TEXTURE2D(depthTex), int2 pixelCoord, out float depth)
&#123;
    float M = LoadOffset(depthTex, pixelCoord, int2(0, 0)).x;
    float N = LoadOffset(depthTex, pixelCoord, int2(0, 1)).x;
    float E = LoadOffset(depthTex, pixelCoord, int2(1, 0)).x;
    float S = LoadOffset(depthTex, pixelCoord, int2(0, -1)).x;
    float W = LoadOffset(depthTex, pixelCoord, int2(-1, 0)).x;
    #if _TAA_SAMPLE_3X3
    float NW = LoadOffset(depthTex, pixelCoord, int2(-1, 1)).x;
    float NE = LoadOffset(depthTex, pixelCoord, int2(1, 1)).x;
    float SW = LoadOffset(depthTex, pixelCoord, int2(-1, -1)).x;
    float SE = LoadOffset(depthTex, pixelCoord, int2(1, -1)).x;
    #endif

    float3 offset = float3(0, 0, M);
    offset = lerp(offset, float3(0, 1, N), COMPARE_DEVICE_DEPTH_CLOSER(N, offset.z));
    offset = lerp(offset, float3(1, 0, E), COMPARE_DEVICE_DEPTH_CLOSER(E, offset.z));
    offset = lerp(offset, float3(0, -1, S), COMPARE_DEVICE_DEPTH_CLOSER(S, offset.z));
    offset = lerp(offset, float3(-1, 0, W), COMPARE_DEVICE_DEPTH_CLOSER(W, offset.z));
    #if _TAA_SAMPLE_3X3
    offset = lerp(offset, float3(-1, 1, NW), COMPARE_DEVICE_DEPTH_CLOSER(NW, offset.z));
    offset = lerp(offset, float3(1, 1, NE), COMPARE_DEVICE_DEPTH_CLOSER(NE, offset.z));
    offset = lerp(offset, float3(-1, -1, SW), COMPARE_DEVICE_DEPTH_CLOSER(SW, offset.z));
    offset = lerp(offset, float3(1, -1, SE), COMPARE_DEVICE_DEPTH_CLOSER(SE, offset.z));
    #endif

    depth = offset.z;
    return pixelCoord + offset.xy;
&#125;
</code></pre><p>上述代码就是采样当前像素点周围的 5 个或 9 个像素点，找到最近的像素点作为采样 motion vector 的坐标：  </p>
<pre><code>float closestDepth;
float2 velocityPixelCoord = GetClosestDepthPixelCoord(_CameraDepthTexture, IN.positionHCS.xy, closestDepth);
float2 velocity = LOAD_TEXTURE2D_LOD(_CameraMotionVectorTexture, velocityPixelCoord, 0).rg;
</code></pre><p>这个方法膨大了物体的边缘以此减少边缘锯齿。还有一种方法叫做 <strong>Magnitude Dilation</strong>，Depth Dilation 选取的是 neighborhood 中最近像素点的 motion vector，Magnitude Dilation 选取的是 neighborhood 中速度最大的 motion vector，具体我没有实现，不知道效果好不好，有兴趣可以自己尝试。Depth Dilation 的效果如下，仔细观察物体边缘，可以看出物体边缘跟上面比锯齿相对来说少了：  </p>
<div align="center">  
<img src="https://s2.loli.net/2025/07/25/sXKMAf4DVGL5Oe3.gif" width = "512" height = "512" alt="图16 - Closest Velocity（No Adaptive Blending Factor）"/>
</div>

<h2 id="模糊优化"><a href="#模糊优化" class="headerlink" title="模糊优化"></a>模糊优化</h2><p>TAA 的模糊大致上有 3 个来源：<br>①为了抗闪烁，过滤了当前帧颜色引入的模糊；<br>②在重投影小节中有提到过，采样 TAA History 贴图时，由于减去 Motion Vector 导致采样点不在像素点中心位置，所以必须使用 bilinear 采样 TAA History，同时这在一定程度上也引入了模糊。又由于 TAA 会在历史不断累计，导致这种模糊也会在历史中不断累计，更加强了模糊。而解决这种模糊的方式就是使用有锐化功能的过滤核采样 TAA History，比如 Catmull-Rom Bicubic Filter，在后面小节中详细说明；<br>③历史验证以及混合导致的模糊。首先历史验证有个重要假设，即周围像素点包含了当前像素点所覆盖的表面颜色，但是对于高频颜色信息，由于抖动后光栅化的不确定性，这个假设会被打破，导致高频细节的丢失，这一问题经常出现在细节较多的场景。当然历史混合本身也会增加模糊。  </p>
<p>① 和 ③ 这两个来源没有什么特别好的解决方案，只能靠后处理锐化重建高频细节（在 TAA 完成后重建），可以使用 Laplacian Filter、Catmull-Rom Bicubic Filter 或者 Mitchell-Netravali Bicubic Filter，这一块我在本篇文章中就不详细说明了，可以搜索上述关键词（其实图像重建跟 Super-Resolution 技术有很强的关联性，我会在后面的 Super-Resolution 小节中大致说明，作为 TAA 技术的补充）。而 ② 由于 TAA 时就已经拿到 TAA History，所以可以直接在 TAA 时对 TAA History 进行过滤，即下面要讲的 History Filter。</p>
<h3 id="History-Filter"><a href="#History-Filter" class="headerlink" title="History Filter"></a>History Filter</h3><p>常规的 Bicubic Filter 需要采样 16 次，可以被优化到只需采样 9 次，详见链接：<a target="_blank" rel="noopener" href="https://gist.github.com/TheRealMJP/c83b8c0f46b63f3a88a5986f4fa982b1">https://gist.github.com/TheRealMJP/c83b8c0f46b63f3a88a5986f4fa982b1</a> 。而动视 Activision 进行了进一步优化，在 SIGGRAPH 2016 的演讲 <a target="_blank" rel="noopener" href="https://research.activision.com/publications/archives/filmic-smaasharp-morphological-and-temporal-antialiasing">Filmic SMAA: Sharp Morphological and Temporal Antialiasing</a> 中提出了一个只需要使用 5 次采样的 Catmull-Rom Bicubic Filter，代码如下：  </p>
<pre><code>float3 SampleHistoryBicubic(TEXTURE2D(tex), float2 uv)
&#123;
    float2 samplePos = uv * _CameraBufferSize.zw;
    float2 tc1 = floor(samplePos - 0.5) + 0.5;
    float2 f = samplePos - tc1;
    float2 f2 = f * f;
    float2 f3 = f * f2;

    float c = 0.5; // sharpen factor (0, 1)

    float2 w0 = -c         * f3 +  2.0 * c         * f2 - c * f;
    float2 w1 =  (2.0 - c) * f3 - (3.0 - c)        * f2          + 1.0;
    float2 w2 = -(2.0 - c) * f3 + (3.0 - 2.0 * c)  * f2 + c * f;
    float2 w3 = c          * f3 - c                * f2;

    float2 w12 = w1 + w2;
    float2 tc0 = _CameraBufferSize.xy   * (tc1 - 1.0);
    float2 tc3 = _CameraBufferSize.xy   * (tc1 + 2.0);
    float2 tc12 = _CameraBufferSize.xy  * (tc1 + w2 / w12);

    float3 s0 = SampleHistoryLinear(tex, float2(tc12.x, tc0.y));
    float3 s1 = SampleHistoryLinear(tex, float2(tc0.x, tc12.y));
    float3 s2 = SampleHistoryLinear(tex, float2(tc12.x, tc12.y));
    float3 s3 = SampleHistoryLinear(tex, float2(tc3.x, tc12.y));
    float3 s4 = SampleHistoryLinear(tex, float2(tc12.x, tc3.y));

    float cw0 = (w12.x * w0.y);
    float cw1 = (w0.x * w12.y);
    float cw2 = (w12.x * w12.y);
    float cw3 = (w3.x * w12.y);
    float cw4 = (w12.x *  w3.y);

    s0 *= cw0;
    s1 *= cw1;
    s2 *= cw2;
    s3 *= cw3;
    s4 *= cw4;

    float3 historyFiltered = s0 + s1 + s2 + s3 + s4;
    float weightSum = cw0 + cw1 + cw2 + cw3 + cw4;

    float3 filteredVal = historyFiltered * rcp(weightSum);

    return filteredVal;
&#125;
</code></pre><p>在静止场景中，使用 Catmull-Rom Bicubic 过滤 TAA History 可能看不出区别。但是在动态场景中，是可以感受出 Catmull-Rom 过滤后会更加清晰，效果如下，确实比上面 Gaussian Filter 后的效果要清晰一点，虽然不多：  </p>
<div align="center">  
<img src="https://s2.loli.net/2025/07/25/ZcXodYyfsmvwuES.gif" width = "512" height = "512" alt="图17 - After Catmull-Rom History Filter（No Adaptive Blending Factor）"/>
</div>

<h1 id="Object-Motion-Vector"><a href="#Object-Motion-Vector" class="headerlink" title="Object Motion Vector"></a>Object Motion Vector</h1><p>Object Motion Vector 相对于 Camera Motion Vector 来说复杂了很多，需要考虑更多的情形。从计算方式来说，多了 MVP 矩阵的 M 的变化，以及顶点的 positionOS 的变化：需要使用这一帧的 positionOS 乘上这一帧的 M 矩阵和没有抖动过的 VP 矩阵，得到这一帧未抖动的屏幕空间坐标，再使用上一帧的 positionOS 乘上上一帧的 M 矩阵和没有抖动过的 VP 矩阵，得到上一帧未抖动的屏幕空间坐标，两个坐标相减即 Object Motion Vector（可以看出 Object Motion Vector 是包含 Camera Motion Vector 的）。</p>
<p>但是产生 MVP 矩阵的 M 的变化，以及顶点的 positionOS 的变化的来源有很多：<br>①<strong>刚体或变换运动 Rigid &amp; Transform Motion</strong>：物理引擎或者直接修改物体的 transform 本质上都是改变了物体的世界坐标，即 MVP 矩阵的 M。这类移动计算 Object Motion Vector 相对比较容易，只要我们能拿到上一帧的 MVP 矩阵即可计算；<br>②<strong>骨骼动画 Skeletal Animation</strong>：骨骼动画改变的是物体的模型空间的顶点坐标，不改变物体的世界坐标，它通过骨骼变换矩阵将顶点变换到新的模型空间坐标，从而达到让物体运动的效果。而 <strong>Root Motion</strong> 技术，实际上是提取了骨骼动画中根骨骼（或其他指定骨骼）的模型空间位移或旋转信息，并将其应用于物体的世界坐标变换当中，所以 Root Motion 可以理解为 Transform Motion 和 Skeletal Animation 的结合体。骨骼动画计算 Object Motion Vector 除了上一帧的 MVP 矩阵，还需要额外的上一帧的 positionOS 信息，所幸的是 Unity 会帮我们保留这部分信息，只要勾选 Skinned Mesh Renderer -&gt; Additional Settings -&gt; Skinned Motion Vectors 即可（默认是勾选的）；<br>③<strong>混合形状动画 Blend Shape Animation</strong>：Blend Shape 改变的也是模型空间的顶点坐标，只不过它存储的是每个顶点相对于基础形态在模型空间中的偏移量，在使用中可以根据权重值调节形态。所以跟骨骼动画一样，也需要额外的上一帧的 positionOS 信息，并且 Unity 的 Skinned Mesh Renderer 也帮我们保留这部分信息，只要开启了 Skinned Motion Vectors；<br>④<strong>Alembic 动画 Alembic Animation</strong>：Alembic 动画存储了逐帧的几何体数据（包括顶点位置变化或数量变化），所以数据量是极度庞大的，故主要应用于影视级动画。它改变的也是模型空间的顶点坐标，但是 Unity 对 Alembic 动画的处理有点特殊，它额外存储了一个预计算好的模型空间 Velocity，需要在计算 Motion Vectors 额外减去以得到上一帧的模型空间坐标，后面会具体说明；<br>⑤<strong>顶点动画 Vertex Animation</strong>：顶点动画就是在顶点着色器中直接修改顶点位置，所以无法使用上述通用的计算 Object Motion Vector 的方法。不同的顶点动画需要有不同的 Motion Vector Pass，我们需要根据自己实现的顶点动画额外计算出顶点在上一帧的位置，从而实现 Object Motion Vector。</p>
<p>一个通用的 Object Motion Vector Pass 只能处理上述的 ①、②、③、④ 情形，对于 ⑤ 则需要不同情况不同处理，下面主要讲解通用的 Object Motion Vector Pass，了解后根据需求处理情形 ⑤ 也不会很难。额外提一下，TAA 是无法处理<strong>序列帧动画 Sequence Frame Animation</strong> 的，因为没有 Motion Vector，序列帧动画主要用于 2D 游戏和一些特效。至于粒子动画，就得看粒子的实现方法了，看是 CPU 粒子还是 GPU 粒子，具体使用了哪些技术，具体情况具体分析，使用序列帧或透明的粒子在 TAA 下肯定会略微模糊的。透明物体的支持对 TAA 来说也是一个难题，我会在后面的 TAA 其他问题说明小节中说明。</p>
<h2 id="Unity-SRP-中实现-Object-Motion-Vector"><a href="#Unity-SRP-中实现-Object-Motion-Vector" class="headerlink" title="Unity SRP 中实现 Object Motion Vector"></a>Unity SRP 中实现 Object Motion Vector</h2><p>受限于 Unity C++ legacy 代码，在 Unity 中渲染 Object Motion Vector 是有不少的坑点的，稍有不注意就可能会错误渲染 Object Motion Vector，具体坑点有如下：<br>①Unity 不会对静止的物体更新 <code>unity_MatrixPreviousM</code> 矩阵，只会在物体发生移动的时候更新，这会导致当物体发生移动后又保持静止时，<code>unity_MatrixPreviousM</code> 会保持前一次移动的模型矩阵，导致错误渲染 Object Motion Vector。要想让 Unity 只对动态物体渲染 motion vector，不对静态物体渲染，我们还需要在 material 层面禁止 Object Motion Vector Pass，让 Unity C++ legacy 来根据物体是否在运动来渲染 Object Motion Vector Pass；<br>②需要将 <code>Camera.depthTextureMode</code> 设置为 <code>DepthTextureMode.MotionVectors</code>，否则 Unity C++ legacy 不会计算上一帧的模型矩阵；<br>③由于 Unity 只对运动物体绘制 Object Motion Vector，这就导致了必须在 Object Motion Vector Pass 前绘制所有物体的深度值（当然 Z-prepass 几乎是必须的），以正确处理运动物体的遮挡关系。</p>
<p>接下来在实现 Object Motion Vector 的过程中，我们会一步接一步地遇到上述几个问题，遇到时我会详细说明。另外说明一下，除了 Skinned Mesh Renderer 的 Skinned Motion Vectors 设置外，普通的 Mesh Renderer 的 Motion Vector 也有三个设置，如下图：  </p>
<div align="center">  
<img src="https://s2.loli.net/2025/07/25/f6AqDRbPiJ5IcGH.png" width = "45%" height = "45%" alt="图18 - Mesh Renderer Motion Vectors Option"/>
</div>

<p>选择 <strong>Camera Motion Only</strong>，Unity 就不会绘制该 Mesh Renderer 的 object motion vector，即使是在运动；选择 <strong>Per Object Motion</strong>，Unity 会绘制在运动物体的 object motion vector，忽略静止物体的 object motion vector；选择 <strong>Force No Motion</strong>，仍然会渲染 object motion vector，但是强行让运动的物体的 object motion vector 为 0（这个需要自己在 Shader 中设置，后面会讲）。</p>
<h3 id="MotionVectors-Pass"><a href="#MotionVectors-Pass" class="headerlink" title="MotionVectors Pass"></a>MotionVectors Pass</h3><h4 id="DrawRendererList"><a href="#DrawRendererList" class="headerlink" title="DrawRendererList"></a>DrawRendererList</h4><p>理论上我们能拿到上一帧的 M 矩阵以及 positionOS 就可以渲染出 Object Motion Vector，而 Unity 也提供了对应的 PerObjectData，我们只需要在 SRP 调用 <code>CommandBuffer.DrawRendererList</code> 时，设置 <code>PerObjectData.MotionVectors</code> 即可，类似如下：  </p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line">RendererListDesc opaqueRendererListDesc = <span class="keyword">new</span> RendererListDesc(ShaderTagIDs.k_MotionVectorsShaderTagId, data.cullingResults, data.camera)</span><br><span class="line">&#123;</span><br><span class="line">    rendererConfiguration = PerObjectData.MotionVectors,</span><br><span class="line">    renderQueueRange = <span class="keyword">new</span> RenderQueueRange(<span class="number">2000</span>, <span class="number">2449</span>),</span><br><span class="line">    sortingCriteria = SortingCriteria.CommonOpaque</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p><code>k_MotionVectorsShaderTagId</code> 就是 Unity 强制要求的 <code>Tags &#123; &quot;LightMode&quot; = &quot;MotionVectors&quot; &#125;</code>，必须是 <code>MotionVectors</code> 否则 Unity C++ legacy 不会正确设置参数。</p>
<h4 id="UnityPerDraw-cbuffer"><a href="#UnityPerDraw-cbuffer" class="headerlink" title="UnityPerDraw cbuffer"></a>UnityPerDraw cbuffer</h4><p>然后在 UnityInput.hlsl 中的 <strong>UnityPerDraw</strong> cbuffer 中添加对应的矩阵变量和参数：  </p>
<pre><code>CBUFFER_START(UnityPerDraw)
    ...
    float4x4 unity_MatrixPreviousM;
    float4x4 unity_MatrixPreviousMI;
    // x : Use last frame positions (right now skinned meshes are the only objects that use this)
    // y : Force No Motion
    // z : Z bias value
    // w : Camera only
    float4 unity_MotionVectorsParams;
CBUFFER_END
</code></pre><p><code>unity_MotionVectorsParams.x</code> 用于判断是否需要使用上一帧的 positionOS，需要使用 positionOS 只有 Skinned Mesh Renderer；y 当 Mesh Renderer 的 <strong>Force No Motion</strong> 被选择时，会被设置为 0；zw 用不上，就不用讲了。</p>
<h4 id="MotionVectors-Shader"><a href="#MotionVectors-Shader" class="headerlink" title="MotionVectors Shader"></a>MotionVectors Shader</h4><p>因为 Object Motion Vector 是对每一个物体绘制的，需要在每个 Shading Model 对应的 Shader 里都添加 MotionVectors Pass：  </p>
<pre><code>Pass
&#123;
    Name &quot;MotionVectors&quot;
    Tags &#123; &quot;LightMode&quot; = &quot;MotionVectors&quot; &#125;
    ...
&#125;
</code></pre><p>MotionVectors Pass 的 Shader 代码如下：  </p>
<pre><code>struct Attributes
&#123;
    float4 positionOS : POSITION;
    float2 uv : TEXCOORD0;

    float3 previousPositionOS : TEXCOORD4;
    #if _ADD_PRECOMPUTED_VELOCITY
        float3 precomputedVelocity : TEXCOORD5;
    #endif

    UNITY_VERTEX_INPUT_INSTANCE_ID
&#125;;

struct Varyings
&#123;
    float4 positionHCS : SV_POSITION;
    float2 uv : TEXCOORD0;
    float4 nonJitterPositionHCS : TEXCOORD1;
    float4 previousNonJitterPositionHCS : TEXCOORD2;
    UNITY_VERTEX_INPUT_INSTANCE_ID
&#125;;

Varyings MotionVectorVert(Attributes IN)
&#123;
    Varyings OUT;
    UNITY_SETUP_INSTANCE_ID(IN);
    UNITY_TRANSFER_INSTANCE_ID(IN, OUT);
    OUT.positionHCS = TransformObjectToHClip(IN.positionOS.xyz);
    float4 baseST = UNITY_ACCESS_INSTANCED_PROP(UnityPerMaterial, _BaseTex_ST);
    OUT.uv = IN.uv * baseST.xy + baseST.zw;

    OUT.nonJitterPositionHCS = mul(UNITY_MATRIX_NONJITTERED_VP, mul(UNITY_MATRIX_M, float4(IN.positionOS.xyz, 1.0)));

    // Skin or morph
    float4 previousPositionOS = unity_MotionVectorsParams.x &gt; 0.0 ? float4(IN.previousPositionOS, 1.0) : float4(IN.positionOS.xyz, 1.0);

    #if _ADD_PRECOMPUTED_VELOCITY
        previousPositionOS = previousPositionOS - float4(IN.precomputedVelocity, 0);
    #endif

    OUT.previousNonJitterPositionHCS = mul(UNITY_PREV_MATRIX_NONJITTERED_VP, mul(UNITY_PREV_MATRIX_M, previousPositionOS));

    return OUT;
&#125;

float4 MotionVectorFrag(Varyings IN) : SV_Target
&#123;
    UNITY_SETUP_INSTANCE_ID(IN);

    float2 currentPositionNDC = IN.nonJitterPositionHCS.xy / IN.nonJitterPositionHCS.w;
    float2 previousPositionNDC = IN.previousNonJitterPositionHCS.xy / IN.previousNonJitterPositionHCS.w;

    float2 velocity = currentPositionNDC - previousPositionNDC;

    #if UNITY_UV_STARTS_AT_TOP
        velocity.y = -velocity.y;
    #endif

    velocity *= 0.5;

    #if defined(_CLIPPING)
        float4 baseColor = UNITY_ACCESS_INSTANCED_PROP(UnityPerMaterial, _BaseColor);
        float alpha = SAMPLE_TEXTURE2D(_BaseTex, sampler_Trilinear_Repeat_BaseTex, IN.uv).a * baseColor.a;
        clip(alpha - UNITY_ACCESS_INSTANCED_PROP(UnityPerMaterial, _Cutoff));
    #endif

    #if defined(LOD_FADE_CROSSFADE)
        float dither = InterleavedGradientNoise(IN.positionHCS.xy, 0);
        float isNextLodLevel = step(unity_LODFade.x, 0);
        dither = lerp(-dither, dither, isNextLodLevel);
        clip(unity_LODFade.x + dither);
    #endif

    // Note: unity_MotionVectorsParams.y is 0 is forceNoMotion is enabled
    bool forceNoMotion = unity_MotionVectorsParams.y == 0.0;
    if (forceNoMotion) return float4(0.0, 0.0, 0.0, 0.0);

    return float4(velocity, 0, 0);
&#125;
</code></pre><p>代码说明：<br>①注意 <code>previousPositionOS</code> 一定要从 TEXCOORD4 读取，才能匹配<strong>顶点输入布局 Vertex Input Layout</strong>，否则会拿不到数据。<code>precomputedVelocity</code> 同理，precomputedVelocity 就是 Unity 为 Alembic Animation 预计算好的模型空间 Velocity，后面小节会专门说明；<br>②因为只有 Skinned Mesh Renderer 需要使用到 <code>previousPositionOS</code>，我们需要使用 <code>unity_MotionVectorsParams.x</code> 来判断当前是否是 Skinned Mesh Renderer 在渲染，即上述代码中的 <code>float4 previousPositionOS = unity_MotionVectorsParams.x &gt; 0.0 ? float4(IN.previousPositionOS, 1.0) : float4(IN.positionOS.xyz, 1.0)</code>；<br>③判断是否开启了 Force No Motion，若开启则强制输出为 0 的 motion vector：<code>bool forceNoMotion = unity_MotionVectorsParams.y == 0.0;</code>；<br>④其他代码就没什么好说明的了，比较简单。</p>
<p>理论上来说，上面的工作完成，就应该能够正确渲染 Object Motion Vector，然而实际上并不能，原因就是之前提到的坑点的第一点：Unity 不会对静止的物体更新 <code>unity_MatrixPreviousM</code> 矩阵，只会在物体运动时更新，并且只会绘制运动物体的 Object Motion Vector。我理解 Unity 一开始这么设计的初衷，应该就是为了减少 Draw Call，防止不运动的物体也绘制 Object Motion Vector，但是这么做对于现在来说，实属大可不必。Unity 只绘制动态物体的 MotionVectors Pass 的隐藏机制，也断绝了我们将 Object Motion Vector 和 DepthNormalPrepass 或者 Gbuffer 一起绘制的可能性，这点我觉得是极其坑的，不知道什么时候 Unity 会抛弃 Legacy Unity 的设计。</p>
<h3 id="ShaderGUI-中关闭-MotionVectors-Pass"><a href="#ShaderGUI-中关闭-MotionVectors-Pass" class="headerlink" title="ShaderGUI 中关闭 MotionVectors Pass"></a>ShaderGUI 中关闭 MotionVectors Pass</h3><p>在上面我们所写的代码中，并没有代码控制让 Unity 只绘制运动物体的 Object Motion Vector，不绘制静止物体。这个是由 Unity C++ legacy 代码自行控制的，但是前提是我们要在 material 的层面上禁用 MotionVectors Pass，通过 <code>Material.SetShaderPassEnabled</code> API。然后 Unity C++ legacy 会针对运动物体启用这个 pass，从而实现只绘制运动物体的 Object Motion Vector。</p>
<p>所以为了能够正确绘制 Object Motion Vector，我们需要确保场景中所有物体的 material 都禁用了 MotionVectors Pass，具体是通过 ShaderGUI 中 <code>ValidateMaterial()</code> 接口实现：  </p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">override</span> <span class="keyword">void</span> <span class="title">ValidateMaterial</span>(<span class="params">Material material</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    DisableMotionVectorsPass(material);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">const</span> <span class="built_in">string</span> k_MotionVectorPassName = <span class="string">&quot;MotionVectors&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// All Setup Keyword functions must be static. It allow to create script to automatically update the shaders with a script if code change</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">DisableMotionVectorsPass</span>(<span class="params">Material material</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (material.GetShaderPassEnabled(k_MotionVectorPassName))</span><br><span class="line">    &#123;</span><br><span class="line">        material.SetShaderPassEnabled(k_MotionVectorPassName, <span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ShaderGUI 的 <code>ValidateMaterial()</code> 根据官方文档中所说：When the user loads a Material using this ShaderGUI into memory or changes a value in the Inspector, the Editor calls this method. 也就是当材质导入或修改属性时会调用，对于已经在项目中的材质，需要手动更改一下属性再调回去，或者使用代码对所有材质做批量处理。</p>
<p>就当我以为这样就可以成功的时候，我发现我的 Object Motion Vector 怎么都绘制不对，但是 URP 和 HDRP 又可以正确绘制 Object Motion Vector，我一直以为是自己的 Shader 写错了，害得我在这里费了将近一个星期的时间，直到我看到了 URP 和 HDRP 的以下注释（这就是我在上面说的坑点 2）：  </p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="comment">// These flags are still required in SRP or the engine won&#x27;t compute previous model matrices...</span></span><br><span class="line"><span class="comment">// If the flag hasn&#x27;t been set yet on this camera, motion vectors will skip a frame.</span></span><br><span class="line">camera.depthTextureMode |= DepthTextureMode.MotionVectors | DepthTextureMode.Depth;</span><br></pre></td></tr></table></figure>
<h3 id="与-Camera-Motion-Vector-合并"><a href="#与-Camera-Motion-Vector-合并" class="headerlink" title="与 Camera Motion Vector 合并"></a>与 Camera Motion Vector 合并</h3><p>由于 Unity 只会绘制运动物体的 Object Motion Vector，我们还需要绘制 Camera Motion Vector 得到静止物体的 Motion Vector（摄像机移动的情况）。本来若静止物体和运动物体都可以绘制 Object Motion Vector，是不需要额外绘制 Camera Motion Vector 的，但是 Unity 的 Legacy 设计让我们不得不这么做。还有就是，与 Camera Motion Vector 合并的过程中，很容易忽略一个事情，就是运动物体被静止物体遮挡的情况，所以我们必须要有一个 depth prepass 来正确处理运动物体的遮挡关系，即坑点 3，当然 Camera Motion Vector 本身就需要采样 depth texture。</p>
<p>我们可以先绘制 Camera Motion Vector 再绘制 Object Motion Vector，这样 Object Motion Vector 可以直接覆盖在 Camera Motion Vector 的上面，就是绘制 Object Motion Vector 设置 render target 时别忘了附上 depth attachment，然后设置 Z test 为 Equal 以正确处理遮挡问题。也可以先绘制 Object Motion Vector 再绘制 Camera Motion Vector，这样就需要用到 stencil 模板值了，绘制 Object Motion Vector 时，绑定 depthStencilAttachment，设置 Z test 为 Equal，确保只绘制可见的运动物体，同时设置模板值 Comp Always 和 Pass Replace，然后在绘制 Camera Motion Vector 设置模板为 Comp NotEqual，这样 Camera Motion Vector 就会绘制 Object Motion Vector 没有绘制到的地方。先绘制 Object Motion Vector 在有大量运动物体的情况下，肯定比先绘制 Camera Motion Vector 要好一些。</p>
<p>这样子 SRP 的 Object Motion Vector 的绘制可以说是大功告成了，物体移动的 TAA 效果如下：  </p>
<blockquote>
<p>顺便提一下，unity 的 Frame Debugger 好像无法查看 Object Motion Vector 或 Camera Motion Vector 的绘制，因为它好像会暂停一帧（不是很确定具体原因），最好使用 RenderDoc 查看。</p>
</blockquote>
<div align="center">  
<img src="https://s2.loli.net/2025/07/26/lRaczJLSsZDwmOd.gif" width = "512" height = "512" alt="图19 - Object Motion Vector 后物体移动的 TAA 效果（No Adaptive Blending Factor）"/>
</div>

<h3 id="其他说明"><a href="#其他说明" class="headerlink" title="其他说明"></a>其他说明</h3><h4 id="重复绘制问题"><a href="#重复绘制问题" class="headerlink" title="重复绘制问题"></a>重复绘制问题</h4><p>上面的方法中，因为 Object Motion Vector 要和 DepthNormal PrePass 或者 GBuffer 分开绘制，这就会导致同个运动物体在 Object Motion Vector 和 DepthNormal PrePass 或者 GBuffer 中分别绘制了一次。但是因为 Unity C++ legacy 的设计问题，我们无法在 DepthNormal PrePass 或者 GBuffer 的同时绘制 Object Motion Vector。于是 Unity 还提供了一个补丁，就是绘制 DepthNormal PrePass 或者 GBuffer 剔除运动物体，然后在 MotionVectors Pass 中输出运动物体 Object Motion Vector 的同时输出 normal 或其他信息。</p>
<p>这个 API 就是 <code>RendererListDesc.excludeObjectMotionVectors</code>，官方文档说它会在 RendererList 中排除掉运动物体。我看 HDRP 的代码中也使用了这个 API：  </p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="built_in">bool</span> fullDeferredPrepass = hdCamera.frameSettings.IsEnabled(FrameSettingsField.DepthPrepassWithDeferredRendering);</span><br><span class="line"><span class="comment">// To avoid rendering objects twice (once in the depth pre-pass and once in the motion vector pass when the motion vector pass is enabled) we exclude the objects that have motion vectors.</span></span><br><span class="line"><span class="built_in">bool</span> objectMotionEnabled = hdCamera.frameSettings.IsEnabled(FrameSettingsField.ObjectMotionVectors);</span><br><span class="line"><span class="built_in">bool</span> excludeMotion = fullDeferredPrepass ? objectMotionEnabled : <span class="literal">false</span>;</span><br><span class="line"><span class="built_in">bool</span> shouldRenderMotionVectorAfterGBuffer = (hdCamera.frameSettings.litShaderMode == LitShaderMode.Deferred) &amp;&amp; !fullDeferredPrepass;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">passData.rendererList = builder.UseRendererList(renderGraph.CreateRendererList(</span><br><span class="line">                CreateOpaqueRendererListDesc(cull, hdCamera.camera, m_DepthOnlyAndDepthForwardOnlyPassNames, stateBlock: stateBlock, excludeObjectMotionVectors: objectMotionEnabled)));</span><br></pre></td></tr></table></figure>
<p>但是我在 HDRP 怎么试，DepthNormal PrePass 或者 GBuffer 都绘制了运动物体的信息，按理说只要开启了 Object Motion Vectors 就行，不知道有没有人可以试出来。我觉得这个补丁有点略微愚蠢，还是等以后 Unity 彻底改动底层代码了，想办法将 Object Motion Vectors 和 DepthNormal PrePass 或者 GBuffer 一起绘制，才是最佳方案。</p>
<h4 id="Alembic-Animation"><a href="#Alembic-Animation" class="headerlink" title="Alembic Animation"></a>Alembic Animation</h4><p>Alembic Animation 常用于存储复杂的动画模拟效果，比如布料模拟、流体模拟等等。在 URP 和 HDRP 的 Material 的下方都有这么一个属性：  </p>
<div align="center">  
<img src="https://s2.loli.net/2025/07/27/8yOWd9sHjLkG6te.png" width = "35%" height = "35%" alt="图20 - 上为 HDRP，下为 URP"/>
</div>

<p>它们就是用来开启 MotionVectors Pass 里的关键字 <code>_ADD_PRECOMPUTED_VELOCITY</code> 的。另外，由于官方文档的说明有限，我只能大致猜测 Unity 渲染 Alembic Animation 的机制，官方文档中有这么几句话：<br>① Use materials with the <strong>Alembic Motion Vectors</strong> checkbox enabled only on <strong>alembic vertex animation caches</strong> rendered with a <strong>PlayableDirectors</strong> component. When using such materials with regular draw calls and MeshRenderers, the materials cannot read the correct motion vector attribute stream, which results in incorrect motion vectors.<br>② Unity renders per-object motion vectors，If any of the following conditions is true: The MotionVectors pass is enabled on the material (for example, when a material has a <strong>vertex animation</strong> in Shader Graph or <strong>alembic animation</strong>).<br>③ When <strong>Alembic Motion Vectors</strong> checkbox is enabled, the material will use motion vectors from the Alembic animation cache. Should NOT be used on regular meshes or <strong>Alembic caches without precomputed motion vectors</strong>.<br>④ The <strong>Alembic package</strong>（Unity 用于导入 Alembic Animation 的官方插件）brings in vertex cache data from a 3D modeling software, such as facial animation (skinning) and cloth simulation (dynamics).</p>
<p>所以我的猜测是，Unity 对待 Alembic Animation 的方式跟<strong>顶点动画</strong>类似，且 Alembic Animation 导入 Unity 后，若有顶点变动（动画），Unity 会计算 precomputed velocity，若没有顶点变动，则没有 precomputed velocity。我在 Blender 中导出一个只有物体移动的 Alembic 动画文件，和一个布料模拟的 Alembic 动画文件，导入 Unity 后拿 Playable Director 播放了导入 timeline 的上述 Alembic 文件试了试，和我的猜想基本是一致的。只有物体移动的 Alembic 动画若开启了 Alembic Motion Vectors，渲染会出问题。布料模拟的 Alembic 开启了 Alembic Motion Vectors 效果会更好。目前对 Alembic Animation 的理解比较浅，先这么理解，以后有需求可以再好好了解。</p>
<p>那么如何在 SRP 中设置上述选项，并开启关键字 <code>_ADD_PRECOMPUTED_VELOCITY</code> 呢？还是通过之前关闭 MotionVectors Pass 时，使用的 <strong>ShaderGUI</strong> 的 <code>ValidateMaterial()</code> API。首先在 Shader 中添加 <code>_AddPrecomputedVelocity</code> 属性：  </p>
<pre><code>Shader &quot;XXXX/XXXX&quot;
&#123;
    Properties
    &#123;
        ...
        [Enum(Off, 0, On, 1)] _AddPrecomputedVelocity(&quot;Add Precomputed Velocity&quot;, Float) = 0.0
    &#125;
&#125;
</code></pre><p>然后在之前关闭 MotionVectors Pass 的方法 <code>DisableMotionVectorsPass</code> 中（我改名为了 <code>SetupMotionVectorsPassAndKeywords</code>）：  </p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">SetupMotionVectorsPassAndKeywords</span>(<span class="params">Material material</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">bool</span> motionVectorPassEnabled = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(material.HasProperty(<span class="string">&quot;_AddPrecomputedVelocity&quot;</span>))</span><br><span class="line">    &#123;</span><br><span class="line">        motionVectorPassEnabled = material.GetFloat(<span class="string">&quot;_AddPrecomputedVelocity&quot;</span>) != <span class="number">0.0f</span>;</span><br><span class="line">        CoreUtils.SetKeyword(material, ShaderKeywordStrings._ADD_PRECOMPUTED_VELOCITY, motionVectorPassEnabled);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (material.GetShaderPassEnabled(k_MotionVectorPassName) != motionVectorPassEnabled)</span><br><span class="line">    &#123;</span><br><span class="line">        material.SetShaderPassEnabled(k_MotionVectorPassName, motionVectorPassEnabled);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样就可以正确渲染 Alembic Animation 的 object motion vector 了。</p>
<h1 id="TAA-其他补充"><a href="#TAA-其他补充" class="headerlink" title="TAA 其他补充"></a>TAA 其他补充</h1><h2 id="TAA-的挑战"><a href="#TAA-的挑战" class="headerlink" title="TAA 的挑战"></a>TAA 的挑战</h2><p>没有 Motion Vector 的物体的渲染，对于 TAA 来说都是很大的挑战，比如之前说的<strong>序列帧动画</strong>，或者<strong>有复杂程序纹理应用的动画</strong>，比如烟雾、水流、云朵等等，还有<strong>透明物体</strong>、<strong>反射</strong>的渲染等等。可能有人会想到，在 TAA 后面渲染上述无 Motion Vector 的物体，但是不推荐这么做，因为这样物体的边缘会出现 jitter，因为 depth test 使用的 depth buffer 是被 jitter 过的。反射的 Motion Vector，顽皮狗在 SIGGRAPH 2016 的演讲 <a target="_blank" rel="noopener" href="https://advances.realtimerendering.com/s2016/">Temporal Antialiasing in Uncharted 4</a> 有解决方案，有兴趣可以了解一下，虽然只适用于 planar reflection。</p>
<h2 id="Upsampling-Super-Resolution"><a href="#Upsampling-Super-Resolution" class="headerlink" title="Upsampling / Super-Resolution"></a>Upsampling / Super-Resolution</h2><p><strong>时序上采样 Temporal Upsampling/Upscaling</strong> 技术是 TAA 技术的延申，它进一步减少采样率，将单像素一次采样减少至单像素部分采样，简单来说就是累计低分辨率的渲染结果去渲染高分辨率的图片。这种方法重构出来的细节会比<strong>空间上采样 Spatial Upsampling</strong> 更好。UE4 的 <strong>Temporal Anti-Aliasing Upsampling (TAAU)</strong> 以及 UE5 对 TAAU 的进化 <strong>Temporal Super Resolution (TSR)</strong> 本质上都属于该技术。  </p>
<p>最近几年常听说的<strong>超级分辨率技术 Super Resolution/Super Sampling</strong> 也是基于此的，包括 NVIDIA 的 <strong>DLSS Deep Learning Super Sampling (DLSS)</strong> 和 AMD 的 <strong>FidelityFX Super Resolution (FSR)</strong>，只不过 DLSS 使用了 AI 相关技术。<strong>棋盘格渲染 Checkerboard rendering</strong>，包括隔行扫描等，也可以说是时序上采样的一种特殊类型。与时序上采样对采样点进行随机抖动不同，棋盘格渲染渲染 2 × 2 像素块的对角线，故称为棋盘格。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://ybniaobu.github.io">鸟布</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://ybniaobu.github.io/2025/06/21/2025-06-21-TAA/">https://ybniaobu.github.io/2025/06/21/2025-06-21-TAA/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://ybniaobu.github.io" target="_blank">鸟布的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/">游戏开发</a><a class="post-meta__tags" href="/tags/unity/">unity</a><a class="post-meta__tags" href="/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/">图形学</a></div><div class="post_share"><div class="social-share" data-image="https://s2.loli.net/2025/06/23/kEPO3zg8IRXwUFC.gif" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/images/wechat.png" target="_blank"><img class="post-qr-code-img" src="/images/wechat.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/images/alipay.png" target="_blank"><img class="post-qr-code-img" src="/images/alipay.png" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2025/08/01/2025-08-01-SSAO1/" title="屏幕空间环境光遮蔽（一）SSAO"><img class="cover" src="https://s2.loli.net/2025/08/01/287gfDiMYRFrmUs.gif" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">屏幕空间环境光遮蔽（一）SSAO</div></div></a></div><div class="next-post pull-right"><a href="/2025/06/08/2025-06-08-TileBasedLightCulling/" title="Tile-Based Light Culling"><img class="cover" src="https://s2.loli.net/2025/06/08/1hF5QplnZjxBvJS.gif" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Tile-Based Light Culling</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/09/15/2023-09-15-UnityShader1/" title="《Unity Shader入门精要》读书笔记（一）"><img class="cover" src="https://s2.loli.net/2023/09/19/cDvdURBPhjwkOsY.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-15</div><div class="title">《Unity Shader入门精要》读书笔记（一）</div></div></a></div><div><a href="/2023/10/13/2023-10-13-UnityShader2/" title="《Unity Shader入门精要》读书笔记（二）"><img class="cover" src="https://s2.loli.net/2023/10/15/RZftaNSscWoLH1u.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-13</div><div class="title">《Unity Shader入门精要》读书笔记（二）</div></div></a></div><div><a href="/2023/11/22/2023-11-22-UnityShader3/" title="《Unity Shader入门精要》读书笔记（三）"><img class="cover" src="https://s2.loli.net/2023/11/23/L3ts4WnThMlDN9d.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-22</div><div class="title">《Unity Shader入门精要》读书笔记（三）</div></div></a></div><div><a href="/2023/12/19/2023-12-19-UnityShader4/" title="《Unity Shader入门精要》读书笔记（四）"><img class="cover" src="https://s2.loli.net/2023/12/20/9Ah5ugiIpONK1cX.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-12-19</div><div class="title">《Unity Shader入门精要》读书笔记（四）</div></div></a></div><div><a href="/2024/03/20/2024-03-20-NPR_StarRail1/" title="基于星穹铁道的卡通渲染（一）"><img class="cover" src="https://s2.loli.net/2024/03/26/dZTwsApi59CSUal.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-20</div><div class="title">基于星穹铁道的卡通渲染（一）</div></div></a></div><div><a href="/2023/12/30/2023-12-30-UnityShader5/" title="《Unity Shader入门精要》读书笔记（五）"><img class="cover" src="https://s2.loli.net/2023/12/30/hc2s7BS45l1wUdQ.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-12-30</div><div class="title">《Unity Shader入门精要》读书笔记（五）</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/images/wechat%20avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">鸟布</div><div class="author-info__description">教练，我想学技术</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">47</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://niaobu.notion.site/787824630ea6480e944c1ae5ae7f4792"><i class="fa-solid fa-book"></i><span>My Notion</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ybniaobu/ybniaobu.github.io" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:niaobubob@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">为了蒂法！！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#TAA-%E5%8E%9F%E7%90%86%E5%8F%8A%E6%B5%81%E7%A8%8B%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text">TAA 原理及流程简单介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%B4%AF%E8%AE%A1%E5%8E%86%E5%8F%B2%E6%A0%B7%E6%9C%AC"><span class="toc-number">2.</span> <span class="toc-text">累计历史样本</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8A%96%E5%8A%A8-Jitter"><span class="toc-number">2.1.</span> <span class="toc-text">抖动 Jitter</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Exponential-Blending"><span class="toc-number">2.2.</span> <span class="toc-text">Exponential Blending</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%8D%E6%8A%95%E5%BD%B1-Reprojection"><span class="toc-number">2.3.</span> <span class="toc-text">重投影 Reprojection</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%B0%E5%BD%95%E4%B8%8A%E4%B8%80%E5%B8%A7-VP-%E7%9F%A9%E9%98%B5"><span class="toc-number">2.3.1.</span> <span class="toc-text">记录上一帧 VP 矩阵</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Camera-Motion-Vector-Shader"><span class="toc-number">2.3.2.</span> <span class="toc-text">Camera Motion Vector Shader</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%AA%8C%E8%AF%81%E5%8E%86%E5%8F%B2%E6%A0%B7%E6%9C%AC"><span class="toc-number">3.</span> <span class="toc-text">验证历史样本</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Color-Rejection-Rectification"><span class="toc-number">3.1.</span> <span class="toc-text">Color Rejection&#x2F;Rectification</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Color-Clamping"><span class="toc-number">3.1.1.</span> <span class="toc-text">Color Clamping</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Color-Clipping"><span class="toc-number">3.1.2.</span> <span class="toc-text">Color Clipping</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Playdead-%E7%9A%84-Clip-to-AABB-Center"><span class="toc-number">3.1.2.1.</span> <span class="toc-text">Playdead 的 Clip to AABB Center</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#UE4-%E7%9A%84-Clip-to-Filtered-Color"><span class="toc-number">3.1.2.2.</span> <span class="toc-text">UE4 的 Clip to Filtered Color</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Variance-Clipping"><span class="toc-number">3.1.3.</span> <span class="toc-text">Variance Clipping</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Geometry-Rejection"><span class="toc-number">3.2.</span> <span class="toc-text">Geometry Rejection</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF"><span class="toc-number">4.</span> <span class="toc-text">其他优化技术</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AA%E7%83%81%E4%BC%98%E5%8C%96"><span class="toc-number">4.1.</span> <span class="toc-text">闪烁优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Luma-Weighted-Exponential-Blending"><span class="toc-number">4.1.1.</span> <span class="toc-text">Luma Weighted Exponential Blending</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Filter-Current-Color"><span class="toc-number">4.1.2.</span> <span class="toc-text">Filter Current Color</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Dynamic-Adaptive-Blending-Factor"><span class="toc-number">4.1.3.</span> <span class="toc-text">Dynamic&#x2F;Adaptive Blending Factor</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%8D%E6%8A%95%E5%BD%B1%E4%BC%98%E5%8C%96"><span class="toc-number">4.2.</span> <span class="toc-text">重投影优化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E7%B3%8A%E4%BC%98%E5%8C%96"><span class="toc-number">4.3.</span> <span class="toc-text">模糊优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#History-Filter"><span class="toc-number">4.3.1.</span> <span class="toc-text">History Filter</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Object-Motion-Vector"><span class="toc-number">5.</span> <span class="toc-text">Object Motion Vector</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Unity-SRP-%E4%B8%AD%E5%AE%9E%E7%8E%B0-Object-Motion-Vector"><span class="toc-number">5.1.</span> <span class="toc-text">Unity SRP 中实现 Object Motion Vector</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#MotionVectors-Pass"><span class="toc-number">5.1.1.</span> <span class="toc-text">MotionVectors Pass</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#DrawRendererList"><span class="toc-number">5.1.1.1.</span> <span class="toc-text">DrawRendererList</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#UnityPerDraw-cbuffer"><span class="toc-number">5.1.1.2.</span> <span class="toc-text">UnityPerDraw cbuffer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MotionVectors-Shader"><span class="toc-number">5.1.1.3.</span> <span class="toc-text">MotionVectors Shader</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ShaderGUI-%E4%B8%AD%E5%85%B3%E9%97%AD-MotionVectors-Pass"><span class="toc-number">5.1.2.</span> <span class="toc-text">ShaderGUI 中关闭 MotionVectors Pass</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8E-Camera-Motion-Vector-%E5%90%88%E5%B9%B6"><span class="toc-number">5.1.3.</span> <span class="toc-text">与 Camera Motion Vector 合并</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E8%AF%B4%E6%98%8E"><span class="toc-number">5.1.4.</span> <span class="toc-text">其他说明</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%87%8D%E5%A4%8D%E7%BB%98%E5%88%B6%E9%97%AE%E9%A2%98"><span class="toc-number">5.1.4.1.</span> <span class="toc-text">重复绘制问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Alembic-Animation"><span class="toc-number">5.1.4.2.</span> <span class="toc-text">Alembic Animation</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#TAA-%E5%85%B6%E4%BB%96%E8%A1%A5%E5%85%85"><span class="toc-number">6.</span> <span class="toc-text">TAA 其他补充</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#TAA-%E7%9A%84%E6%8C%91%E6%88%98"><span class="toc-number">6.1.</span> <span class="toc-text">TAA 的挑战</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Upsampling-Super-Resolution"><span class="toc-number">6.2.</span> <span class="toc-text">Upsampling &#x2F; Super-Resolution</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/09/09/2025-09-09-SSAO2/" title="屏幕空间环境光遮蔽（二）HBAO 与 GTAO"><img src="https://s2.loli.net/2025/09/09/Uq93S46lgTAHs7Q.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="屏幕空间环境光遮蔽（二）HBAO 与 GTAO"/></a><div class="content"><a class="title" href="/2025/09/09/2025-09-09-SSAO2/" title="屏幕空间环境光遮蔽（二）HBAO 与 GTAO">屏幕空间环境光遮蔽（二）HBAO 与 GTAO</a><time datetime="2025-09-09T12:10:09.000Z" title="发表于 2025-09-09 20:10:09">2025-09-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/08/01/2025-08-01-SSAO1/" title="屏幕空间环境光遮蔽（一）SSAO"><img src="https://s2.loli.net/2025/08/01/287gfDiMYRFrmUs.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="屏幕空间环境光遮蔽（一）SSAO"/></a><div class="content"><a class="title" href="/2025/08/01/2025-08-01-SSAO1/" title="屏幕空间环境光遮蔽（一）SSAO">屏幕空间环境光遮蔽（一）SSAO</a><time datetime="2025-08-01T04:54:23.000Z" title="发表于 2025-08-01 12:54:23">2025-08-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/21/2025-06-21-TAA/" title="Temporal Anti-Aliasing (TAA)"><img src="https://s2.loli.net/2025/06/23/kEPO3zg8IRXwUFC.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Temporal Anti-Aliasing (TAA)"/></a><div class="content"><a class="title" href="/2025/06/21/2025-06-21-TAA/" title="Temporal Anti-Aliasing (TAA)">Temporal Anti-Aliasing (TAA)</a><time datetime="2025-06-21T11:43:03.000Z" title="发表于 2025-06-21 19:43:03">2025-06-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/08/2025-06-08-TileBasedLightCulling/" title="Tile-Based Light Culling"><img src="https://s2.loli.net/2025/06/08/1hF5QplnZjxBvJS.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Tile-Based Light Culling"/></a><div class="content"><a class="title" href="/2025/06/08/2025-06-08-TileBasedLightCulling/" title="Tile-Based Light Culling">Tile-Based Light Culling</a><time datetime="2025-06-08T05:03:10.000Z" title="发表于 2025-06-08 13:03:10">2025-06-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/04/29/2025-04-29-CustomSRP8/" title="Unity Custom SRP 基础（八）"><img src="https://s2.loli.net/2025/04/29/IHYjvyKDR2uoGEt.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Unity Custom SRP 基础（八）"/></a><div class="content"><a class="title" href="/2025/04/29/2025-04-29-CustomSRP8/" title="Unity Custom SRP 基础（八）">Unity Custom SRP 基础（八）</a><time datetime="2025-04-29T12:00:38.000Z" title="发表于 2025-04-29 20:00:38">2025-04-29</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2025 By 鸟布</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Your time is limited, so don't waste it living someone else's life.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>