<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Unity Custom SRP 基础（七） | 鸟布的博客</title><meta name="author" content="鸟布"><meta name="copyright" content="鸟布"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本笔记的主要内容包含自定义 Particle System 的 Unlit Shader；Depth &amp;amp; Color Texture 的创建以及通过它们实现的特殊粒子效果；Depth Prepass 的实现；如何修改 Render Scale；FXAA Quality 和 Console 的实现。"><link rel="shortcut icon" href="https://s2.loli.net/2022/09/08/Ygib4lfw6z1khnr.png"><link rel="canonical" href="https://ybniaobu.github.io/2025/04/07/2025-04-07-CustomSRP7/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 鸟布","link":"链接: ","source":"来源: 鸟布的博客","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Unity Custom SRP 基础（七）',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-05-05 16:40:45'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/images/wechat%20avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">47</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-bars"></i><span> 目录</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/images/black.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="鸟布的博客"><span class="site-name">鸟布的博客</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-bars"></i><span> 目录</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Unity Custom SRP 基础（七）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-04-07T12:57:36.000Z" title="发表于 2025-04-07 20:57:36">2025-04-07</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-05-05T08:40:45.889Z" title="更新于 2025-05-05 16:40:45">2025-05-05</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/unity/">unity</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/">图形学</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/unity/pipeline/">pipeline</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">10k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>39分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Unity Custom SRP 基础（七）"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote>
<p>本笔记是关于 Unity 的<strong>自定义可编程渲染管线</strong>的入门基础，即 <strong>SRP (Scriptable Rendering Pipeline)</strong>，主要参考了著名的教程 <a target="_blank" rel="noopener" href="https://catlikecoding.com/">https://catlikecoding.com/</a> 的 Custom SRP Tutorial，以及知乎上各位图形学大神们的文章。  </p>
<p>笔者使用的 Unity 版本是 6000.0.27f1，Core RP Library 的版本是 17.0.3。</p>
</blockquote>
<h1 id="Particles"><a href="#Particles" class="headerlink" title="Particles"></a>Particles</h1><p>Unity 自带的<strong>内置 Particle System</strong> 大部分工作都是 CPU 计算的，而实现项目 CPU 瓶颈居多，所以它只适用于一些只使用少量粒子（数千以内）的简单特效，比如烟雾、火焰、爆炸等。而 <strong>Visual Effect Graph</strong> 是基于 GPU 计算，适合需要高质量、复杂粒子效果的场景。教程中只涉及内置 Particle System，没有涉及如何接入 Visual Effect Graph，需要自行研究如何接入。</p>
<p>其实什么都不用做就已经可以使用 Particle System 了，通过 GameObject / Effects / Particle System 创建即可。Particle System 可以使用任意材质，只不过使用并非专门为内置粒子系统而写的任意材质会带有一定的限制。教程中也只涉及 Particle System 的 Unlit Shader，不涉及 Particle Lit Shader ，但 Lit 跟 Unlit 类似，只是多了光照计算等，可以查阅 URP 或 HDRP。</p>
<h2 id="Unlit-Particles-Shader"><a href="#Unlit-Particles-Shader" class="headerlink" title="Unlit Particles Shader"></a>Unlit Particles Shader</h2><p>我们先将自己的 Unlit Shader 全部复制出来，新建一个 ParticlesUnlit.Shader 然后粘贴进去，将 Shader 菜单路径改一下就行：  </p>
<pre><code>Shader &quot;Custom RP/Particles/Unlit&quot;
&#123;
    ...
&#125;
</code></pre><p>顺便提一下，对于内置粒子系统，GPU instancing 是不起作用的。然后将自己的 ParticlesUnlit.Shader 附给 Particle System 的 Renderer 就可以渲染粒子了：  </p>
<blockquote>
<p>教程里说 Particle System 不支持 GPU instancing，但是我看官方文档时，发现是可以支持的，详见：<a target="_blank" rel="noopener" href="https://docs.unity3d.com/Manual/gpu-instancing-particle-systems.html">https://docs.unity3d.com/Manual/gpu-instancing-particle-systems.html</a> 。只是需要将 Particle System 的 Renderer 模式改为 Mesh，点击 Enable GPU Instancing，并且需要一个支持 Particle GPU instancing 的 Shader。</p>
</blockquote>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/09/1dkv7G9OBUXMqi4.jpg" width = "60%" height = "60%" alt="图115 - 使用了一张圆形渐变贴图的 billboard particles"/>
</div>

<h2 id="Vertex-Color"><a href="#Vertex-Color" class="headerlink" title="Vertex Color"></a>Vertex Color</h2><p>Particle System 里面的很多颜色属性都是通过顶点色来传递的，比如 Start Color、Color over Lifetime、Color by Speed 等等，所以我们要为 Particle Unlit Shader 增加顶点色以使用这些属性：  </p>
<pre><code>struct Attributes
&#123;
    ...
    float4 color : COLOR;
    ...
&#125;;

struct Varyings
&#123;
    ...
    float4 color : COLOR;
    ...
&#125;;

Varyings ParticlesUnlitVert(Attributes IN)
&#123;
    Varyings OUT;
    ...
    OUT.color = IN.color;
    ...
    return OUT;
&#125;

float4 ParticlesUnlitFrag(Varyings IN) : SV_Target
&#123;
    ...
    return float4(albedo.rgb * IN.color.rgb + emission * IN.color.rgb, albedo.a * IN.color.a);
&#125;
</code></pre><p>当然你也可以为顶点色和 base color 的混合做正片叠底 Multiply 以外的混合方式。</p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/10/4jfHxRgLF5AUvzl.jpg" width = "60%" height = "60%" alt="图116 - Start Color 选择 Random Color 设置从黑到白渐变的粒子效果"/>
</div>

<p>还有一点就是，当粒子有不同的颜色时，排序上就会出现问题，这点跟透明物体的排序问题是一致的。所以我们最好在 Particle System 的 Renderer 中将 Sort Mode 改为 By Distance。</p>
<h2 id="Flipbooks"><a href="#Flipbooks" class="headerlink" title="Flipbooks"></a>Flipbooks</h2><p>Flipbooks 就是粒子的序列帧动画，让每个粒子播放一段动画。其实不用做任何事情就已经可以使用 Flipbooks 了，我们点开 Particle System 的 Texture Sheet Animation 就可以，并将 Shader 赋予如下贴图：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/10/bhZ3VTRavrOuzmI.jpg" width = "25%" height = "25%" alt="图117 - flipbook texture"/>
</div>

<p>这张贴图是 4 × 4 的，故 Texture Sheet Animation 里的 Tiles 属性也要设置为 4 × 4。然后就会出现类似一下效果，我特意把循环速度调慢了以降低动画播放速度方便看清：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/10/CyU4bZnsNmKXvf9.gif" width = "60%" height = "60%" alt="图118 - flipbook particle 效果"/>
</div>

<p>可以看到每个粒子的动画播放速度非常得慢，并且帧与帧之间衔接不是很顺畅，这就需要对帧与帧之间做混合。</p>
<h3 id="Flipbook-Blending"><a href="#Flipbook-Blending" class="headerlink" title="Flipbook Blending"></a>Flipbook Blending</h3><p>为了方便混合，我们需要传递第二套 uv 以及一个 animation blend 参数给 Shader，同时我们需要在 Particle System 的 Renderer 里面勾选上 Custom Vertex Streams 并添加 UV2 和 AnimBlend，如下图：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/10/2ASenfjD4R59pVs.jpg" width = "40%" height = "40%" alt="图119 - Custom Vertex Streams"/>
</div>

<p>然后我们就要去 Shader 里添加这些属性，首先添加一个 Flipbook Blending 的开关，如下：  </p>
<pre><code>Shader &quot;YPipeline/Particles/Unlit&quot;
&#123;
    Properties
    &#123;
        ...
        [Toggle(_FLIPBOOK_BLENDING)] _FlipbookBlending (&quot;Flipbook Blending&quot;, Float) = 0.0
    &#125;

    SubShader
    &#123;
        Pass
        &#123;
            ...
            #pragma shader_feature_local _FLIPBOOK_BLENDING
            ...
        &#125;
    &#125;
&#125;
</code></pre><p>之后 Pass 里的修改如下：  </p>
<pre><code>struct Attributes
&#123;
    ...
    #if defined(_FLIPBOOK_BLENDING)
        float4 uv : TEXCOORD0;
        float uvBlend : TEXCOORD1;
    #else
        float2 uv : TEXCOORD0;
    #endif
&#125;

struct Varyings
&#123;
    ...
    float2 uv : TEXCOORD0;

    #if defined(_FLIPBOOK_BLENDING)
        float3 uv2AndBlend : TEXCOORD1;
    #endif
&#125;;

Varyings ParticlesUnlitVert(Attributes IN)
&#123;
    ...
    float4 baseST = UNITY_ACCESS_INSTANCED_PROP(UnityPerMaterial, _BaseTex_ST);
    OUT.uv = IN.uv.xy * baseST.xy + baseST.zw;
    #if defined(_FLIPBOOK_BLENDING)
        OUT.uv2AndBlend.xy = IN.uv.zw * baseST.xy + baseST.zw;
        OUT.uv2AndBlend.z = IN.uvBlend;
    #endif
    return OUT;
&#125;

float4 ParticlesUnlitFrag(Varyings IN) : SV_Target
&#123;
    ...
    #if defined(_FLIPBOOK_BLENDING)
        albedo = lerp(albedo, SAMPLE_TEXTURE2D(_BaseTex, sampler_Trilinear_Repeat_BaseTex, IN.uv2AndBlend.xy), IN.uv2AndBlend.z);
    #endif
    ...
&#125;
</code></pre><p>效果如下：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/10/6FSR5ng9CrQo43j.gif" width = "60%" height = "60%" alt="图120 - Flipbook Blending"/>
</div>

<p>可以看到粒子动画帧与帧之间的衔接变得舒服很多。</p>
<h2 id="Fading-Near-Camera"><a href="#Fading-Near-Camera" class="headerlink" title="Fading Near Camera"></a>Fading Near Camera</h2><p>当摄像机在粒子发射的区域内部，由于粒子会离摄像机很近，从而占据画面的大部分并影响到玩家观察场景。Particle System 中 Renderer 的 Max Particle Size 可以限制粒子最大能占据画面的百分比，但是该属性会导致，当粒子达到最大大小并逐渐接近近裁切平面时，粒子看起来在变小，所以效果并不是很好。</p>
<p>另外一个方案就是，我们可以让粒子根据深度进行渐变，越接近屏幕越透明，这样子当模拟大气效果时，会有个更好的效果。首先我们为 Particle Unlit Shader 添加 <code>_CAMERA_NEAR_FADE</code> 关键字开关属性，以及一个距离和距离范围属性：  </p>
<pre><code>[Toggle(_CAMERA_NEAR_FADE)] _CameraFading (&quot;Camera Fading&quot;, Float) = 0.0
_NearFadeDistance (&quot;Near Fade Distance&quot;, Range(0.0, 10.0)) = 1
_NearFadeRange (&quot;Near Fade Range&quot;, Range(0.0, 10.0)) = 1
</code></pre><p>别忘了加上 shader_feature：  </p>
<pre><code>#pragma shader_feature _NEAR_FADE
</code></pre><p>然后在 Pass 里，根据深度值和 Distance 以及 Range 属性进行 lerp 改变 alpha 的值，深度值可以根据 SV_POSITION 语义来获取，如何获取就不解释了，忘了看之前相关文章，就是正交投影需要注意一下，代码如下（<code>unity_OrthoParams</code> 和 <code>_ProjectionParams</code> 都是 UnityInput）：  </p>
<pre><code>UNITY_INSTANCING_BUFFER_START(UnityPerMaterial)
    ...
    UNITY_DEFINE_INSTANCED_PROP(float, _NearFadeDistance)
    UNITY_DEFINE_INSTANCED_PROP(float, _NearFadeRange)
    ...
UNITY_INSTANCING_BUFFER_END(UnityPerMaterial)

float GetViewDepthFromSVPosition(float4 positionHCS)
&#123;
    if (unity_OrthoParams.w &lt; 0.5f) // Perspective
    &#123;
        return positionHCS.w;
    &#125;
    else // Orthographic
    &#123;
        float normalizedDepth = positionHCS.z;

        #if UNITY_REVERSED_Z
            normalizedDepth = 1.0 - normalizedDepth;
        #endif

        return (_ProjectionParams.z - _ProjectionParams.y) * normalizedDepth + _ProjectionParams.y;
    &#125;
&#125;

...

float4 ParticlesUnlitFrag(Varyings IN) : SV_Target
&#123;
    ...
    #if defined(_CAMERA_NEAR_FADE)
        float depth = GetViewDepthFromSVPosition(IN.positionHCS);
        float nearFadeDistance = UNITY_ACCESS_INSTANCED_PROP(UnityPerMaterial, _NearFadeDistance);
        float nearFadeRange = UNITY_ACCESS_INSTANCED_PROP(UnityPerMaterial, _NearFadeRange);
        float nearAttenuation = (depth - nearFadeDistance) / nearFadeRange;
        albedo.a *= saturate(nearAttenuation);
    #endif
    ...
&#125;
</code></pre><p>开启 _CAMERA_NEAR_FADE 后，改变 NearFadeDistance 效果如下：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/11/2ZClqOErxANXIR7.gif" width = "60%" height = "60%" alt="图121 - NearFadeDistance 逐渐变大的 Camera Near Fade 效果"/>
</div>

<h2 id="Soft-Particles"><a href="#Soft-Particles" class="headerlink" title="Soft Particles"></a>Soft Particles</h2><p>当粒子和非透明物体重合交叠时，部分粒子在物体前部分粒子在物体后，就会显得特别突兀。为了解决这个问题，我们需要对比粒子和物体的深度，当物体在粒子背后很近时，将粒子 fade out，于是就需要采样 depth texture，depth texture 的相关前置内容见下一章节的 Copy Depth 小节。</p>
<h3 id="重构-View-Space-Depth"><a href="#重构-View-Space-Depth" class="headerlink" title="重构 View Space Depth"></a>重构 View Space Depth</h3><p>这部分内容的逻辑 <a href="https://ybniaobu.github.io/2023/12/19/2023-12-19-UnityShader4/#%E7%AC%AC%E5%8D%81%E4%BA%8C%E7%AB%A0-%E4%BD%BF%E7%94%A8%E6%B7%B1%E5%BA%A6%E5%92%8C%E6%B3%95%E7%BA%BF%E7%BA%B9%E7%90%86">《Unity Shader入门精要》读书笔记（四）</a> 里面已经讲得很详细了，就不再赘述了。下面就简单记录下步骤：  </p>
<p>因为我们要用屏幕空间的 uv 坐标对 <code>_CameraDepthTexture</code> 进行采样，最简单的计算屏幕 uv 的方式是使用带 SV_POSITION 语义的 PositionHCS 的 xy 分量除以屏幕分辨率，屏幕分辨率可以通过 UnityInput 的 <code>_ScreenParams</code> 获取，我们需要添加在 UnityInput 里。与此同时，我们重构 View Space Depth 需要用到远近裁切平面的相关参数，需要使用到 <code>_ZBufferParams</code>，也要添加在 UnityInput 里：  </p>
<pre><code>...
float4 _ProjectionParams;
// x = width
// y = height
// z = 1 + 1.0/width
// w = 1 + 1.0/height
float4 _ScreenParams;
// x = 1-far/near
// y = far/near
// z = x/far
// w = y/far
// or in case of a reversed depth buffer (UNITY_REVERSED_Z is 1)
// x = -1+far/near
// y = 1
// z = x/far
// w = 1/far
float4 _ZBufferParams;
float4 unity_OrthoParams;
...
</code></pre><p>然后因为 Unity 内置的使用 _ZBufferParams 的 <code>LinearEyeDepth()</code> 函数不适用于正交投影的情形下，需要区分：  </p>
<pre><code>float GetViewDepthFromDepthTexture(float sampledDepth)
&#123;
    if (unity_OrthoParams.w &lt; 0.5f) // Perspective
    &#123;
        return LinearEyeDepth(sampledDepth, _ZBufferParams);
    &#125;
    else // Orthographic
    &#123;
        #if UNITY_REVERSED_Z
        sampledDepth = 1.0 - sampledDepth;
        #endif
        return (_ProjectionParams.z - _ProjectionParams.y) * sampledDepth + _ProjectionParams.y;
    &#125;
&#125;
</code></pre><h3 id="Soft-Particles-Fading"><a href="#Soft-Particles-Fading" class="headerlink" title="Soft Particles Fading"></a>Soft Particles Fading</h3><p>可以获取到深度了，就可以实现 Soft Particles 的效果了。首先为 Soft Particles 添加几个 Shader 参数：  </p>
<pre><code>[Toggle(_SOFT_PARTICLES)] _SoftParticles (&quot;Soft Particles&quot;, Float) = 0
_SoftParticlesDistance (&quot;Soft Particles Distance&quot;, Range(0.0, 10.0)) = 0
_SoftParticlesRange (&quot;Soft Particles Range&quot;, Range(0.01, 10.0)) = 1
</code></pre><p>别忘了添加 shader feature：  </p>
<pre><code>#pragma shader_feature _SOFT_PARTICLES
</code></pre><p>然后在 UnityPerMaterial 里加上上面说的参数变量，片元着色器里的计算跟 Camera Near Fade 很类似：  </p>
<pre><code>float viewDepth = GetViewDepthFromSVPosition(IN.positionHCS);
#if defined(_SOFT_PARTICLES)
    float2 screenUV = IN.positionHCS.xy / _ScreenParams.xy;
    float sampledDepth = SAMPLE_DEPTH_TEXTURE_LOD(_CameraDepthTexture, sampler_CameraDepthTexture, screenUV, 0);
    float viewSampledDepth = GetViewDepthFromDepthTexture(sampledDepth);
    float depthDelta = abs(viewSampledDepth - viewDepth);
    float softParticlesDistance = UNITY_ACCESS_INSTANCED_PROP(UnityPerMaterial, _SoftParticlesDistance);
    float softParticlesRange = UNITY_ACCESS_INSTANCED_PROP(UnityPerMaterial, _SoftParticlesRange);
    float softParticlesAttenuation = (depthDelta - softParticlesDistance) / softParticlesRange;
    albedo.a *= saturate(softParticlesAttenuation);
#endif
</code></pre><p>从不开启 Soft Particles 到开启后的效果如下： </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/17/JRPLleGKdHscoDT.gif" width = "60%" height = "60%" alt="图122 - 前半为关闭 Soft Particles 的效果，后半为开启 Soft Particles 的效果"/>
</div>

<h2 id="Distortion"><a href="#Distortion" class="headerlink" title="Distortion"></a>Distortion</h2><p>跟 Soft Particles 类似，Soft Particles 需要 Depth 信息，Distortion 这种透明效果则需要场景颜色信息。所以需要采样 Color Texture，Color Texture 的前置知识详见下一章节的 Copy Color 小节。</p>
<h3 id="Distortion-Map"><a href="#Distortion-Map" class="headerlink" title="Distortion Map"></a>Distortion Map</h3><p>Distortion Map 是一个类似于法线贴图的贴图，它可以用于随机化采样场景颜色的 uv 从而达到一种扭曲的效果，类似如下贴图：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/17/guX4UYb5sGRljdp.png" width = "15%" height = "15%" alt="图123 - Round Particle Distortion Map"/>
</div>

<p>接下来就是为 Distortion 添加 Shader 参数：  </p>
<pre><code>[Toggle(_DISTORTION)] _Distortion (&quot;Distortion&quot;, Float) = 0.0
[NoScaleOffset] _DistortionTex (&quot;Distortion Texture&quot;, 2D) = &quot;bump&quot; &#123;&#125;
_DistortionStrength (&quot;Distortion Strength&quot;, Range(0.0, 2.0)) = 0.1
</code></pre><p>别忘了添加 shader feature：</p>
<pre><code>#pragma shader_feature _DISTORTION
</code></pre><p>然后为这些参数添加变量。使用 Distortion Map 跟 Normal Map 类似，需要解码，解码后我们只需要 xy 分量对 uv 进行偏移，并使用偏移后的 uv 对 <code>_CameraColorTexture</code> 进行采样，先直接输出采样的颜色：  </p>
<pre><code>#if defined(_DISTORTION)
    float4 packedDistortion = SAMPLE_TEXTURE2D(_DistortionTex, sampler_Trilinear_Repeat_BaseTex, IN.uv);
    #if defined(_FLIPBOOK_BLENDING)
        float4 packedDistortion2 = SAMPLE_TEXTURE2D(_DistortionTex, sampler_Trilinear_Repeat_BaseTex, IN.uv2AndBlend.xy);
        packedDistortion = lerp(packedDistortion, packedDistortion2, IN.uv2AndBlend.z);
    #endif
    float distortionStrength = UNITY_ACCESS_INSTANCED_PROP(UnityPerMaterial, _DistortionStrength);
    float3 distortion = UnpackNormalScale(packedDistortion, distortionStrength);

    float3 sampledColor = SAMPLE_TEXTURE2D_LOD(_CameraColorTexture, sampler_LinearClamp, screenUV + distortion * albedo.a, 0).rgb;
    albedo.rgb = sampledColor;
#endif
</code></pre><p>这样就可以有扭曲空间的效果了：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/17/sroxIVtXEFcHyeB.gif" width = "60%" height = "60%" alt="图124 - Round Particle Distortion Effect"/>
</div>

<h3 id="Distortion-Blend"><a href="#Distortion-Blend" class="headerlink" title="Distortion Blend"></a>Distortion Blend</h3><p>之前因为我们直接输出了采样的 <code>_CameraColorTexture</code> 的颜色，但是有时候我们想要粒子原来的颜色，这时候我们可以使用 <code>_DistortionBlend</code> 在两者之间做混合：  </p>
<pre><code>_DistortionBlend(&quot;Distortion Blend&quot;, Range(0.0, 1.0)) = 1
</code></pre><p>当 <code>_DistortionBlend</code> 为 1 时，只能看到 Distortion 的效果；当 <code>_DistortionBlend</code> 为 0 时，能看到 Distortion 和粒子原来颜色混合的效果。并且我们希望粒子原来的 alpha 越小，即越透明 Distortion 效果越弱：  </p>
<pre><code>#if defined(_DISTORTION)
    ...
    float3 sampledColor = SAMPLE_TEXTURE2D_LOD(_CameraColorTexture, sampler_LinearClamp, screenUV + distortion * albedo.a, 0).rgb;
    float distortionBlend = UNITY_ACCESS_INSTANCED_PROP(UnityPerMaterial, _DistortionBlend);
    albedo.rgb = lerp(sampledColor, albedo.rgb, saturate(albedo.a - distortionBlend));
#endif
</code></pre><p>下面的效果是上面讲 Flipbook 时的那张 Flipbook Map 和它对应的 Flipbook Distortion Map 共同产生的，Flipbook Distortion Map 在教程里有，我这里就不放出来了：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/17/yGLZNih6I3c4nbf.gif" width = "60%" height = "60%" alt="图125 - Filpbook Particle Distortion Blend Effect（关闭了 Camera Near Fade）"/>
</div>

<h1 id="Depth-amp-Color-Texture"><a href="#Depth-amp-Color-Texture" class="headerlink" title="Depth &amp; Color Texture"></a>Depth &amp; Color Texture</h1><p>我们之前只使用了一张 frame buffer，同时包含了颜色和深度信息。但其实深度模板缓冲区和目标视图缓冲区（color buffer）的资源是分开的，即<strong>颜色附件 Color Attachment</strong> 和<strong>深度/模板附件 Depth/Stencil Attachment</strong>，我们可以根据需求分别创建。</p>
<p>首先替换之前的 <code>_CameraFrameBuffer</code> 相关代码：  </p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">readonly</span> <span class="built_in">int</span> k_ColorBufferId = Shader.PropertyToID(<span class="string">&quot;_CameraColorBuffer&quot;</span>);</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">readonly</span> <span class="built_in">int</span> k_DepthBufferId = Shader.PropertyToID(<span class="string">&quot;_CameraDepthBuffer&quot;</span>);</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">&#123;</span><br><span class="line">    data.buffer.GetTemporaryRT(RenderTargetIDs.k_ColorBufferId, data.camera.pixelWidth, data.camera.pixelHeight, <span class="number">0</span>, FilterMode.Bilinear, asset.enableHDRFrameBufferFormat ? RenderTextureFormat.DefaultHDR : RenderTextureFormat.Default);</span><br><span class="line">    data.buffer.GetTemporaryRT(RenderTargetIDs.k_DepthBufferId, data.camera.pixelWidth, data.camera.pixelHeight, <span class="number">32</span>, FilterMode.Point, RenderTextureFormat.Depth);</span><br><span class="line">    data.buffer.SetRenderTarget(<span class="keyword">new</span> RenderTargetIdentifier(RenderTargetIDs.k_ColorBufferId), </span><br><span class="line">                                RenderBufferLoadAction.DontCare, RenderBufferStoreAction.Store,</span><br><span class="line">                                <span class="keyword">new</span> RenderTargetIdentifier(RenderTargetIDs.k_DepthBufferId),</span><br><span class="line">                                RenderBufferLoadAction.DontCare, RenderBufferStoreAction.Store);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后别忘了 ReleaseTemporaryRT。</p>
<h2 id="Depth-Prepass"><a href="#Depth-Prepass" class="headerlink" title="Depth Prepass"></a>Depth Prepass</h2><p>教程中没有提到 Depth Prepass，这个技术是一个较为简单的优化技术，在复杂场景中能有效地提升性能，故顺便在这里实现一下。</p>
<h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><p>首先需要注意区分 <strong>Early-Z</strong> 和 <strong>Depth Prepass</strong>（Z-Prepass）：<br><strong>①Early-Z</strong> 是一个移动设备 GPU 的 TBR/TBDR 架构下的硬件技术（但是好像现在大部分 GPU 都支持，网上的资料都有点老了），它在硬件层面上修改了渲染管线，在光栅化阶段和片元着色器阶段中间，加入了一个 Early-Z 阶段，这个阶段进行的操作和原本逐片元操作/输出合并阶段的 z-test（为了与 early-z 区别，这个阶段也会被成为 <strong>Late-Z</strong>）操作完全一样。这样做的目的是为了提前剔除掉被遮挡的片元，减少 over-draw 从而节省 GPU 性能。Early-Z 的问题在于，若开启了 alpha test ，或者有丢弃像素的操作，又或者在片元着色器开启了深度写入，就会使 Early-Z 失效，所以一般情况下会配合软件层面的 Depth Prepass 使用。<br><strong>②Depth Prepass</strong> 是一个软件技术，其做法就是使用两个 pass，第一个 pass 渲染物体的深度（即 Depth Prepass），第二个 pass 渲染该物体的颜色。在渲染深度时，只开启 Zwrite 和 ZTest 渲染物体的深度；在渲染颜色时，关闭 Zwrite，并将 ZTest 设置为 <strong>Equal</strong>，注意这里深度比较函数必须是 Equal 不能是 LessEqual，Equal 下性能是最优的。Depth Prepass 可以有效地减少片元着色器的工作，特别适用于复杂的片元着色器（比如 PBR）以及复杂的场景（比如场景中有较多的花草树木，以及头发渲染）。</p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p><strong><em>①第一步 Depth Prepass：</em></strong><br>首先为 Opaque 和 AlphaTest 的物体准备一个 Depth Prepass，Shader 里类似如下：  </p>
<pre><code>Pass
&#123;
    Name &quot;Depth&quot;

    Tags &#123; &quot;LightMode&quot; = &quot;Depth&quot; &#125;

    ZWrite On
    ColorMask 0
    Cull [_Cull]

    HLSLPROGRAM
    #pragma target 4.5

    #pragma vertex DepthVert
    #pragma fragment DepthFrag

    #pragma shader_feature_local_fragment _CLIPPING

    #pragma multi_compile _ LOD_FADE_CROSSFADE

    #include &quot;StandardForwardDepthPass.hlsl&quot;
    ENDHLSL
&#125;
</code></pre><p>然后只需要在片元着色器中做裁切就行，大致如下：  </p>
<pre><code>struct Attributes
&#123;
    float4 positionOS   : POSITION;
    float2 uv           : TEXCOORD0;
&#125;;

struct Varyings
&#123;
    float4 positionHCS  : SV_POSITION;
    float2 uv           : TEXCOORD0;
&#125;;

Varyings DepthVert(Attributes IN)
&#123;
    Varyings OUT;
    OUT.uv = TRANSFORM_TEX(IN.uv, _BaseTex);
    OUT.positionHCS = TransformObjectToHClip(IN.positionOS.xyz);
    return OUT;
&#125;

float DepthFrag(Varyings IN) : SV_DEPTH
&#123;
    float baseTexAlpha = SAMPLE_TEXTURE2D(_BaseTex, sampler_Trilinear_Repeat_BaseTex, IN.uv).a;
    float opacityTexAlpha = SAMPLE_TEXTURE2D(_OpacityTex, sampler_Trilinear_Repeat_BaseTex, IN.uv).r;
    float alpha = baseTexAlpha * opacityTexAlpha * _BaseColor.a;

    #if defined(_CLIPPING)
        clip(alpha - _Cutoff);
    #endif

    #if defined(LOD_FADE_CROSSFADE)
        float dither = InterleavedGradientNoise(IN.positionHCS.xy, 0);
        float isNextLodLevel = step(unity_LODFade.x, 0);
        dither = lerp(-dither, dither, isNextLodLevel);
        clip(unity_LODFade.x + dither);
    #endif

    return IN.positionHCS.z;
&#125;
</code></pre><p><strong><em>②第二步修改渲染颜色的 Pass：</em></strong><br>这一步只需要将原先渲染颜色的 Pass 的 ZWrite 关闭，ZTest 设置为 <strong>Equal</strong> 即可：  </p>
<pre><code>Pass 
&#123;
    ...
    ZWrite Off
    ZTest Equal
    Cull [_Cull]
    ...
&#125;
</code></pre><p><strong><em>③第三步在 SRP 中提交绘制指令：</em></strong><br>首先为 Depth Prepass 创建一个 ShaderTagId：  </p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> ShaderTagId k_DepthShaderTagId = <span class="keyword">new</span> ShaderTagId(<span class="string">&quot;Depth&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>然后就是绘制，Filtering &amp; Sorting Settings 可以和 Draw Opaque、alphaTest 流程中的局部参数共用，流程就不重复说明了，详见第一篇文章。这里要注意一下的是绘制时无需传递 perObjectData，还有就是因为只写入深度，ClearRenderTarget 时只需要清除深度：  </p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Filtering &amp; Sorting</span></span><br><span class="line">FilteringSettings opaqueFiltering = </span><br><span class="line">    <span class="keyword">new</span> FilteringSettings(<span class="keyword">new</span> RenderQueueRange(<span class="number">2000</span>, <span class="number">2449</span>));</span><br><span class="line"></span><br><span class="line">FilteringSettings alphaTestFiltering =</span><br><span class="line">    <span class="keyword">new</span> FilteringSettings(<span class="keyword">new</span> RenderQueueRange(<span class="number">2450</span>, <span class="number">2499</span>));</span><br><span class="line"></span><br><span class="line">SortingSettings opaqueSorting = <span class="keyword">new</span> SortingSettings(data.camera)</span><br><span class="line">&#123;</span><br><span class="line">    criteria = SortingCriteria.CommonOpaque</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">SortingSettings alphaTestSorting = <span class="keyword">new</span> SortingSettings(data.camera)</span><br><span class="line">&#123;</span><br><span class="line">    criteria = SortingCriteria.OptimizeStateChanges</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Depth PrePass</span></span><br><span class="line">data.buffer.BeginSample(<span class="string">&quot;Depth PrePass&quot;</span>);</span><br><span class="line">data.buffer.SetRenderTarget(<span class="keyword">new</span> RenderTargetIdentifier(RenderTargetIDs.k_DepthBufferId), RenderBufferLoadAction.DontCare, RenderBufferStoreAction.Store);</span><br><span class="line">data.buffer.ClearRenderTarget(<span class="literal">true</span>, <span class="literal">false</span>, data.camera.backgroundColor.linear);</span><br><span class="line"></span><br><span class="line">DrawingSettings depthOpaqueDrawing = <span class="keyword">new</span> DrawingSettings(k_DepthShaderTagId, opaqueSorting)</span><br><span class="line">&#123;</span><br><span class="line">    enableInstancing = asset.enableGPUInstancing,</span><br><span class="line">    perObjectData = PerObjectData.None</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">DrawingSettings depthAlphaTestDrawing = <span class="keyword">new</span> DrawingSettings(k_DepthShaderTagId, alphaTestSorting)</span><br><span class="line">&#123;</span><br><span class="line">    enableInstancing = asset.enableGPUInstancing,</span><br><span class="line">    perObjectData = PerObjectData.None</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">RendererListParams depthOpaqueRendererListParams =</span><br><span class="line">    <span class="keyword">new</span> RendererListParams(data.cullingResults, depthOpaqueDrawing, opaqueFiltering);</span><br><span class="line"></span><br><span class="line">RendererListParams depthAlphaTestRendererListParams =</span><br><span class="line">    <span class="keyword">new</span> RendererListParams(data.cullingResults, depthAlphaTestDrawing, alphaTestFiltering);</span><br><span class="line"></span><br><span class="line">RendererList depthOpaqueRendererList = data.context.CreateRendererList(<span class="keyword">ref</span> depthOpaqueRendererListParams);</span><br><span class="line">RendererList depthAlphaTestRendererList = data.context.CreateRendererList(<span class="keyword">ref</span> depthAlphaTestRendererListParams);</span><br><span class="line"></span><br><span class="line">data.buffer.DrawRendererList(depthOpaqueRendererList);</span><br><span class="line">data.buffer.DrawRendererList(depthAlphaTestRendererList);</span><br><span class="line"></span><br><span class="line">data.buffer.EndSample(<span class="string">&quot;Depth PrePass&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>最后在渲染颜色阶段，即 Draw Opaque、alphaTest 时，将渲染好的 DepthBuffer 与 ColorBuffer 同时设置为 RenderTarget，并且 Depth Buffer 的 RenderBufferLoadAction 是 Load，然后 ClearRenderTarget 只需要清除颜色即可：  </p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line">data.buffer.SetRenderTarget(<span class="keyword">new</span> RenderTargetIdentifier(RenderTargetIDs.k_ColorBufferId), </span><br><span class="line">                RenderBufferLoadAction.DontCare, RenderBufferStoreAction.Store,</span><br><span class="line">                <span class="keyword">new</span> RenderTargetIdentifier(RenderTargetIDs.k_DepthBufferId),</span><br><span class="line">                RenderBufferLoadAction.Load, RenderBufferStoreAction.Store);</span><br><span class="line">            </span><br><span class="line">data.buffer.ClearRenderTarget(<span class="literal">false</span>, <span class="literal">true</span>, data.camera.backgroundColor.linear);</span><br></pre></td></tr></table></figure>
<p>大致测试了下面渲染场景的帧率变化（在一个点光源下，开了后处理）：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/17/LzruBWN9wt6mKRc.png" width = "100%" height = "100%" alt="图126 - 左图：无 Depth PrePass 时总消耗 5.3 ms；右图：Depth PrePass 后总消耗 3.5 ms"/>
</div>

<h2 id="Copy-Depth"><a href="#Copy-Depth" class="headerlink" title="Copy Depth"></a>Copy Depth</h2><p>我们在渲染的时候，有时候需要采样 depth buffer，比如之前的 Soft Particles 效果、SSAO 等等。但是当我们以 depth buffer 作为 render target 的时候，不能同时对 depth buffer 进行采样，所以我们需要将 depth buffer 复制到 depth texture 里，Unity URP 的 CopyDepth 阶段就是在做这件事情。我们新创建一个 <code>_CameraDepthTexture</code> 的 RT 资源，创建的过程就不再赘述了，跟上面 <code>_CameraDepthBuffer</code> 一样。</p>
<p>我们之前后处理中提到的 Copy Shader 复制的是整个 Color Buffer，我们现在要创建一个复制 Depth Buffer 的版本，即 Copy Depth Shader，Shader 代码大致如下，将 ColorMask 设置为 0，开启深度写入：  </p>
<pre><code>Shader &quot;Hidden/YPipeline/CopyDepth&quot;
&#123;
    SubShader
    &#123;
        Tags
        &#123;
            &quot;RenderType&quot; = &quot;Opaque&quot;
        &#125;

        ZTest Always
        ZWrite On
        ColorMask 0
        Cull Off

        Pass
        &#123;
            Name &quot;CopyDepth&quot;

            HLSLPROGRAM
            #pragma target 3.5

            #pragma vertex CopyDepthVert
            #pragma fragment CopyDepthFrag

            #include &quot;CopyDepthPass.hlsl&quot;
            ENDHLSL
        &#125;
    &#125;
&#125;
</code></pre><p>然后顶点着色器跟之前的 Copy Shader 一样，片元着色器目标是 SV_DEPTH，而不是 SV_TARGET：  </p>
<pre><code>TEXTURE2D(_CameraDepthBuffer);
SAMPLER(sampler_CameraDepthBuffer);

struct Varyings
&#123;
    float4 positionHCS  : SV_POSITION;
    float2 uv           : TEXCOORD0;
&#125;;

Varyings CopyDepthVert(uint vertexID : SV_VertexID)
&#123;
    Varyings OUT;
    OUT.uv = float2((vertexID &lt;&lt; 1) &amp; 2, vertexID &amp; 2);
    OUT.positionHCS = float4(OUT.uv * 2.0 - 1.0, UNITY_NEAR_CLIP_VALUE, 1.0);

    if (_ProjectionParams.x &lt; 0.0) OUT.uv.y = 1.0 - OUT.uv.y;

    // #if UNITY_UV_STARTS_AT_TOP
    //     OUT.uv.y = 1.0 - OUT.uv.y;
    // #endif

    return OUT;
&#125;

float CopyDepthFrag(Varyings IN) : SV_DEPTH
&#123;
    return SAMPLE_TEXTURE2D_LOD(_CameraDepthBuffer, sampler_CameraDepthBuffer, IN.uv, 0).r;
&#125;
</code></pre><p>具体什么时候 Copy Depth 我是参考了 URP 放在 Depth Prepass 和 Draw Opaque &amp; AlphaTest 之间。</p>
<h2 id="Gizmos-and-Depth"><a href="#Gizmos-and-Depth" class="headerlink" title="Gizmos and Depth"></a>Gizmos and Depth</h2><p>之前在 Post Processing 时提到过，Gizmo 的绘制依赖于原来的 CameraTarget 中的深度信息。若没有深度信息，gizmos 就不会被物体遮挡。现在我们可以将深度信息复制进 CameraTarget 了：  </p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (Handles.ShouldRenderGizmos())</span><br><span class="line">&#123;</span><br><span class="line">    BlitUtility.CopyDepth(data.buffer, RenderTargetIDs.k_DepthBufferId, BuiltinRenderTextureType.CameraTarget);</span><br><span class="line">    RendererList gizmosRendererList = data.context.CreateGizmoRendererList(data.camera, GizmoSubset.PreImageEffects);</span><br><span class="line">    data.buffer.DrawRendererList(gizmosRendererList);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样子就可以看到 Gizmo 被正确地遮挡了：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/17/WGaoFULMK1l9JjR.jpg" width = "15%" height = "15%" alt="图127 - Gizmos recognizing depth"/>
</div>

<p>教程中有提到，虽然 Unity 将 Gizmos 的绘制分为了 pre-FX 和 post-FX，但是教程作者并没有发现任何 pre-FX gizmos，所以可以将 pre-FX 和 post-FX 合并在一起在最后（即 Post Processing 后）绘制。</p>
<h2 id="Copy-Color"><a href="#Copy-Color" class="headerlink" title="Copy Color"></a>Copy Color</h2><p>很多透明物体的效果都需要用到场景颜色信息，比如透明物体的折射、透视、扭曲等等，简单使用透明度混合的透明效果其实不是很好，不能很好地做到玻璃、水面等效果。此时我们可以在 Opaque、AlphaTest 和 Skybox 渲染完成后，将 Color Buffer 复制到 <code>_CameraColorTexture</code> 纹理当中，然后在实现透明物体的效果时，采样它。创建 <code>_CameraColorTexture</code> 纹理跟上面 <code>_CameraDepthTexture</code> 类似，然后在 Skybox 渲染后进行复制即可：  </p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line">data.buffer.BeginSample(<span class="string">&quot;Copy Color&quot;</span>);</span><br><span class="line">data.buffer.GetTemporaryRT(RenderTargetIDs.k_ColorTextureId, data.camera.pixelWidth, data.camera.pixelHeight, <span class="number">0</span>, FilterMode.Bilinear, </span><br><span class="line">    asset.enableHDRFrameBufferFormat ? RenderTextureFormat.DefaultHDR : RenderTextureFormat.Default);</span><br><span class="line">BlitUtility.BlitTexture(data.buffer, RenderTargetIDs.k_ColorBufferId, RenderTargetIDs.k_ColorTextureId);</span><br><span class="line"></span><br><span class="line">data.buffer.EndSample(<span class="string">&quot;Copy Color&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>还是别忘了 ReleaseTemporaryRT。这里顺便提一下，教程中类似于 URP 在 PipelineAsset 里提供了一个选项用于是否开启 Copy Color（Copy Depth 也有一个选项，即 URP 中的 Depth Texture 和 Opaque Texture 选项），若不开启则将 <code>_CameraColorTexture</code> 设置为纯灰贴图。因为我觉得 URP 是通用渲染管线，所以它给了这个选项，而我们的渲染管线完全可以根据项目需求选择是否 Copy Color，所以我没有添加这个选项，若不需要 Copy Color，完全可以注释掉这些代码。</p>
<h1 id="Render-Scale"><a href="#Render-Scale" class="headerlink" title="Render Scale"></a>Render Scale</h1><p>这一章节主要讲调整渲染分辨率，这样可以让低分辨率的画面呈现在高分辨率的屏幕上，即像素风格。或者对更高分辨率的渲染图进行超采样 supersample，从而减少走样问题，即 <strong>Super Sampling Anti-Aliasing (SSAA) 超采样抗锯齿</strong>。</p>
<h2 id="Buffer-Size"><a href="#Buffer-Size" class="headerlink" title="Buffer Size"></a>Buffer Size</h2><p>首先在 PipelineAsset 里添加 renderScale 属性用于控制渲染分辨率：  </p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line">[<span class="meta">Range(0.1f, 2f)</span>] </span><br><span class="line"><span class="keyword">public</span> <span class="built_in">float</span> renderScale = <span class="number">1.0f</span>;</span><br></pre></td></tr></table></figure>
<p>最大值设置为 2 是因为我们采样时用的 bilinear，renderScale 大于 2 了会导致下采样至 cameraTarget 时有些像素被完全抛弃，从而反而恶化渲染质量。当然你也可以自己写个 8×SSAA 的采样方式。然后我们给 Color Attachment 和 Depth Attachment 设置新的分辨率：  </p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line">Vector2Int bufferSize = <span class="keyword">new</span> Vector2Int((<span class="built_in">int</span>) (camera.pixelWidth * asset.renderScale), (<span class="built_in">int</span>) (camera.pixelHeight * asset.renderScale));</span><br><span class="line"></span><br><span class="line">data.buffer.GetTemporaryRT(YPipelineShaderIDs.k_ColorBufferID, bufferSize.x, bufferSize.y, <span class="number">0</span>, FilterMode.Bilinear, </span><br><span class="line">    data.asset.enableHDRFrameBufferFormat ? RenderTextureFormat.DefaultHDR : RenderTextureFormat.Default);</span><br><span class="line">data.buffer.GetTemporaryRT(YPipelineShaderIDs.k_DepthBufferID, bufferSize.x, bufferSize.y, <span class="number">32</span>, FilterMode.Point, </span><br><span class="line">    RenderTextureFormat.Depth);</span><br><span class="line">data.buffer.GetTemporaryRT(YPipelineShaderIDs.k_ColorTextureID, bufferSize.x, bufferSize.y, <span class="number">0</span>, FilterMode.Bilinear, </span><br><span class="line">    data.asset.enableHDRFrameBufferFormat ? RenderTextureFormat.DefaultHDR : RenderTextureFormat.Default);</span><br><span class="line">data.buffer.GetTemporaryRT(YPipelineShaderIDs.k_DepthTextureID, bufferSize.x, bufferSize.y, <span class="number">32</span>, FilterMode.Point, </span><br><span class="line">    RenderTextureFormat.Depth);</span><br></pre></td></tr></table></figure>
<p>在 Unity URP 中，Scene 窗口的渲染不会受到 renderScale 的影响，我觉得这样没有必要，若是想要 Scene 窗口的渲染不受到影响，可以当摄像机为 SceneView 时，不使用 renderScale：  </p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (camera.cameraType == CameraType.SceneView)</span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="对-Shader-的影响"><a href="#对-Shader-的影响" class="headerlink" title="对 Shader 的影响"></a>对 Shader 的影响</h2><p>之前 particle shader 的某些效果采样了 ColorTexture 或 DepthTexture，但是使用的是 UnityInput 里的 <code>_ScreenParams</code>，这个参数是 CameraTarget 的分辨率，而不是我们设置的渲染分辨率。为了让 particle shader 效果不出错误，我们需要自己传递渲染分辨率：  </p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">readonly</span> <span class="built_in">int</span> k_BufferSizeID = Shader.PropertyToID(<span class="string">&quot;_CameraBufferSize&quot;</span>);</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Vector2Int bufferSize = <span class="keyword">new</span> Vector2Int((<span class="built_in">int</span>) (camera.pixelWidth * asset.renderScale), (<span class="built_in">int</span>) (camera.pixelHeight * asset.renderScale));</span><br><span class="line">data.buffer.SetGlobalVector(YPipelineShaderIDs.k_BufferSizeID, <span class="keyword">new</span> Vector4(<span class="number">1f</span> / bufferSize.x, <span class="number">1f</span> / bufferSize.y, bufferSize.x, bufferSize.y));</span><br></pre></td></tr></table></figure>
<p>然后计算 ScreenUV 时讲 <code>_ScreenParams</code> 改为 <code>_CameraBufferSize</code>：  </p>
<pre><code>float2 screenUV = IN.positionHCS.xy * _CameraBufferSize.xy;
</code></pre><p>除了 particle shader，后处理中的 Bloom 也要修改分辨率：  </p>
<figure class="highlight c#"><table><tr><td class="code"><pre><span class="line"><span class="comment">// do bloom at half or quarter resolution</span></span><br><span class="line"><span class="built_in">int</span> width;</span><br><span class="line"><span class="built_in">int</span> height;</span><br><span class="line"><span class="keyword">if</span> (m_Bloom.ignoreRenderScale.<span class="keyword">value</span>)</span><br><span class="line">&#123;</span><br><span class="line">    width = data.camera.pixelWidth &gt;&gt; (<span class="built_in">int</span>) m_Bloom.bloomDownscale.<span class="keyword">value</span>;</span><br><span class="line">    height = data.camera.pixelHeight &gt;&gt; (<span class="built_in">int</span>) m_Bloom.bloomDownscale.<span class="keyword">value</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line">    width = data.bufferSize.x &gt;&gt; (<span class="built_in">int</span>) m_Bloom.bloomDownscale.<span class="keyword">value</span>;</span><br><span class="line">    height = data.bufferSize.y &gt;&gt; (<span class="built_in">int</span>) m_Bloom.bloomDownscale.<span class="keyword">value</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>因为 Bloom 是一个跟分辨率相关的效果，调整 RenderScale 会影响到 Bloom 的表现，降低 RenderScale 会使 Bloom 效果变大，增加 RenderScale 会使 Bloom 效果变小。所以可以在 Bloom 的 Volume Component 里添加了 ignoreRenderScale 的 bool 属性，即上面代码 if 语句中的控制变量，用于控制 Bloom 是否受到渲染分辨率的影响。</p>
<h2 id="Rescaling"><a href="#Rescaling" class="headerlink" title="Rescaling"></a>Rescaling</h2><p>改变渲染分辨率后，当上采样或下采样到最终的 CameraTarget 时，会有一些额外的副作用。主要有两点，第一点是 HDR 颜色因为数值太大，导致其对 Bilinear 插值的结果造成了显著的影响；第二点是当 color correction 时，有可能会产生意外的颜色带，比如改变 midtone 后物体边界产生颜色带：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/25/3ciAFzNtWIdjoLD.png" width = "40%" height = "40%" alt="图128 - 上：render scale 0.5 和 2 时 HDR 产生的颜色带；下：render scale 0.5, 1, 以及 2 时，Strong red midtones 调整后产生的颜色带"/>
</div>

<p>产生这个现象的原因是，我们在 color correction 和 tone mapping 前对渲染图进行了 Bilinear 采样。解决方案就是在 color correction 和 tone mapping 前使用 Point 采样，然后将 Post Processing 的结果不直接输出到 CameraTarget，而是使用 finalPost Shader 额外复制一次，使用 Bilinear 复制进 CameraTarget。finalPost 的采样方式除了 Bilinear 还可以选择 Bicubic 以及其他采样方式，特别是在上采样的时候可以提高渲染质量（即 render scale 小于 1 时）。具体实现也比较简单，我这里就不摘抄了。</p>
<p>上述问题解决的主要还是 3D 像素风游戏的问题，即 render scale 小于 1 时。若是没有做 3D 像素风游戏的需求，其实可以完全不添加这些功能，毕竟 URP 添加这些功能的主要原因是它是通用引擎。</p>
<h1 id="FXAA"><a href="#FXAA" class="headerlink" title="FXAA"></a>FXAA</h1><p>由于最终输出的分辨率有限，图像上会有很多<strong>锯齿 jaggies</strong>。上面提到的 <strong>SSAA</strong> 虽然能有效处理锯齿问题，但是它是非常耗费性能的，4X SSAA 的计算量就是原来的 4 倍。除了硬件 MSAA 外，常见的主流抗锯齿有 <strong>FXAA（快速近似抗锯齿 Fast Approximate Anti-Aliasing）</strong>、<strong>SMAA（增强型子像素形态抗锯齿 Enhanced Subpixel Morphological Anti-Aliasing）</strong>、<strong>TAA (时间抗锯齿 Temporal Anti-Aliasing)</strong> 等等。这里只介绍最简单的性能最好的方法，即 FXAA，当然它从效果上而言相对也比较一般，它最大的问题就是看起来会变得模糊，但是由于它性能开销较低，适用于性能较低的设备，比如手机。</p>
<p><strong>FXAA</strong> 是一个基于后处理的屏幕空间的抗锯齿技术，它是由 NVIDIA 的 Timothy Lottes 开发的，受到了 <strong>MLAA（形态抗锯齿 Morphological Anti-Aliasing）</strong>的启发。形态抗锯齿的主要原理就是检测物体或颜色边缘然后选择性地模糊，FXAA 和 SMAA 都是形变抗锯齿的一种。教程中介绍的 FXAA 版本是 3.11（应该就是最终版本了），它是质量最高的版本，能够一定程度上缓解长边的锯齿问题。Unity URP 有把 NVIDIA 的实现全部复制下来，详见 <code>com.unity.render-pipelines.universal/Shaders/PostProcessing/FXAA3_11.hlsl</code>。</p>
<blockquote>
<p>有关 FXAA 的资料有：<a target="_blank" rel="noopener" href="https://developer.download.nvidia.com/assets/gamedev/files/sdk/11/FXAA_WhitePaper.pdf">https://developer.download.nvidia.com/assets/gamedev/files/sdk/11/FXAA_WhitePaper.pdf</a> 、<a target="_blank" rel="noopener" href="https://www.iryoku.com/aacourse/downloads/09-FXAA-3.11-in-15-Slides.pdf">https://www.iryoku.com/aacourse/downloads/09-FXAA-3.11-in-15-Slides.pdf</a> 、<a target="_blank" rel="noopener" href="https://gist.github.com/kosua20/0c506b81b3812ac900048059d2383126">https://gist.github.com/kosua20/0c506b81b3812ac900048059d2383126</a> 。</p>
</blockquote>
<p>FXAA 3.11 有两个版本，其中 Quality 版本是较注重抗锯齿质量的版本，Console 版本是较注重抗锯齿速度的版本。教程中主要讲解的是 Quality 版本。</p>
<blockquote>
<p>下面代码有个小问题是使用的 TexelSize 应该是基于输出的分辨率，而不是基于输入的。否则调小 Render Scale 会出现奇怪图案。</p>
</blockquote>
<h2 id="FXAA-Quality"><a href="#FXAA-Quality" class="headerlink" title="FXAA Quality"></a>FXAA Quality</h2><p>FXAA 应该发生在 color grading 的后面，但是有些后处理应该放在 FXAA 后面，比如 Film Grain 胶片颗粒效果，具体顺序可以参考 URP 或 HDRP。我跟 URP 或 HDRP 一样，将 FXAA 放在了 FinalPost Shader 中处理。</p>
<h3 id="Luma-Contrast"><a href="#Luma-Contrast" class="headerlink" title="Luma Contrast"></a>Luma Contrast</h3><p>FXAA 通过确定水平和垂直方向上像素点的亮度差，来计算对比值，当对比度值较大时，则进行抗锯齿处理。而亮度可以通过 $\,Y = 0.2126 R + 0.7152 G + 0.0722 B\,$ 计算，但是 FXAA 的白皮书里提到，FXAA 需要的是 Non-Linear RGB 的输入，因为我们需要根据感知上的差异大小以获取更优秀的抗锯齿效果。教程中也提到了这一点，所以需要计算 <strong>Gamma-Adjusted Luminance</strong>，即 <strong>Luma</strong>。我实际测试了一下，使用 Luma 确实会比 Luminance 效果好一点点，但是肉眼还是很难区分出区别，特别是当输出分辨率较高时，我看知乎上很多 FXAA 教程也没有将使用 Luma，都是直接使用 Luminance。</p>
<pre><code>float GetLuma(float3 rgb)
&#123;
    return sqrt(Luminance(rgb));
&#125;
</code></pre><p>还有就是因为人眼对绿色的亮度最为敏感，我们可以直接使用绿色来替代 Luma 作为亮度以节省性能。亮度值也可以在上一个 Pass 中处理时，写入到 alpha 通道中，这样可以减少采样时亮度的计算，因为采样的时候可能会重复采样从而重复计算亮度。</p>
<p>采样的位置是下图所示，分别得到中间点 M 和周围四个点 N、E、W、S 的亮度值：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/28/OSvIorZFNbdnauC.png" width = "20%" height = "20%" alt="图129 - FXAA Neighborhood Samples"/>
</div>

<pre><code>float4 SampleOffset(float2 uv, float uOffset, float vOffset)
&#123;
    uv += float2(uOffset, vOffset) * _BlitTexture_TexelSize.xy;
    return SAMPLE_TEXTURE2D_LOD(_BlitTexture, sampler_LinearClamp, uv, 0);
&#125;

float3 ApplyFXAAQuality(float2 uv, float4 middleColor)
&#123;
    float M = GetLuma(middleColor);
    float N = GetLuma(SampleOffset(uv, 0, 1));
    float E = GetLuma(SampleOffset(uv, 1, 0));
    float S = GetLuma(SampleOffset(uv, 0, -1));
    float W = GetLuma(SampleOffset(uv, -1, 0));
&#125;
</code></pre><p>然后就是计算出这 5 个值中的最大值和最小值，相减得到<strong>对比值 Contrast</strong>：  </p>
<pre><code>float3 ApplyFXAAQuality(float2 uv, float4 middleColor)
&#123;
    ...
    // Calculate Contrast
    float maxLuma = max(max(max(N, E), max(W, S)), M);
    float minLuma = min(min(min(N, E), min(W, S)), M);
    float contrast = maxLuma - minLuma;
&#125;
</code></pre><p>直接输出 Contrast，相当于提取了基于颜色的边缘，边缘正好会是两个像素点宽度，如下图：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/28/AKNpUuGHSf6WmTl.jpg" width = "25%" height = "25%" alt="图130 - Luma Contrast Visualization"/>
</div>

<h3 id="Threshold"><a href="#Threshold" class="headerlink" title="Threshold"></a>Threshold</h3><p>为了防止模糊到非边缘的像素点，我们需要给 Contrast 设置一个 Threshold，只要超过 Threshold 的像素点才需要做抗锯齿处理，这种 Threshold 称为 <strong>Contrast Threshold</strong> 或者 <strong>Fixed Threshold</strong>。还有一种 Threshold 称为 <strong>Relative Threshold</strong>，它是根据亮度的最大值的比例来拒绝像素点的。白皮书中对 Contrast Threshold 和 Relative Threshold 的值的规定和说明如下：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/28/K7zsdMU8JaDhLc1.jpg" width = "40%" height = "40%" alt="图131 - FXAA Threshold，上为 Relative Threshold，下位 Contrast Threshold"/>
</div>

<p>Contrast Threshold 值范围在 0.03125 ~ 0.08333 之间，Relative Threshold 值范围在 0.0625 ~ 0.3333 之间。我们可以根据 Relative Threshold 和 Contrast Threshold 的较大值作为基准来判断是否跳过该像素：  </p>
<pre><code>float4 _FXAAParams; // x: contrastThreshold, y: relativeThreshold, z: blendFactor

float3 ApplyFXAAQuality(float2 uv, float4 middleColor)
&#123;
    ...
    // Threshold
    if (contrast &lt; max(_FXAAParams.x, maxLuma * _FXAAParams.y)) return middleColor;
&#125;
</code></pre><h3 id="Blend-Factor"><a href="#Blend-Factor" class="headerlink" title="Blend Factor"></a>Blend Factor</h3><p>接下来就是确定要进行抗锯齿处理的像素点进行混合（模糊）时的系数，混合系数是根据原像素点（中间像素点）的亮度和周围像素点的亮度平均值的差异来确定的。计算周围像素点亮度的平均值时，简单的算术平均效果肯定没这么好，为了更好地效果，需要再额外采样并得到斜对角上四个点的亮度值，即 NW、NE、SW、SE 点，对角像素距离中心像素比较远，所以权重会比周围 4 个低，滤波核如下图：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/28/WnjMxZ69os3TmlX.png" width = "20%" height = "20%" alt="图132 - FXAA Filter Kernel"/>
</div>

<p>为了使混合权重更加平滑，我们对得到的混合权重再用 smoothstep 处理一下，再将结果进行平方处理，代码如下：  </p>
<pre><code>float3 ApplyFXAAQuality(float2 uv, float4 middleColor)
&#123;
    ...
    float NW = GetLuma(SampleOffset(uv, -1, 1));
    float NE = GetLuma(SampleOffset(uv, 1, 1));
    float SW = GetLuma(SampleOffset(uv, -1, -1));
    float SE = GetLuma(SampleOffset(uv, 1, -1));
    ...
    // Blend Factor Calculation
    float filter = 2.0 * (N + E + S + W) + NE + NW + SE + SW;
    filter = filter / 12.0;
    filter = abs(filter - M);
    filter = saturate(filter / contrast);
    float blendFactor = smoothstep(0.0, 1.0, filter);
    blendFactor = blendFactor * blendFactor;
&#125;
</code></pre><h3 id="Blend-Direction"><a href="#Blend-Direction" class="headerlink" title="Blend Direction"></a>Blend Direction</h3><p>然后就是确定进行混合计算的方向（锯齿边界的方向）。FXAA 会混合中间像素和 N、E、S、W 中的一个像素，选择哪个像素取决于锯齿边界的方向：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/28/wOpCnoZU8Rfv94W.png" width = "30%" height = "30%" alt="图133 - Four Possible Blend Directions"/>
</div>

<p>当然锯齿边界不会是完美的水平或者垂直方向，下面的方法只是寻找一个最接近的方向，如果是一条水平锯齿边，那么中间像素的上下像素的对比值应该很高，如果是一条垂直锯齿边，那么中间像素的左右像素的对比值应该很高。那么一个简单的判断，如下：  </p>
<pre><code>// Measure Blend Direction
float horizontal = abs(N + S - 2.0 * M);
float vertical   = abs(E + W - 2.0 * M);
bool isHorizontal = horizontal &gt; vertical;
</code></pre><p>但是这样只比较了上下左右四个像素，我们还可以把 NE、NW、SE、SW 也都考虑进去，同时算上权重，如下：  </p>
<pre><code>// Measure Blend Direction
float horizontal = abs(N + S - 2.0 * M) * 2.0 + abs(NE + SE - 2.0 * E) + abs(NW + SW - 2.0 * W);
float vertical   = abs(E + W - 2.0 * M) * 2.0 + abs(NE + NW - 2.0 * N) + abs(SE + SW - 2.0 * S);
bool isHorizontal = horizontal &gt; vertical;
</code></pre><p>将 isHorizontal 输出为红色如下图：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/28/TkQp37qVLK1iJBU.jpg" width = "40%" height = "40%" alt="图134 - Horizontal edges are red, Vertical edges are white"/>
</div>

<p>可以看到方向大致判断没错。判断完方向后，我们就可以知道要混合的像素是在 u 方向还是 v 方向了：  </p>
<pre><code>float2 pixelStep = isHorizontal ? float2(0, _BlitTexture_TexelSize.y) : float2(_BlitTexture_TexelSize.x, 0);
</code></pre><p>当然我们还需要判断正负方向，只需要比较正负方向的亮度与中间像素的亮度的差值的大小即可：  </p>
<pre><code>float positive = abs((isHorizontal ? N : E) - M);
float negative = abs((isHorizontal ? S : W) - M);
if (positive &lt; negative) pixelStep = -pixelStep;
</code></pre><p>拿到了混合方向和混合系数后，就可以混合了，将 BlendFactor 乘上 pixelStep 加在原 uv 上，进行采样即可，这里是利用了 Bilinear 采样器的混合效果：  </p>
<pre><code>return SampleOffsetZero(uv + pixelStep * blendFactor).rgb;
</code></pre><p>最终效果对比如下（这个是个光滑的球，由于使用的是寒霜的 Renormalized Disney diffuse，在边缘有条暗边，加剧了抗锯齿的需求，汗）：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/28/LpqYJNdj4IlXuRc.png" width = "40%" height = "40%" alt="图135 - 左：无 FXAA；右：FXAA Blending"/>
</div>

<p>我们可以为 Blend Factor 设置一个 Strength 参数，在 NVIDIA FXAA 3.11 的实现中对该参数的说明如下：  </p>
<pre><code>// It is here now to allow easier tuning.
// Choose the amount of sub-pixel aliasing removal.
// This can effect sharpness.
//   1.00 - upper limit (softer)
//   0.75 - default amount of filtering
//   0.50 - lower limit (sharper, less sub-pixel aliasing removal)
//   0.25 - almost off
//   0.00 - completely off
</code></pre><p>因为 FXAA 经常被诟病太模糊，所以可以通过该参数来减轻模糊，乘在 blendFactor 里就行：  </p>
<h3 id="Edge-Blend"><a href="#Edge-Blend" class="headerlink" title="Edge Blend"></a>Edge Blend</h3><p>上述的 Blend Factor 只是根据中间像素点周围 3 × 3 的像素点进行采样分析，并且假设锯齿边界是完全垂直或者水平的，但是很多时候，我们的锯齿边界是带有角度的。这样，要得到得到正确的混合系数，就需要将采样范围扩展到 3 × 3 像素块之外。</p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/28/nsXUu1C9iEgqcjz.png" width = "25%" height = "25%" alt="图136 - 最下为理想情况下的抗锯齿效果"/>
</div>

<p>为了进一步确定边缘，我们需要使用之前计算的待混合像素点与中间像素的亮度的差值（即上面的 positive 或 negative，又称为<strong>梯度值 Gradient</strong>）以及待混合像素点的亮度：  </p>
<pre><code>// if (positive &lt; negative) pixelStep = -pixelStep;

// Reserve Blending Pixel Gradient &amp; Luma
float gradient, oppositeLuma;
if (positive &gt; negative)
&#123;
    gradient = positive;
    oppositeLuma = isHorizontal ? N : E;
&#125;
else
&#123;
    pixelStep = -pixelStep;
    gradient = negative;
    oppositeLuma = isHorizontal ? S : W;
&#125;
</code></pre><p>接下来就是沿着边界两侧的方向，进行搜索，直到找到锯齿边界终点为止。判断边界的方式是计算两侧的亮度值的差，是否和当前的亮度变化梯度值符合，如下图所示：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/28/5NQub23jWcYULDe.png" width = "30%" height = "30%" alt="图137 - Searching for the end pixel"/>
</div>

<p>但是其实不需要每次采样两个点，可以利用双线性插值，在边界处采样，这样也足以判断出边界的终点，如下图：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/28/olvienRMAwjVd42.png" width = "30%" height = "30%" alt="图138 - Searching for the end pixel"/>
</div>

<p>所以我们首先得确定采样的 uv，以及每次采样的步长：  </p>
<pre><code>// Edge Factor Calculation
float2 edgeUV = uv;
edgeUV += pixelStep * 0.5f;
float2 edgeStep = isHorizontal ? float2(_BlitTexture_TexelSize.x, 0) : float2(0, _BlitTexture_TexelSize.y);
</code></pre><p>然后先算出中间像素点和待混合像素点的平均亮度值，沿着两侧进行搜索采样时，计算当前采样点平均值和中间像素点平均值的亮度差，若亮度差超过了 0.25 倍的梯度值，则认为是到达了锯齿边界的终点，代码大致如下：  </p>
<pre><code>float edgeLuma = (M + oppositeLuma) * 0.5f;
float gradientThreshold = gradient * 0.25f;

float2 uvP = edgeUV + edgeStep;
float lumaGradientP = abs(GetLuma(SampleOffsetZero(uvP)) - edgeLuma);
bool atEndP = lumaGradientP &gt; gradientThreshold;
</code></pre><p>当然只做一步是不够的，我们需要循环遍历，将上面代码删除。因为不可能无限循环去搜索，我们需要假设一个最大循环步长，先假设为 10 步，我们需要向两端都进行搜索，并记录两端的像素距离，同时若搜索步长超过了 10 步还是没有找到边界，则默认边界像素距离长度额外加 8：  </p>
<pre><code>#define EXTRA_EDGE_STEPS 10
#define LAST_EDGE_STEP_GUESS 8.0
...

float edgeLuma = (M + oppositeLuma) * 0.5f;
float gradientThreshold = gradient * 0.25f;

float2 uvP = edgeUV;
float2 uvN = edgeUV;
float lumaDeltaP, lumaDeltaN, distanceP, distanceN;
int i;

UNITY_UNROLL
for (i = 1; i &lt;= EXTRA_EDGE_STEPS; i++)
&#123;
    uvP += edgeStep;
    lumaDeltaP = GetLuma(SampleOffsetZero(uvP)) - edgeLuma;
    if (abs(lumaDeltaP) &gt; gradientThreshold) break;
&#125;
if (i == EXTRA_EDGE_STEPS + 1)
&#123;
    uvP += LAST_EDGE_STEP_GUESS * edgeStep;
&#125;

UNITY_UNROLL
for (i = 1; i &lt;= EXTRA_EDGE_STEPS; i++)
&#123;
    uvN -= edgeStep;
    lumaDeltaN = GetLuma(SampleOffsetZero(uvN)) - edgeLuma;
    if (abs(lumaDeltaN) &gt; gradientThreshold) break;
&#125;
if (i == EXTRA_EDGE_STEPS + 1)
&#123;
    uvP -= LAST_EDGE_STEP_GUESS * edgeStep;
&#125;

if (isHorizontal)
&#123;
    distanceP = uvP.x - uv.x;
    distanceN = uv.x - uvN.x;
&#125;
else
&#123;
    distanceP = uvP.y - uv.y;
    distanceN = uv.y - uvN.y;
&#125;
</code></pre><p>接下来就是计算 Edge 混合系数了，我们可以根据锯齿边界最近端的像素距离占总长度的比例来计算出一个基于 Edge 的混合系数。但是在此之前，我们还需要判断一下混合的方向是否和当前需要计算的一致，这里是通过比较相对亮度的正负值来实现的。比如下图中的锯齿边界，在水平的锯齿边界上计算时，两个黄色的点是现在我们要计算混合系数的目标像素点，两个红色标记的点是我们期望进行混合的点。因为左边的混合方向其实应该是向上的，因此这种情况下就不需要进行计算，而是在处理上面红色像素点时进行计算。而右边的黄色标记目标像素点，是需要在当前处理的。</p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/29/fwAi1HCWdI4GFxL.png" width = "60%" height = "60%" alt="图139 - Blending on a Single Side"/>
</div>

<p>如果判断出边界方向不符合时，就直接设 Edge 混合系数为 0，边界方向符合时，按照相对的距离，来估算混合系数：  </p>
<pre><code>float edgeFactor;
if (distanceP &lt; distanceN)
&#123;
    if (sign(lumaDeltaP) == sign(M - edgeLuma))
    &#123;
        edgeFactor = 0;
    &#125;
    else
    &#123;
        edgeFactor = 0.5f - distanceP / (distanceP + distanceN);
    &#125;
&#125;
else
&#123;
    if (sign(lumaDeltaN) == sign(M - edgeLuma))
    &#123;
        edgeFactor = 0;
    &#125;
    else
    &#123;
        edgeFactor = 0.5f - distanceN / (distanceP + distanceN);
    &#125;
&#125;
</code></pre><p>最终取 Edge Factor 和 Blend Factor 的最大值作为最终混合系数：  </p>
<pre><code>float finalFactor = max(blendFactor, edgeFactor);
return SampleOffsetZero(uv + pixelStep * finalFactor).rgb;
</code></pre><p>最终效果如下：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/29/9tfrdN1XSUZAQPl.png" width = "40%" height = "40%" alt="图140 - 左：无 FXAA；右：FXAA finalFactor"/>
</div>

<h3 id="Edge-Quality"><a href="#Edge-Quality" class="headerlink" title="Edge Quality"></a>Edge Quality</h3><p>我们可以为 Edge 的搜索设置步长来限制性能消耗（步长可以参考 NVIDIA FXAA 3.11 的实现中的部分预设），如下：  </p>
<pre><code>#if defined(FXAA_QUALITY_LOW)
    #define EXTRA_EDGE_STEPS 5
    #define EDGE_STEP_SIZES 1.0, 1.5, 2.0, 2.0, 2.0
    #define LAST_EDGE_STEP_GUESS 8.0
#elif defined(FXAA_QUALITY_MEDIUM)
    #define EXTRA_EDGE_STEPS 8
    #define EDGE_STEP_SIZES 1.0, 1.5, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0
    #define LAST_EDGE_STEP_GUESS 8.0
#else
    #define EXTRA_EDGE_STEPS 12
    #define EDGE_STEP_SIZES 1.0, 1.0, 1.0, 1.0, 1.0, 1.5, 1.5, 2.0, 2.0, 2.0, 2.0, 4.0
    #define LAST_EDGE_STEP_GUESS 8.0
#endif

static const float EdgeStepSizes[EXTRA_EDGE_STEPS] = &#123; EDGE_STEP_SIZES &#125;;

···
float3 ApplyFXAAQuality(float2 uv, float4 middleColor)
&#123;
    ...
    UNITY_UNROLL
    for (i = 1; i &lt;= EXTRA_EDGE_STEPS; i++)
    &#123;
        uvP += EdgeStepSizes[i - 1] * edgeStep;
        lumaDeltaP = GetLuma(SampleOffsetZero(uvP)) - edgeLuma;
        if (abs(lumaDeltaP) &gt; gradientThreshold) break;
    &#125;
    ...
&#125;
</code></pre><p>因为图片会压缩以及采样，上述三种预设质量效果的差别不是很能展示出来，故我就不展示了。我实测下来，FXAA_QUALITY_LOW 的质量会比较差，FXAA_QUALITY_MEDIUM 和 FXAA_QUALITY_HIGH 的差别肉眼不是很能察觉得出来，但是其实 FXAA_QUALITY_MEDIUM 和 FXAA_QUALITY_HIGH 的性能差距也不会很大，所以默认开 FXAA_QUALITY_HIGH 就行。</p>
<h2 id="FXAA-Console"><a href="#FXAA-Console" class="headerlink" title="FXAA Console"></a>FXAA Console</h2><p>FXAA Quality 版本需要的采样次数是比较多的，Console 版本每个像素点最多只需要进行 9 次采样，比 Quality 版本要少很多，当然效果也会差一点。FXAA Console 的主要逻辑是计算锯齿边的法线方向，然后根据法线方向做混合。</p>
<p>首先还是采样周围像素点，然后做阈值判断，只不过 Console 版本只采样对角线上 4 个点，并且这里的偏移只有半个像素，如下：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/29/yBT8NCVrsM2ObSQ.png" width = "20%" height = "20%" alt="图141 - FXAA Console Sampling Pixels"/>
</div>

<pre><code>float M  = GetLuma(middleColor);
float NW = GetLuma(SampleOffset(uv, -0.5,  0.5));
float NE = GetLuma(SampleOffset(uv,  0.5,  0.5));
float SW = GetLuma(SampleOffset(uv, -0.5, -0.5));
float SE = GetLuma(SampleOffset(uv,  0.5, -0.5));

// Calculate Contrast
float maxLuma = max(max(NW, NE), max(SW, SE));
float minLuma = min(min(NW, NE), min(NW, NE));
float contrast = max(maxLuma, M) - min(minLuma, M);

// Threshold
if (contrast &lt; max(FXAA_CONSOLE_CONTRAST_THRESHOLD, maxLuma * FXAA_CONSOLE_RELATIVE_THRESHOLD)) return middleColor.rgb;
</code></pre><p>注意 Console 版本的 Contrast Threshold（fxaaConsoleEdgeThresholdMin）和 Relative Threshold（fxaaConsoleEdgeThreshold）的数值预设和 Quality 版本不太一样：  </p>
<pre><code>//   0.125 leaves less aliasing, but is softer (default!!!)
//   0.25 leaves more aliasing, and is sharper
FxaaFloat fxaaConsoleEdgeThreshold,
//   0.06 - faster but more aliasing in darks
//   0.05 - default
//   0.04 - slower and less aliasing in darks
FxaaFloat fxaaConsoleEdgeThresholdMin,
</code></pre><p>然后就是计算当前亮度变化的梯度，亮度变化最快的方向，就是锯齿边界的法线方向，如下图所示：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/29/mgsj4P1NIrqdkGE.png" width = "20%" height = "20%" alt="图142 - Determine Blending Direction"/>
</div>

<p>如上图中红色箭头的方向就是亮度变化的梯度方向，即法线方向，锯齿方向是和法线方向垂直的绿色箭头的方向。我们之后混合的是沿着锯齿方向的前后两个像素，故需要求绿色箭头的方向：  </p>
<pre><code>// Determine Blending Direction
float2 dir;
dir.x = -((NW + NE) - (SW + SE));
dir.y = ((NE + SE) - (NW + SW));
dir = normalize(dir);
</code></pre><p>沿着锯齿方向分别向正负方向偏移 uv，进行两次采样，再平均后作为抗锯齿的结果。</p>
<pre><code>float2 dir1 = dir * TEXEL_SIZE.xy * FXAA_CONSOLE_SCALE;
float4 rgbN1 = SampleOffsetZero(uv - dir1);
float4 rgbP1 = SampleOffsetZero(uv + dir1);
float4 rgbA = (rgbN1 + rgbP1) * 0.5;
</code></pre><p><code>FXAA_CONSOLE_SCALE</code> 是个可控制的变量，NVIDIA FXAA 3.11 中的参数建议如下，建议默认值为 0.5：  </p>
<pre><code>// N = 0.50 (default)
// N = 0.33 (sharper)
// &#123;x___&#125; = -N/screenWidthInPixels  
// &#123;_y__&#125; = -N/screenHeightInPixels
// &#123;__z_&#125; =  N/screenWidthInPixels  
// &#123;___w&#125; =  N/screenHeightInPixels 
FxaaFloat4 fxaaConsoleRcpFrameOpt,
</code></pre><p>不过这样做的问题就是，这种方式对于斜向的锯齿比较友好，但是对于水平和垂直方向的锯齿，却不是很友好。因为水平和垂直方向的锯齿，计算的方向的一个维度会是 0，会导致两次采样几乎没有覆盖到应该要混合区域的区域。因此我们要进行一次额外的计算，将偏移距离延伸至更远处，具体的做法就是使用 dir 向量分量的最小值的倒数，将 dir 进行缩放。这样如果 dir 的最小分量的值越小，就能采样到越远的地方：</p>
<pre><code>float dirAbsMinTimesC = min(abs(dir.x), abs(dir.y)) * FXAA_CONSOLE_EDGE_SHARPNESS;
float2 dir2 = clamp(dir / dirAbsMinTimesC, -2.0, 2.0) * 2.0;
float4 rgbN2 = SampleOffsetZero(uv - dir2 * TEXEL_SIZE.xy);
float4 rgbP2 = SampleOffsetZero(uv + dir2 * TEXEL_SIZE.xy);
float4 rgbB = rgbA * 0.5 + (rgbN2 + rgbP2) * 0.25;
</code></pre><p>为了防止 dir2 采样到亮度变化较大的区域，产生噪点，这里我们再对 dir2 采样到的亮度值进行一次判断，如果得到的结果超过了周围最小最大的亮度范围，则丢弃新的采样的结果：  </p>
<pre><code>float newLum = GetLuma(rgbB);
if((newLum &gt; minLuma) &amp;&amp; (newLum &lt; maxLuma))
&#123;
    rgbA = rgbB;
&#125;
return rgbA.rgb;
</code></pre><p>FXAA Quality 和 FXAA Console 对比如下（实测下来感觉 FXAA Quality 即使是 Low 的预设也会比 Console 略微好一点）：  </p>
<div  align="center">  
<img src="https://s2.loli.net/2025/04/29/cWn2ixg5Z3Hqzjy.png" width = "100%" height = "100%" alt="图143 - 上：无 FXAA；左：FXAA Console；右：FXAA Quality"/>
</div>

<p>图片上可能看不太出来区别，最好还是实践看效果。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://ybniaobu.github.io">鸟布</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://ybniaobu.github.io/2025/04/07/2025-04-07-CustomSRP7/">https://ybniaobu.github.io/2025/04/07/2025-04-07-CustomSRP7/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://ybniaobu.github.io" target="_blank">鸟布的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/">游戏开发</a><a class="post-meta__tags" href="/tags/unity/">unity</a><a class="post-meta__tags" href="/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/">图形学</a></div><div class="post_share"><div class="social-share" data-image="https://s2.loli.net/2025/04/07/2zi6pj3XtAPHvmy.gif" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/images/wechat.png" target="_blank"><img class="post-qr-code-img" src="/images/wechat.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/images/alipay.png" target="_blank"><img class="post-qr-code-img" src="/images/alipay.png" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2025/04/29/2025-04-29-CustomSRP8/" title="Unity Custom SRP 基础（八）"><img class="cover" src="https://s2.loli.net/2025/04/29/IHYjvyKDR2uoGEt.gif" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Unity Custom SRP 基础（八）</div></div></a></div><div class="next-post pull-right"><a href="/2025/03/13/2025-03-13-CustomSRP6/" title="Unity Custom SRP 基础（六）"><img class="cover" src="https://s2.loli.net/2025/03/13/LozNxAmnlEJSOyV.gif" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Unity Custom SRP 基础（六）</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/09/15/2023-09-15-UnityShader1/" title="《Unity Shader入门精要》读书笔记（一）"><img class="cover" src="https://s2.loli.net/2023/09/19/cDvdURBPhjwkOsY.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-15</div><div class="title">《Unity Shader入门精要》读书笔记（一）</div></div></a></div><div><a href="/2023/10/13/2023-10-13-UnityShader2/" title="《Unity Shader入门精要》读书笔记（二）"><img class="cover" src="https://s2.loli.net/2023/10/15/RZftaNSscWoLH1u.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-13</div><div class="title">《Unity Shader入门精要》读书笔记（二）</div></div></a></div><div><a href="/2023/11/22/2023-11-22-UnityShader3/" title="《Unity Shader入门精要》读书笔记（三）"><img class="cover" src="https://s2.loli.net/2023/11/23/L3ts4WnThMlDN9d.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-22</div><div class="title">《Unity Shader入门精要》读书笔记（三）</div></div></a></div><div><a href="/2023/12/19/2023-12-19-UnityShader4/" title="《Unity Shader入门精要》读书笔记（四）"><img class="cover" src="https://s2.loli.net/2023/12/20/9Ah5ugiIpONK1cX.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-12-19</div><div class="title">《Unity Shader入门精要》读书笔记（四）</div></div></a></div><div><a href="/2023/12/30/2023-12-30-UnityShader5/" title="《Unity Shader入门精要》读书笔记（五）"><img class="cover" src="https://s2.loli.net/2023/12/30/hc2s7BS45l1wUdQ.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-12-30</div><div class="title">《Unity Shader入门精要》读书笔记（五）</div></div></a></div><div><a href="/2024/03/20/2024-03-20-NPR_StarRail1/" title="基于星穹铁道的卡通渲染（一）"><img class="cover" src="https://s2.loli.net/2024/03/26/dZTwsApi59CSUal.gif" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-20</div><div class="title">基于星穹铁道的卡通渲染（一）</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/images/wechat%20avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">鸟布</div><div class="author-info__description">教练，我想学技术</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">47</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">14</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://niaobu.notion.site/787824630ea6480e944c1ae5ae7f4792"><i class="fa-solid fa-book"></i><span>My Notion</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ybniaobu/ybniaobu.github.io" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:niaobubob@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">为了蒂法！！！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Particles"><span class="toc-number">1.</span> <span class="toc-text">Particles</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Unlit-Particles-Shader"><span class="toc-number">1.1.</span> <span class="toc-text">Unlit Particles Shader</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Vertex-Color"><span class="toc-number">1.2.</span> <span class="toc-text">Vertex Color</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Flipbooks"><span class="toc-number">1.3.</span> <span class="toc-text">Flipbooks</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Flipbook-Blending"><span class="toc-number">1.3.1.</span> <span class="toc-text">Flipbook Blending</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Fading-Near-Camera"><span class="toc-number">1.4.</span> <span class="toc-text">Fading Near Camera</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Soft-Particles"><span class="toc-number">1.5.</span> <span class="toc-text">Soft Particles</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%8D%E6%9E%84-View-Space-Depth"><span class="toc-number">1.5.1.</span> <span class="toc-text">重构 View Space Depth</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Soft-Particles-Fading"><span class="toc-number">1.5.2.</span> <span class="toc-text">Soft Particles Fading</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Distortion"><span class="toc-number">1.6.</span> <span class="toc-text">Distortion</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Distortion-Map"><span class="toc-number">1.6.1.</span> <span class="toc-text">Distortion Map</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Distortion-Blend"><span class="toc-number">1.6.2.</span> <span class="toc-text">Distortion Blend</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Depth-amp-Color-Texture"><span class="toc-number">2.</span> <span class="toc-text">Depth &amp; Color Texture</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Depth-Prepass"><span class="toc-number">2.1.</span> <span class="toc-text">Depth Prepass</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="toc-number">2.1.1.</span> <span class="toc-text">基本原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.1.2.</span> <span class="toc-text">实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Copy-Depth"><span class="toc-number">2.2.</span> <span class="toc-text">Copy Depth</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Gizmos-and-Depth"><span class="toc-number">2.3.</span> <span class="toc-text">Gizmos and Depth</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Copy-Color"><span class="toc-number">2.4.</span> <span class="toc-text">Copy Color</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Render-Scale"><span class="toc-number">3.</span> <span class="toc-text">Render Scale</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Buffer-Size"><span class="toc-number">3.1.</span> <span class="toc-text">Buffer Size</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9-Shader-%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">3.2.</span> <span class="toc-text">对 Shader 的影响</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Rescaling"><span class="toc-number">3.3.</span> <span class="toc-text">Rescaling</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#FXAA"><span class="toc-number">4.</span> <span class="toc-text">FXAA</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#FXAA-Quality"><span class="toc-number">4.1.</span> <span class="toc-text">FXAA Quality</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Luma-Contrast"><span class="toc-number">4.1.1.</span> <span class="toc-text">Luma Contrast</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Threshold"><span class="toc-number">4.1.2.</span> <span class="toc-text">Threshold</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Blend-Factor"><span class="toc-number">4.1.3.</span> <span class="toc-text">Blend Factor</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Blend-Direction"><span class="toc-number">4.1.4.</span> <span class="toc-text">Blend Direction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Edge-Blend"><span class="toc-number">4.1.5.</span> <span class="toc-text">Edge Blend</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Edge-Quality"><span class="toc-number">4.1.6.</span> <span class="toc-text">Edge Quality</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#FXAA-Console"><span class="toc-number">4.2.</span> <span class="toc-text">FXAA Console</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/09/09/2025-09-09-SSAO2/" title="屏幕空间环境光遮蔽（二）HBAO 与 GTAO"><img src="https://s2.loli.net/2025/09/09/Uq93S46lgTAHs7Q.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="屏幕空间环境光遮蔽（二）HBAO 与 GTAO"/></a><div class="content"><a class="title" href="/2025/09/09/2025-09-09-SSAO2/" title="屏幕空间环境光遮蔽（二）HBAO 与 GTAO">屏幕空间环境光遮蔽（二）HBAO 与 GTAO</a><time datetime="2025-09-09T12:10:09.000Z" title="发表于 2025-09-09 20:10:09">2025-09-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/08/01/2025-08-01-SSAO1/" title="屏幕空间环境光遮蔽（一）SSAO"><img src="https://s2.loli.net/2025/08/01/287gfDiMYRFrmUs.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="屏幕空间环境光遮蔽（一）SSAO"/></a><div class="content"><a class="title" href="/2025/08/01/2025-08-01-SSAO1/" title="屏幕空间环境光遮蔽（一）SSAO">屏幕空间环境光遮蔽（一）SSAO</a><time datetime="2025-08-01T04:54:23.000Z" title="发表于 2025-08-01 12:54:23">2025-08-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/21/2025-06-21-TAA/" title="Temporal Anti-Aliasing (TAA)"><img src="https://s2.loli.net/2025/06/23/kEPO3zg8IRXwUFC.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Temporal Anti-Aliasing (TAA)"/></a><div class="content"><a class="title" href="/2025/06/21/2025-06-21-TAA/" title="Temporal Anti-Aliasing (TAA)">Temporal Anti-Aliasing (TAA)</a><time datetime="2025-06-21T11:43:03.000Z" title="发表于 2025-06-21 19:43:03">2025-06-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/08/2025-06-08-TileBasedLightCulling/" title="Tile-Based Light Culling"><img src="https://s2.loli.net/2025/06/08/1hF5QplnZjxBvJS.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Tile-Based Light Culling"/></a><div class="content"><a class="title" href="/2025/06/08/2025-06-08-TileBasedLightCulling/" title="Tile-Based Light Culling">Tile-Based Light Culling</a><time datetime="2025-06-08T05:03:10.000Z" title="发表于 2025-06-08 13:03:10">2025-06-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/04/29/2025-04-29-CustomSRP8/" title="Unity Custom SRP 基础（八）"><img src="https://s2.loli.net/2025/04/29/IHYjvyKDR2uoGEt.gif" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Unity Custom SRP 基础（八）"/></a><div class="content"><a class="title" href="/2025/04/29/2025-04-29-CustomSRP8/" title="Unity Custom SRP 基础（八）">Unity Custom SRP 基础（八）</a><time datetime="2025-04-29T12:00:38.000Z" title="发表于 2025-04-29 20:00:38">2025-04-29</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2025 By 鸟布</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Your time is limited, so don't waste it living someone else's life.</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>