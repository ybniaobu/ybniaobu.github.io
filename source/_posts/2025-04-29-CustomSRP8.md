---
title: Unity Custom SRP 基础（八）
date: 2025-04-29 20:00:38
categories: 
  - [图形学]
  - [unity, pipeline]
tags:
  - 图形学
  - 游戏开发
  - unity
top_img: /images/black.jpg
cover: https://s2.loli.net/2025/04/29/IHYjvyKDR2uoGEt.gif
mathjax: true
description: 本笔记的主要内容包含XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX。
---

> 本笔记是关于 Unity 的**自定义可编程渲染管线**的入门基础，即 **SRP (Scriptable Rendering Pipeline)**，主要参考了著名的教程 https://catlikecoding.com/ 的 Custom SRP Tutorial，以及知乎上各位图形学大神们的文章。  
>    
> 笔者使用的 Unity 版本是 6000.0.27f1，Core RP Library 的版本是 17.0.3。

# Render Graph
**Render Graph / Frame Graph** 最早由寒霜引擎于 GDC 2017 提出，PPT 详见：https://www.slideshare.net/slideshow/framegraph-extensible-rendering-architecture-in-frostbite/72795495 。Unity 也因此实现了一套自己的 Render Graph，在 Core RP Library 内，命名空间为 `UnityEngine.Rendering.RenderGraphModule`。

> 下面参考了几篇文章：https://zhuanlan.zhihu.com/p/582415505 ，https://zhuanlan.zhihu.com/p/425830762 。

## Render Graph 基本概念
随着现代游戏引擎渲染效果的不断丰富，Pass 的数量日益增多、逻辑日益复杂，传统的 Immediate mode 下的渲染管线具有诸多挑战：比如各功能之间存在强耦合、开发者需要手动管理资源的生命周期、功能的拓展具有局限性以及难以 Debug 等等，因此寒霜对渲染 **passes** 以及 **resources** 的管理提出了更高程度的抽象，即 Frame Graph。

**Pass** 指一组渲染操作或者函数，每个 Pass 可以负责渲染特定的内容或物体，或仅用于设置全局状态。Pass 可以接受一个或多个输入资源，调用自己内部的执行函数，并产生一个或多个输出资源。现代游戏引擎的 pass 可能会达到数十个或上百个。

<div  align="center">  
<img src="https://s2.loli.net/2025/05/21/CrLNshp7aGgKZTw.png" width = "60%" height = "60%" alt="图144 - 战地 4 的 Passes"/>
</div>

**Resources** 指 Buffer 以及 Texture。这些资源在用完之后若不能及时收回，那将会导致 GPU 的内存利用率降低，甚至是 GPU 内存泄露，所以资源的及时回收非常得重要。对于大部分的 Texture 的生命周期只会在一帧之内，即**临时资源 Transient Resource**。

与此同时，现代图形 API（如 Vulkan、Metal 或 DirectX 12）暴露了更多底层的 API 接口，对比 DirectX 11 时代图形开发人员往往需要先提前设定好或加载好所有需要的东西，最后才去执行它们，即延迟执行。DirectX 11 依赖驱动程序自动优化资源管理，渲染逻辑通常集中在单个线程。而 DirectX 12 开发者需要直接管理硬件资源，同时引入了**命令队列 Command Queue** 和**命令列表 Command List**，允许多线程并行生成渲染指令，另外开发者需手动管理资源状态（如使用**资源屏障 Resource Barrier**），避免不必要的状态切换，提升效率，故增加了代码的复杂度。

所以 Render Graph 的产生可以更好地调配、跟踪、管理、回收资源，并且自动管理资源而非手动管理。此外 Render Graph 的目标还有①简化资源的管理；②简化渲染管线的配置；③简化多线程计算以及资源屏障；④独立有效的渲染单元；⑤渲染管线可视化以及更容易 Debug。

## Render Graph 的设计
Render Graph 将渲染代码分为一个个 Pass，每个 Pass 相互独立，不存在相互调用。Render Graph 主要分为三个阶段：**Setup Phase**、**Compile Phase**、**Execute Phase**。

**①Setup Phase** 中主要定义 render passes 或者 compute passes，并为每个 pass 定义输入和输出资源，然后对这些资源定义执行哪种操作，比如 **read**、**write**、**create**。对于一些外部永久资源（生命周期大于一帧），需要**导入 import**，比如 backbuffer、TAA 的历史帧等等。寒霜的示例代码如下：   

``` C++
RenderPass::RenderPass(FrameGraphBuilder& builder)
{
  // Declare new transient resource
  FrameGraphTextureDesc desc;
  desc.width = 1280;
  desc.height = 720;
  desc.format = RenderFormat_D32_FLOAT;
  desc.initialSate = FrameGraphTextureDesc::Clear;
  m_renderTarget = builder.createTexture(desc);
}

RenderPass::RenderPass(FrameGraphBuilder& builder,
  FrameGraphResource input,
  FrameGraphMutableResource renderTarget)
{
  // Declare resource dependencies
  m_input = builder.read(input, readFlags);
  m_renderTarget = builder.write(renderTarget, writeFlags);
}
```

pass 对于 resource 的声明，能够让 Render Graph 帮我们确定 resource 的生命周期，resource 应该在何时被分配，应该在何时被回收，Render Graph 会自动帮我们计算，并使 resource 的生命周期尽可能得短。同时在 setup 阶段，resource 还没有被分配空间，因为该阶段并没有使用到 resource。

**②Compile Phase**，该阶段主要**裁剪 Cull** 未引用的 resource 和 pass，留下真正需要执行的部分。同时对 resource 的生命周期进行计算，确定 resource 应该在何时分配资源、何时被回收。

**③Execute Phase** 就是开始执行每个未裁剪 Pass 的回调函数，并真正为 Setup Phase 申明的资源分配 GPU 资源。

## Render Graph 的其他优化
**①Asynchronous Compute**  
程序优化的一个大方向就是提高并行度，即使在执行很密集的渲染任务时，GPU 的绝大部分时间都是闲置状态。现在的渲染管线需要处理大量的多边形和像素，处理得越快得到的结果质量就会越高，因为 GPU 的渲染管线的各个部分（顶点着色、光栅化、片元着色等）都是有专门的运算单元负责的，管线中的任意一个阶段出现瓶颈都会使其他阶段不能充分利用，每个阶段的吞吐量 Throughput 还依赖于其他阶段。这也是 Forward Rendering 的弊端之一，因为 Forward Rendering 在片元着色阶段具有一定的瓶颈。

与此同时，现代 GPU 通常包括多个独立的 Engine 来提供专用的功能。很多 GPU 包含一个 （3D）Graphic Engine、一个 Compute Engine、一个或多个 Copy Engine。Engine 本质上就是 Command Processor，它们可以并行处理命令。3D Engine 包括 VS、光栅化、PS 等；Compute Engine 执行的就是 Compute Shader；Copy Engine 则用来拷贝资源。

在 DirectX 12 中提供了三种 Command Queue 驱动这三个 Engine，3D (Graphic) Queue 可以驱动这三个 Engine，Compute Queue 可以驱动 Compute 和 Copy Engine，Copy Queue 只能驱动 Copy Engine。向 3D Queue 提交一个 3D Command List，向 Compute Queue 提交一个 Compute Command List，这样的结果就是 3D Queue 驱动 3D Engine，同时 Compute Queue 驱动 Compute Engine，这种行为就叫做 **Async Compute**。Async Compute 的目的是让开发者在比线程更高的层次上实现并行，提高 GPU 的利用率。

<div  align="center">  
<img src="https://s2.loli.net/2025/05/21/c6yxaid3WBSFzJ9.png" width = "50%" height = "50%" alt="图145 - Async Compute"/>
</div>

需要注意的是要让 Graphic Queue 和 Compute Queue 利用不同的 GPU 资源，比如 Shadow maps 的瓶颈在光栅化这些固定功能单元，这时执行计算任务是很合适的，如下图：  

<div  align="center">  
<img src="https://s2.loli.net/2025/05/21/7bXleEs6xnrMfo1.png" width = "60%" height = "60%" alt="图146 - Shadow Maps Async Compute（Deferred Rendering 下）"/>
</div>

但如果将 SSAO 和 Shading 异步执行，可能效率还不如不用 Async Compute。甚至让多帧重叠也可以进一步提高利用率，比如上图中 Post-Processing 和 G-Buffer 阶段异步执行。在使用 Async Compute 时，Render Graph 可以帮助我们自动调度 Async Compute、处理同步点，降低了维护成本，使开发者可以专注图形特性的开发。

**②Resource Barrier**  
在 DirectX 11 及 OpenGL 中，资源状态管理是隐式进行的，大部分状态管理工作是由驱动程序自动完成的。每当应用程序执行一个操作，如绘制调用或资源绑定，驱动程序需要检查所涉及资源的当前状态，并确定是否需要进行状态转换。就和 GC 一样系统为了安全，牺牲了一部分性能。但在 DirectX 12 中，需要手动管理，GPU 会对某一个资源进行先写入后读这两种操作，若写操作还没有完全执行完毕的时候进行读取就产生资源冒险的现象，故 DirectX 12 提供了**资源屏障 Resource Barriers** 去管理资源的同步，确保资源在被不同的命令访问时处于正确的状态。常见的使用资源屏障的情景：①Render Targets 切换：当一个渲染目标完成写入后，需要被另一个操作读取时，需要插入一个资源屏障来保证所有的写入操作完成后才能开始读取；②纹理更新：当你更新一个纹理的内容，然后想用它进行渲染或作为着色器的输入，你需要在写入纹理数据和使用这些数据之间插入资源屏障；③深度缓冲区：在深度缓冲区被用作渲染目标进行深度写入后，如果想将其用作深度纹理进行采样，需要在这两种用途之间设置资源屏障；④Compute Shader 和 Graphics Pipeline 之间的资源共享：当资源在 Compute Shader 和 Graphics Pipeline 之间共享时，通常需要在两者之间插入资源屏障，以确保 Compute Shader 的修改在 Graphics Pipeline 访问该资源之前完成。

> CPU 和 GPU 之间的同步是通过**围栏 Fence** 来控制的。

还有一个叫**分隔屏障 Spilt Barrier**，它通知 GPU 处于状态 A 中的资源稍后将以状态 B 来使用，Split Barrier 分为 Begin 和 End，Begin Barrier 提交后这个资源就不能被访问了，在 Begin Barrier 和 End Barrier 之间的其他任务就可以填充 Barrier 导致的阻塞，使用分割屏障有助于提高性能。

Render Graph 可以自动管理 Resource Barrier 并进行优化，最小化 Barrier 的数量，尽早开始 Barrier，把多个 Barrier 合并提交，这样降低了出错的概率，使代码更清晰，开发者可以专注图形特性的开发。

**③Memory Aliasing**  
Render Graph 提供的创建资源接口没有真正创建资源，而是返回一个 Handle 表示这个资源，Render Graph 会使用整帧的信息计算资源的生命周期，实际用到的资源才会分配内存，这样就不用自己实现复杂的资源管理逻辑，还能利用 memory aliasing 高效的复用内存。渲染管线中的某些资源往往只会被少数几个阶段使用。比如在后处理中：Bloom 的输出只会被下一个阶段 Tone mapping 使用。在一帧中很多资源的有效生命周期很短，但是会提前分配内存并在整帧中占用。首先想到的方法是在使用这个资源时进行分配，使用完后就释放，这样是可以优化内存的大小，但是分配、释放内存是个很慢的操作，在渲染时频繁的分配、释放就更影响性能了。

解决内存频繁分配释放的方法就是**对象池**，对象池本质上是一种上层的 memory aliasing，传统 API 中开发者不需要关注内存管理，也没办法，而现代图形 API 提供了内存管理的接口，可以实现底层的 memory aliasing。**Memory Aliasing** 指的是不同变量指向同一地址的现象，在这里指的是在同一片内存区域中同时存放多个资源。如果有很多大型资源在时间上不会重叠，就可以在相同的内存分配这些资源，memory aliasing 相比对象池可以进一步降低内存占用，因为不需要考虑资源的类型、格式、大小等待，在底层都是一堆字节。

使用 Render Graph 在声明一个 Render Pass 时需要声明该 Pass 使用的资源，所以我们可以计算出这一帧使用的所有资源的生命周期，这样就可以很容易实现 Memory Aliasing。Unity SRP 的 Render Graph 应该仍然使用的是对象池，而非 Memory Aliasing。

# Unity Render Graph
Unity Render Graph 总体思路和上面是一样的，下面大致讲一下 Unity Render Graph 的 Resources 分类，以及如何在自定义 SRP 中使用。这里不打算像 Catlike Coding 教程中一样，将渲染管线的每个部分转换为 Render Graph Render Passes 的代码都记录下来，因为其实代码都是类似的，下面只讲一个笼统的 Render Pass 代码。我使用的 Render Graph 的 Core RP Library 版本为 17.0.4。

## Unity Render Graph Resources
首先 Unity Render Graph 将 Resources 分为了 **Internal resources** 和 **Imported resources**：  

**①Internal resources**：即 render graph 内部的资源，这些资源不能从 render graph 实例外部获取，并且 render graph 管理着这些资源的生命周期。Internal resources 又分为 **Transient** 和 **Non-Transient** 的资源，并且都是对象池管理的，依赖于底层的 IRenderGraphResourcePool。Unity 的 Transient 概念和寒霜  Frame Graph 里的 Transient 概念有所不同，寒霜的 Transient 指的是一帧之内的临时资源，Unity 的 Transient resources 的生命周期只在当前 Render Pass 内。而 Unity 的 Non-Transient resources 相当于寒霜的 Transient 概念，生命周期会跨越多个 Pass，在第一个对资源进行写操作的 Pass 中创建，在最后一个对资源进行读操作的 Pass 中释放，即放回资源池中。创建 Non-Transient resources 的 API 是 `RenderGraph.CreateTexture(in TextureDesc desc)`。创建 Transient resources 的 API 是 `RenderGraphBuilder.CreateTransientTexture(in TextureDesc desc)`。

**②Imported resources**：即之前提到过的 back buffer 和 TAA 历史帧等，这些资源的生命周期需要自己控制，导入的 API 是 `RenderGraph.ImportTexture(RTHandle)`。但 Imported resources 中有一类比较特殊，叫 **Shared resources**，通过 `RenderGraph.CreateSharedTexture(in TextureDesc, bool)` 创建，这类型资源更多是为了跨相机使用的资源，其的生命周期仍是由 render graph 管理，若 render graph 30 次 Execution 中都没有使用到就直接释放，相当于允许跨 30 个摄像机共享该资源。

对于上面所有的资源，我们所持有的都只是资源的一个 Handle，比如 TextureHandle、ComputeBufferHandle 等等都保存着资源对应的哈希值。

## SRP 中实现
### 创建 Render Graph 实例
首先 render pipeline 要维持一个 Render Graph 实例：  

``` C#
using UnityEngine.Rendering;
using UnityEngine.Rendering.RenderGraphModule;

public class XXRenderPipeline : RenderPipeline
{
    private RenderGraph m_RenderGraph;

    public XXRenderPipeline(XXRenderPipelineAsset asset)
    {
        m_RenderGraph = new RenderGraph("Custom Render Graph");
        ...
    }

    protected override void Render(ScriptableRenderContext context, List<Camera> cameras)
    {
        for (int i = 0; i < cameras.Count; i++)
        {
            ...
        }
        m_RenderGraph.EndFrame();
    }

    protected override void Dispose(bool disposing)
    {
        m_RenderGraph.Cleanup();
        ...
    }
}
```

注意别忘了，在 `Render()` 函数中调用 `EndFrame()` 函数，以及在覆写的 `Dispose()` 函数中调用 Render Graph 的 `Cleanup()` 函数从而正确地释放 Render Graph 分配的资源。然后我们需要将 Render Graph 实例传递到各个 Pass 当中，以便各个 Pass 中调用。

### Recording And Execute
在为 Render Graph 添加 render passes 之前，需要先调用 `BeginRecording()` 函数。添加完 render passes 后，调用 `EndRecordingAndExecute()` 执行：  

``` C#
var renderGraphParams = new RenderGraphParameters()
{
    scriptableRenderContext = renderContext,
    commandBuffer = cmd,
    currentFrameIndex = Time.frameCount,
    rendererListCulling = true
};

m_RenderGraph.BeginRecording(renderGraphParams);

// Add your passes here

m_RenderGraph.EndRecordingAndExecute();
```

### 添加 Pass
在 Render Graph 执行前，需要声明所有的 render passes，而每个 render pass 有两个部分：Setup 和 Render。在此之前，我们还需要为 Render 委托函数提供 PassData 以便委托使用（委托方法需要签名一致）：  

``` C#
    class MyRenderPassData
    {
        public float parameter;
        public TextureHandle inputTexture;
        public TextureHandle outputTexture;
    }
```

然后在 Setup 阶段定义或计算 PassData 中的数据或资源，最后调用 `RenderGraphBuilder.SetRenderFunc()` 设置渲染函数，渲染函数可以是一个 lambda 表达式或静态方法，大致如下：  

``` C#
using (var builder = renderGraph.AddRenderPass<MyRenderPassData>("My Render Pass", out var passData))
{
    passData.parameter = 2.5f;
    passData.inputTexture = builder.ReadTexture(inputTexture);

    TextureHandle output = renderGraph.CreateTexture(new TextureDesc(Vector2.one, true, true)
    { 
        colorFormat = GraphicsFormat.R8G8B8A8_UNorm, 
        clearBuffer = true, 
        clearColor = Color.black, 
        name = "Output" 
    });

    passData.outputTexture = builder.WriteTexture(output);

    builder.SetRenderFunc((MyRenderPassData data, RenderGraphContext context) => 
    {
        // Rendering Code
    });
}
```

### 示例
我这里以前向渲染下的 Geometry Pass 为例子，大致阐述一下如何将代码转变为 Render Graph 下的 render pass：  

``` C#
public class ForwardGeometryPass : PipelinePass
{
    private class ForwardGeometryPassData
    {
        public TextureHandle colorAttachment;
        public TextureHandle depthAttachment;
        
        public RendererListHandle opaqueRendererList;
        public RendererListHandle alphaTestRendererList;
    }

    public override void OnRecord(ref YPipelineData data)
    {
        using (var builder = data.renderGraph.AddRenderPass<ForwardGeometryPassData>("Draw Opaque & AlphaTest", out var passData))
        {
            var opaqueRendererListDesc = new RendererListDesc(YPipelineShaderTagIDs.k_OpaqueShaderTagIds, data.cullingResults, data.camera)
            {
                rendererConfiguration = PerObjectData.ReflectionProbes | PerObjectData.Lightmaps | PerObjectData.LightProbe,
                renderQueueRange = new RenderQueueRange(2000, 2449),
                sortingCriteria = SortingCriteria.OptimizeStateChanges
            };
            
            var alphaTestRendererListDesc = new RendererListDesc(YPipelineShaderTagIDs.k_OpaqueShaderTagIds, data.cullingResults, data.camera)
            {
                rendererConfiguration = PerObjectData.ReflectionProbes | PerObjectData.Lightmaps | PerObjectData.LightProbe,
                renderQueueRange = new RenderQueueRange(2450, 2499),
                sortingCriteria = SortingCriteria.OptimizeStateChanges
            };
            
            passData.opaqueRendererList = data.renderGraph.CreateRendererList(opaqueRendererListDesc);
            passData.alphaTestRendererList = data.renderGraph.CreateRendererList(alphaTestRendererListDesc);
            builder.UseRendererList(passData.opaqueRendererList);
            builder.UseRendererList(passData.alphaTestRendererList);

            passData.colorAttachment = builder.UseColorBuffer(data.CameraColorAttachment, 0);
            passData.depthAttachment = builder.UseDepthBuffer(data.CameraDepthAttachment, DepthAccess.Read);
            if (data.isSunLightShadowMapCreated) builder.ReadTexture(data.SunLightShadowMap);
            if (data.isSpotLightShadowMapCreated) builder.ReadTexture(data.SpotLightShadowMap);
            if (data.isPointLightShadowMapCreated) builder.ReadTexture(data.PointLightShadowMap);
            
            builder.AllowPassCulling(false);
            builder.AllowRendererListCulling(false);

            builder.SetRenderFunc((ForwardGeometryPassData data, RenderGraphContext context) =>
            {
                context.cmd.SetRenderTarget(data.colorAttachment, RenderBufferLoadAction.DontCare, RenderBufferStoreAction.Store,
                    data.depthAttachment, RenderBufferLoadAction.Load, RenderBufferStoreAction.Store);
                
                context.cmd.DrawRendererList(data.opaqueRendererList);
                context.cmd.DrawRendererList(data.alphaTestRendererList);
                
                context.renderContext.ExecuteCommandBuffer(context.cmd);
                context.cmd.Clear();
            });
        }
    }
}
```

具体细节就不在这里讲了，可以多看看 URP、HDRP 的实现或者官方 API 文档。目前为止的管线转换至 Render Graph 后的 Render Graph Viewer 如下（通过 Window / Analysis / Render Graph Viewer 打开）：  

<div  align="center">  
<img src="https://s2.loli.net/2025/05/22/rh5c6nePRbTN3UM.jpg" width = "50%" height = "50%" alt="图147 - 目前管线的 Render Graph 可视化"/>
</div>

# Light Data Structured Buffers
之前传递灯光相关数据给 GPU 使用的是 constant buffer，并在 constant buffer 通过多个数组存储多个灯光的光照和阴影信息。接下来将改用 structured buffer 来存储这些数据，然而使用 structured buffer 有好处也有坏处，好处就是代码更加简单也更易维护，其次是可以支持巨量的灯光，constant buffer 的大小有一定的限制，想要更多的灯光或者给灯光更多的参数会存在限制并且拉低性能。坏处就是在一定数量的灯光下 structured buffer 的性能是不如 constant buffer 的，特别是手机，并且平台的支持也会减少，但是如果只专注 pc 平台，这些问题其实可以不用考虑，损失的性能可以忽略不计，毕竟要支持更多的灯光。

因为我认为平行光只需要支持一个就行，所以平行光的数据我还是放在了 constant buffer。而 punctual light 中的 point light 和 spot light 相关数据改为了 structured buffer，又因为投射阴影灯光的数量和灯光数量是不一致的，故又将灯光信息和阴影信息分开，灯光信息 point light 和 spot light 共用一个 structured buffer，阴影信息分别使用一个 structured buffer，唯一的问题就是点光源的光源矩阵因为有 6 个面，数量更多，故我为 point light 和 spot light 的光源矩阵都单独开了一个 structured buffer。我下面就只展示灯光信息的那一个 structured buffer 的代码，其他代码因为区别不大，就不重复摘录了。

## Punctual Light Data
### Struct
首先在 C# 代码中添加用于存储 Punctual Light Data 数据的结构体：  

``` C#
using System.Runtime.InteropServices;

[StructLayout(LayoutKind.Sequential)]
private struct PunctualLightStructuredBuffer
{
    public Vector4 punctualLightColors;
    public Vector4 punctualLightPositions;
    public Vector4 punctualLightDirections;
    public Vector4 punctualLightParams;

    public void Setup(YPipelineLightsData lightsData, int index)
    {
        if (lightsData.punctualLightCount > 0)
        {
            punctualLightColors = lightsData.punctualLightColors[index];
            punctualLightPositions = lightsData.punctualLightPositions[index];
            punctualLightDirections = lightsData.punctualLightDirections[index];
            punctualLightParams = lightsData.punctualLightParams[index];
        }
    }
}
```

`[StructLayout(LayoutKind.Sequential)]` 特性是用来控制结构体的布局的，让编译器严格按照在结构体定义中声明字段的顺序，在内存中排列这些字段，同时字段会根据其数据类型的大小和当前运行平台的默认对齐规则进行对齐，通常字段会被对齐到其自身大小的内存地址边界上（例如，一个 int 通常会对齐到 4 字节边界）。这样子做可以保证我们传送到 GPU 的数据布局不发生变化，但其实结构体布局默认就是 LayoutKind.Sequential，理论上来说不加也可以。

然后我们在 Render Graph 的 passData 类中添加上述结构体的数组，以便在 builder.SetRenderFunc 函数中传递给 buffer 并上传 GPU：  

``` C#
private class ForwardLightsPassData
{
    ...
    public PunctualLightStructuredBuffer[] punctualLightsData = new PunctualLightStructuredBuffer[k_MaxPunctualLightCount];
    ...
}
```

记录数据的过程就不放了，没什么好说的。

### Graphics Buffer
在 CPU 中使用的是 Graphics Buffer 或 Compute Buffer API 对应 GPU 中的各种 Buffer，我们需要使用 `CommandBuffer.SetBufferData()` 将数据上传至 GPU，当然首先要创建 Render Graph 的 BufferHandle，同时注册为资源写入：  

``` C#
public override void OnRecord(ref YPipelineData data)
{
    ...
    data.PunctualLightBufferHandle = data.renderGraph.CreateBuffer(new BufferDesc()
    {
        count = k_MaxPunctualLightCount,
        stride = 16 * 4,
        target = GraphicsBuffer.Target.Structured,
        name = "Punctual Lights Data"
    });
    passData.punctualLightsBuffer = builder.WriteBuffer(data.PunctualLightBufferHandle);
    ...

    builder.SetRenderFunc((ForwardLightsPassData data, RenderGraphContext context) => {...});
}
```

有资源写入，自然也需要资源读取，我们要在 Geometry Pass 中添加资源读取，这里我就不摘抄了。然后就是在 `builder.SetRenderFunc` 中传递数据，然后绑定资源：  

``` C#
builder.SetRenderFunc((ForwardLightsPassData data, RenderGraphContext context) =>
{
    context.cmd.SetBufferData(data.punctualLightsBuffer, data.punctualLightsData, 0, 0, data.punctualLightsCount);
    context.cmd.SetGlobalBuffer(YPipelineShaderIDs.k_PunctualLightDataID, data.punctualLightsBuffer);
}
```

### Shader
Shader 里 Structured Buffer 如下：

    struct PunctualLightData
    {
        float4 punctualLightColors; // xyz: light color * intensity, w: light type (point 1, spot 2)
        float4 punctualLightPositions; // xyz: light position, w: shadowing spot/point light index (non-shadowing is -1)
        float4 punctualLightDirections; // xyz: spot light direction
        float4 punctualLightParams; // x: 1.0 / light range square, y: range attenuation scale, z: invAngleRange, w: cosOuterAngle
    };

    StructuredBuffer<PunctualLightData> _PunctualLightData;

    float3 GetPunctualLightColor(int lightIndex)                { return _PunctualLightData[lightIndex].punctualLightColors.xyz; }
    float GetPunctualLightType(int lightIndex)                  { return _PunctualLightData[lightIndex].punctualLightColors.w; }
    float3 GetPunctualLightPosition(int lightIndex)             { return _PunctualLightData[lightIndex].punctualLightPositions.xyz; }
    float GetShadowingLightIndex(int lightIndex)                { return _PunctualLightData[lightIndex].punctualLightPositions.w; }
    float3 GetSpotLightDirection(int lightIndex)                { return _PunctualLightData[lightIndex].punctualLightDirections.xyz; }
    float GetPunctualLightInverseRangeSquare(int lightIndex)    { return _PunctualLightData[lightIndex].punctualLightParams.x; }
    float GetPunctualLightRangeAttenuationScale(int lightIndex) { return _PunctualLightData[lightIndex].punctualLightParams.y; }
    float2 GetSpotLightAngleParams(int lightIndex)              { return _PunctualLightData[lightIndex].punctualLightParams.zw; }
    float GetSpotLightInverseAngleRange(int lightIndex)         { return _PunctualLightData[lightIndex].punctualLightParams.z; }
    float GetSpotLightCosOuterAngle(int lightIndex)             { return _PunctualLightData[lightIndex].punctualLightParams.w; }


这样子就改好了，Shadow 相关的 Structured Buffers 的逻辑也是类似的，全部完成后 Render Graph Viewer 就多了如下：  

<div  align="center">  
<img src="https://s2.loli.net/2025/06/04/1YIFXOPstEHNRnx.jpg" width = "50%" height = "50%" alt="图148 - Structured Buffer 在 Render Graph 中的生命周期"/>
</div>

# Simple Tiled Forward+
我们之前计算光照时，是逐像素（z-prepass 下）遍历所有光源进行计算的，但是场景中有大量灯光时，这种粗暴遍历所有光源会导致巨大的性能开销，很多时候是不可以接受的。这也是灯光剔除相关技术出现的原因，比如 **Tile-based Light Culling** 和 **Cluster-based Light Culling**，这些技术无论 Forward 还是 Deferred 渲染都可以使用，故被称为 **Forward+** 或者 **Deferred+**。

Tile-based Light Culling 的方案比较多，该技术也是在过去一直被不断改进的。这里先根据 catlikecoding 教程实现一个非常简单的 Tile-based Light Culling（只基于屏幕做相交测试，不基于深度），之后在后面的文章中实现剔除粒度更高的 Tile-based Light Culling。

Tile-based Light Culling 的总体思路是，将屏幕分割成许许多多的小格子，即 **tile**，然后针对每个格子做光源剔除，为每个格子存储一个可见光的列表。然后在 shading 阶段，我们只要判断当前像素属于哪个格子，仅与当前格子的灯光列表做光照计算即可。Culling 的过程可以在 CPU 做，即通过 Job System 多线程，也可以在 GPU 做，即通过 Compute Shader。教程里跟 URP 一样是使用 Job System 进行 Culling 的，毕竟要照顾到更多的设备，我下面改为了 Compute Shader 实现。

> Compute Shader 的基础知识可以看这篇文章：https://zhuanlan.zhihu.com/p/368307575 。

我先创建了如下场景，方便后面进行对比（我把 light attenuation 都开小了，方便观测光照影响范围），里面有 1 盏平行光源、9 盏点光源、17 盏聚光灯，每帧大概 4.1 ms：  

<div  align="center">  
<img src="https://s2.loli.net/2025/06/04/AUh2ac4r7lGyzbo.jpg" width = "70%" height = "70%" alt="图149 - Tile-based Light Culling 前"/>
</div>

## 简单实现
### CPU 中的工作
首先我们需要一个 Structured Buffer 来存储每个 tile 里的灯光索引，并且每个 tile 都包含一个 header，用于存储每个 tile 里有多少个灯光，每个 tile 能够存储的灯光数量是固定的，故这个 Structured Buffer 的大小应该为每个 tile 最大灯光数量加上 1 后乘以 tile 的数量。我这里设置每个 tile 最大灯光数量为 32 个，因此每个 tile 的数据大小为 33，同时设定每个 tile 的大小为 16 × 16，最大支持的 punctual light 的数量也改为了 256（这个数字跟每个 tile 的大小以及 Compute Shader 有一定的关系，后面会讲）：  

``` C#
public const int k_MaxPunctualLightCount = 256;

public const int k_MaxLightCountPerTile = 32
public const int k_PerTileDataSize = k_MaxLightCountPerTile + 1; // 1 for the header (light count)
public const int k_TileSize = 16;
```

然后创建上述 Structured Buffer：

``` C#
public override void OnRecord(ref YPipelineData data)
{
    using (RenderGraphBuilder builder = data.renderGraph.AddRenderPass<TiledLightCullingPassData>("Tiled Based Light Culling", out var passData))
    {
        ...
        data.TilesLightIndicesBufferHandle = data.renderGraph.CreateBuffer(new BufferDesc()
        {
            count = tileCount * YPipelineLightsData.k_PerTileDataSize,
            stride = 4,
            target = GraphicsBuffer.Target.Structured,
            name = "Tiled Light Indices Buffer"
        });
        passData.tilesLightIndicesBuffer = builder.WriteBuffer(data.TilesLightIndicesBufferHandle);
        ...
    }
}
```

与此同时，我们需要传递每个灯光在屏幕空间的影响范围，方便与 tile 求交，VisibleLight 的 `screenRect` 字段提供了灯光在屏幕中的 uv 边界，我们可以直接拿来使用，这是一个非常保守的 bounding box，这里先使用着，后面的文章中这一块应该会得到更好的处理：  

``` C#
private void RecordLightsData(ref YPipelineData data)
{
    ...
    for (int i = 0; i < visibleLights.Length; i++)
    {
        ...
        else if (visibleLight.lightType == LightType.Point)
        {
            ...
            Rect bound = visibleLight.screenRect;
            data.lightsData.lightsBound[punctualLightCount] = new Vector4(bound.xMin, bound.yMin, bound.xMax, bound.yMax);
            ...
        }
        else if (visibleLight.lightType == LightType.Spot)
        {
            ...
            Rect bound = visibleLight.screenRect;
            data.lightsData.lightsBound[punctualLightCount] = new Vector4(bound.xMin, bound.yMin, bound.xMax, bound.yMax);
            ...
        }
        ...
    }
}
```

知道了灯光的影响范围，我们还要让 GPU 知道每个 tile 的影响范围，所以我们还要传递 tile 的相关参数到 GPU，和 lightsBound 的 buffer 准备如下：  

``` C#
passData.lightsBound = data.lightsData.lightsBound;

passData.lightsCullingInputBuffer = builder.CreateTransientBuffer(new BufferDesc()
{
    count = YPipelineLightsData.k_MaxPunctualLightCount,
    stride = 4 * sizeof(float),
    target = GraphicsBuffer.Target.Structured,
    name = "Lights Culling Input Buffer"
});

float pixelToTileX = data.BufferSize.x / (float) YPipelineLightsData.k_TileSize;
float pixelToTileY = data.BufferSize.y / (float) YPipelineLightsData.k_TileSize;
passData.tileCountXY = new Vector2Int(Mathf.CeilToInt(pixelToTileX), Mathf.CeilToInt(pixelToTileY));
int tileCount = passData.tileCountXY.x * passData.tileCountXY.y;
passData.tileUVSize = new Vector2(1.0f / pixelToTileX, 1.0f / pixelToTileY);
```

最后将上述所有数据上传到 GPU：  

``` C#
builder.SetRenderFunc((TiledLightCullingPassData data, RenderGraphContext context) =>
{
    int kernel = data.cs.FindKernel("TiledLightCulling");
    context.cmd.SetBufferData(data.lightsCullingInputBuffer, data.lightsBound);
    context.cmd.SetComputeBufferParam(data.cs, kernel, YPipelineShaderIDs.k_LightsCullingInputBufferID, data.lightsCullingInputBuffer);
    
    context.cmd.SetGlobalVector(YPipelineShaderIDs.k_TileParamsID, new Vector4(data.tileCountXY.x, data.tileCountXY.y, data.tileUVSize.x, data.tileUVSize.y));
    context.cmd.SetGlobalBuffer(YPipelineShaderIDs.k_TilesLightIndicesBufferID, data.tilesLightIndicesBuffer);
    context.cmd.DispatchCompute(data.cs, kernel, data.tileCountXY.x, data.tileCountXY.y, 1);
    
    context.renderContext.ExecuteCommandBuffer(context.cmd);
    context.cmd.Clear();
});
```

### Compute Shader
因为屏幕按照每个 tile 16 × 16 进行了划分，故 Compute Shader 的线程数量也选择为了 16 × 16 × 1，这里这么选择是因为原本 Tiled Light Culling 还需要跟深度进行求交，需要用 tile 里的每个像素采样 depth texture 获取最大最小深度值，但这里实现的是简单的 Tiled Light Culling 只跟屏幕上的 2d 方块求交，故这么设置暂时没什么必要，但先这么做。

线程数量为 16 × 16 × 1，那么每个线程组即代表一个 tile，这也是为什么上面代码中 `DispatchCompute` 中将传递线程组数量的参数设置为了 tile 的数量。之后求交的时候，每个线程都代表一个灯光，跟当前 tile 求交（即当前线程组），这也是为什么最大 punctual light 数量为 256 个，因为是 16 × 16，一个 tile 最多可以跟 256 个灯光求交（当然也可以用 for 循环支持更多灯光求交）。求交完了，就记录灯光索引至 TilesLightIndicesBuffer。全部代码如下：  

    #pragma kernel TiledLightCulling

    #define THREAD_NUM_X 16 // equal to per tile size
    #define THREAD_NUM_Y 16

    #include "../../ShaderLibrary/Core/YPipelineCSCore.hlsl"

    StructuredBuffer<float4> _LightsCullingInputBuffer;
    RWStructuredBuffer<uint> _TilesLightIndicesBuffer;
    float4 _TileParams; // xy: tileCountXY, zw: tileUVSizeXY

    groupshared uint lightCountInTile;
    groupshared uint lightIndicesInTile[MAX_PUNCTUAL_LIGHT_COUNT];

    [numthreads(THREAD_NUM_X, THREAD_NUM_Y, 1)]
    void TiledLightCulling(uint3 id : SV_DispatchThreadID, uint3 groupThreadId : SV_GroupThreadID, uint3 groupId : SV_GroupID, uint groupIndex : SV_GroupIndex)
    {
        if (groupIndex == 0)
        {
            lightCountInTile = 0;
        }

        GroupMemoryBarrierWithGroupSync();
        
        float4 tileBound = float4(groupId.x, groupId.y, groupId.x + 1, groupId.y + 1) * _TileParams.zwzw;
        float4 lightBound = _LightsCullingInputBuffer[groupIndex];

        // Intersect
        if ((lightBound.x < tileBound.z) && (lightBound.y < tileBound.w) && (tileBound.x < lightBound.z) && (tileBound.y < lightBound.w))
        {
            uint offset;
            InterlockedAdd(lightCountInTile, 1, offset);
            lightIndicesInTile[offset] = groupIndex;
        }
        
        GroupMemoryBarrierWithGroupSync();

        uint headerIndex = (groupId.y * _TileParams.x + groupId.x) * (MAX_LIGHT_COUNT_PER_TILE + 1);
        uint minLightCount = min(lightCountInTile, MAX_LIGHT_COUNT_PER_TILE);

        UNITY_BRANCH
        if (groupIndex == 0)
        {
            _TilesLightIndicesBuffer[headerIndex] = lightCountInTile;
        }
        else
        {
            if (groupIndex - 1 < minLightCount) _TilesLightIndicesBuffer[headerIndex + groupIndex] = lightIndicesInTile[groupIndex - 1];
        }
    }

> Interlocked 原子操作和 `GroupMemoryBarrierWithGroupSync()` 进行组内线程同步的相关 Compute Shader 异步知识这里不阐述了，后面的详细的 Tile-based Light Culling 的文章中会讲解。

因为 TilesLightIndicesBuffer 要存储每个 tile（每个线程组）中相交灯光的个数，故使用组共享内存即 `groupshared` 变量。同时灯光个数是由每个线程加记的，为了防止线程读写冲突，需要使用原子操作中的加法 `InterlockedAdd`，最后使用 `GroupMemoryBarrierWithGroupSync()` 同步组内共享内存写入，之后才能读取 groupshared 变量存储到 TilesLightIndicesBuffer 中。

第一个 `GroupMemoryBarrierWithGroupSync()` 前的代码是为了初始化 groupshared 变量，防止不同线程组（tile）之间的数据污染。第二个 `GroupMemoryBarrierWithGroupSync();` 之前的代码即 AABB 相交测试，测试通过则记录灯光数量以及灯光索引。后面的代码就是将数据存储到 TilesLightIndicesBuffer 中。


### Shading
在 Computer Shader 计算完了后，就可以根据着色点所在屏幕 uv 坐标，来判断着色点位于哪个 tile，来获取该 tile 中的灯光索引进行灯光计算：  

    struct LightsTileParams
    {
        int tileIndex;
        int headerIndex;
        int lightCount;
        int lastLightIndex;
    };

    void InitializeLightsTileParams(out LightsTileParams lightsTileParams, float2 pixelCoord)
    {
        uint2 coord = floor(pixelCoord * _CameraBufferSize.xy / _TileParams.zw);
        lightsTileParams.tileIndex = coord.y * (int) _TileParams.x + coord.x;
        lightsTileParams.headerIndex = lightsTileParams.tileIndex * (MAX_LIGHT_COUNT_PER_TILE + 1);
        lightsTileParams.lightCount = _TilesLightIndicesBuffer[lightsTileParams.headerIndex];
        lightsTileParams.lastLightIndex = lightsTileParams.headerIndex + lightsTileParams.lightCount;
    }

然后在像素着色器中循环计算，类似如下：  

    LightsTileParams lightsTileParams = (LightsTileParams) 0;
    InitializeLightsTileParams(lightsTileParams, IN.positionHCS.xy);
    
    for (int i = lightsTileParams.headerIndex + 1; i <= lightsTileParams.lastLightIndex; i++)
    {
        uint lightIndex = _TilesLightIndicesBuffer[i];
        
        LightParams punctualLightParams = (LightParams) 0;
        
        UNITY_BRANCH
        if (GetPunctualLightType(lightIndex) == SPOT_LIGHT) InitializeSpotLightParams(punctualLightParams, lightIndex, standardPBRParams.V, normalize(IN.normalWS), IN.positionWS, IN.positionHCS.xyz);
        else if (GetPunctualLightType(lightIndex) == POINT_LIGHT) InitializePointLightParams(punctualLightParams, lightIndex, standardPBRParams.V, normalize(IN.normalWS), IN.positionWS, IN.positionHCS.xyz);
    
        BRDFParams punctualBRDFParams = (BRDFParams) 0;
        InitializeBRDFParams(punctualBRDFParams, standardPBRParams.N, punctualLightParams.L, standardPBRParams.V, punctualLightParams.H);
    
        renderingEquationContent.directPunctualLights += CalculateLightIrradiance(punctualLightParams) * StandardPBR_EnergyCompensation(punctualBRDFParams, standardPBRParams, energyCompensation);
    }

这样子就完成了一个简单的 Tile-based Light Culling，本章开头的测试场景重新测试如下，可以看到帧率上升了，每帧变为了 3.0 ms：  

<div  align="center">  
<img src="https://s2.loli.net/2025/06/04/VqS2n8WZCtPEigk.jpg" width = "70%" height = "70%" alt="图150 - Tile-based Light Culling 后"/>
</div>

## Debug
为更加直观地看到每个 tile 包含了多少个灯光，我们可以添加一个 debug 功能，可以利用 Unity 的 Rendering Debugger 的相关功能，Rendering Debugger 通过 Window / Analysis / Rendering Debugger 打开，除了编辑器中，在 development build 也可以通过快捷键 <kbd>LeftCtrl</kbd> + <kbd>Backspace</kbd> 打开。

<div  align="center">  
<img src="https://s2.loli.net/2025/06/05/V3GW5sFn2Cbx7rk.jpg" width = "55%" height = "55%" alt="图151 - 添加 Light Culling 功能后的 Rendering Debugger"/>
</div>

### Debug Settings
先要为 Rendering Debugger 的参数以及 Panel 的显示做准备工作，我创建了一个 LightingDebugSettings 类专门处理相关工作。首先该类需要一个 bool 参数用于控制是否显示 tile，即上图中的 show light tiles，以及控制 tile 的可见程度的参数，即上图中的 tile opacity，同时还需要用于显示 tile 的材质：  

``` C#
public bool showLightTiles;
public float tileOpacity = 0.5f;

private const string k_LightCullingDebug = "Hidden/YPipeline/Debug/LightCullingDebug";
public Material lightCullingDebugMaterial;
```

然后创建一个 `Initialize()` 方法，用于创建 material 和 Rendering Debugger 的 panel。创建 panel 使用 `DebugManager.instance.GetPanel` API：  

``` C#
public void Initialize()
{
    lightCullingDebugMaterial = CoreUtils.CreateEngineMaterial(k_LightCullingDebug);
    
    DebugManager.instance.GetPanel(k_PanelName, true, 0).children.Add(
        new DebugUI.RuntimeDebugShadersMessageBox(),
        new DebugUI.Foldout
        {
            displayName = "Light Culling",
            opened = false,
            children =
            {
                new DebugUI.BoolField
                {
                    displayName = "Show Light Tiles",
                    tooltip = "Whether the light tiles overlay is shown.",
                    getter = () => showLightTiles,
                    setter = value => showLightTiles = value
                },
                new DebugUI.FloatField
                {
                    displayName = "Tile Opacity",
                    tooltip = "Opacity of the overlay.",
                    min = () => 0f,
                    max = () => 1f,
                    getter = () => tileOpacity,
                    setter = value => tileOpacity = value
                },
            }
        }
    );
}
```

然后在 `Dispose()` 方法中 remove panel：  

``` C#
public void OnDispose()
{
    CoreUtils.Destroy(lightCullingDebugMaterial);
    DebugManager.instance.RemovePanel(k_PanelName);
}
```

`Initialize()` 和 `Dispose()` 的调用的地方就在 RenderPipeline 里，这样就可以呈现出上图中 Rendering Debugger 内的样子。

### Debug Pass
我们要为 Debug 创建一个单独的 Pipeline Pass，就不详细讲了，代码如下：  

``` C#
#if UNITY_EDITOR || DEVELOPMENT_BUILD
    public class DebugPass : PipelinePass
    {
        private class DebugPassData
        {
            public Material lightCullingDebugMaterial;
            public bool showLightTiles;
            public float tileOpacity;
        }

        protected override void Initialize()
        {
            
        }

        public override void OnRecord(ref YPipelineData data)
        {
            using (RenderGraphBuilder builder = data.renderGraph.AddRenderPass<DebugPassData>("Debug (Editor)", out var passData))
            {
                passData.lightCullingDebugMaterial = data.debugSettings.lightingDebugSettings.lightCullingDebugMaterial;
                passData.showLightTiles = data.debugSettings.lightingDebugSettings.showLightTiles;
                passData.tileOpacity = data.debugSettings.lightingDebugSettings.tileOpacity;
                
                builder.SetRenderFunc((DebugPassData data, RenderGraphContext context) =>
                {
                    if (data.showLightTiles)
                    {
                        data.lightCullingDebugMaterial.SetFloat(LightingDebugSettings.k_TilesDebugOpacityID, data.tileOpacity);
                        context.cmd.DrawProcedural(Matrix4x4.identity, data.lightCullingDebugMaterial, 0, MeshTopology.Triangles, 3);
                    }
                    
                    context.renderContext.ExecuteCommandBuffer(context.cmd);
                    context.cmd.Clear();
                });
            }
        }
    }
#endif
```

上述 Pass 最好放在最后的 GizmosPass 的前面。

### Debug Shader
我们为 tile 显示效果添加一个 shader 用于绘制：  

    Shader "Hidden/YPipeline/Debug/LightCullingDebug"
    {
        SubShader
        {
            Tags { "RenderType"="Opaque" }
            
            ZTest Always
            ZWrite Off
            Cull Off

            Pass
            {
                Name "Light Culling Debug"
                
                Blend SrcAlpha OneMinusSrcAlpha
                
                HLSLPROGRAM
                #pragma target 2.0
                
                #pragma vertex Vert
                #pragma fragment Frag

                #include "LightCullingDebugPass.hlsl"
                ENDHLSL
            }
        }
    }

注意要 Blend SrcAlpha OneMinusSrcAlpha，因为我们需要 tileOpacity 参数控制透明度。顶点着色器跟 copy shader 一样就是全屏三角形，就不重复摘抄了，像素着色器中首先要计算 tile 的边缘：  

    float4 Frag(Varyings IN) : SV_TARGET
    {
        uint2 tileCoord = floor(IN.uv / _TileParams.zw);
        float2 startUV = tileCoord * _TileParams.zw;
        bool IsMinimumEdgePixel = any(IN.uv - startUV < _CameraBufferSize.xy);
        
        float3 color;
        if (IsMinimumEdgePixel) color = 1.0;
        else color = 0.0;
        
        return float4(color, _TilesDebugOpacity);
    }

<div align="center">  
<img src="https://s2.loli.net/2025/06/05/tkZUuPl1QsNfR9W.jpg" width = "70%" height = "70%" alt="图152 - screen 中每个 tile"/>
</div>

然后显示出每个 tile 中有多少个灯光，好在 Core RP library 中的 Debug.hlsl 提供了相关方法 `OverlayHeatMap()`，直接调用即可：  

    ...
    int tileIndex = tileCoord.y * (int) _TileParams.x + tileCoord.x;
    int headerIndex = tileIndex * (MAX_LIGHT_COUNT_PER_TILE + 1);
    int lightCount = _TilesLightIndicesBuffer[headerIndex];

    float3 color;
    if (IsMinimumEdgePixel) color = 1.0;
    else color = OverlayHeatMap(IN.uv * _CameraBufferSize.zw, _CameraBufferSize.zw * _TileParams.zw, lightCount, MAX_LIGHT_COUNT_PER_TILE, 1.0).rgb;
    ...

最后显示如下：  

<div align="center">  
<img src="https://s2.loli.net/2025/06/05/SgFcv9elpoOKi6x.jpg" width = "70%" height = "70%" alt="图152 - screen 中每个 tile 中的灯光数量"/>
</div>

因为 tile 比较小，数字可能需要放大才能看清楚。从图中可以看出，虽然剔除了部分灯光，但即使光源完全照不到的地方仍然没有剔除干净，这就是上述的 simple tiled light culling 没解决的问题，在后面的文章中解决。但即使这样，也可以感受到该技术对性能的提升，这给了我们进一步优化的动力。

# Upgrade Code For Unity 6


# 后记
