---
title: MIT 线性代数公开课笔记（二）
date: 2024-02-18 13:52:33
categories: 
  - [数学, 3d数学基础]
  - [数学, 线性代数]
tags:
  - 游戏开发
  - 数学
  - 线性代数
top_img: /images/black.jpg
cover: https://s2.loli.net/2024/02/18/6rKVn5pm3sXlxS8.gif
mathjax: true
---

> 该笔记主要内容为XXXXXXXXXXXXX；
> 该笔记主要参考了 MLNLP 的关于该公开课的 GitHub 公开项目的笔记：<https://github.com/MLNLP-World/MIT-Linear-Algebra-Notes>  
> 公开课 B 站 bv 号：BV16Z4y1U7oU


# 第十四课 正交向量与正交子空间

<div  align="center">  
<img src="https://s2.loli.net/2024/02/18/iwvTI9XHNrf4QjB.png" width = "60%" height = "60%" alt="图4 - 四个子空间的关系"/>
</div>

## 向量正交
**正交 Orthogonal **就是**垂直 perpendicular** 的另一种说法。两向量正交的判据之一是其点积 $\,x^Ty = y^Tx = 0\,$。

可以根据勾股定理（毕达哥拉斯定理 Pythagorean theorem）推出上述判断，当两个向量的夹角为 90 度时，x，y 满足：  

$$ |x|^2 + |y|^2 = |x + y|^2 $$

其中 $\,|x|^2 = x^Tx\,$（x 为 列向量），可得：

$$ x^Tx + y^Ty = (x + y)^T(x + y) = x^Tx + y^Ty + x^Ty + y^Tx$$

可得 $\,x^Ty + y^Tx = 0\,$，因 $\,x^Ty\,$ 与 $\,y^Tx\,$ 其实是一样的，都表示两个一维向量的点乘，故若两个向量正交，则 $\,x^Ty = y^Tx = 0\,$。

> 零向量与所有向量都正交。

## 子空间正交
**两个子空间正交**就是：**一个子空间中的任意一个向量，都与另一个子空间中的任意一个向量正交。**

在三维空间中，假设世界原点为黑板和地板交接处的一点，黑板所在的平面（子空间）和地板所在平面（子空间）不是正交关系，沿两者的交线方向的向量同时属于两个平面，但并不与自己正交。即两个平面在某一非零向量处相交，那这两个平面一定不正交，因为相交处的这个非零向量无法满足空间正交定义。

再从子空间角度看一看正交空间，以 $\,R^2\,$ 的子空间为例，一个平面上的子空间有三种：  
①整个平面 D；  
②过原点的直线 L；  
③原点 O。

看一看这些子空间之间的正交，以 L 为例：  
①L 与 D 什么时候正交？  
一个平面上的直线不可能与这个平面垂直；  
②L 什么时候与 O 正交？  
L 与 O 永远是正交的；  
③L 什么时候与另一个 L 正交？  
由正交的定义，两条直线在原点处互相垂直，这两个 L 空间才正交。

## 零空间与行空间的正交关系 
零空间与行空间之间是正交的，得到这个结论并不难，我们把 A 写成行向量形式，再看 Ax = 0 这个方程：  

$$ \begin{bmatrix} R_1 \\ R_2 \\ ... \\ ... \\ R_m \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \\ ... \\ ... \end{bmatrix} = \begin{bmatrix} R_1(x_1, x_2, ...) \\ R_2(x_1, x_2, ...) \\ ... \\ ... \\ R_m(x_1, x_2, ...) \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \\ ... \\ ... \\ 0 \end{bmatrix} $$

x 与矩阵 A 的行向量点积都等于 0，则它和矩阵 A 行向量的线性组合进行点积也为 0，所以 x 与 A 的行空间正交。x 为零空间内的任意向量，所以零空间与行空间正交。同理可以证明列空间与左零空间正交。

---

行空间和零空间类似于把 $\,R^n\,$ 空间分割成了两个正交的子空间。例如对于矩阵：$\,A = \begin{bmatrix} 1 & 2 & 5 \\ 2 & 4 & 10 \end{bmatrix}\,$，其行空间是 1 维的，向量 (1, 2, 5) 是它的基向量，而其零空间是垂直于 (1, 2, 5) 并穿过原点的二维平面。行空间和零空间不仅仅是正交，并且其维数之和等于 n，我们称行空间和零空间为 $\,R^n\,$ 空间内的**正交补 orthogonal complements**。这表示零空间包含所有和行空间正交的向量，反之亦然。

> 想想我们之前提到的黑板和地板平面不是正交子空间的例子，二者都在三维空间中，分别为二维空间，因此不可能正交。一个空间中正交子空间的维数之和不可能超过原空间的维数。

## 无解方程的最优解
下面讨论如何求解一个无解方程组 Ax = b 的解（引出下一节的内容）。矩阵的数据来源于实际测量，那么就势必会有测量不准确的时候，如果 A 是长方形矩阵，m 大于 n。当左侧方程数特别多的时候，容易混入“坏”数据，方程变得无解。但是对于数据的可信度我们无从判断，线性代数要做的就是在这种条件下求一个方程的“最优解”。矩阵 $\,A^TA\,$ 会发挥重要作用，它是一个 n x n 方阵，并且是对称矩阵。

将方程改写成：$\,A^TA \hat {x} = A^Tb\,$，即求解 $\,\hat {x}\,$ 这个最优解。我们利用了 $\,A^TA\,$ 矩阵的特殊性质如下：  
①设 A 为 m × n 矩阵，则 $\,A^TA\,$ 为 n × n 矩阵；  
②$\,A^TA\,$，总为对称矩阵。$\,(A^TA)^T = A^TA\,$，故 $\,A^TA\,$ 总是对称的。

有一点需要注意，$\,A^TA\,$ 矩阵不一定总是可逆的，所以在求解时要注意 A 的特点。很明显，当 A 矩阵列向量线性相关时候，$\,A^TA\,$ 就不可逆了。因此若要 $\,A^TA\,$ 矩阵可逆，则要求 A 的零空间只有零向量，即 A 的列向量线性无关。


# 第十五课 子空间投影
这节主要讲**投影 projection**，从向量的投影入手，延伸到高维投影，并将投影用矩阵形式给出。做投影即是向另一个向量上做垂线，跟上节课的正交有联系。

## 向量投影

<div  align="center">  
<img src="https://s2.loli.net/2024/02/19/xU4EQOj73XNgM2F.jpg" width = "50%" height = "50%" alt="图5 - 向量投影"/>
</div>

投影问题的几何解释就是：如何在向量 a 的方向上寻找与向量 b 距离最近的一点。从图中可以看出，这个距离最近的点 p 就位于穿过 b 点并与向量 a 正交的直线与向量 a 所在直线的交点，即 b 在 a 上的投影。

> 如果我们将向量 p 视为 b 的一种近似，则长度 e = b - p 就是这一近似的误差。

因为 p 在向量 a 的方向上，因此可以令 p = xa，而因为它和 e 正交，我们可以得到方程：  

$$ a^Te = a^T(b - p) = a^T(b - xa) = 0 $$

可得：  

$$ x = \frac {a^Tb} {a^Ta}, p = xa = a \frac {a^Tb} {a^Ta} $$

如果 b 变为原来的 2 倍，则 p 也变为原来的 2 倍。而如果 a 变为原来的 2 倍，p 不发生变化。从几何上和计算中都会得到验证。

## 投影矩阵
接下来我们将投影问题用投影矩阵的方式进行描述，即 $\,p = Pb\,$，其中 $\,P\,$ 为投影矩阵。

根据 $\,p = xa = a \frac {a^Tb} {a^Ta}\,$，可知 $\,P = \frac {aa^T} {a^Ta}\,$，注意当 a 是列向量时，分母 $\,a^Ta\,$ 是一个数，分子 $\,aa^T\,$ 是一个矩阵。

观察这个矩阵可知，因为 a 是列向量，$\,aa^T\,$ 得到的必然是秩一矩阵，矩阵 P 的列空间就是向量 a 所在的直线，矩阵 P 的秩为 1。同样，投影矩阵 P 是一个对称矩阵，即 $\,P^T = P\,$；另一方面，如果投影两次，第二次投影还在原来的位置，即 $\,P^2 = P\,$。

## Why Project
如上一节结尾所述，方程 Ax = b 有可能无解，我们需要得到方程的“最优解”。这里的问题在于向量 Ax 一定在矩阵 A 的列空间之内，但是 b 不一定，因此我们希望将 b 投影到 A 的列空间得到 p，将问题转化为 $\,A\hat {x} = p\,$。

## 平面投影

<div  align="center">  
<img src="https://s2.loli.net/2024/02/19/7uG81TXxNLzUKnQ.jpg" width = "50%" height = "50%" alt="图6 - 平面投影"/>
</div>

$\,a_1\,$，$\,a_2\,$ 构成平面的一组基，平面是矩阵 $\,A = \begin{bmatrix} a_1 & a_2\end{bmatrix}\,$ 的列空间。

p 在平面上，即 $\,p = \hat {x_1} a_1 + \hat {x_2} a_2\,$，即 $\,p = A\hat {x}\,$。

而 $\,e = b - p = b - A \hat {x}\,$ 与投影平面正交，也就是 $\,e\,$ 与 $\,a_1\,$ 和 $\,a_2\,$ 均正交，可得 $\,a_1^T(b - A \hat {x}) = 0\,$ 和 $\,a_2^T(b - A \hat {x}) = 0\,$。

因为 $\,a_1\,$ 和 $\,a_2\,$ 分别为矩阵 A 的列向量，即 $\,a_1^T\,$ 和 $\,a_2^T\,$ 为矩阵 $\,A^T\,$ 的行向量，所以将两个方程式写成矩阵形式即为 $\,A^T(b - A \hat {x}) = 0\,$，这与一维投影的方程形式相同，一维投影只是 A 只有一列的情况下。

$\,A^T(b - A \hat {x}) = 0\,$ 这个公式说明了，向量 $\,e = b - A \hat {x}\,$ 存在于矩阵 $\,A^T\,$ 的零空间 $\,N(A^T)\,$ ，即 e 向量与 $\,A^T\,$ 的行向量正交，也就与 A 的列向量正交。

--- 

将方程 $\,A^T(b - A \hat {x}) = 0\,$ 改写，可得 $\,A^TA \hat {x} = A^Tb\,$，也就是上一节结尾的公式。

我们要注意一点：不能直接在两边左乘 $\,(A^T)^{-1}\,$。因为 $\,A^T\,$ 不一定是方阵，不一定有逆矩阵。但是这里 A 为两个基向量构成的矩阵，两个基向量线性无关，根据上节的知识，$\,A^TA\,$是可逆的。在两侧同时左乘 $\,(A^TA)^{-1}\,$：

$$ \hat x = (A^TA)^{-1} A^T b $$

代入 $p = A \hat {x}$：  

$$ p = A \hat x = A(A^TA)^{-1} A^T b $$

即投影矩阵为：  

$$ P =  A(A^TA)^{-1} A^T $$

可以看出，之前一维的 $\,P = \frac {aa^T} {a^Ta}\,$ 是上式的特殊情况。

因为矩阵 A 不是方阵，无法简单地用 $\,(A^TA)^{-1} = A^{-1}(A^T)^{-1}\,$ 对投影矩阵进行化简。若 A 是可逆方阵，则化简得到 P = I。此时 A 的列空间就是整个 $\,R^n\,$ 空间，b 到这个空间的投影就是其本身，投影矩阵等于单位阵。

对 $\,P =  A(A^TA)^{-1} A^T\,$ 用矩阵乘法的结合律和矩阵乘积的转置公式，可以证明投影矩阵的性质：$\,P^T = P\,$，$\,P^2 = P\,$。

## 最小二乘法 Least Squares 初涉
应用投影矩阵求方程组最优解的方法，最常用于“最小二乘法”拟合曲线。

例如：求解三个点（1，1），（2,2），（3，2）拟合的直线方程

我们假设最优直线方程：b = C + Dt，代入三个点列出方程。

$$ C + D = 1 $$
$$ C + 2D = 2 $$
$$ C + 3D = 2 $$

矩阵形式为：

$$ \begin{bmatrix} 1 & 1 \\ 1 & 2 \\ 1 & 3 \end{bmatrix} \begin{bmatrix} C \\ D \end{bmatrix} = \begin{bmatrix} 1 \\ 2 \\ 2 \end{bmatrix} $$

这个的方程 Ax = b 是无解的，解决办法就是求其最优解，即方程 $\,A^TA \hat {x} = A^Tb\,$ 的解。

最小二乘法下节还会详述。


# 第十六课 投影矩阵和最小二乘法
## 投影矩阵回顾
上一节中介绍过投影矩阵 P，即：  

$$ P = A(A^TA)^{-1}A^T $$

投影矩阵 P 与一向量 b 的乘积可以理解为：将 b 向量投影到它在列空间中的最近一点上，类似于上节课中，将 p 投影到平面上的过程。

两个问题：  

①如果 b 在矩阵 A 的列空间里，则 Pb = ？  

此时 Pb = b，因为 b 本身就在 A 列空间中。b 在 A 的列空间里，就一定可以写成：$\,Ax = b\,$。代入投影矩阵：$\,A(A^TA)^{-1}A^TAx = A(A^TA)^{-1}(A^TA)x = Ax = b\,$

②如果 b 垂直于 A 的列空间，则 Pb = ？
此时 Pb = 0，此时没有投影。b 垂直于 A 的列空间，也就垂直于 A 的所有列向量，故 b 在左零空间中，即 $\,A^Tb = 0\,$。代入投影矩阵：$\,A(A^TA)^{-1}A^Tb = A(A^TA)^{-1}0 = 0\,$

通过上面两个问题，我们可以看出来，一个向量 b 总有两个分量，一个分量在 A 的列空间中，另一个分量垂直于 A 的列空间。而投影矩阵的作用就是保留列空间中的那个分量，拿掉垂直于列空间的分量。

<div  align="center">  
<img src="https://s2.loli.net/2024/02/21/iTJeK6R5ts7OSVL.jpg" width = "30%" height = "30%" alt="图7 - 投影矩阵的理解"/>
</div>

$\,b = p + e\,$，p 就是投影矩阵作用于 b 上得到的向量，而 e 这个左零空间中的分量，如果也用类似投影矩阵来表示的话，就是：$\,p = Pb\,$，$\,e = b - p = b - Pb = (I - P)b \,$。$\,I-P\,$可以看作是左零空间的投影矩阵，并且 $\,(I - P)^T = I - P\,$，$\,(I - P)^2 = I - P\,$。

## 最小二乘法
接着上节课的例子：  

$$ \begin{bmatrix} 1 & 1 \\ 1 & 2 \\ 1 & 3 \end{bmatrix} \begin{bmatrix} C \\ D \end{bmatrix} = \begin{bmatrix} 1 \\ 2 \\ 2 \end{bmatrix} $$

这个的方程 Ax = b 是无解的，解决办法就是求其最优解，最优解的含义即为直线与各点之间的误差（偏移量）最小，为了便于计算，研究它们的平方和：$\,|e|^2 = |Ax - b|^2\,$，因此就是寻找具有最小误差平方和的解 x，这就是所谓的“最小二乘”问题。

<div  align="center">  
<img src="https://s2.loli.net/2024/02/21/bdhuCi1Zo9qctK2.jpg" width = "30%" height = "30%" alt="图8 - 误差"/>
</div>

从几何上讨论求解过程，就是试图寻找数据点到直线距离的平方和 $\,e_1^2 + e_2^2 + e_3^2\,$ 最小的情况。另一种看法是，对于 $\,R^3\,$ 空间上的向量 b，它投影到矩阵 A 的列空间中会得到向量 p = [p1 p2 p3]，投影到矩阵 A 的左零空间中则为 e。

计算如下，使用上节课中我们介绍的方程：  

$$ A^TA \hat {x} = A^Tb $$

对应方程：$\,\begin{bmatrix} 1 & 1 \\ 1 & 2 \\ 1 & 3 \end{bmatrix} \begin{bmatrix} C \\ D \end{bmatrix} = \begin{bmatrix} 1 \\ 2 \\ 2 \end{bmatrix}\,$，其中 $\,A = \begin{bmatrix} 1 & 1 \\ 1 & 2 \\ 1 & 3 \end{bmatrix}\,$，$\,\hat x = \begin{bmatrix} \hat c \\ \hat d \end{bmatrix}\,$，$\,b = \begin{bmatrix} 1 \\ 2 \\ 2 \end{bmatrix}\,$。

其中 $\,A \hat {x} = b\,$ 可以写成增广矩阵模式，故 $\,A^TA \hat {x} = A^Tb\,$ 可以写成：

$$ \begin{bmatrix} 1 & 1 & 1 \\ 1 & 2 & 3 \end{bmatrix} \left[ \begin{array}{cc|c} 1 & 1 & 1 \\ 1 & 2 & 2 \\ 1 & 3 & 2 \end{array} \right] = \left[ \begin{array}{cc|c} 3 & 6 & 5 \\ 6 & 14 & 11 \end{array} \right] $$

即有：  

$$ \begin{bmatrix} 3 & 6 \\ 6 & 14 \end{bmatrix} \begin{bmatrix} \hat {C} \\ \hat {D} \end{bmatrix} = \begin{bmatrix} 5 \\ 11 \end{bmatrix} $$

解得：

$$ \hat {C} = 2/3，\hat {D} = 1/2 $$

得到直线表达式 y = 2/3 + t/2。

还可以从误差最小的角度出发求解：  

$$ e_1^2 + e_2^2 + e_3^2 = (C + D - 1)^2 + (C + 2D - 2)^2 + (C + 3D - 2)^2 $$

对等号右边的表达式求偏导数，极值出现在偏导数为 0 的位置。求偏导最终会得到相同的线性方程组和相同的解。

得到直线表达式 y = 2/3 + t/2。将 t = 1, 2, 3 分别代入，以及 b = p + e 可得：  

$$ b = \begin{bmatrix} 1 \\ 2 \\ 2 \end{bmatrix}, p = \begin{bmatrix} 7/6 \\ 10/6 \\ 13/6 \end{bmatrix}, e = \begin{bmatrix} -1/6 \\ 2/6 \\ -1/6 \end{bmatrix} $$

得到如下性质：  
①误差向量与投影向量 p 垂直（二者点乘为 0）  
②误差向量不仅仅垂直于 p，它还垂直于列空间中的每一个向量。

## 矩阵 $\,A^TA\,$
之前有一个结论没有验证过：如果矩阵 A 各列线性无关，则矩阵 $\,A^TA\,$ 可逆。

引入之前几节的结论：如果矩阵可逆，则其对应的零空间仅为零向量。$\,x^Tx\,$ 对应是在求 x 的长度（x 是列向量）。如果 $\,x^Tx = 0\,$，则 x = 0（x 是列向量）。

假设存在 x 使得 $\,A^TAx = 0\,$。则有 $\,x^TA^TAx = 0 = (Ax)^T(Ax)\,$，可推得 Ax = 0，因为 A 各列线性无关，所以也就推得了 x 必为零向量。即 $\,A^TA\,$ 为可逆矩阵。

## 标准正交基
这部分是引出下节的部分，内容较少：

如果矩阵的列向量是互相垂直的单位向量，则它们一定是线性无关的。我们将这种向量称之为**标准正交 orthonormal**。

例如：$\,\begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix}\,$，$\,\begin{bmatrix} 0 \\ 1 \\ 0 \end{bmatrix}\,$，$\,\begin{bmatrix} 0 \\ 0 \\ 1 \end{bmatrix}\,$，以及 $\,\begin{bmatrix} \cos \theta \\ \sin \theta \end{bmatrix}\,$ 和 $\,\begin{bmatrix} -\sin \theta \\ \cos \theta \end{bmatrix}\,$。


# 第十七课 正交矩阵和施密特正交化
## 标准正交向量 Orthonormal vectors
满足如下条件的向量 $\,q_1, q_2, q_3\,$ 为标准正交：  

$$ q_i^Tq_j = \begin{cases} 0 & i \ne j \\[2ex] 1 & i = j \end{cases} $$

即，这些向量都具有单位长度 1，并且彼此正交。标准正交向量是线性无关的。

## 标准正交矩阵 Orthonormal matrix
所谓标准正交矩阵 Q，就是将标准正交向量组中的 $\,q_1, q_2 ··· q_n\,$ 列在同一个
矩阵中：  

$$ Q = \begin{bmatrix} q_1 & ... & q_n \end{bmatrix} $$

这样的标准正交矩阵有一个很好的性质：  

$$ Q^TQ = \begin{bmatrix} q_1 \\ q_2 \\ ... \\ q_n \end{bmatrix} \begin{bmatrix} q_1 & q_2 & ... & q_n \end{bmatrix} = \begin{bmatrix} 1 & 0 & \cdots & 0 & 0 \\ 0 & 1 & \cdots & 0 & 0 \\ \vdots & \vdots & \ddots & \vdots & \vdots \\ 0 & 0 & \cdots & 1 & 0 \\ 0 & 0 & \cdots & 0 & 1 \end{bmatrix} = I $$

注意这里的标准正交矩阵 Q 可以不是方阵；一个标准正交的方阵我们称之为**正交矩阵 orthogonal matrix**。如果 Q 为方阵，因为 $\,Q^TQ = I\,$，所以 $\,Q^T = Q^{-1}\,$。

正交矩阵不要忘了单位化。例如，$\,\begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}\,$，这个矩阵各列是正交的，但并不是正交矩阵，因为没有单位化，正确的正交矩阵是 $\,\frac {1} {\sqrt 2}\begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}\,$。由这个矩阵可以延伸出**阿达马矩阵 Adamar Matrix**，这里不做详细介绍。

## 标准正交矩阵的作用
记得上面介绍的投影矩阵 $\,P = A(A^TA)^{-1}A^T\,$，若 A 矩阵是标准正交矩阵 Q 时：  

$$ Q(Q^TQ)^{-1}Q^T = QQ^T $$

特别的，当 Q 时方阵（正交阵）时，由于此时 $\,Q^T = Q^{-1}\,$。所以投影矩阵即为 I。

很多复杂问题使用标准正交向量之后都变得简单。如果基为标准正交，则方程 $\,A^TA \hat {x} = A^Tb\,$ 的解变为 $\,\hat {x} = Q^Tb\,$，$\,\hat {x}\,$ 的分量 $\,\hat {x_i} = q_i^Tb\,$。

## 施密特正交化 Gram-Schmidt
**施密特正交化 Gram-Schmidt Orthogonalization** 即从线性无关向量组入手，将其矩阵标准正交化。

有两个线性无关的向量 a，b。我们想从中得到标准正交向量 $\,q_1\,$，$\,q_2\,$。

Schmidt 给出的结论是如果我们有一组正交基 A 和 B（注意这个小节 A，B，C 均为向量），那么我们令它们除以自己的长度就得到标准正交基：  

$$ q_1 = \frac {A} {|A|}, q_2 = \frac {B} {|B|} $$

Gram 做了重要的工作，在 a 和 b 张成的空间中，将 a 向量定为 A 向量，然后将 b 向量投影到 a 向量上。然后取 B = b - p：  

<div  align="center">  
<img src="https://s2.loli.net/2024/02/22/abOJoXkDYQEpyv2.jpg" width = "40%" height = "40%" alt="图9 - 二维施密特正交化"/>
</div>

即：  

$$ B = b - \cfrac {A^Tb} {A^TA} A $$

验证 A 与 B 是否正交：$\,A^TB = A^T(b - \cfrac {A^Tb} {A^TA} A) = 0\,$，说明 A 与 B 是正交的。接下来通过 $\,q_1 = \cfrac {A} {|A|}, q_2 = \cfrac {B} {|B|}\,$ 单位化各个向量，就得到了 a, b 空间的标准正交基。

---

同样的道理，推广到三维：

<div  align="center">  
<img src="https://s2.loli.net/2024/02/22/AyuORYN4vqm5oCj.jpg" width = "40%" height = "40%" alt="图10 - 三维施密特正交化"/>
</div>

寻找三个正交的向量 A, B, C 的话，其中 A，B 方法不变：

$$ A = a $$
$$ B = b - \cfrac {A^Tb} {A^TA} A $$

而 C 通过将 c 减去在 A, B 上的投影就可以得到：  

$$ C = c - \cfrac {A^Tb} {A^TA} A - \cfrac {B^Tc} {B^TB} B$$

得到三个正交的向量 A, B, C，再进行单位化即可。

---

示例：$\,a = \begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix}\,$，$\,b = \begin{bmatrix} 1 \\ 0 \\ 2 \end{bmatrix}\,$，求标准正交矩阵 Q。

$$ A = a = \begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix} $$

$$ B = b - \cfrac {A^Tb} {A^TA} A = \begin{bmatrix} 1 \\ 0 \\ 2 \end{bmatrix} - \frac {3} {3} \begin{bmatrix} 1 \\ 1 \\ 1 \end{bmatrix} = \begin{bmatrix} 0 \\ -1 \\ 1 \end{bmatrix} $$

再进行单位化，得到标准正交矩阵 Q：

$$ Q = \begin{bmatrix} q_1 & q_2 \end{bmatrix} = \begin{bmatrix} 1/\sqrt {3} & 0 \\ 1/\sqrt {3} & -1/\sqrt {2} \\ 1/\sqrt {3} & 1/\sqrt {2} \end{bmatrix} $$

观察矩阵 $\,A = \begin{bmatrix} 1 & 1\\ 1 & 0 \\ 1 & 2 \end{bmatrix}\,$ 和矩阵 Q 的列空间，它们是相同的，也就是说我们的正交化过程都是在同一个空间中进行的，只是最后得到了一个更好的标准正交基而已。

从矩阵的角度来看，类似于 A 的 LU 分解，在 Gram-Schmidt 正交化中，A 可分解为 Q 与 R。其中 R 是上三角矩阵：$\,A = QR\,$

$$ A = \begin{bmatrix} a_1 & a_2 \end{bmatrix} $$
$$ Q = \begin{bmatrix} q_1 & q_2 \end{bmatrix} $$
$$ R = \begin{bmatrix} a_1^Tq_1 & a_2^Tq_1 \\ a_1^Tq_2 & a_2^Tq_2 \end{bmatrix} $$

其中 R 中的 $\,a_1^Tq_2\,$ 为 0，这是因为 $\,a_1\,$ 就是 $\,q_1\,$ 的方向，而 $\,q_1\,$ 和 $\,q_2\,$ 为标准正交向量，因此 $\,q_2\,$ 的方向与 $\,a_1\,$ 垂直，因此内积为 0。

R 在 Q 右侧相当于对 Q 做列操作，即 A 的列向量是 Q 列向量的线性组合。


# 第十八课 行列式及其性质
接下来课程进入了下一个部分，之前学习了大量长方形矩阵的性质，现在我们集中讨论方阵的性质，包括**行列式 determinants** 和**特征值 Eigen values**。

## 行列式 Determinants
行列式是跟每个方阵都有关的一个数字。这个数字包含了这个矩阵的很多性质，比如方阵行列式为 0，
则方阵不可逆。矩阵 A 的行列式记作：  

$$ det(A) 或 | A | $$

## 行列式的性质
直接给出 n 阶行列式的公式，则一下子代入了大量信息，并不利于接受这个概念，我们从行列式的三个性质开始讲起，这三个性质定义了行列式。

**性质一**：对于单位阵 I，有：$\,det(I) = 1\,$。

$$ \begin{vmatrix} 1 & 0 \\ 0 & 1 \end{vmatrix} = 1 $$

**性质二**：交换两行后，行列式的值相反。可以推知置换矩阵的行列式是 +1 或者 -1。

$$ \begin{vmatrix} 0 & 1 \\ 1 & 0 \end{vmatrix} = -1 $$

**性质三①**：如果在矩阵的一行乘上 t，则行列式的值就要乘上 t：  

$$ \begin{vmatrix} ta & tb \\ c & d \end{vmatrix} = t\begin{vmatrix} a & b \\ c & d \end{vmatrix} $$

**性质三②**：行列式是一个线性函数，但是这个线性单独反映在每一行上。即：

$$ \begin{vmatrix} a + a' & b + b' \\ c & d \end{vmatrix} = \begin{vmatrix} a & b \\ c & d \end{vmatrix} + \begin{vmatrix} a' & b' \\ c & d \end{vmatrix} $$

---

更多的性质可以从以上的三条性质中推导出来：  

**性质四**：如果矩阵的两行是完全相同的，则它的行列式为 0。

这可以从第二条性质推导出来，因为交换这个相同的两行，行列式应该变号；但是新生成的矩阵跟原矩阵没有区别，因此行列式应该不变，所以有 det = -det，所以 det 等于 0。

**性质五**：从矩阵的行 k 减去另一行的 i 倍，对应的行列式值不发生改变：  

$$ \begin{align*} \begin{vmatrix} a & b \\ c - ta & d - tb \end{vmatrix} &= \begin{vmatrix} a & b \\ c & d \end{vmatrix} - \begin{vmatrix} a & b \\ ta & tb \end{vmatrix} \\ &= \begin{vmatrix} a & b \\ c & d \end{vmatrix} - t\begin{vmatrix} a & b \\ a & b \end{vmatrix} \\ &= \begin{vmatrix} a & b \\ c & d \end{vmatrix} \end{align*} $$

**性质六**：如果有一行为零，那么 A 的行列式为 0： 

这个性质很简单，让性质 3 中的 t = 0，行列式值也为 0。

**性质七**：上三角矩阵对应的行列式的值等于其对角线上元素的乘积。  

性质五告诉我们行消元的过程，行列式的数值没有发生变化，即三角阵通过行消元法得到对角阵的行列式不变；性质三①告诉我们对角阵的行列式等于其主元的乘积再乘以单位阵的行列式；性质一表明单位阵行列式为 1。故有：  

$$ \begin{align*} \begin{bmatrix} d_1 & * & * & \cdots & * \\ 0 & d_2 & * & \cdots & * \\ 0 & 0 & \ddots & \ddots & * \\ \vdots & \vdots & \ddots & \ddots & \vdots \\ 0 & 0 & \cdots & \cdots & d_n \end{bmatrix} &= \begin{bmatrix} d_1 & 0 & 0 & \cdots & 0 \\ 0 & d_2 & 0 & \cdots & 0 \\ 0 & 0 & \ddots & \ddots & 0 \\ \vdots & \vdots & \ddots & \ddots & \vdots \\ 0 & 0 & \cdots & \cdots & d_n \end{bmatrix} \\ &= d_1d_2 \cdots d_n \begin{bmatrix} 1 & 0 & 0 & \cdots & 0 \\ 0 & 1 & 0 & \cdots & 0 \\ 0 & 0 & \ddots & \ddots & 0 \\ \vdots & \vdots & \ddots & \ddots & \vdots \\ 0 & 0 & \cdots & \cdots & 1 \end{bmatrix} \\ &= d_1d_2 \cdots d_n \end{align*} $$

**性质八**：当且仅当矩阵 A 为奇异矩阵时，其行列式为 0。当且仅当 A 可逆，行列式不为 0。  

如果矩阵 A 为奇异阵，则必可通过消元法使得矩阵的某行全等于零，则按照性质六，A 的行列式为 0。如果其不是奇异阵，则通过消元可以得到一个上三角矩阵，且其主元均不为 0，则按照性质七，行列式的数值等于主元的乘积也不等于 0。

> 计算非奇异矩阵的行列式有确切的公式，但通常计算机是靠消元的方法来转化为三角阵，然后将主元相乘来进行计算的。

**性质九**：方阵乘积的行列式 = 方阵行列式的乘积，即：$\,|AB| = |A||B|\,$。

由此结论可知：  
①可逆矩阵的行列式与其逆矩阵的行列式互为倒数：$\,AA^{-1} = I \rightarrow |A||A^{-1}| = 1\,$  

②矩阵平方的行列式等于矩阵行列式的平方：$\,|A^2| = (|A|)^2\,$  

③$\,|kA| = k^n|A|\,$，其中 k 为常数，A 为 n 阶矩阵，提出了每一行中的 k。

**性质十**：$\,|A^T| = |A|\,$。

证明：矩阵消元可得 $\,A = LU\,$，则 $\,A^T = U^TL^T\,$，由性质九可知 $\,|A| = |L||U|\,$，$\,|A^T| = |L^T||U^T|\,$。第四课中的 LU 分解中介绍过，L 是一个主对角线全为 1 的下三角矩阵(因为消元过程总是向下消元)。而 U 是一个上三角矩阵。很明显。像 U,L 这样的上/下三角矩阵，不论转置与否，其行列式都为对角线上各元素乘积，即 $\,|L^T| = |L|\,$，$\,|U^T| = |U|\,$。故$\,|A^T| = |A|\,$

因为性质十成立，交换行和交换列本质上没什么区别，之前的性质都可以应用在列变换上。

> 这一课结尾时，教授提到了行交换的奇偶问题，这个问题很重要，因为行交换的奇偶性会影响最终值的正负号，所以置换矩阵行列式的正负性受其行交换次数影响。


# 第十九课 行列式公式和代数余子式
认识到了行列式的性质后，可以推导出其公式：  

## 行列式公式
从上节课的十个性质出发可以得到二阶方阵的行列式公式：  

$$ \begin{align*} \begin{vmatrix} a & b \\ c & d \end{vmatrix} &= \begin{vmatrix} a & 0 \\ c & d \end{vmatrix} + \begin{vmatrix} 0 & b \\ c & d \end{vmatrix} \\ &= \begin{vmatrix} a & 0 \\ c & 0 \end{vmatrix} + \begin{vmatrix} a & 0 \\ 0 & d \end{vmatrix} + \begin{vmatrix} 0 & b \\ c & 0 \end{vmatrix} + \begin{vmatrix} 0 & b \\ 0 & d \end{vmatrix} \\ &= 0 + ad - bc + 0 \\ &= ad - bc \end{align*} $$

观察上面的求解过程，不难发现，行列式其实取决于那些分解后非零的行列式的和，这些非零行列式有这样一个特点：各行格列均有元素。根据这个特点，我们可以简化更高阶的行列式解法。接下来将问题扩展到三阶：  

$$ \begin{align*} \begin{vmatrix} a_{11} & a_{12} & a_{13} \\ a_{21} & a_{22} & a_{23} \\ a_{31} & a_{32} & a_{33} \end{vmatrix} &= \begin{vmatrix} a_{11} & 0 & 0 \\ 0 & a_{22} & 0 \\ 0 & 0 & a_{33} \end{vmatrix} + \begin{vmatrix} a_{11} & 0 & 0 \\ 0 & 0 & a_{23} \\ 0 & a_{32} & 0 \end{vmatrix} + \begin{vmatrix} 0 & a_{12} & 0 \\ a_{21} & 0 & 0 \\ 0 & 0 & a_{33} \end{vmatrix} \\ &+ \begin{vmatrix} 0 & a_{12} & 0 \\ 0 & 0 & a_{23} \\ a_{31} & 0 & 0 \end{vmatrix} + \begin{vmatrix} 0 & 0 & a_{13} \\ a_{21} & 0 & 0 \\ 0 & a_{32} & 0 \end{vmatrix} + \begin{vmatrix} 0 & 0 & a_{13} \\ 0 & a_{22} & 0 \\ a_{31} & 0 & 0 \end{vmatrix} \\ &= a_{11}a_{22}a_{33} - a_{11}a_{23}a_{32} - a_{12}a_{21}a_{33} + a_{12}a_{23}a_{31} + a_{13}a_{21}a_{32} - a_{13}a_{22}a_{31} \end{align*} $$

下面通过类比得到一般公式，这个拆分过程其实是每次从一行中选择某一列上相交位置的元素来累乘，而且各行选定的列不相同。注意该项的符号的正负，写成以下形式：  

$$ det(A) = \sum_{n!} \pm a_{1 \alpha} a_{2 \beta} a_{3 \gamma} \cdots a_{n \omega} $$

其中列标号 $\,\alpha, \beta, \gamma \cdots \,$ 是列标号（1, 2, 3 ... n）的某个排列。比如说对于单位阵而言，只有 $\,\alpha = 1, \beta = 2, \cdots \omega = n \,$，所得到的行列式为 +1，其它都为零，所以单位阵的行列式为 1。用以下例子来更好的说明：  

$$ \begin{vmatrix} 0 & 0 & 1 & 1 \\ 0 & 1 & 1 & 0 \\ 1 & 1 & 0 & 0 \\ 1 & 0 & 0 & 1 \end{vmatrix} = \begin{vmatrix} 0 & 0 & 0 & 1 \\ 0 & 0 & 1 & 0 \\ 0 & 1 & 0 & 0 \\ 1 & 0 & 0 & 0 \end{vmatrix} + \begin{vmatrix} 0 & 0 & 1 & 0 \\ 0 & 1 & 0 & 0 \\ 1 & 0 & 0 & 0 \\ 0 & 0 & 0 & 1 \end{vmatrix} $$

列标号取（4, 3, 2, 1）得到第一个拆分行列式，符号为正，因为只要经过两次交换就能变为（1, 2, 3, 4）。第二个为（3, 2, 1, 4），因为只需交换一次就可变为正序，所以符号为负。因此本行列式为 0。

## 代数余子式 Cofactor formula
利用代数余子式我们可以更方便地求解行列式，其作用即是将 n 阶行列式化成 n-1 阶。

比如上面的三阶矩阵：  

$$ det(A) = \begin{vmatrix} a_{11} & 0 & 0 \\ 0 & a_{22} & a_{23} \\ 0 & a_{32} & a_{33} \end{vmatrix} + \begin{vmatrix} 0 & a_{12} & 0 \\ a_{21} & 0 & a_{23} \\ a_{31} & 0 & a_{33} \end{vmatrix} + \begin{vmatrix} 0 & 0 & a_{13} \\ a_{21} & a_{22} & 0 \\ a_{31} & a_{32} & 0 \end{vmatrix} $$

将原公式中属于矩阵第一行的 $\,a_{1j}\,$ 提出来，其系数即为代数余子式，是一个低阶行列式的值。这个低阶行列式是由原矩阵去掉 $\,a_{1j}\,$ 所在的行和列组成的。

对于 n 阶方阵，其行列式的代数余子式公式为：  

$$ det(A) = a_{11}C_{11} + a_{12}C_{12} + \cdots + a_{1n}C_{1n} $$

$\,a_{ij}\,$ 位置对应的代数余子式 $\,C_{ij}\,$ 为去掉原行列式中第 i 行第 j 列后剩余元素组成的矩阵的行列式值与 $\,a_{ij}\,$ 的乘积的正或负值。当 i + j 为偶数时为正，奇数为负，可以理解为：$\,(-1)^{i+j}\,$ * 剩余元素组成的行列式值。

对于矩阵行列式的计算，消元的得到主元是一个很好的方法，与之相比行列式的展开公式较为复杂，而代数余子式的方法介于两者之间，它的核心想法是通过降阶来将原来的行列式展开成更简单的行列式。

---

接下来通过一种特殊的矩阵熟悉一下按行展开行列式的计算方法：

举三对角阵 tridiagonal matrix 为例，它除了对角线和对角线两侧相邻的元素之外，其它元素均为 0。

$$ A_4 = \begin{bmatrix} 1 & 1 & 0 & 0 \\ 1 & 1 & 1 & 0 \\ 0 & 1 & 1 & 1 \\ 0 & 0 & 1 & 1 \end{bmatrix} $$

我们可以从 1 阶开始算起：$\,|A_1| = 1\,$，$\,|A_2| = \begin{vmatrix} 1 & 1 \\ 1 & 1 \end{vmatrix} = 0\,$，$\,|A_3| = \begin{vmatrix} 1 & 1 & 0 \\ 1 & 1 & 1 \\ 0 & 1 & 1 \end{vmatrix} = -1\,$

则有 $\,|A_4| = 1\begin{vmatrix} 1 & 1 & 0 \\ 1 & 1 & 1 \\ 0 & 1 & 1 \end{vmatrix} - 1\begin{vmatrix} 1 & 1 & 0 \\ 0 & 1 & 1 \\ 0 & 1 & 1 \end{vmatrix} = |A_3| - 1|A_2| = -1\,$

从三对角阵的特殊结构我们可以得到：$\,|A_n| = |A_{n-1}| - 1|A_{n-2}|\,$，由 1 组成的 n 阶三对角阵的行列式从 1 阶开始按照 1, 0, -1, -1, 0, 1 进行循环。


# 第二十课 克莱姆法则、逆矩阵、体积
这一节强调行列式的应用，包含三个方面：克莱姆法则、逆矩阵、体积

## 逆矩阵公式
逆矩阵公式：  

$$ A^{-1} = \frac {1} {|A|} C^T $$

$\,C^T\,$ 为代数余子式矩阵 C 的转置矩阵，称为伴随矩阵 adjoint matrix。代数余子式矩阵 C 为矩阵 A 的各个元素的对应的代数余子式组成的矩阵。比如，二阶逆矩阵公式为：  

$$ \begin{bmatrix} a & b \\ c & d \end{bmatrix}^{-1} = \frac {1} {ad - bc} \begin{bmatrix} d & -b \\ -c & a \end{bmatrix} $$

---

验证上述公式，上述公式等价于：  

$$ AC^T = |A|I $$

将其展开观察：  

$$ AC^T = \begin{bmatrix} a_{11} & \cdots & a_{1n} \\ \vdots & \ddots & \vdots \\ a_{n1} & \cdots & a_{nn} \end{bmatrix} \begin{bmatrix} C_{11} & \cdots & C_{n1} \\ \vdots & \ddots & \vdots \\ C_{1n} & \cdots & C_{nn} \end{bmatrix} $$

矩阵 $\,AC^T\,$ 第一行第一列的元素等于矩阵 A 第一行和矩阵 $\,C^T\,$ 第一列进行点积，计算可得：  

$$ \sum_{j=1}^n a_{1j}C_{1j} = det(A) $$

这就是计算 A 行列式的计算公式。可以得到矩阵 $\,AC^T\,$ 对角线上所有的元素都是如此，因此其对角戏上的元素都等于 det(A)。

而对于非对角线元素，我们以第二行第一列的元素为例，其计算公式为：  

$$ \sum_{j=1}^n a_{2j}C_{1j} = det(A_s) $$

这可以视为矩阵 $\,A_s\,$ 的行列式数值，各个代数余子式的形式不变，但是与代数余子式相乘的变为了矩阵 A 第二行的元素。也就是说这个 $\,A_s\,$ 的样子相对于第一行为 A 的第二行，其他行和 A 一样，即：  

$$ det(A_s) = \begin{vmatrix} a_{21} & a_{22} & \cdots & a_{2n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ a_{31} & a_{32} & \cdots & a_{3n} \\ \vdots & \ddots & \ddots & \vdots \\ a_{n1} & a_{n2} &\cdots & a_{nn} \end{vmatrix} = 0 $$

因为该矩阵中前两行完全相同，按照行列式性质 4，$\,det(A_s)=0\,$。

因此矩阵 $\,AC^T\,$ 为：  

$$ AC^T = \begin{bmatrix} det(A) & 0 & \cdots & 0 \\ 0 & det(A) & \cdots & 0 \\ \vdots & \ddots & \ddots & \vdots \\ 0 & 0 &\cdots & det(A) \end{bmatrix} = det(A)I $$

## 克莱姆法则 Cramer’s Rule
对于可逆矩阵 A，方程 $\,Ax=b\,$ 必然有解 $\,x=A^{-1}b\,$，将逆矩阵的公式带入其中，则有：

$$ x = A^{-1}b = \cfrac {1} {det(A)} C^Tb $$

克莱姆法则是从另一个角度来看待这个公式。实际上 x 的分量 $\,x_j = \cfrac {det(B_j)} {det(A)}\,$。$\,C^Tb\,$ 为矩阵 $\,B_j\,$ 的行列式值。

其中矩阵 $\,B_j\,$ 为用向量 b 替换矩阵 A 的第 j 列所得到的新矩阵。例如：  

$$ B_1 = \begin{bmatrix} b_1 & a_{12} & \cdots & a_{1n} \\ b_2 & a_{22} & \cdots & a_{2n} \\ b_3 & a_{32} & \cdots & a_{3n} \\ \vdots & \ddots & \ddots & \vdots \\ b_n & a_{n2} & \cdots & a_{nn} \end{bmatrix}, B_n = \begin{bmatrix} a_{11} & a_{12} & \cdots & b_1 \\ a_{21} & a_{22} & \cdots & b_2 \\ a_{31} & a_{32} & \cdots & b_3 \\ \vdots & \ddots & \ddots & \vdots \\ a_{n1} & a_{n2} & \cdots & b_n \end{bmatrix} $$
  
矩阵 $\,B_j\,$ 的行列式的数值从第 j 列用代数余子式进行展开计算，正好是伴随矩阵 $\,C^T\,$ 的第 j 行与向量 b 点积的结果。此处我们用到了行列式的性质十。

$\,C^T\,$ 矩阵为：  

$$ C^T = \begin{bmatrix} C_{11} & \cdots & C_{n1} \\ \vdots & \ddots & \vdots \\ C_{1n} & \cdots & C_{nn} \end{bmatrix} $$

即：  

$$ (C^Tb)_1 = \begin{bmatrix} C_{11} & \cdots & C_{n1} \end{bmatrix}  \begin{bmatrix} b_1 \\ \cdots \\ b_n \end{bmatrix} = \begin{vmatrix} b_1 & a_{12} & \cdots & a_{1n} \\ b_2 & a_{22} & \cdots & a_{2n} \\ b_3 & a_{32} & \cdots & a_{3n} \\ \vdots & \ddots & \ddots & \vdots \\ b_n & a_{n2} & \cdots & a_{nn} \end{vmatrix} = |B_1| $$

就这样，我们得到了另一种解方程 Ax = b 的方法。相比于消元法，采用克莱姆法则计算方程的解，效率较低。

## 体积
**矩阵 A 行列式的绝对值等于以矩阵 A 行（列）向量为边所构成的平行六面体的体积。行列式的正负对应左手系和右手系。**

如果矩阵 A 是单位矩阵，则其构成的是三个边长均为 1 且互相垂直的立方体，其体积为 1。这也是行列式的性质 1。

如果矩阵 A 为正交矩阵 Q，则其构成的也是三个边边长为1且三边互相垂直的立方体，其体积也为 1。

交换矩阵 A 中的行并不会改变其行列式的绝对值，显然也不会改变向量围成的体积，因此这也和体积理论相符。这是行列式的性质 2。

对于长方体，也非常直观，当你将其中一条边的边长增加 2 倍时，平行六面体的体积也会增加 2 倍，这相当于性质 3a。

对于性质 3b，实际上是要求体积理论摆脱角度的限制（之前几条完全都是在直角的背景下讨论得），我们可以在二维条件下简单证明。

<div  align="center">  
<img src="https://s2.loli.net/2024/03/02/BXEp8ZanfyMCwsY.png" width = "40%" height = "40%" alt="图11 - 行列式性质 3b"/>
</div>

从上面的二维图像可以看出来，$\,\begin{vmatrix} a + a' & b + b' \\ c & d \end{vmatrix}\,$ 对应的面积和 $\,\begin{vmatrix} a & b \\ c & d \end{vmatrix}\,$ 的面积与 $\,\begin{vmatrix} a' & b' \\ c & d \end{vmatrix}\,$ 的面积的和相等。高维类似。

有上面的启发，求过原点的三角形面积就可以用行列式求解 $\,S = 1/2\begin{vmatrix} a & b \\ c & d \end{vmatrix}\,$。

而不过原点的三角形，三个顶点为 $\,(x_1,y_1)\,$、$\,(x_2,y_2)\,$、$\,(x_3,y_3)\,$，其面积等于 $\,S = 1/2\begin{vmatrix} x_1 & y_1 & 1 \\ x_2 & y_2 & 1 \\ x_3 & y_3 & 1 \end{vmatrix}\,$。可以把它理解为高为 1 的体积。


# 第二十一课 特征值和特征向量
在这个议题下讨论的都是方阵。
## 特征值和特征向量
**特征值 eigenvalues** 与**特征向量 eigenvectors** 的定义：对矩阵 A，若有 $\,Ax = \lambda x\,$，则 $\,x\,$ 为矩阵 A 的特征向量，$\,\lambda\,$ 为矩阵的特征值。

解特征值与特征向量的意义：对于不同的向量 x，Ax 这个式子像是一个函数，输入一个向量 x，则输出一个向量 Ax。而在我们输入的众多向量 x 生成的 Ax 中，会有这样的向量 Ax，它们平行于 x，即  $\,Ax = \lambda x\,$。

---

①特别注意下特征值为 0 的情况，如果 0 是矩阵的特征值，则有 Ax = 0x = 0。特征值 0 所对应的向量生成了矩阵的零空间。如果矩阵 A 为不可逆矩阵，则 0 是其特征值之一。

②对于投影矩阵，特征值是多少。若该投影矩阵将向量投影到一个平面上，对于平面上的任意 $\,x_1\,$ 来说，投影矩阵根本不会影响它的大小，所以就有 $\,Ax_1 = x_1\,$ 恒成立，即 $\,\lambda = 1\,$。如果对垂直于平面的任意 $\,x_2\,$，投影矩阵作用在此向量之后始终会有：$\,Ax_1 = 0\,$，即 $\,\lambda = 0\,$。矩阵 A 的所有特征向量张成了整个空间，投影矩阵为对称矩阵。  

③矩阵 $\,A = \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix}\,$，具有特征向量 $\,x = \begin{bmatrix} 1 \\ 1 \end{bmatrix}\,$，对应特征向量为 1；另一个特征向量为 $\,x = \begin{bmatrix} 1 \\ -1 \end{bmatrix}\,$，对应的特征向量为 -1。这些特征向量张成了整个空间。因为是对称矩阵，其特征向量互相垂直。

---

## 特征值求解方法
任意 n x n 矩阵 A 具有 n 个特征值，并且它们的和等于矩阵对角线上的元素之和，这个数值为矩阵的**迹 trace**。对于二阶矩阵，在已知一个特征值的条件下，可以据此得到另一个特征值。

方程 $\,Ax = \lambda x\,$ 中特征值和特征向量均未知，没法直接求解。因此我们做如下数学处理： $\,Ax = \lambda x \rightarrow (A - \lambda I)x = 0\,$，则 $\,A - \lambda I\,$ 为奇异矩阵，因此 $\,det(A - \lambda I) = 0\,$。在这个没有 x 的方程中，可以解得 n 个特征值，但是有可能方程有重根，则会得到重复的特征值。最后利用 $\,(A - \lambda I)x = 0\,$ 求解零空间中的向量即为矩阵的特征向量。

【示例一】求矩阵 $\,A = \begin{bmatrix} 3 & 1 \\ 1 & 3 \end{bmatrix}\,$ 的特征向量与特征值：

$$ det(A - \lambda I) = \begin{vmatrix} 3 - \lambda & 1 \\ 1 & 3 - \lambda \end{vmatrix} = (3 - \lambda)^2 - 1 = \lambda^2 - 6 \lambda + 8 $$

解得 $\,\lambda_1 = 2\,$，$\,\lambda_2 = 4\,$。

$$ (A - 4I)x_1 = \begin{bmatrix} -1 & 1 \\ 1 & -1 \end{bmatrix} x_1 = 0 $$
$$ (A - 2I)x_1 = \begin{bmatrix} 1 & 1 \\ 1 & 1 \end{bmatrix} x_2 = 0 $$

解得 $\,x_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}\,$，$\,x_2 = \begin{bmatrix} -1 \\ 1 \end{bmatrix}\,$。

我们也可以看到①特征值之和与迹相等，都为 6；②特征值之积为 A 矩阵行列式的值，都为 8。

【示例二】在例 1 的基础上，如果矩阵 $\,A = \begin{bmatrix} 3 & 1 \\ 1 & 3 \end{bmatrix} + 3I \,$，那么它的特征值、特征向量将如何变化：根据题意，改变后的方程变为 $\,(A + 3I)x = \lambda x + 3x = (\lambda + 3)x\,$，即新的特征值变为 λ + 3，而对应的特征向量不会改变。

需要注意的是，两个矩阵的和的特征值不是两特征值直接相加之和，因为特征向量并不相同。

## 复数特征值
矩阵 $\,Q = \begin{bmatrix} 0 & -1 \\ 1 & 0 \end{bmatrix} = \begin{bmatrix} cos90 & -sin90 \\ sin90 & cos90 \end{bmatrix}\,$ 是一个 90 度旋转矩阵。从矩阵的迹和行列式的值可以得到 $\,\lambda_1 + \lambda_2 = 0\,$，$\,\lambda_1 \lambda_2 = 1\,$

从矩阵的性质可知它的实数特征向量只有零向量，因为其他任何向量乘以旋转矩阵，向量的方向都会发生改变。计算可得：  

$$ det(Q - \lambda I) = \begin{bmatrix} -\lambda & -1 \\ 1 & -\lambda \end{bmatrix} = \lambda^2 + 1 = 0 $$

可以解得 $\,\lambda = \pm i\,$。如果一个矩阵具有复数特征值 a + bi ，则它的共轭复数 a - bi 也是矩阵的特征值。**实数特征值让特征向量伸缩而虚数让其旋转**。

对称矩阵永远具有实数的特征值，而**反对称矩阵 antisymmetric matrices**，即满足 $\,A^T = -A\,$ 的矩阵，具有纯虚数的特征值。

## 三角阵和重特征值 Triangular matrices and repeated eigenvalues
对于 $\,A = \begin{bmatrix} 3 & 1 \\ 0 & 3 \end{bmatrix}\,$ 的三角矩阵，特征值就是矩阵对角线上的元素。

$$ det(A - \lambda I) = \begin{bmatrix} 3 -\lambda & 1 \\ 0 & 3 -\lambda \end{bmatrix} = (3 - \lambda)^2 = 0 $$

可以解得 $\,\lambda = \pm 3\,$。这时的特征向量只会有一个，也就是说，三角矩阵的结构的特殊性导致了其行列式为对角线上元素，而如果对角线上两个元素相等，那么就会造成特征向量短缺情况。


# 第二十二课 对角化和矩阵的幂
## 矩阵对角化
矩阵对角化，即一种矩阵分解方式。如果 A 有 n 个线性无关的特征向量，那么可以将它们组成一个可逆方阵 S，进而将矩阵分解：  

假设 A 的 n 个线性无关的特征向量组成矩阵 S，有：

$$ S = \begin{bmatrix} x_1 & x_2 & \cdots & x_n \end{bmatrix} $$

构造：

$$ AS = A \begin{bmatrix} x_1 & x_2 & \cdots & x_n \end{bmatrix} $$

由特征值定义可得：  

$$ A \begin{bmatrix} x_1 & x_2 & \cdots & x_n \end{bmatrix} = \begin{bmatrix} \lambda x_1 & \lambda x_2 & \cdots & \lambda x_n \end{bmatrix} $$

写成矩阵乘法形式：

$$ \begin{bmatrix} \lambda x_1 & \lambda x_2 & \cdots & \lambda x_n \end{bmatrix} = \begin{bmatrix} x_1 & x_2 & \cdots & x_n \end{bmatrix} \begin{bmatrix} {\lambda}_1 & 0 & \cdots & 0 \\ 0 & {\lambda}_2 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & {\lambda}_n \end{bmatrix} $$

将由特征值组成的此对角矩阵记为 $\,\Lambda\,$，即 $\,AS = S \Lambda\,$。因为矩阵 S 中的列向量线性无关，因此逆矩阵 $\,S^{-1}\,$ 存在。在等式两侧左乘逆矩阵，得到 $\,S^{-1}AS = \Lambda\,$，同样地，$\,S^{-1}AS = S\Lambda S^{-1}\,$。

对于消元法而言，矩阵有 LU 分解，对于施密特正交法，矩阵有 QR 分解，而上面的推导是一种新的矩阵分解。

> 之前曾经提到过消元进行行操作和列操作最后会得到“相抵标准型”。现在我们得到的是矩阵的“相似标准形”，它还保有矩阵操作的基本性质 - 特征值，而相抵标准型只剩下最内核的秩信息还保留着。

## 矩阵幂运算
特征值给矩阵的幂计算提供了方法。如果 $\,Ax = \lambda x\,$，则有 $\,A^2x = \lambda Ax = {\lambda}^2 x\,$。这说明矩阵 $\,A^2\,$ 有和 A 一样的特征向量，而特征值为 $\,{\lambda}^2\,$。写成对角化形式则有：$\,A^2 = S\Lambda S^{-1}S\Lambda S^{-1} = S {\Lambda}^2 S^{-1}\,$，同理可得：$\,A^k = S {\Lambda}^k S^{-1}\,$。这说明 $\,A^k\,$ 有着和 A 一样的特征向量，而特征值为 $\,{\lambda}^k\,$。

【问题】若矩阵 A 存在 n 个线性无关的特征向量，那什么条件下能使矩阵的幂：$\,A^k\,$ 趋近为零？

解：当所有的特征值满足：$\,|{\lambda}_i| < 1\,$，则当 k 趋近于无穷大时，矩阵 $\,A^k\,$ 趋近于零。

## 重特征值 Repeated eigenvalues
注意**矩阵是否能够成功对角化取决于该矩阵是否有 n 个线性无关的特征向量**，而特征向量与特征值之间有着紧密的联系：  
①如果矩阵 A 没有重复的特征值，矩阵就一定有 n 个线性无关的特征向量（这也就意味着，不同特征值对应特征向量线性无关）。  
②但是如果有重复的特征值，结论不是完全否定的，也就是说这时也可能存在 n 个线性无关的特征向量。例如：10x10 的单位矩阵，其特征值只有 1，但是事实上我们可以取得 10 个线性无关的特征向量。  

对于如 $\,A = \begin{bmatrix} 2 & 1 \\ 0 & 2 \end{bmatrix}\,$ 的三角矩阵，特征值就是矩阵对角线上的元素 2。其特征向量在 $\,A - \lambda I\,$ 的零空间中，满足 $\,(A - \lambda I)x = \begin{bmatrix} 0 & 1 \\ 0 & 0 \end{bmatrix} x = 0\,$。求解可得 $\,x = \begin{bmatrix} 1 \\ 0 \end{bmatrix}\,$，而没有第二个特征向量。

## 差分方程 Difference equations
从给定的一个向量 $\,u_0\,$ 出发，我们可以通过对前一项乘以矩阵 A 得到下一项的方式，得到一个向量序列：$\,u_{k+1} = Au_k\,$。

$\,u_{k+1} = Au_k\,$ 为一个一阶差分方程，根据递推，不难得到：$\,u_{k} = A^ku_0\,$，即方程的解，但这种简洁形式并没有给出足够的信息，我们需要通过特征向量和矩阵的幂运算给出真实解的结构。

因为 $\,u_0\,$ 是 n 维的，n x n 的矩阵 A 具有 n 个线性无关的特征向量，所以我们可以把 $\,u_0\,$ 写为一个由 A 的 n 个特征向量组成的线性组合，类似于基：

$$ u_0 = c_1x_1 + c_2x_2 + \cdots + c_nx_n $$

再将 A 化为特征值形式：

$$ u_1 = Au_0 = c_1{\lambda}_1x_1 + c_2{\lambda}_2x_2 + \cdots + c_n{\lambda}_nx_n $$
$$ u_k = A^ku_0 = c_1{\lambda}_1^kx_1 + c_2{\lambda}_2^kx_2 + \cdots + c_n{\lambda}_n^kx_n = S {\Lambda}^k C$$

其中 $\,\Lambda\,$ 是特征值构成的对角阵，S 由特征向量构成，C 即系数。

下面用**斐波那契数列**进行举例。

【例】 斐波那契数列 0, 1, 1, 2, 3, 5, 8, 13, ...试求第 100 项的值，以及它的增长速度有多快？

其通项公式为 $\,F_{k+2} = F_{k+1} + F_{k}\,$，如果我们以矩阵的方式来理解数列，则矩阵的特征值可以告诉我们数列中数值的增长速度。

我们希望构造一阶差分，但是仅仅上面这个方程是无法构造矩阵形式的，我们添加一个方程：令 $\,u_k = \begin{bmatrix} F_{k+2} \\ F_{k+1} \end{bmatrix}\,$，则有：

$$ F_{k+2} = F_{k+1} + F_{k} $$
$$ F_{k+1} = F_{k+1} $$

写成矩阵形式为：

$$ u_{k + 1} = \begin{bmatrix} 1 & 1 \\ 1 & 0 \end{bmatrix} u_{k} $$

这样我们成功将一个二阶方程化为了一个一阶方程组，也就是我们上面介绍 $\,u_{k + 1} = Au_{k}\,$ 形式。

观察矩阵 $\,A = \begin{bmatrix} 1 & 1 \\ 1 & 0 \end{bmatrix}\,$ 的特征值和特征向量，因为其为对称矩阵，特征值为实数，且特征向量正交。

$$ det(A - \lambda I) = \begin{vmatrix} 1 - \lambda & 1 \\ 1 & - \lambda \end{vmatrix} = {\lambda}^2 - \lambda - 1 = 0 $$

解得 $\, {\lambda}_1 = \cfrac { 1 + \sqrt 5} {2}\,$，$\, {\lambda}_2 = \cfrac { 1 - \sqrt 5} {2}\,$，绝对值大于 1 的 $\,{\lambda}_1\,$ 控制着在斐波那契数列的增长。

根据上面的介绍，$\,u_k = A^ku_0 = c_1{\lambda}_1^kx_1 + c_2{\lambda}_2^kx_2 + \cdots + c_n{\lambda}_n^kx_n\,$，而对于裴波那契数列来说，n = 2，有：$\,u_k = c_1{\lambda}_1^kx_1 + c_2{\lambda}_2^kx_2\,$。而 $\,{\lambda}_2\,$ 比 1 小，后一项趋于 0，所以影响数列变化的只剩下了 $\,{\lambda}_1\,$。

从特征值可以求得对应的特征向量 $\,x_1 = \begin{bmatrix} {\lambda}_1 \\ 1 \end{bmatrix}\,$ 和 $\,x_2 = \begin{bmatrix} {\lambda}_2 \\ 1 \end{bmatrix}\,$。

从 $\,u_0 = \begin{bmatrix} F_1 \\ F_0 \end{bmatrix} = \begin{bmatrix} 1 \\ 0 \end{bmatrix} = c_1x_1 + c_2x_2\,$，可以求得 $\,c_1 = \cfrac {1} {\sqrt {5}}\,$，$\,c_2 = -\cfrac {1} {\sqrt {5}}\,$。

$$ \begin{bmatrix} F_{100} \\ F_{99}\end{bmatrix} = A^{99} \begin{bmatrix} F_{1} \\ F_{0} \end{bmatrix} = \begin{bmatrix} {\lambda}_{1} & {\lambda}_{2} \\ 1 & 1 \end{bmatrix} \begin{bmatrix} {\lambda}_{1}^{99} & 0 \\ 0 & {\lambda}_{2}^{99} \end{bmatrix} \begin{bmatrix} c_{1} \\ c_{2} \end{bmatrix} = \begin{bmatrix} c_1{\lambda}_{1}^{100} & c_2{\lambda}_{2}^{100} \\ c_1{\lambda}_{1}^{99} & c_2{\lambda}_{2}^{99} \end{bmatrix} $$

可知：$\, F_{100} \approx c_1{\lambda}_{1}^{100}\,$

> 特征值特征向量可以把矩阵的操作变成一个简单的参数，在物理中出现非常频繁。可以有如下理解：物理中常见的被研究物体都有一个自身的内禀结构，这个内在结构的方向往往和观察者也就是外场的坐标有区别。当我们给物体施加一个外场刺激的时候，比如说外力或者电场极化等等，物体沿着其内在结构的取向来响应外场，但是观察者从外场坐标下采集反馈。实际上矩阵在不同坐标之间实现变换，特征向量显示了物体内结构的方向，特征值则是在这个主方向上物体对外场的响应参数。在有的领域直接将特征值称为**伸缩系数**，实际上它反应了在其所对应的特征向量方向上，内结构与外场之间的相互关系。特征值还有一个应用是作为降维的判据，比如在**图像压缩**过程中，极小的特征值会被赋值为0，以此节省存储空间，也便于其它操作。反应在图像上，降维后的图像基本轮廓依旧清晰，图像细节有所牺牲。


# 第二十三课 微分方程和矩阵指数
