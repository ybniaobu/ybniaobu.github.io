---
title: Unity Custom SRP 基础（三）
date: 2025-01-07 20:43:16
categories: 
  - [图形学]
  - [unity, pipeline]
tags:
  - 图形学
  - 游戏开发
  - unity
top_img: /images/black.jpg
cover: https://s2.loli.net/2025/01/14/ELDF7wHpCPn2mKM.gif
mathjax: true
description: 本笔记的主要内容有XXXXXXXXXXXXXXXXXXXXXXXXXX。
---

> 本笔记是关于 Unity 的**自定义可编程渲染管线**的入门基础，即 **SRP (Scriptable Rendering Pipeline)**，主要参考了著名的教程 https://catlikecoding.com/ 的 Custom SRP Tutorial，以及知乎上各位图形学大神们的文章。  
>    
> 笔者使用的 Unity 版本是 6000.0.27f1，Core RP Library 的版本是 17.0.3。

# 烘焙光照
这一章节主要讲的就是 Unity 的**离线烘焙 Lightmap 系统**，即 **Progressive Lightmapper**，以及如何将我们的 SRP 和该系统结合在一起，该系统同时会烘焙光照探针 light probe 和反射探针 reflection probe。而 Unity 的**实时 Lightmap 系统**，即 **Enlighten** 系统，Unity 对其的说明是，它只适用于缓慢移动的光照，比如太阳在天空中的移动，不适用于变化特别快的光照，因为 Enlighten 在 CPU 上的计算造成了一定的性能瓶颈，只适合较为高端的设备使用。在 catlikecoding 的教程中没有将 Enlighten 系统融合进 SRP，故我这里也不做详细说明，但想要使用也相对比较简单，可以参考 URP。

我们知道 Lightmap 是**全局光照 Global Illumination** 的离线实现方式，而全局光照的实现包括直接光漫反射、直接光镜面反射、间接光漫反射以及间接光镜面反射。直接光漫反射和直接光镜面反射之前实现了一部分，即方向光的实现。间接光漫反射的实现，可以采用 Skybox 的球谐函数（即 IBL 的漫反射部分）、Lightmap 或者光照探针 light probe，这就是本章节的内容。而间接光镜面反射，则采用 Spilt sum approximation 的方式，要么采样预过滤的 Skybox，要么采样预过滤的反射探针 reflection probe，这个在之后的章节中实现。至于更加高级的全局光照方案，诸如 **SSGI (Screen Space Global Illumination)、VXGI (Voxel Global Illumination)、DDGI (Dynamic Diffuse Global Illumination)** 等等，我会在完成 catlikecoding 教程后再进行学习并实现，这些都是间接光漫反射的实现。至于间接光镜面反射，则有 **SSR (Screen Space Reflection)**、**SSPR (Screen Space Planar Reflection)** 等等。

我在之前的文章 [IBL 基于图像的光照（二）](https://ybniaobu.github.io/2024/08/16/2024-08-16-IBL_Basics2/#Unity-URP-%E7%9A%84-IBL-%E5%AE%9E%E7%8E%B0) 的 Unity URP 的 IBL 实现章节中有大致说明过 URP 如何实现 Lightmap。我会略微修改 URP 的实现方式，使其更适配我选用的 PBR 模型以及之前 IBL 的相关知识，之后会详细说明。

## Lighting Settings
我们可以使用 <kbd>Ctrl</kbd> + <kbd>9</kbd> 打开 Lighting Settings，这个 Lighting Settings 是 per scene 的，我们每个场景都可以配置。我们目前先只打开 Mixed Lighting 的 Baked Global Illumination，Lighting Mode 先选择为 Baked Indirect（后面一章节讲 Shadowmask），Directional Mode 先设置为 Non-Directional：  

<div  align="center">  
<img src="https://s2.loli.net/2025/01/15/MsnF27gWoHQCG39.png" width = "45%" height = "45%" alt="图44 - Lighting Settings"/>
</div>

其他设置随意。为了更好地体现烘焙光照的效果，我创建了一个由简单的几何体组成的场景：  

<div  align="center">  
<img src="https://s2.loli.net/2025/01/15/8e9z5dNJmgVFHvc.jpg" width = "50%" height = "50%" alt="图45 - 只有直接光影响的一个简单场景"/>
</div>

此时还不能进行烘焙，我们需要在场景中的物体的 MeshRenderer 组件中勾选上 Contribute Global Illumination，勾选上后 Receive Global Illumination 会自动切换至 Lightmaps。或者也可以直接在 Static 下拉菜单中勾选 Contribute GI，又或者直接勾选 Static 成为完全静态物体。也就是说 Lightmap 只影响静态物体。此时再点击 Generate Lighting 按钮，就可以烘焙光照贴图了。

如果场景中的灯光都设置为 Realtime Mode，那么光照贴图就不会包含这些灯光产生的间接光照，只会包含 Skybox 的间接光照。若灯光设置为 Mixed Mode，光照贴图就会包含这些灯光产生的间接光照，而直接光照则由我们的 Shader 计算生成。若灯光设置为 Baked Mode，光照贴图就会包含这些灯光的直接光照和间接光照。

<div  align="center">  
<img src="https://s2.loli.net/2025/01/15/jzt9ArLOG2QKMHi.png" width = "35%" height = "35%" alt="图46 - 上：场景中唯一的方向光为 Realtime Mode，光照贴图只包含 Skybox 的间接光照，烘焙系统同时会把 Skybox 的最亮的部分当作太阳光产生阴影；中：将  Environment Lighting 的 Intensity Multiplier 设置为 0，即天空光的贡献为 0，同时直接光为 Mixed Mode，可以看到只有方向光产生的间接光；下：天空光的贡献为 0，同时直接光为 Baked Mode，包含方向光的直接光和间接光。"/>
</div>

观察上面的光照贴图，有一点比较奇怪，就是我们场景中地面为绿色，但贴图没有一点绿色，这是因为我们还没有定义 **Meta Pass**，Unity 默认物体表面为白色，这个在后面说明。

## 光照贴图实现
### 传递 Light Map UV 坐标
为了让 Shader 可以得到物体在 Light Map 中的 uv 坐标，我们需要在 `DrawingSettings` 设置 `perObjectData`：  

``` C#
DrawingSettings opaqueDrawing = new DrawingSettings(m_UnlitShaderTagId, opaqueSorting)
{
    enableInstancing = asset.enableGPUInstancing,
    perObjectData = PerObjectData.Lightmaps
};
opaqueDrawing.SetShaderPassName(1, m_ForwardLitShaderTagId);
```

此外我们需要在 Shader 中设置 `LIGHTMAP_ON` 关键字，当物体使用 Light Map，Unity 会激活该关键字：  

    #pragma multi_compile _ LIGHTMAP_ON
  
接下来就是在 `Attributes` 和 `Varyings` 结构体中声明 LightMapUV 参数，但是我们直接声明不太好，因为不是所有的物体都使用 LightMap，我们可以定义宏来分支化处理，我放在了我新建的 UnityLightMappingLibrary.hlsl 文件中：  

    #if defined(LIGHTMAP_ON)
        #define LIGHTMAP_UV(index)                      float2 lightMapUV : TEXCOORD##index;
        #define TRANSFER_LIGHTMAP_UV(IN, OUT)           OUT.lightMapUV = IN.lightMapUV * unity_LightmapST.xy + unity_LightmapST.zw;
        #define LIGHTMAP_UV_FRAGMENT(IN)                IN.lightMapUV
    #else
        #define LIGHTMAP_UV(index)
        #define TRANSFER_LIGHTMAP_UV(IN, OUT)
        #define LIGHTMAP_UV_FRAGMENT(IN)                float2(0.0, 0.0)
    #endif

然后在 `Attributes` 和 `Varyings` 结构体中声明，以及在顶点着色器中传递：  

    struct Attributes
    {
        ...
        float2 uv           : TEXCOORD0;
        LIGHTMAP_UV(1)
    };

    struct Varyings
    {
        ...
        float3 binormalWS   : TEXCOORD4;
        LIGHTMAP_UV(5)
    };

    Varyings StandardVert(Attributes IN)
    {
        Varyings OUT;
        ...
        TRANSFER_LIGHTMAP_UV(IN, OUT)
        return OUT;
    }

### 传递 Light Map UV 偏移
在上面的宏定义中的 `unity_LightmapST` 就是我们要传递的 uv 偏移，Unity 会将物体展开至贴图空间，并且多个物体可能会共享一张光照贴图，所以必定会有缩放以及偏移。我们需要将 uv 变换相关参数传递至 `UnityPerDraw` cbuffer 中，比如 `unity_LightmapST`，另外教程里说要加上 `unity_DynamicLightmapST` 否则会破坏 SRP batcher compatibility，但我试了一下不会，可能是版本问题：  

    CBUFFER_START(UnityPerDraw)
      float4x4 unity_ObjectToWorld;
      float4x4 unity_WorldToObject;
      float4 unity_LODFade;
      real4 unity_WorldTransformParams;

      float4 unity_LightmapST;
      float4 unity_DynamicLightmapST;
    CBUFFER_END

### 采样 Light Map
我将 Light Map 相关函数都放在了 UnityLightMappingLibrary.hlsl 文件中，首先最好引入 core RP library 的 EntityLighting.hlsl 文件：  

    #include "Packages/com.unity.render-pipelines.core/ShaderLibrary/EntityLighting.hlsl"
  
这个函数里面定义了一些宏，用于处理 Lightmap 编码和解码相关代码，具体可以查看这篇文档：https://docs.unity3d.com/Manual/Lightmaps-TechnicalInformation.html 。接下来在 UnityInput.hlsl 中定义光照贴图和贴图采样器：  

    TEXTURE2D(unity_Lightmap);
    SAMPLER(samplerunity_Lightmap);
  
创建 `SampleLightMap()` 函数并调用 EntityLighting.hlsl 中的 `SampleSingleLightmap()` 函数：  

    float3 SampleLightMap(float2 lightMapUV)
    {
        #if defined(LIGHTMAP_ON)
            return SampleSingleLightmap(unity_Lightmap, samplerunity_Lightmap, lightMapUV, float4(1, 1, 0, 0), true);
        #else
            return float3(0, 0, 0);
        #endif
    }

`SampleSingleLightmap()` 函数的第四个参数传递的是 Light Map UV 的缩放和偏移，但是之前已经设置好了，所以这里只需要传递 `float4(1, 1, 0, 0)` 就行。第五个参数，当使用离线烘焙的 Lightmap (Progressive Lightmapper) 时选择 true，即 `LIGHTMAP_ON`，当使用实时 Lightmap (Enlighten) 系统时选择 false，即 `DYNAMICLIGHTMAP_ON`。

此时只要将之前 IBL 的 Diffuse 相关代码替换为采样 Light Map 的代码就可以渲染了。我将 Renormalized Disney diffuse 的预计算部分也考虑了进去，实现如下：  

    float3 CalculateLightMap_Diffuse(float2 lightMapUV, StandardPBRParams standardPBRParams, float envBRDF_Diffuse)
    {
        float3 irradiance = SampleLightMap(lightMapUV);
        float3 envBRDFDiffuse = standardPBRParams.albedo * envBRDF_Diffuse;
        float Kd = 1.0 - standardPBRParams.metallic;
        float3 Diffuse = irradiance * envBRDFDiffuse * Kd * standardPBRParams.ao;
        return Diffuse;
    }

    float3 IndirectLighting_Diffuse(float2 lightMapUV, StandardPBRParams standardPBRParams, float envBRDF_Diffuse)
    {
        #if defined(LIGHTMAP_ON)
            return CalculateLightMap_Diffuse(lightMapUV, standardPBRParams, envBRDF_Diffuse);
        #else
            return CalculateIBL_Diffuse(standardPBRParams, envBRDF_Diffuse);
        #endif
    }

最后在片元着色器中计算：  

    float3 envBRDF = SampleEnvLut(_EnvBRDFLut, sampler_Point_Clamp_EnvBRDFLut, standardPBRParams.NoV, standardPBRParams.roughness);

    renderingEquationContent.indirectLightDiffuse += IndirectLighting_Diffuse(LIGHTMAP_UV_FRAGMENT(IN), standardPBRParams, envBRDF.b);

我选用了如下的 HDR 贴图，并且场景中无直接光照，结果如下。若把 Renormalized Disney diffuse 的预计算部分考虑进去，光滑物体边缘会有黑边（比如下面的白球），粗糙物体边缘会有亮边（比如下面的绿球），没实现 Indirect Light Specular 之前区别不大，实现后我觉得考虑进去更好看更有层次感，也更能体现光滑与否：  

<div  align="center">  
<img src="https://s2.loli.net/2025/01/15/mqkSbzW4YsdrpZg.png" width = "80%" height = "80%" alt="图47 - 无直接光，只有 Skybox 的烘焙结果。左图：考虑 diffuse 预积分，右图：不考虑 diffuse 预积分"/>
</div>

我同时也对比了只有方向光的情况下（Skybox 的 Intensity Multiplier 设置为 0），3 种不同 mode 下的结果，即 Realtime、Mixed、Baked。这里特别说明一下，Unity 的 LightMap 系统因为比较早，和现在的 PBR 模型在亮度上存在一个 PI 的差别，这也是为什么 Unity 在 URP 的直接光的 Diffuse 计算中没有除以 PI，以及 Specular 项多乘了 PI 的原因。所以在烘焙的时候我把直接光亮度设为了 1，而 Realtime Mode 下亮度设置为了 3.14，Indirect Multiplier 都为 1：  

<div  align="center">  
<img src="https://s2.loli.net/2025/01/15/OhZLPeaVwrSFuYq.png" width = "100%" height = "100%" alt="图48 - 左：Realtime Mode，亮度为 3.14，无烘焙；中：Mixed Mode，烘焙时亮度为 1，烘焙完设置回 3.14；右：Baked Mode，亮度为 1。"/>
</div>

我将半影宽度设置为了 5，但还是不如烘焙的半影宽度大。除了半影宽度以外，可以看到 Mixed 和 Baked 效果已经很接近了。我感觉在 URP 下，Mixed 和 Baked 效果应该几乎一模一样。

## 光照探针实现
在 Unity 中，光照贴图只适用于静态物体，对于动态物体，无法使用光照贴图也无法在烘焙贴图时对全局光照做贡献。动态物体只能通过光照探针来接受全局光照的影响。动态物体会使用一定距离内的数个光照探针的球谐光照信息的插值作为接受到的间接漫反射光照。

### Light Probe Group
我们可以通过 GameObject / Light / Light Probe Group 在场景中添加巨量的光照探针。在场景中可以有无数个 Light Probe Group，Unity 会自动生成四面体将所有场景中的光照探针连接在一起。每个动态物体都会处于一个四面体当中，四面体的每个角上的 Light Probe 的数据插值后就是动态物体的间接漫反射光照。如果一个物体超过了光照探针覆盖的区域，它会使用最近的三角形上的每个 Light Probe。

放置 Light Probe 有一些注意点，比如：放置在动态物体需要经过的地方；放置在光线会发生变化的地方等等。Light Probe 还可能造成漏光问题，比如室内的动态物体采样到了室外的光照探针。

### 采样 Light Probe
首先需要传递插值后的球谐光照数据，跟 Light Map 一样，需要设置 `perObjectData`：  

``` C#
perObjectData = PerObjectData.Lightmaps | PerObjectData.LightProbe
```

这就需要在 `UnityPerDraw` cbuffer 中添加 7 个球谐光照参数，Unity 如何实现的球谐光照细节忘了就详见笔记 [IBL 基于图像的光照（一）](https://ybniaobu.github.io/2024/07/09/2024-07-09-IBL_Basics1/#Unity-%E7%9A%84%E7%90%83%E8%B0%90%E5%85%89%E7%85%A7%E5%AE%9E%E7%8E%B0)：  

    CBUFFER_START(UnityPerDraw)
        ...
        float4 unity_SHAr;
        float4 unity_SHAg;
        float4 unity_SHAb;
        float4 unity_SHBr;
        float4 unity_SHBg;
        float4 unity_SHBb;
        float4 unity_SHC;
    CBUFFER_END

然后我们就在 Shader 中采样球谐光照即可，采样的函数跟 IBL Diffuse 是一模一样的，直接用 IBL 的函数就可以：  

    float3 SampleSH(float3 N)
    {
        float3 L0L1;
        float4 vA = float4(N, 1.0);
        L0L1.r = dot(unity_SHAr, vA);
        L0L1.g = dot(unity_SHAg, vA);
        L0L1.b = dot(unity_SHAb, vA);

        float3 L2;
        float4 vB = N.xyzz * N.yzzx;
        L2.r = dot(unity_SHBr, vB);
        L2.g = dot(unity_SHBg, vB);
        L2.b = dot(unity_SHBb, vB);
        
        float vC = N.x * N.x - N.y * N.y;
        L2 += unity_SHC.rgb * vC;

        return L0L1 + L2;
    }

    float3 CalculateIBL_Diffuse(StandardPBRParams standardPBRParams, float envBRDF_Diffuse)
    {
        float3 irradiance = SampleSH(standardPBRParams.N);
        float3 envBRDFDiffuse = standardPBRParams.albedo * envBRDF_Diffuse;
        float Kd = 1.0 - standardPBRParams.metallic;
        float3 IBLDiffuse = irradiance * envBRDFDiffuse * Kd * standardPBRParams.ao;
        return IBLDiffuse;
    }

具体实现效果就不放出来了。这里提一嘴，如果场景中没有 Light Probe，动态物体就会使用 Skybox 的球谐光照，可以在动态物体的 Mesh Renderer 组件的 Probes 中将 Light Probes 选择为 off ，在 Light Probe 插值球谐和 Skybox 的球谐切换对比效果差别。

### Light Probe Proxy Volume
Light Probe 只适用于比较小的动态物体，但是对于大型物体就很容易出现光照错误。比如下图：  

<div  align="center">  
<img src="https://s2.loli.net/2025/01/16/rj4loLU5mRANOQD.png" width = "40%" height = "40%" alt="图49 - 图中长方体只采样到了处于暗处的光照探针，故整个长方体较暗，不符合光照逻辑"/>
</div>

Unity 对此的解决方案就是 **Light Probe Proxy Volume，LPPV**。直接在长方体添加 LPPV 组件，并且需要将 Mesh Renderer 组件的 Light Probes 属性设置为 Use Proxy Volume。

> URP 没有在管线中支持 LPPV，但 HDRP 和 Built-in Pipeline 支持。

<div  align="center">  
<img src="https://s2.loli.net/2025/01/16/U8YKzNjRwV7furg.png" width = "40%" height = "40%" alt="图50 - Light Probe Proxy Volume"/>
</div>

### 采样 LPPV
我不打算在自己的管线中支持 LPPV，但是支持的方法记录一下。首先同样需要设置 perObjectData 传递数据：  

``` C#
perObjectData = PerObjectData.Lightmaps | PerObjectData.LightProbe | PerObjectData.LightProbeProxyVolume
```

在 UnityPerDraw cbuffer 中添加 4 个参数：  

    CBUFFER_START(UnityPerDraw)
        ...
        // x = Disabled(0)/Enabled(1)
        // y = Computation are done in global space(0) or local space(1)
        // z = Texel size on U texture coordinate
        float4 unity_ProbeVolumeParams;
        float4x4 unity_ProbeVolumeWorldToObject;
        float4 unity_ProbeVolumeSizeInv;
        float4 unity_ProbeVolumeMin;
    CBUFFER_END

LPPV 的数据存储在 3D 纹理当中，定义对应的纹理和采样器：  

    TEXTURE3D(unity_ProbeVolumeSH);
    SAMPLER(samplerunity_ProbeVolumeSH);

core RP library 的 EntityLighting.hlsl 文件中的函数 `SampleProbeVolumeSH4()` 和 `SampleProbeVolumeSH9()` 就是专门用于采样 LPPV 的。我们可以将采样的代码大致写成如下：

    if (unity_ProbeVolumeParams.x) 
    {
        return SampleProbeVolumeSH9(
            unity_ProbeVolumeSH, samplerunity_ProbeVolumeSH,
            IN.positionWS, standardPBRParams.N,
            unity_ProbeVolumeWorldToObject,
            unity_ProbeVolumeParams.y, unity_ProbeVolumeParams.z,
            unity_ProbeVolumeMin.xyz, unity_ProbeVolumeSizeInv.xyz
        );
    }

这样就可以采样了。效果图就不贴了。

## Meta Pass
光照贴图是 indirect diffuse，应该受到物体表面颜色的影响。Unity 通过 **Meta Pass** 使用物体颜色 albedo 或者自发光 emission 值来决定弹射光线的颜色，从而决定烘焙出来的间接光照。若没有定义 Meta Pass，Unity 会默认物体表面为白色，这也是为什么之前烘焙出来的光照贴图没收到物体表面颜色影响的原因。

### 一个简单的 Meta Pass
首先在我们的 Shader 中添加一个新的 Pass，LightMode 必须设置为 Meta，同时要关闭剔除：  

    Pass
    {
        Name "Meta"
        
        Tags { "LightMode" = "Meta" }

        Cull Off

        HLSLPROGRAM
        #pragma target 4.5
        
        #pragma vertex MetaVert
        #pragma fragment MetaFrag
        
        #include "StandardForwardMetaPass.hlsl"
        ENDHLSL
    }

顶点着色器和片元着色器写在 StandardForwardMetaPass.hlsl 里面，一个简单的 Meta Pass 如下，先让片元着色器输出白色：  

    #ifndef YPIPELINE_STANDARD_FORWARD_META_PASS_INCLUDED
    #define YPIPELINE_STANDARD_FORWARD_META_PASS_INCLUDED

    #include "../../ShaderLibrary/Core/YPipelineCore.hlsl"
    #include "../../ShaderLibrary/UnityMetaPassLibrary.hlsl"

    CBUFFER_START (UnityPerMaterial)
        float4 _BaseColor;
        float4 _BaseTex_ST;
    CBUFFER_END

    Texture2D _BaseTex;             SamplerState sampler_Trilinear_Repeat_BaseTex;

    struct Attributes
    {
        float4 positionOS   : POSITION;
        float2 uv           : TEXCOORD0;
        float2 lightMapUV   : TEXCOORD1;
    };

    struct Varyings
    {
        float4 positionHCS  : SV_POSITION;
        float2 uv           : TEXCOORD0;
    };

    Varyings MetaVert(Attributes IN)
    {
        Varyings OUT;
        OUT.positionHCS = MetaVertexPosition(IN.positionOS.xyz, IN.lightMapUV);
        OUT.uv = TRANSFORM_TEX(IN.uv, _BaseTex);
        return OUT;
    }

    float4 MetaFrag(Varyings IN) : SV_TARGET
    {
        return float4(1.0, 1.0, 1.0, 1.0);
    }

    #endif

> 我这里犯了个错误，UnityPerMaterial CBuffer 在所有 Pass 中必须一样，否则会破坏 SRP batcher compatibility，需要注意！！

注意顶点着色器，MetaPass 中输出的 positionHCS 不是裁切空间的坐标，而是 lightMapUV 经过一个比较特殊的坐标变换后的坐标。具体变换逻辑在上面代码中的 `MetaVertexPosition()` 函数中，我写在了 UnityMetaPassLibrary.hlsl 里面，其实 core RP library 中的 MetaPass.hlsl 里面也有类似的函数，叫做 `UnityMetaVertexPosition()`，因为我们目前不使用 DynamicLightmap，所以我把它给简化了：  

    float4 MetaVertexPosition(float3 positionOS, float2 lightMapUV)
    {
        positionOS.xy = lightMapUV * unity_LightmapST.xy + unity_LightmapST.zw;
        positionOS.z = positionOS.z > 0.0 ? FLT_MIN : 0.0;
        return TransformWorldToHClip(positionOS);
    }

注意最后返回的是 `TransformWorldToHClip()`，而不是 `TransformObjectToHClip()`，不要搞错了。我之前搞错了，烘焙一直不对，害得我找了好久问题。至于为什么要这样坐标变换，教程里没讲，我在其他网站上也没找到答案，总之就这么变换就行了。此时已经可以烘焙了，并且烘焙出来的效果和没有 Meta Pass 是一模一样的，也就是物体表面均为白色，图片就没必要放了，反正都一样。

### 传递 Albedo 颜色
之前提到过我们需要向 Meta Pass 传递 albedo 或者 emission，需要通过 `unity_MetaFragmentControl` 来判断传递的是什么数据。x 为 true 时传递 albedo，y 为 true 时传递 emission，具体逻辑详见下面的函数中：  

> URP 的 Meta Pass 的颜色输出为 `metaInput.Albedo = brdfData.diffuse + brdfData.specular * brdfData.roughness * 0.5;`，它计算了 diffuse color 和 F0 颜色并合计在了一起，我觉得没有必要，合计数和物体颜色差不了太多，直接输出物体表面颜色就行。 

    struct UnityMetaParams
    {
        float3 albedo;
        float3 emission;
    };

    CBUFFER_START(UnityMetaPass)
        // x = use uv1 as raster position, lightmap
        // y = use uv2 as raster position, DynamicLightmap
        bool4 unity_MetaVertexControl;

        // x = return albedo
        // y = return emission
        bool4 unity_MetaFragmentControl;
    CBUFFER_END

    float unity_OneOverOutputBoost;
    float unity_MaxOutputValue;

    float4 TransportMetaColor(UnityMetaParams params)
    {
        float4 color;
        if (unity_MetaFragmentControl.x)
        {
            color = float4(params.albedo, 1.0);
            // Apply Albedo Boost from LightmapSettings.
            color.rgb = clamp(pow(abs(color.rgb), saturate(unity_OneOverOutputBoost)), 0, unity_MaxOutputValue);
        }

        if (unity_MetaFragmentControl.y)
        {
            color = float4(params.emission, 1.0);
        }
        
        return color;
    }

然后在片元着色器输出就可以了，我这个材质暂时不支持 emission，故 emission 设为 0：  

    float4 MetaFrag(Varyings IN) : SV_TARGET
    {
        UnityMetaParams meta = (UnityMetaParams) 0.0;
        meta.albedo = SAMPLE_TEXTURE2D(_BaseTex, sampler_Trilinear_Repeat_BaseTex, IN.uv).rgb * _BaseColor.rgb;
        meta.emission = 0.0;
        return TransportMetaColor(meta);
    }

最后输出效果如下，可以和之前的效果对比看看，可以看到间接光有了反射的颜色：  

<div  align="center">  
<img src="https://s2.loli.net/2025/01/17/cZSzkfJjdQTw48p.jpg" width = "35%" height = "35%" alt="图51 - Meta Pass 传递颜色"/>
</div>

### 支持 Emission 烘焙
发光物体的烘焙功能不会自动开启，除了需要在 Meta Pass 中输出 emission 值外。还需要在 Shader 中开启 Emission 烘焙功能，但是这个功能是隐藏的，需要通过 ShaderGUI 去开启，有些麻烦：  

``` C#
public override void OnGUI(MaterialEditor materialEditor, MaterialProperty[] properties)
{
    base.OnGUI(materialEditor, properties);
    UnityEmissionProperty();
}

private void UnityEmissionProperty()
{
    EditorGUI.BeginChangeCheck();
    // m_MaterialEditor.LightmapEmissionProperty();
    m_MaterialEditor.LightmapEmissionFlagsProperty(0, true);
    if (EditorGUI.EndChangeCheck())
    {
        foreach (Material m in m_Materials) 
        {
            m.globalIlluminationFlags &= ~MaterialGlobalIlluminationFlags.EmissiveIsBlack;
        }
    }
}
```

`MaterialEditor.LightmapEmissionFlagsProperty` 和 `MaterialEditor.LightmapEmissionProperty` 这两个 API 都是可以的，它们可以让 Emission 的 Global Illumination 下拉菜单出现，默认设置为 None，即不支持 Emission 烘焙到 Light Map，还可以设置为 Realtime 和 Baked。Realtime 是 DynamicLightmap，也就是 Enlighten 系统使用的，我们不支持。

但是这样仍然不够，上述 API 本质是只是绘制 UI。但 Unity 仍然默认所有材质不发光，我们需要取消 `MaterialGlobalIlluminationFlags.EmissiveIsBlack` flag，代码中 `~` 是位非运算符，得到二进制反码。

> ShaderGUI 有需求可以花时间好好了解，上述代码的逻辑我觉得可以更改，重点就在于改变 `Material` 的 `globalIlluminationFlags`，可以不使用 Unity 自带的 LightmapEmissionProperty 来绘制 UI，名称（Global Illumination）很容易让人误解。另外建议查看 globalIlluminationFlags 的官方文档。

<div  align="center">  
<img src="https://s2.loli.net/2025/01/17/HTbc8hAQZNMs9nG.jpg" width = "50%" height = "50%" alt="图52 - Emission Global Illumination 下拉菜单"/>
</div>

<div  align="center">  
<img src="https://s2.loli.net/2025/01/17/QwcAh1lYKEWLiGO.jpg" width = "35%" height = "35%" alt="图53 - Emission 烘焙效果（Unlit Shader）"/>
</div>

### 支持 Transparency 烘焙
烘焙系统会查看材质的渲染队列来决定材质是不透明、透明度裁切还是透明物体。对于透明物体，会自带使用 `_MainTex` 和 `_Color` 这两个属性的 Alpha 通道相乘来作为材质的透明度，或者是使用了 `[MainTexture]` 以及 `[MainColor]` 特性的材质属性，笔记 [Unity URP 基础](https://ybniaobu.github.io/2024/02/23/2024-02-23-URP%E5%9F%BA%E7%A1%80/#%E5%B8%B8%E7%94%A8%E7%9A%84%E6%9D%90%E8%B4%A8%E5%B1%9E%E6%80%A7%E7%9A%84%E7%89%B9%E6%80%A7) 中有对主纹理和主颜色进行说明。对于透明度裁切物体，则自动使用 `_Cutoff` 属性决定透明度测试。烘焙结果如下：  

<div  align="center">  
<img src="https://s2.loli.net/2025/01/17/lY5id4SUnyvJj3I.png" width = "70%" height = "70%" alt="图54 - 左：透明度裁切；右：透明度混合"/>
</div>

# Shadow mask
## Lighting Mode
之前在 Lighting Settings 的 Mixed Lighting 的 Lighting Mode 属性选择的是 Baked Indirect。这个属性决定的其实是 Mixed Mode 下 Lights 的表现，包括三种模式：Baked Indirect、Shadowmask、Subtractive：  
**①Baked Indirect**：就是上一章节讲的模式，在该模式下，Mixed Mode 的灯光具有实时的直接光、实时的阴影（限制到自己设定的最大阴影距离）、烘焙的间接光（动态物体通过探针、静态物体通过 lightmaps）；  
**②Shadowmask**：这个模式跟 Baked Indirect 类似，都提供实时直接光和烘焙的间接光。但是若我们想在自己设定的最大阴影距离内使用实时阴影，之外使用烘焙阴影，就需要使用该模式。该模式下，会烘焙出另外一张贴图，叫做 shadow mask，并且会在光照探针中存储更多信息（称为 **Occlusion Probe**），这样在最大阴影距离之外的动态物体可以通过光照探针获得阴影效果。该模式是 Unity 最推荐的模式，也是最真实、效果最好也最耗性能的模式（本章节就是讲这个模式的）。该模式又分为 Distance Shadowmask 和 Shadowmask，在 Edit -> Project Settings -> Quality -> Shadows -> Shadowmask Mode 设置：  
&emsp;&emsp;&emsp;&emsp; - **Distance Shadowmask**：在最大阴影距离之外的动态物体通过光照探针获得静态物体产生的烘焙阴影效果，静态物体通过 shadow mask 贴图获取静态物体产生的烘焙阴影效果。最大阴影距离之内都是完全的实时阴影，即获得静态和动态物体产生的实时阴影；  
&emsp;&emsp;&emsp;&emsp; - **Shadowmask**：动态和静态物体都在最大阴影距离之内接受动态物体产生的实时阴影，并且都在最大阴影距离的内外都接受静态物体的烘焙阴影（分别通过光照探针和 shadow mask 贴图）。  
**③Subtractive**：这个模式比较特殊，它的混合只对一盏方向光（Main Light）有效。所有静态物体的直接光、间接光和阴影都烘焙进光照贴图，只有一盏方向光对动态物体产生直接光和实时阴影，动态物体能通过光照探针接受烘焙阴影和烘焙间接光。但是这样会导致烘焙阴影和实时阴影的结合问题，即同一方向光下的双重阴影，这是不符合常理的，所以 Unity 在 Lighting Settings -> Environment 中提供了 Realtime Shadow Color 的属性，用于一定程度上缓解双重阴影的问题。我不是很明白为什么该模式称为 Subtractive，但这个模式的效果是最不真实的，所以教程并没有支持这种模式，我的 SRP 也不打算支持。  

## Shadowmask map
在 Lighting Mode 设置为 Shadowmask，以及 Shadowmask Mode 设置为 Distance Shadowmask 后（后面再讲普通的 Shadowmask 模式），点击烘焙可以看到多了一种贴图，如下（场景中只有一盏 Mixed Mode 的方向光，无 Skybox）：  

<div  align="center">  
<img src="https://s2.loli.net/2025/01/18/NtkxGuifyU54Ynv.png" width = "35%" height = "35%" alt="图55 - Shadowmask 贴图"/>
</div>

这张贴图其实就是场上那盏唯一方向光的阴影贴图，只不过是在光照贴图空间下的阴影贴图，并且只包含静态物体的阴影，不包含动态物体的阴影。若我们要使用 Shadowmask map，我们得确保光照方向不发生变化，否则采样它得到的阴影将不太合理。另外，如果场景中的灯光都为 Baked Mode，那么将不会烘焙出 Shadowmask 贴图。

### 传递 Shadowmask 和 Occlusion Probe
还是老样子，首先得指示 Unity 传递 Shadowmask 或 Occlusion Probe 相关数据给 GPU，即设置 PerObjectData：  

``` C#
perObjectData = PerObjectData.Lightmaps | PerObjectData.ShadowMask | PerObjectData.LightProbe | PerObjectData.OcclusionProbe
```

然后我们得设置 shader keyword 用于控制 Shader 使用 Distance Shadowmask 还是 Shadowmask：  