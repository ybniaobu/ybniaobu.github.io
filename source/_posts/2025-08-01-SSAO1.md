---
title: 屏幕空间环境光遮蔽（一）SSAO
date: 2025-08-01 12:54:23
categories: 
  - [图形学]
  - [unity, pipeline]
tags:
  - 图形学
  - 游戏开发
  - unity
top_img: /images/black.jpg
cover: https://s2.loli.net/2025/08/01/287gfDiMYRFrmUs.gif
mathjax: true
description: XXXXXXXXXXXXXXXXXXXXXX
---

> 终于要进入**全局光照 Global Illumination** 的领域了，之前 YPipeline 能够使用的全局光照技术基本只有 **IBL** 和 **Light Map**。Unity 的 Progressive Lightmapper 在离线烘焙 Light Map 时理论上应该隐式地包含了因遮挡导致的环境光减弱的 AO 效果，所以若使用了 Light Map 理论上来说是不需要使用 SSAO 的，当然具体还得看美术需求。Progressive Lightmapper 也提供了 AO 的烘焙，可以额外开启加强 AO 效果。但是若只使用 IBL (Light Probe)，它只为场景添加了一个整体的颜色或者均匀的光照，但是没有考虑因遮挡导致的暗处或光线衰减，所以整体呈现的效果会让玩家在一定程度上感到不真实或不可信。而**环境光遮蔽 Ambient Occlusion (AO)** 通过描绘物体之间由于遮挡而产生的阴影可以更好地增强场景的可信度和立体感，是一个非常不错的补充 IBL 环境光的方式。IBL (Light Probe) + SSAO 的组合可以说是一种较为廉价的全局光照效果，一般对于小作坊的简陋的 3D 游戏来说肯定是足够了的。  
> 
> 其实我原来并不想先补充学习屏幕空间环境光遮蔽相关技术，想直接一步到位进入 SSGI 的学习，但是我后来看到 https://github.com/cdrinmatane/SSRT3 实现的 SSGI 借鉴了 GTAO 的思想，实现效果看得我非常心动，所以为了巩固基础，先实现 SSAO 相关算法。

# Ambient Occlusion 介绍
> 以下内容主要参考了《Real-Time Rendering, Fourth Edition》的 Chapter 11 Global Illumination。  

**环境光遮蔽 Ambient Occlusion** 最早是由**工业光魔**（又是你乔治卢卡斯）在电影《珍珠港》中为提高计算机生成飞机的环境光照质量所开发的。尽管环境光遮蔽是对光照物理效果进行了很大程度地简化，但是所呈现的效果往往能极大地增加可信度。当光源较为均匀，无法展现物体细节时，这种廉价方法可以提供对于物体形状的视觉暗示。

<div align="center">  
<img src="https://s2.loli.net/2025/08/24/GsMnljdwgZOqySr.png" width = "70%" height = "70%" alt="图1 - B25 bomber, Spinosaurus and Tyrannosaurus, Example Ambient Occlusion images. c©Lucas Digital Ltd. LLC."/>
</div>

## 理论基础
量化环境光遮蔽的理论背景就是反射方程，相关知识忘了详见[《GAMES101-图形学入门公开课笔记（二）》](https://ybniaobu.github.io/2024/04/23/2024-04-23-GAMES_101_2/)第十四课和第十五课。因为环境光遮蔽估计的是整个半球内的光照可见性，所以要基于表面 irradiance ($\,E\,$) 计算，表面 irradiance 是所有入射 radiance 的余弦加权积分。同时假设所有入射方向 $\,\omega_{i}\,$ 或 $\,l\,$ 上的 radiance 都是相同且恒定的，这样子计算表面 irradiance，即 $\,E(p)\,$ ，的方程和积分结果如下：  

$$ E(p) = \int_{\Omega} L_i (n \cdot l) dl = \pi L_i $$

上述方程没有考虑可见性问题，在着色点半球范围内的某些方向，可能会被自身物体的其他部分或者是场景中的其他物体所遮挡。为了简单起见，我们假设来自这些遮挡方向上的入射 radiance 为零，这个假设忽略了场景中可能会被其他物体反弹，并最终从这些遮挡方向到达点 p 的光线，但是它极大地简化了推理过程。基于上述假设，补充可见性后，可以得到下述方程：  

$$ E(p) = L_i \int_{\Omega} v(p,l) (n \cdot l) dl = k_{AO}(p) \pi L_i $$

$\,v(p,l)\,$ 是一个**可见性函数**，如果从点 p 向方向 l 投射的光线会被物体遮挡，则该函数值为 0，反之为 1。而 $\,k_{AO}(p)\,$ 则为**环境遮挡系数**，它的范围位于 \[0, 1\] 内，根据上述公式，环境遮挡系数可以被量化为：  

$$ k_{AO}(p) = \cfrac{1}{\pi} \int_{\Omega} v(p,l) (n \cdot l) dl $$

注意，表面的朝向会影响到 $\,k_{AO}(p)\,$ 的数值，因为可见性函数 $\,v(p,l)\,$ 会被余弦加权。若某表面大部分未遮挡区域都位于其表面法线的两端，因此该位置的余弦因子相对较小，$\,k_{AO}(p)\,$ 也会相对较小。还有一点，环境遮挡系数的名称可能会造成一定的误解，它本质上应该是可见性系数，因为它是对可见性函数（未遮挡为 1）的余弦加权积分。

### 环境法线 Bent Normal
除了环境遮挡系数，还有个概念叫做**环境法线 Bent Normal**，首先它是个方向向量，且是未遮挡方向的余弦加权平均值。在计算环境光着色时，可以使用它来代替几何法线，从而提供更加准确的全局光照结果，同时不需要额外的性能开销。注意，环境法线包含了遮挡信息，使用环境法线采样全局光照（IBL）后，理论上不应该再使用其他环境光遮蔽算法，当然实际上还得看美术需求。环境法线的计算公式如下：  

$$ n_{bent} = \cfrac { \int_{\Omega} l\cdot v(p,l) (n \cdot l) dl }{ ||\int_{\Omega} l\cdot v(p,l) (n \cdot l) dl|| } $$

其中符号 $\,||x||\,$ 是向量 x 的长度，积分的结果再除以它自身的长度，即归一化向量。

### Obscurance
环境遮挡系数的可见性函数方法对于封闭的几何体是不起作用的，因为对于封闭的几何体内部的物体来说，来自表面的所有射线都会击中该封闭的空间。所以有人提出了 Obscurance 思想，即通过**距离映射函数** $\,\rho(l)\,$ 来替代可见性函数 $\,v(l)\,$，从而对环境光遮蔽的计算进行了修改：  

$$ k_{AO}(p) = \cfrac{1}{\pi} \int_{\Omega} \rho(l) (n \cdot l) dl $$

距离映射函数是一个连续的函数，其返回值取决于射线与表面相交之前所传播的距离，当相交距离为 0 时，$\,\rho(l)\,$ 的值为 0；当相交距离大于设定的最大距离，或者没有相交时，$\,\rho(l)\,$ 的值为 1。Obscurance 在物理上是不正确的。然而，Obscurance 通常可以给出符合期望的合理结果。

### 相互反射
环境光遮蔽与完整全局光照之间的一个重要区别是**相互反射 interreflection**，所以相对于完整全局光照模拟产生的结果，会更暗一些。Occlusion 假设被遮挡方向上的 radiance 为零，但是实际上相互反射会为这些方向引入一个非零的 radiance。使用 Obscurance 距离映射函数来代替可见性函数也可以缓解这个问题，因为 Obscurance 函数的值通常会大于零。

以一种更加精确的方式来追踪相互反射是很昂贵的，因为它需要求解一个递归问题。想要给一个点进行着色，必须首先对其他点进行着色，以此类推。因此有人提出了一种廉价但较为准确的方法来近似相互反射，它基于在漫反射光照下对 Lambertian 场景的观察，即从一个给定位置能够看见的表面，往往会具有相似的 radiance。假设遮挡方向的 radiance $\,L_i\,$，等于当前着色点的出射 radiance $\,L_o\,$，从而打破递归，可以得到这样一个解析表达式：  

$$ E = \cfrac {\pi k_{AO}}{1 - \rho_{ss}(1 - k_{AO})} L_i $$

其中 $\,\rho_{ss}\,$ 是次表面反照率（漫反射率），上述表达式相当于使用了新的环境遮挡因子 $\,k'_{AO}\,$ 来替代之前的 $\,k_{AO}\,$ ：  

$$ k'_{AO} = \cfrac {k_{AO}}{1 - \rho_{ss}(1 - k_{AO})} $$

上式倾向于让环境遮挡因子变得更大（更亮），从而使得它在视觉上更加接近一个完整全局光照所产生的结果，它在一定程度上模拟了相互反射效应。

### 计算环境光遮蔽
环境遮挡因子的计算可能会很耗时，可以在渲染之前离线计算，预计算任何与光照相关的信息（包括环境光遮蔽），这个过程通常被称为**烘焙 Baking**，预计算环境光遮蔽最常见的方法就是蒙特卡罗方法。除了直接预计算环境光遮蔽的结果，对于静态场景还可以先预先计算环境遮挡因子 $\,k_{AO}\,$ 和环境法线 $\,n_{bent}\,$。遮挡数据对于物体上的每个顶点都是唯一的，它们通常会存储在纹理、体积或者网格顶点中。可以将环境遮挡因子和环境法线（可选）存储一个三维网格中，称为**环境光遮蔽体 ambient occlusion volume**。这类方法的计算成本较低，因为可以从纹理中直接读取出环境遮挡因子，不用实时计算。

但上述方法只适用于静态场景，对于动态场景，还是要实时计算这些参数，实际计算的方式，按照空间可以划分为两类：在**世界空间**中执行的方法和在**屏幕空间**中执行的方法。世界空间中执行的方法跟全局光照技术类似，比如符号距离场 SDF、稀疏体素八叉树 Sparse Voxel Octree 等等，世界空间的方法不是本篇文章的重点，而且对于现在来说，真的要实现，可以直接和全局光照技术一起实现。

在**屏幕空间**中执行的方法中，最出名的当属**屏幕空间环境光遮蔽 screen-space ambient occlusion (SSAO)** 算法，它最早是由 Crytek 在 SIGGRAPH 2007 的演讲 <a href="https://www.realtimerendering.com/advances/s2007/Mittring-Finding_NextGen_CryEngine2(Siggraph07).pdf">Finding Next Gen CryEngine2</a> 中提出，为它的孤岛危机 Crysis 所开发，最早该技术使用 z-buffer 作为唯一的输入，来估计环境遮挡因子 $\,k_{AO}\,$，该方法会将球形范围内的所有样本都考虑在内，而不是只考虑表面上半球范围内的样本，并且没有考虑余弦因子，所以该方法产生的 AO 效果相对来说不太正确，但尽管如此，最终产生结果在视觉上还是令人较为满意的。

<div align="center">  
<img src="https://s2.loli.net/2025/08/24/5PpT7VmQriSXh16.png" width = "50%" height = "50%" alt="图2 - Crytek 的 SSAO，球内样本所对应的深度，超过了 z-buffer 中对应位置的深度，则被认为被遮挡，即图中红色点。环境遮挡因子是通过测试的样本数与总样本数的加权比值。"/>
</div>

Crytek 的方法可以被解释为蒙特卡洛积分，计算出来的值可以称为 **Volumetric Obscurance**，可以被定义为：  

$$ \int_{\chi} d(x) o(x) dx $$

其中 $\,\chi\,$ 是围绕该像素点的一个三维球形邻域，$\,d(x)\,$ 是距离映射函数，$\,o(x)\,$ 是占用函数（occupancy function），即 0 和 1。另外，距离映射函数对于最终视觉质量的影响很小，因此可以使用常数。Szirmay-Kalos 等人据此提出了 [Volumetric Ambient Occlusion](https://cg.iit.bme.hu/~szirmay/ambient8.pdf)，它将积分转换到一个球面上，而不是在一个半球上；这个球体的半径为半球的一半，并且会沿着法线移动一个球体半径的距离，最终这个球体会与半球内接，被半球完全包裹。

之后 NVIDIA 的 Louis Bavoil 和 Miguel Sainz 提出了一个不同的方法，在 SIGGRAPH 2008 的演讲 [Image-Space Horizon-Based Ambient Occlusion](https://developer.download.nvidia.com/presentations/2008/SIGGRAPH/HBAO_SIG08b.pdf) 提出了基于视界的环境光遮蔽，即大名鼎鼎的 **Horizon-Based Ambient Occlusion (HBAO)**，它假设 z-buffer 中的数据表示了一个连续的高度场。通过确定**视界角 horizon angle**，可以对像素点的可见性进行估计，这里的视界角，指的是切面上方被邻域遮挡的最大角度。也就是说，对于某个点上的给定方向，我们会记录最高的可见物体所对应的角度。

再之后，受到上述算法的启发，动视 Activision 的 Jorge Jiménez 在 SIGGRAPH 2016 的演讲 [Practical Real-Time Strategies for Accurate Indirect Occlusion](https://blog.selfshadow.com/publications/s2016-shading-course/activision/s2016_pbs_activision_occlusion.pptx) 提出了 **Ground-truth Ambient Occlusion (GTAO)**，还可以看他们的论文：[链接一](https://www.activision.com/cdn/research/Practical_Real_Time_Strategies_for_Accurate_Indirect_Occlusion_NEW%20VERSION_COLOR.pdf)，[链接二](https://www.activision.com/cdn/research/PracticalRealtimeStrategiesTRfinal.pdf) 。HBAO 在计算遮挡的时候并不包括余弦项，并且它还增加了一个特殊的衰减，因此它的结果最多只能与光线追踪相接近，但是始终还是不一样的。GTAO 引入了缺失的余弦因子，去除了这个特殊的衰减函数，并在绕观察向量的参考系中给出了遮挡积分。

之后会详细讲解 **SSAO**、**HBAO**、**GTAO** 这三种算法，其实在屏幕空间实现的 AO 算法都可以称为 SSAO，所以在文章中提到的 SSAO 需要自行判断是特指 Crytek 的 SSAO 算法还是广义上的 SSAO。

> 其他关于 SSAO 相关算法的文章或演讲有：  
> ① A Comparative Study of Screen-Space Ambient Occlusion Methods ：https://www.gamedevs.org/uploads/comparative-study-of-ssao-methods.pdf ；  
> ② NIVDIA 的 Multi-Layer Dual-Resolution Screen-Space Ambient Occlusion（SIGGRAPH 2009）：https://developer.download.nvidia.com/presentations/2009/SIGGRAPH/Bavoil_MultiLayerDualResolutionSSAO.pdf ；  
> ③ NIVDIA 的 The Alchemy Screen-space Ambient Obscurance Algorithm ：https://research.nvidia.com/publication/2011-08_alchemy-screen-space-ambient-obscurance-algorithm ；  
> ④ NIVDIA 的 Scalable Ambient Obscurance ：https://research.nvidia.com/publication/2012-06_scalable-ambient-obscurance ；  
> ⑤ Efficient Screen-Space Approach to High-Quality Multi-Scale Ambient Occlusion：https://www.comp.nus.edu.sg/~lowkl/publications/mssao_visual_computer_2012.pdf 。


## 着色中的运用
### Diffuse Occlusion
我们计算出环境遮挡系数 $\,k_{AO}\,$ 之后，如何在着色光照计算中进行运用呢？首先只讨论**漫反射遮蔽 Diffuse Occlusion**，回顾反射方程，假设漫反射 Lambertian 表面，使用 Lambertian BRDF 作为反射方程的 $\,f_r(l, v)\,$，并补充上可见性函数 $\,v(l)\,$：  

$$ L_o = \int_{\Omega} \cfrac {\rho_{ss}}{\pi} L_i v(l) (n \cdot l) dl = \cfrac {\rho_{ss}}{\pi} \int_{\Omega} L_i v(l) (n \cdot l) dl $$

从中拆分出 $\,k_{AO}\,$ 项：  

$$ \begin{align*} L_o &= \cfrac {\rho_{ss}}{\pi} \int_{\Omega} L_i v(l) (n \cdot l) dl \\ &= \cfrac {\rho_{ss}}{\pi} \cfrac {\int_{\Omega} L_i v(l) (n \cdot l) dl}{\int_{\Omega} v(l) (n \cdot l) dl} \int_{\Omega} v(l) (n \cdot l) dl \\ &= \rho_{ss} k_{AO} \cfrac {\int_{\Omega} L_i v(l) (n \cdot l) dl}{\int_{\Omega} v(l) (n \cdot l) dl} \end{align*} $$

接下来做出了一个大胆的假设，就是忽略了可见性函数，忽略可见性是一个影响很大的近似操作，所产生的阴影没有任何预期的方向性，也就是说，它们看起来并不像是由特定光源产生的，比如精确光源。那么上面公式可以进一步简化为（余弦在单位半球上积分为 $\,\pi\,$）：  

$$ \begin{align*} L_o &\approx \rho_{ss} k_{AO} \cfrac {\int_{\Omega} L_i (n \cdot l) dl}{\int_{\Omega} (n \cdot l) dl} \\ &= \cfrac {\rho_{ss}}{\pi} k_{AO} \int_{\Omega} L_i (n \cdot l) dl \\ &= k_{AO} \int_{\Omega} \cfrac {\rho_{ss}}{\pi} L_i (n \cdot l) dl \end{align*} $$

$\,k_{AO}\,$ 后面的部分就是漫反射 BRDF 计算的 IBL 环境光积分，忘了回去看 [IBL 基于图像的光照（一）](https://ybniaobu.github.io/2024/07/09/2024-07-09-IBL_Basics1/#%E6%BC%AB%E5%8F%8D%E5%B0%84-BRDF-%E7%A7%AF%E5%88%86)。这意味着，可以直接通过计算 irradiance，即 IBL，并将其乘上环境光遮蔽值来完成环境光遮蔽的效果着色。

### Specular Occlusion
到目前为止，我们都是假设处理的是 Lambertian BRDF，对于**镜面反射遮蔽 Specular Occlusion** 来说，直接乘以 $\,k_{AO}\,$ 项可能无法产生可信的结果，因为此时除了可见性和法线，还取决于观察方向。同时，相比于漫反射的半球波瓣，镜面反射的 BRDF 波瓣也更窄。

寒霜引擎在它的 [Moving Frostbite to Physically Based Rendering 3.0](https://media.contentapi.ea.com/content/dam/eacom/frostbite/files/course-notes-moving-frostbite-to-pbr-v32.pdf) (SIGGRAPH 2014) 中提到过一个近似方法来模拟 GGX 波瓣的镜面反射遮蔽效果，对于粗糙表面来说，下述公式得到的 AO 值几乎是没有修改的，但对于光滑表面来说，观察方向越接近法线，ao 效果越低，即值越高，越接近掠射角，ao 效果越大，即值越低：  

    float computeSpecOcclusion ( float NdotV , float AO , float roughness )
    {
        return saturate (pow( NdoV + AO , exp2 ( -16.0 f * roughness - 1.0 f )) - 1.0 f + AO );
    }

具体如何应用，我在 [Custom Better PBR in Unity](https://ybniaobu.github.io/2024/10/22/2024-10-22-BetterPBR1/#Ambient-Occlusion) 文章中的 Ambient Occlusion 中有详细说明过，就不再赘述了。

而动视 Activision 在 GTAO 中还提出了 **Ground Truth Based Specular Occlusion (GTSO)**，使用了类似于分割求和近似 Split Sum Approximation（由 Epic Games 在 SIGGRAPH 2013 的 [Real Shading in Unreal Engine 4](https://cdn2-unrealengine-1251447533.file.myqcloud.com/Resources/files/2013SiggraphPresentationsNotes-26915738.pdf) 中提出）的方法，将 Visibility 项也拆分了出来，这个之后学习 GTAO 时会详细说明。

**<font color = red> 【TODO：可能还有很多内容可以补充，看看 GDC 或 SIGGRAPH 的演讲】 </font>**

# Normal Buffer
因为 SSAO 算法需要使用到场景法线信息，在正式进入 SSAO 之前，先了解一下获取法线信息的方式，基本上有两张方式：①通过 Normal Buffer；②通过 Depth Buffer 重建法线信息。

我们先讲额外开 Normal Buffer 的方式，对于延迟管线，GBuffer 肯定是要存储法线信息的，不需要额外处理，对于前向管线，则需要额外开一张 Normal Buffer（和其他前向管线需要使用的场景信息一起又可称为 **Thin G-Buffer**），可以和 Depth Prepass 一起输出。我目前的前向管线参考了 Unity HDRP 前向管线的方案，开了格式为 R8G8B8A8_UNORM 的 Normal Buffer，使用**八面体法线编码 Octahedral Normal Vectors** 将压缩好的两个 float 打包进了 R8G8B8 三个通道，A 通道存储 Rougness 以便后续的 SSR 使用。

> 我看到 DOOM (2016) 的前向管线是 R16G16 + R8G8B8A8 的方式，R16G16 应该是八面体压缩法线后直接存储（猜测，不是很确定，总不至于是 xy only 的存储方式吧），R8G8B8A8 的前三个通道存储了 F0，A 通道存储了 Rougness。而 DOOM Eternal 的前向管线甚至没开 Thin G-Buffer，直接将 SSR 计算放在了 Forward Uber Shader 中，而不是使用 Compute Shader 计算，这点非常神奇。绝大多数的延迟管线游戏的 Normal Buffer，我看到是以 R10G10B10A2_UNORM 不压缩的形式存储前三个通道为主，少数 R8G8B8A8_UNORM，追求精度则是 R16G16_UNORM。从精度来看，应该是 Octahedron 32 > Octahedron 24 > UNORM 10×3 > Octahedron 20 的。关于各种压缩存储 Normal 精度问题可以详看这篇文章：[A Survey of Efficient Representations for Independent Unit Vectors](https://jcgt.org/published/0003/02/01/) 。

下面聊一下 Normal Buffer 的各种压缩存储方式。

## Normal Encoding
首先说明一下，采样 Normal Buffer 无论有没有压缩，使用 Linear 采样器，得到的插值结果都是不对的，会导致一定的渲染瑕疵。之前在讲法线混合的时候就提到过，即使先对 Normal Texture 解码，再线性混合，所得到的结果也是不对的，更不要说直接线性混合压缩过的法线。所以采样 Normal Buffer 最好使用 **Point/Nearest 采样器**。

可能有人会问，为什么 Shader 采样法线贴图的时候，一般使用 Linear 采样器，这是因为法线贴图总是代表某一模型上的法线信息，虽然线性插值会导致凹凸细节看起来变得更平滑，但是却可以因此避免一些锯齿状瑕疵，在视觉上往往也是可以接受的，而且我们会在着色器中再对采样结果进行 normalize 操作，去修正长度。而 Normal Buffer 不同，它代表着场景的世界法线信息，Linear 采样器很可能会混合到不同物体的法线，特别是物体的边缘，混合来自不同表面、不同朝向的法线是毫无意义的，并且会造成一些着色瑕疵。

而常见的对 Normal Buffer 的存储或压缩方式有：  

***①不压缩***：  
&emsp;&emsp; - 直接使用 R16G16B16A16_SNorm 存储，这样子精度是非常高的，虽然非常不常见。但是 Mafia: Definitive Edition 就是这么做的，它使用的还是 R16G16B16A16_SFloat，并且还在 A 通道存储了 Roughness。我看了一下 R16G16B16A16_SFloat 的误差应该是比输出 32 位的八面体编码要大的，但 R16G16B16A16_SNorm 的误差比 32 位八面体要小；  
&emsp;&emsp; - 映射至 0 - 1，并使用 R10G10B10A2_UNORM 的前三个通道存储，这种方式应该是 PC 端游戏最常见的方式了。另外，不推荐使用 R11G11B10_UFLOAT，因为 11-bit Float 精度分布是不均匀的，越接近零的数值，间隔越小（精度越高），越远离零的数值，间隔越大（精度越低）。在接近零的地方，11 位浮点数可以表示非常细小的变化，但在接近 1 的地方，其精度会迅速下降。具体来说，当数值大于 0.2 时，11 位浮点数的精度就已经不如 10 位 UNorm。而 10 位 UNorm 在 0 到 1 的范围内，这 1024 个值是均匀分布的。关于 R11G11B10 的精度问题，可以查看这篇文章：https://bartwronski.com/2017/04/02/small-float-formats-r11g11b10f-precision/ 。这个方式的编码和解码代码也很简单：  

    float3 encode(float3 n)
    {
        return n.xyz * 0.5 + 0.5;
    }

    float3 decode(float3 enc)
    {
        return enc.xyz * 2 - 1;
    }

***② XY Only***：  
这种方式看似美好，但是这种存储方式是极其不均匀的，看 z 的计算公式：  

    n.z = sqrt(1 - dot(n.xy, n.xy));

因为要开根号，所以当 xy 在 1 附近时，z 接近 0 时，x 或 y 分量上一个极小的量化误差或插值误差，都会导致计算出的 z 分量产生巨大的相对误差。

***③坐标映射/投影等压缩方案***：  
这里简单介绍一下常见的压缩方案，主要详细介绍八面体映射，其他方案详见这篇文章：[Compact Normal Storage for small G-Buffers](https://aras-p.info/texts/CompactNormalStorage.html#method04spheremap) 。  
&emsp;&emsp; - **球坐标 Spherical Coordinate** 或**经纬映射 Latitude-Longitude Mapping**：即使用球坐标的天顶角和方位角两个变量存储法线，经纬映射就是对球坐标映射至 \[0, 1\]；  
&emsp;&emsp; - **极射赤面投影法 Stereographic Projection**，具体详见维基百科：https://en.wikipedia.org/wiki/Stereographic_projection ，计算公式如下：  

$$ (X,Y) = \left(\cfrac{x}{1 - z} ,\cfrac{y}{1 - z} \right) $$
$$ (x,y,z) = \left( \cfrac{2X}{1 + X^2 + Y^2} , \cfrac{2Y}{1 + X^2 + Y^2}, \cfrac{-1 + X^2 + Y^2}{1 + X^2 + Y^2} \right) $$

&emsp;&emsp; - **兰勃特方位等积投影 Lambert Azimuthal Equal-Area projection**，还是详见维基百科：https://en.wikipedia.org/wiki/Lambert_azimuthal_equal-area_projection ，计算公式如下：  

$$ (X,Y) = \left( \sqrt{\cfrac{2}{1 - z}}x ,\sqrt{\cfrac{2}{1 - z}}y \right) $$
$$ (x,y,z) = \left( \sqrt{1 - \cfrac{X^2 + Y^2}{4}}X , \sqrt{1 - \cfrac{X^2 + Y^2}{4}}Y, -1 + \cfrac{X^2 + Y^2}{2} \right) $$

类似上述的制图投影应该还有很多，有兴趣可以额外去了解，目前的主流方案应该还是**八面体压缩 Octahedron Encoding**，并且从 A Survey of Efficient Representations for Independent Unit Vectors 的测试来看，在相同位数下，上述映射方式跟八面体压缩相比平均误差会大一点，当然也有比八面体压缩更高精度的压缩方式，但基本上都比八面体压缩更耗性能。

> 关于各种球面映射或者球函数，建议详细阅读这篇论文：[Spherical Function Representations: a Practical Survey](https://jojendersie.de/wp-content/uploads/2013/06/sfcsurvey.pdf) 。

### Octahedral Normal Vectors
**八面体映射 Octahedral Mapping** 就是将三维单位向量投影到正八面体的表面，然后将该八面体展开成二维平面，这种方式得到的分布是较为均匀的，具体如下图：  

<div align="center">  
<img src="https://s2.loli.net/2025/08/24/BbeEzY5ouLTFnQh.png" width = "50%" height = "50%" alt="图3 - Octahedral Mapping"/>
</div>

看起来映射方式较为复杂，但实际上映射方式非常简单，因为描述单位八面体的公式较为简单，即：  

$$ |x| + |y| + |z| = 1 $$

映射过程分为两步：①将球面投影到八面体表面，就是对 x, y, z 除以 $\,|x| + |y| + |z|\,$ 的值，这个过程相当于将球面“挤压”到八面体的表面上；②将八面体表面展开成一个平面，对于 z 大于 0 的情况来说，不需要任何转换，如果 z 小于 0，则将 x, y 反转即可。注意，八面体压缩后获得的两个坐标的范围是 \[-1, 1\]，若想输出 \[0, 1\] 范围值还需要再映射一次。代码如下：  

    float2 PackNormalOctQuadEncode(float3 n)
    {
        n *= rcp(max(dot(abs(n), 1.0), 1e-6));
        float t = saturate(-n.z);
        return n.xy + float2(n.x >= 0.0 ? t : -t, n.y >= 0.0 ? t : -t);
    }

    float3 UnpackNormalOctQuadEncode(float2 f)
    {
        float3 n = float3(f.x, f.y, 1.0 - (f.x < 0 ? -f.x : f.x) - (f.y < 0 ? -f.y : f.y));

        float t = max(-n.z, 0.0);
        n.xy += float2(n.x >= 0.0 ? -t : t, n.y >= 0.0 ? -t : t);

        return normalize(n);
    }

这段代码是 Unity 根据 A Survey of Efficient Representations for Independent Unit Vectors 上的代码而来的，并且根据推特上的[一个帖子](https://twitter.com/Stubbesaurus/status/937994790553227264)做出了优化，它巧妙得利用了 z 轴的数据，减少了一次判断。还有就是，`sign()` 是比三元操作符 `x >= 0 ? 1 : -1` 要昂贵的。

将法线的三个坐标值转换为八面体的两个坐标后，我们可以选用贴图的两个通道来存储，常见的存储方式有 Octahedron 20、Octahedron 24 以及 Octahedron 32。Octahedron 20 就是选用格式 R10G10B10A2_UNORM 的前两个通道，但据说 20 个 bit 的视觉瑕疵在拉近距离时是较为明显的，而视觉瑕疵的临界点大概在 22~23 个 bit 左右（道听途说的，不确定）。而 Octahedron 32 即格式 R16G16_UNORM，追求高精度的视觉效果可以选择这个。Octahedron 24 则相对麻烦点，需要将两个数据打包进 R8G8B8A8_UNORM 的前三个通道当中，打包的代码我就不摘抄了，详见 Unity 的实现代码。

另外提一下，还有一种对八面体映射的改进叫做**同心/轴八面体映射 Concentric Octahedral Map**，它结合了同心映射和八面体映射，具体详见这篇论文：[Fast Equal-Area Mapping of the (Hemi)Sphere using SIMD](https://fileadmin.cs.lth.se/graphics/research/papers/2008/simdmapping/clarberg_simdmapping08_preprint.pdf) ，这种方式比八面体映射更加均匀，当然也要更昂贵一些。

## Derived From Depth Buffer
除了额外开 Normal Buffer 的方法外，还可以直接通过 Depth Buffer 重建法线信息。但是通过 Depth Buffer 重建法线的方式，相比于直接采样 Normal Buffer 走样瑕疵会更多一点，所以 PC 端的前向管线建议还是开 Normal Buffer，移动端可以考虑使用 Depth Buffer 重建法线。

而通过 Depth Buffer 重建法线的方式有两种：  
**①**通过内置函数 `ddx()` / `ddy()` 重建法线；  
**②**通过计算当前像素点以及邻近像素点的世界坐标，然后计算法线；

### ddx/ddy 重建法线
HLSL 中叫 `ddx()` / `ddy()`，GLSL 中叫 `dFdx()` / `dFdy()`，在像素 (片元) 着色器中，用来快速估算水平方向和垂直方向上数值变化率（导数）的内建函数。在三角形光栅化阶段，GPU 会成批（每批 2×2 像素，称为 **Quad**）地并行运行多个片元着色器实例，如果你渲染一个三角形，并且它没有覆盖整个 2x2 Quad，那么空像素仍然需要运行，即使三角形只覆盖一个像素。而导数就是在 Quad 中进行计算的，只有栅格化时才执行 Quad，因此 ddx 和 ddy 只能在像素 (片元) 着色器中才能使用。

导数的计算就是在同一 Quad 内对像素值做差分，从下图可以看出来 ddx 就是右边的像素块的值减去左边像素块的值，而 ddy 就是下面像素块的值减去上面像素块的值。其中的 x，y 代表的是屏幕坐标。

<div align="center">  
<img src="https://s2.loli.net/2025/08/24/sjXd84ACEtBgKyh.jpg" width = "50%" height = "50%" alt="图4 - ddx/ddy"/>
</div>

然后 `ddx(f)` / `ddy(f)` 的参数 f 可以是标量和任意向量浮点元素值，是要被计算导数的变量。之所以可以计算数值变化率（导数），是因为光栅化阶段的顶点属性插值是线性插值。这个 `ddx(f)` / `ddy(f)` 也是在纹理采样过程中计算 **mipmap** 级别的依据，贴图 uv 偏导数过大的时候代表贴图离我们过远，就会选择低等级的 mipmap，在 Shader 中采样纹理时，采样的内部代码类似如下：  

    float lod = log2(max(length(ddx(uv)), length(ddy(uv))));
    tex.SampleLevel(sampler, uv, lod);


如果调用 `ddx(Pos)` / `ddy(Pos)` 就可以求出水平垂直坐标的两个差值，即两个向量，而这两个向量都在这个三角形的平面上，将这两个向量做叉乘，结果就是是垂直于这两条“边”所在平面的向量，即三角形的面法线：  

    normalize(cross(ddx(IN.worldPos), ddy(IN.worldPos)));

用这种方法重构出来的法线，在物体边缘处是有较多的 artifacts 的，并且该方法只能在片元着色器中使用，不能在 compute shader 中使用，因此不推荐使用。

### 邻近像素点重建法线
这个方法的原理其实和 ddx/ddy 是一样的，就是取邻近像素点的世界坐标的位置，计算出两个向量，再叉乘计算出法向量。关于这个方法可以参考这两篇文章：[Improved normal reconstruction from depth](https://wickedengine.net/2019/09/improved-normal-reconstruction-from-depth/) ，[Accurate Normal Reconstruction from Depth Buffer](https://atyuwen.github.io/posts/normal-reconstruction/#fn:2) 。

但是这个方法假设了邻近像素点属于同一个物体，所以当邻近像素点属于不同物体时（即物体边缘时），这个方法会出现瑕疵，当给 SSAO 使用时，物体边缘会出现黑边。所以在选择邻近像素点时，Improved normal reconstruction from depth 这篇文章推荐在上下左右 4 个像素点中，选择离中心像素点最近的两个像素点，计算向量并叉乘。代码大致如下（ue4 的代码）：  

    float DeviceZ = depth;
    float DeviceZLeft = sampleDepth(uv + lUV);
    float DeviceZTop = sampleDepth(uv + uUV);
    float DeviceZRight = sampleDepth(uv + rUV);
    float DeviceZBottom = sampleDepth(uv + dUV);

    float DeviceZDdx = TakeSmallerAbsDelta(DeviceZLeft, DeviceZ, DeviceZRight);
    float DeviceZDdy = TakeSmallerAbsDelta(DeviceZTop, DeviceZ, DeviceZBottom);

    float ZRight = (DeviceZ + DeviceZDdx);
    float ZDown = (DeviceZ + DeviceZDdy);

    float3 Right = GetViewPosition(uv + rUV, ZRight) - vPos;
    float3 Down = GetViewPosition(uv + dUV, ZDown) - vPos;
    return float3(normalize(cross(Right, Down)));

其中 `TakeSmallerAbsDelta`：  

    float TakeSmallerAbsDelta(float left, float mid, float right)
    {
        float a = mid - left;
        float b = right - mid;
        return (abs(a) < abs(b)) ? a : b;
    }

# SSAO
> SSAO 的相关内容主要参考了以下几篇文章：  
> ①Learn OpenGL 教程中的 SSAO 章节：https://learnopengl.com/Advanced-Lighting/SSAO ；  
> ②John Chapman 的博客文章 SSAO Tutorial：http://john-chapman-graphics.blogspot.com/2013/01/ssao-tutorial.html ；  
> ③Alex Tardif 的博客文章 SSAO ：https://alextardif.com/SSAO.html 。

前面有提到过，SSAO 最早由 Crytek 为孤岛危机 Crysis 开发，当时这个算法的思想非常简单，没有使用到场景的法线信息，只使用了 depth buffer，大致思想就是对于屏幕的每一个像素都计算一个 **Occlusion Factor**，步骤如下：  
①根据当前屏幕的像素位置，生成数个球形范围内的样本；  
②计算出这些样本的屏幕空间的坐标以及深度，同时根据屏幕空间坐标对 depth buffer 进行采样；  
③若这些样本的真实深度，比采样 depth buffer 得到的深度远，即被遮挡，则贡献于 Occlusion Factor。

<div align="center">  
<img src="https://s2.loli.net/2025/08/25/W1zMwuB9dIU7Svm.jpg" width = "30%" height = "30%" alt="图5 - Each of the gray depth samples that are inside geometry contribute to the total occlusion factor"/>
</div>

上述方法得到的结果其实是不太对的，但在视觉上还算可以接受。因为采样区域是球形，故平整的墙面也会是灰色，因为一半的样本是被遮挡的，而物体边缘因为只有少数样本会被遮挡，看起来会比其他区域白，如下图：  

<div align="center">  
<img src="https://s2.loli.net/2025/08/25/r7F6LxAdYIM24pz.png" width = "45%" height = "45%" alt="图6 - Crytek SSAO in 2007"/>
</div>

而接下来要实现的 SSAO 对上述方法进行了两个改进：①在以 normal 为朝向的半球内进行采样；②使用余弦权重，让算法相对来说更符合理论公式。虽然做出了改进，但使用 Normal-oriented Hemisphere 的 SSAO 与 Crysis 的 SSAO 的步骤基本上没有什么区别。

<div align="center">  
<img src="https://s2.loli.net/2025/08/25/uWYE81cQyZ2hjS3.jpg" width = "30%" height = "30%" alt="图7 - Normal-oriented Hemisphere"/>
</div>

## 基本实现
> 我的实现也会和著名的 SSAO 教程，即 [john-chapman](http://john-chapman-graphics.blogspot.com/2013/01/ssao-tutorial.html) 的教程，以及 LearnOpenGL 的教程有些许不同。

### 生成半球样本
我们要在像素点的半球领域内生成样本，john-chapman 的教程中是对 xyz 三个值取范围 \[0, 1\] 的随机值，再进行归一化确保每个样本在半球表面，再对每个样本乘以 0 - 1 的随机值进行缩放，让所有样本分布在半球内部。这样子生成的样本，首先在半球表面上应该是不均匀的（我没有验证过，但应该是对的），因为这样子其实生成的是立方体内的均匀样本，在立方体四个角方向上的样本应该是偏多的。其次在半球内也是不均匀的，靠近圆心的样本会多。

于是我很快就想到了**逆变换采样**，但是要注意区分半球表面均匀采样和半球内均匀采样，若使用半球表面，并对每个样本乘以 0 - 1 的随机值进行缩放，靠近圆心的样本会多，如下面所示。半球内均匀采样的公式如下（假设在左手坐标系下，$\,\phi\,$ 是 xz 平面上离 x 轴的角度，范围在 $\,[-\pi, \pi]\,$ 之间，$\,\theta\,$ 是相对于 y 轴的角度，范围在 $\,[0, \pi]\,$ 之间，半球就是 $\,[0, \pi / 2]\,$ ）：

$$ \theta = arccos(1 - \xi_1) $$
$$ \phi = 2 \pi \xi_2 - \pi $$
$$ r = \sqrt[3]{\xi_3} $$

<div align="center">  
<img src="https://s2.loli.net/2025/08/25/E3G58YoQskVbF6C.png" width = "60%" height = "60%" alt="图8 - 左图：半球内均匀采样；右图：半球表面均匀采样，并且 r 为 0 - 1 的随机值"/>
</div>

然而半球内均匀采样的最终结果并不好，因为我们不可能在无限距离上生成样本，我们需要规定一个半径值，而规定了半径值会导致 SSAO 出现泾渭分明的边线，特别是墙壁拐角处。所以为了生成平滑的 SSAO 效果，我们会选择让样本更集中在圆心附近，而这种方法其实是一种**隐式的距离映射函数**，即上面理论介绍小节中讨论到的 **Obscurance** 的思想，即距离越远样本对 **Occlusion Factor** 的贡献越小。虽然 Obscurance 不符合物理准则，但是这样子效果确实会更好。根据实践，即使采用了 $\,r = \xi_3\,$ 随机值的半球样本，样本向球心的聚拢程度仍然不够，最好对 r 再乘上一次 $\,\xi_3\,$，即 $\,r = \xi_3 * \xi_3\,$ 。

【增加：Fibonacci Spiral ！！！！！！！！！！！！】

还有就是我们要考虑余弦权重的问题，毕竟 AO 的公式中带有余弦权重，余弦半球表面采样的代码如下：  

    float4 CosineSampleHemisphere(float2 xi) // Left-handed Spherical and Cartesian Coordinate
    {
        float phi = PI * (2.0 * xi.x - 1.0);
        float cosTheta = sqrt(1 - xi.y);
        float sinTheta = sqrt(1 - cosTheta * cosTheta);

        float3 N = float3(sinTheta * cos(phi), cosTheta, sinTheta * sin(phi));
        float PDF = cosTheta * INV_PI;
        return float4(N, PDF);
    }



## Downsample
depth/normal downsample

## Filter
### Spatial Filter

### Temproal Filter
Stable SSAO in Battlefield 3 with Selective Temporal Filtering : https://d29g4g2dyqv443.cloudfront.net/sites/default/files/akamai/gamedev/files/gdc12/GDC12_Bavoil_Stable_SSAO_In_BF3_With_STF.pdf

## Upsample


# 其他说明
## SSDO
