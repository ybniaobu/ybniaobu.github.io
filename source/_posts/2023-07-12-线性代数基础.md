---
title: 线性代数
date: 2023-07-12 19:07:45
categories: 
  - [数学, 3d数学基础]
tags:
  - 游戏开发
  - 数学
top_img: /images/black.jpg
cover: https://s2.loli.net/2023/07/12/tAXf9jPcbOqzyDN.gif
mathjax: true
---

> 该笔记来源于《麻省理工公开课：线性代数》，以及 MLNLP 的关于该公开课的 GitHub 公开项目的笔记：<https://github.com/MLNLP-World/MIT-Linear-Algebra-Notes>  
> 公开课 B 站 bv 号：BV16Z4y1U7oU


# 第一课 方程组的几何解释
通过一个例子来阐述对**方程组的不同几何理解**：

方程组形式：  

$$ \left\{ \begin{array}{c} 2x - y = 0 \\ −x + 2y = 3  \end{array} \right.\\ $$

列向量形式：

$$ x\begin{bmatrix} 2 \\ -1 \end{bmatrix} + y \begin{bmatrix} -1 \\ 2 \end{bmatrix} = \begin{bmatrix} 0 \\ 3 \end{bmatrix} $$

矩阵形式：

$$ \begin{bmatrix} 2 & -1 \\ -1 & 2 \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} 0 \\ 3 \end{bmatrix} $$

①方程组形式（行图像）的理解：在坐标系的两条直线，相交点即为解；  
②列向量形式（列图像）的理解：将公式左侧的向量以未知方式进行组合，组合的结果为右侧向量，该未知组合为解；  
③矩阵形式的理解：即坐标系变换，将未知向量进行矩阵坐标系变换得到的结果为右侧向量，该未知向量为解。

**矩阵乘法**：  
方法 1，将矩阵看做列向量的组合（建议使用这个理解，更好一点）：

$$ \begin{bmatrix} 2 & 5 \\ 1 & 3 \end{bmatrix} \begin{bmatrix} 1 \\ 2 \end{bmatrix} = 1\begin{bmatrix} 2 \\ 1 \end{bmatrix} + 2\begin{bmatrix} 5 \\ 3 \end{bmatrix} = \begin{bmatrix} 12 \\ 7 \end{bmatrix} $$

方法 2，将矩阵 A 看做行向量的组合（点乘）：

$$ \begin{bmatrix} 2 & 5 \\ 1 & 3 \end{bmatrix} \begin{bmatrix} 1 \\ 2 \end{bmatrix} = \begin{bmatrix} (2, 5)\cdot(1, 2) \\ (1, 3)\cdot(1, 2) \end{bmatrix}  = \begin{bmatrix} 12 \\ 7 \end{bmatrix} $$

# 第二课 消元法
## 消元法介绍
$ 求解方程组: \left\{ \begin{aligned} x + 2y + z &= 2 \\ 3x + 8y + z &= 12 \\ 4y + z &= 2  \end{aligned} \right.\\ $

使用矩阵运算，将方程写为矩阵形式 Ax = b（系数矩阵为 A）：  

$$ \begin{bmatrix} 1 & 2 & 1 \\ 3 & 8 & 1 \\ 0 & 4 & 1 \end{bmatrix} \begin{bmatrix} x \\ y \\ z\end{bmatrix} = \begin{bmatrix} 2 \\ 12 \\2 \end{bmatrix} $$

**增广矩阵 Augmented matrix** 就是在系数矩阵的右边添上一列，即线性方程组的等号右边的值：

$$ \left[ \begin{array}{ccc|c} 1 & 2 & 1 & 2 \\ 3 & 8 & 1 & 12 \\ 0 & 4 & 1 & 2 \end{array} \right] \to \left[ \begin{array}{ccc|c} 1 & 2 & 1 & 2 \\ 0 & 2 & -2 & 6 \\ 0 & 4 & 1 & 2 \end{array} \right] \to \left[ \begin{array}{ccc|c} 1 & 2 & 1 & 2 \\ 0 & 2 & -2 & 6 \\ 0 & 0 & 5 & -10 \end{array} \right] $$

消元后的矩阵就是：

$$ \left\{ \begin{aligned} x + 2y + z &= 2 \\ 2y - 2z &= 6 \\ 5z &= -10  \end{aligned} \right.\\ $$

然后就可以求解了，和解二元一次方程组的消元法一模一样。

## 消元矩阵
①行向量与矩阵的乘法（这里先知道一下，之后会讲）

$$ \begin{bmatrix} 1 & 2 & 7 \end{bmatrix} \begin{bmatrix} ? & ? & ? \\ ? & ? & ? \\ ? & ? & ? \end{bmatrix} $$

上述公式可理解为 1 乘以第一行，2 乘以第二行，7 乘以第三行，解为行向量。而第一课的列向量是 x 乘以第一列，y 乘以第二列，z 乘以第三列，解为列向量。至于为什么一个在左侧和一个右侧，见后面，即**矩阵运算不符合交换律 commutative law**。

②消元矩阵介绍（重点）

首先先看**单位矩阵 identity matrix**：
$$ \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} 1 & 2 & 1 \\ 3 & 8 & 1 \\ 0 & 4 & 1 \end{bmatrix} = \begin{bmatrix} 1 & 2 & 1 \\ 3 & 8 & 1 \\ 0 & 4 & 1 \end{bmatrix} $$

把单位矩阵看成三行，即[1 0 0]，[0 1 0]，[0 0 1]。可以看作三个行向量与矩阵乘法，首先 [1 0 0]，1个第一行，0个第二行和第三行，结果为值为第一行的行向量。依此类推，得到原矩阵。

所以上面消元法的矩阵可以写成：

$$ \begin{bmatrix} 1 & 0 & 0 \\ -3 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} 1 & 2 & 1 \\ 3 & 8 & 1 \\ 0 & 4 & 1 \end{bmatrix} = \begin{bmatrix} 1 & 2 & 1 \\ 0 & 2 & -2 \\ 0 & 4 & 1 \end{bmatrix} $$

可以算一下，结果矩阵的第二行，即 -3 个参数矩阵的第一行，1 个第二行和 0 个第三行组合而成。另外：若想得到结果矩阵的第二行第三列的数字，就需要第一个矩阵的第二行，第二个矩阵的第三列的数字。

## 置换矩阵 Permutation  
左乘置换矩阵可以完成原矩阵的行变换：

$$ \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix} \begin{bmatrix} a & b \\ c & d \end{bmatrix} = \begin{bmatrix} c & d \\ a & b \end{bmatrix} $$

右乘置换矩阵则为列变换：

$$ \begin{bmatrix} a & b \\ c & d \end{bmatrix} \begin{bmatrix} 0 & 1 \\ 1 & 0 \end{bmatrix} = \begin{bmatrix} b & a \\ d & c \end{bmatrix} $$

对于三阶矩阵，一共有 6 个置换矩阵：  

$$ \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} 0 & 1 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} 1 & 0 & 0 \\ 0 & 0 & 1 \\ 0 & 1 & 0 \end{bmatrix} \begin{bmatrix} 0 & 1 & 0 \\ 0 & 0 & 1 \\ 1 & 0 & 0 \end{bmatrix} \begin{bmatrix} 0 & 0 & 1 \\ 0 & 1 & 0 \\ 1 & 0 & 0 \end{bmatrix} \begin{bmatrix} 0 & 0 & 1 \\ 1 & 0 & 0 \\ 0 & 1 & 0 \end{bmatrix} $$

我们任取两个矩阵相乘，结果仍在这个 6 个矩阵中。

## 逆矩阵初探 Inverse
消元矩阵的逆矩阵的实施效果就是抵消原矩阵的消元操作。消元矩阵实现了对原矩阵 A 的操作，使第二行行向量 [3, 8, 1] 减掉了第一行 [1, 2, 1] 的3倍变为 [0, 2, -2]，则逆向操作就应该是把现在的第二行行向量 [0, 2, -2] 加上第一行 [1, 2, 1] 的3倍，从而变回原来的第二行 [3, 8, 1]。

所以对于$ E = \begin{bmatrix} 1 & 0 & 0 \\ -3 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} $，有 $ E^{-1} = \begin{bmatrix} 1 & 0 & 0 \\ 3 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} $

满足$ E^{-1}E = I $，即 $ \begin{bmatrix} 1 & 0 & 0 \\ 3 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} 1 & 0 & 0 \\ -3 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} $

# 第三课 矩阵乘法和逆矩阵
## 矩阵乘法
①基础求解方法  
假设 A、B、C 为矩阵，且 A * B = C。若要求解元素 $C_{ij}$，将 A 中 i 行的行向量与 B 中 j 列的列向量进行数量积，即为该元素的值：

$$ C_{ij} = (A 中第 i 行向量)(B 中第 j 列向量) = \sum_{k=1}^n a_{ik} b_{kj} $$

根据上述，若要矩阵相乘，A 的列数必须与 B 的行数相同，结果 C 矩阵的规格为 A 的行数，B 的列数。即若 A 是 m 行 n 列，B 是 n 行 p 列，结果为：

$$ \begin{array}{} A & \times & B & = & C \\ m * n & & n * p & & m * p \end{array} $$

②列组合方法：跟前一节课说得一样，把 B 矩阵当作很多个列向量的组合，将问题转化为矩阵与向量的乘法问题。也表明了矩阵 C 就是矩阵 A 中各列向量的线性组合，而 B 其实是在告诉我们，要以什么样的方式组合 A 中的列向量。

③行组合方法：同理，将 A 矩阵当作很多个行向量的组合，将问题转化为矩阵与向量的乘法问题。所以是矩阵 B 各行的线性组合组成了 C 的各行。

④列乘以行  
*若是行向量乘以列向量，得到的是某个位置的单一元素。*即 1 \* n 矩阵和 n \* 1 矩阵得到 1 \* 1 矩阵。  
*若是列向量乘以行向量，得到的是一个矩阵。*即 m \* 1 矩阵和 1 \* p 矩阵得到 m \* p 矩阵。  
所以矩阵相乘使用列乘以行，得到数个矩阵，再将矩阵相加，就可以得到 C。

$$ \begin{bmatrix} 2 & 7 \\ 3 & 8 \\ 4 & 9 \end{bmatrix} \begin{bmatrix} 1 & 6 \\ 0 & 0 \end{bmatrix} = \begin{bmatrix} 2 \\ 3 \\ 4 \end{bmatrix} \begin{bmatrix} 1 & 6 \end{bmatrix} + \begin{bmatrix} 7 \\ 8 \\ 9 \end{bmatrix} \begin{bmatrix} 0 & 0 \end{bmatrix} = \begin{bmatrix} 2 & 12 \\ 3 & 18 \\ 4 & 24 \end{bmatrix} $$

⑤分块乘法  
比如现在有一个 50\*50 的矩阵与 50\*50 矩阵相乘，一个一个进行运算很麻烦，尤其是如果矩阵在某一区域上有一定的性质，那么我们可以将其分块，如：  

 $$ \begin{bmatrix} A_1 & A_2 \\ A_3 & A_4 \end{bmatrix} \begin{bmatrix} B_1 & B_2 \\ B_3 & B_4 \end{bmatrix} = \begin{bmatrix} C_1 & C_2 \\ C_3 & C_4 \end{bmatrix} $$

 其中 $A_{1,2,3,4} $ 和 $B_{1,2,3,4} $ 都是划分之后的一块块矩阵，那么 $C_1 = A_1B_1 + A_2B_3 $ 。

## 逆矩阵
①对于一个方阵（正方形矩阵）$A$，如果 $A$ 可逆，就有这样一个 $A^{−1}$，使：  

$$ AA^{−1} = I = A^{−1}A $$

但是对于非方阵（长方形矩阵），左侧的$A^{−1}$与右侧的$A^{−1}$不可能相同。

②不可逆矩阵  
&emsp;&emsp; - 应行列式为 0，矩阵不可逆（见后面行列式）；  
&emsp;&emsp; - 若存在非零向量 x，使得 Ax = 0，那么 A 就不可能有逆矩阵。因为如果 $A$ 有逆，在 $Ax = 0$ 这个等式两端同时乘上$A^{−1}$，就有：$A^{−1}Ax$ = $Ix$ = 零向量。自相矛盾。所以此时 A 没有逆矩阵。

比如这个没有逆的矩阵 $\begin{bmatrix} 1 & 3 \\ 2 & 6 \end{bmatrix}$，它的行列式为零；矩阵中的两个列向量在同一直线上；非零向量[3, -1]可以使 Ax = 0。

③逆矩阵求解  
方法一：列向量

$$ \begin{bmatrix} 1 & 3 \\ 2 & 7 \end{bmatrix} \begin{bmatrix} a & b \\ c & d \end{bmatrix} = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} $$

即，得到两个方程：

$$ \begin{array}{} \begin{bmatrix} 1 & 3 \\ 2 & 7 \end{bmatrix} \begin{bmatrix} a \\ c \end{bmatrix} = \begin{bmatrix} 1 \\ 0 \end{bmatrix} & \begin{bmatrix} 1 & 3 \\ 2 & 7 \end{bmatrix} \begin{bmatrix} b \\ d \end{bmatrix} = \begin{bmatrix} 0 \\ 1 \end{bmatrix} \end{array} $$

方法二：高斯－若尔当消元法 Gauss-Jordan Elimination  
即使用增广矩阵联系两个方程增广矩阵，并进行消元行变换，将虚线左侧消为单位矩阵 I，此时右侧矩阵即为逆矩阵：

$$ \left[ \begin{array}{cc|cc} 1 & 3 & 1 & 0 \\ 2 & 7 & 0 & 1 \end{array} \right] \to \left[ \begin{array}{cc|cc} 1 & 3 & 1 & 0 \\ 0 & 1 & -2 & 1 \end{array} \right] \to \left[ \begin{array}{cc|cc} 1 & 0 & 7 & -3 \\ 0 & 1 & -2 & 1 \end{array} \right] $$

上述公式，可以理解为对 [A I] 进行左乘消元处理（见上面消元矩阵），即 E [A I] = [I ?]，已知消元矩阵 E 乘以 A 等于 I，所以 E 本身就是逆矩阵，所以逆矩阵乘以 I 还是逆矩阵。

④逆矩阵补充  
AB 的逆矩阵：因为 $ABB^{−1}A^{−1} = I$，所以 $(AB)^{−1}= B^{−1}A^{−1}$。

# 第四课 矩阵 A 的 LU 分解
将矩阵 A 分解为**下三角矩阵 L（lower triangular matrix）** 与**上三角矩阵 U (upper triangular matrix)**，$A=LU$。

我们熟悉的的消元法都是直接使用行变换得来的。而由于消元矩阵的存在，说明用矩阵乘法也可以达与之到一样的消元效果，即对于 2 阶矩阵，消元矩阵 $E$ 左乘 $A$ 变为上三角矩阵 $U$， $E_{21}  A = U$，可以改写为 $A = (E_{21})^{−1} U$，这一形式即 $A = LU$ 形式。并且，每个消元矩阵都是下三角矩阵，它的逆依然是下三角矩阵。**这个等式有更重大的意义，它是将矩阵分解为一个下三角矩阵乘一个上三角矩阵，一个方形系统等于两个三角系统。**

关于矩阵的 LU 分解，下面的关键点值得注意：  
①每个 $E_{ij}$ 都可逆，若其（i，j）元素是负的“乘数”，而 $E_{ij}^{-1}$ 的（i，j）元素就是正的乘数。比如：$ E_{21} = \begin{bmatrix} 1 & 0 & 0 \\ -a & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} $，那么 $E_{21}^{-1} = \begin{bmatrix} 1 & 0 & 0 \\ a & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} $。因为消元矩阵是减去某行的“乘数”倍，它的逆就是加上那行的“乘数”倍。  
②不仅每个 $E_{ij}$ 都可逆，每个 $E_{ij}$ 的逆依然是下三角矩阵，并且对角线上的元素依然是1。  
③$L$ 是一系列 $E_{ij}^{-1}$ 相乘的结果，但是 $E_{ij}^{-1}$ 相乘顺序和 $E_{ij}$ 相反。比如，$E_{32} E_{31} E_{21} A = U$，那么 $L = E_{21}^{-1} E_{31}^{-1} E_{32}^{-1}$。  
④每个 $E_{ij}^{-1}$ 都是对角线为 1 的下三角矩阵，它们的乘积依然是对角线为 1 的下三角矩阵。  
⑤关于 L 最重要的一个结论：L 中下三角部分（i，j）位置的元素 $L_{ij}$ 就等于“乘数”。  
例如，$ E_{21} = \begin{bmatrix} 1 & 0 & 0 \\ -a & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} $ $ E_{31} = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ -b & 0 & 1 \end{bmatrix} $ $ E_{32} = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & -c & 1 \end{bmatrix} $  
则 $ E = E_{32}E_{31}E_{21} = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & -c & 1 \end{bmatrix}\begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ -b & 0 & 1 \end{bmatrix} \begin{bmatrix} 1 & 0 & 0 \\ -a & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix} = \begin{bmatrix} 1 & 0 & 0 \\ -a & 1 & 0 \\ ac-b & -c & 1 \end{bmatrix} $  
那么 $ L = \begin{bmatrix} 1 & 0 & 0 \\ a & 1 & 0 \\ b & c & 1 \end{bmatrix} $


# 第五课 转置、转换、向量空间
## 置换矩阵 Permutation Matrix
置换矩阵回顾：  
①所谓的置换矩阵 P，就是用来完成行交换的矩阵。  
②那么对于 n 阶矩阵来说，有 n! 个置换矩阵。  
③置换矩阵另一个优点就是可逆的，并且对于置换矩阵 P 来说，有 $PP^T = I$，即 $P^{-1} = P^T$。  
④置换矩阵是一种特殊的正交矩阵，正交矩阵未必是置换矩阵。

## 转置矩阵 Transposed Matrix
①转置矩阵回顾：转置矩阵将行元素与列元素交换，即 $A_{ij}^T = A_{ji}$。  
②转置矩阵的运算规律：${(AB)}^T = B^TA^T$。  
③**对称矩阵 Symmetric matrix**，即主对角线两侧元素对应相等的矩阵，即对于该矩阵来说 $A^T = A$。任意矩阵和它的转置矩阵相乘得到的方阵一定是对称矩阵，即 ${(A^TA)}^T = A^TA^{TT} = A^TA$，所以对于任何 $A^TA$，其转置仍然是本身，所以是对称矩阵。

## 向量空间 Vector Space 与子空间
### 向量空间
向量空间，又称线性空间，定义为带有加法和标量乘法的集合。在一个向量空间中，如果我们将任意向量相加或者乘以一个标量，也就是任意向量的线性组合，它们的结果仍然在这个向量空间中（向量空间必然包括原点，因为任意向量乘以一个标量也在向量空间，而这个标量可以为零）。向量空间 $R^n$ 由所有的 n 维向量 v 组成，向量中的每个元素都是实数 R。

比如，$R^2$ 就是一个向量空间，即一个平面，其中的向量均为二维实向量。$R^3$ 这个三维空间也是向量空间。在三维空间中过原点的一个平面也是一个向量空间，这个向量空间和 $R^2$ 很像，但其中的每个向量都有三个元素。

### 子空间
一个向量空间的子空间是由一系列包含零向量的向量组成的，并且满足：如果是 v 和 w 是子空间的两个向量并且 c 是任意标量，那么有 (1) v + w 在子空间中， (2) cv 在子空间中。也就是说，所有向量的线性组合都仍然在这个子空间中，即子空间本身也是向量空间。

对于 $R^3$ 三维空间来说，有 4 类子空间：  
①$L$：所有过 (0, 0, 0) 的直线；  
②$P$：所有过 (0, 0, 0) 的平面；  
③$Z$：零向量 (0, 0, 0)；  
④$R^3$：整个三维空间

### 列空间初探
矩阵 A 的列空间 $C(A)$ 是其列向量的所有线性组合所构成的空间（某个子空间）。比如：

$$ A = \begin{bmatrix} 1 & 3 \\ 2 & 3 \\ 4 & 1 \end{bmatrix} $$

其 2 个列向量都属于 $R^3$ ，这两个向量组成一个平面，构成了 $R^3$ 的一个子空间。


# 第六课 列空间和零空间
### 列空间回顾
列空间的 Ax = b 解释(从 A 的角度)：  
①子空间是和矩阵紧密联系的。当我们求解 Ax = b 时，Ax 的本质是对 A 的列向量进行线性组合。为了得到 b，我们用任何可能的 x 来求取 A 的列向量的所有可能的线性组合，这产生了一个 A 的列空间 $C(A)$ 。$C(A)$ 不仅仅包含的所有列向量，还包括他们的所有线性组合。  
②只要 b 在 A 的列空间这个子空间中，那么就可以找到一种 A 列向量的线性组合来构成 b。也就是使得 Ax = b 有解。

### 零空间
①零向量介绍  
即 Ax = 0 的所有解 x 所构成的一个空间。以下面 A 为例，其零空间就是下面这个方程的解构成的空间：

$$ Ax = \begin{bmatrix} 1 & 1 & 2 \\ 2 & 1 & 3 \\ 3 & 1 & 4 \\ 4 & 1 & 5 \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} = 0 $$

可以看到 x 有三个分量，所以其零空间是 $R^3$ 的子空间。假设向量 v 和 w 位于此零空间中，也就是 Av = 0 、Aw = 0，那就有 A(v + w) = 0、A(cv) = 0，即它们相加或者乘以一个标量后仍然在零空间中，因此零空间是一个向量空间。

所以，对于 m*n 的矩阵来说，列空间是 $R^m$ 的子空间，零空间是 $R^n$ 的子空间。列空间关键在于列向量的维数，零空间的关键在于列向量的个数。

对于上面的例子，可以看出 $ \begin{bmatrix} 1 \\ 1 \\ -1 \end{bmatrix} $ 是一个解，而其零空间即为：$ C \begin{bmatrix} 1 \\ 1 \\ -1 \end{bmatrix} $ (C 表示任意常数)。表现在图像上就是 $R^3$ 中的一条穿过原点的直线。

②从 x 的角度看 Ax = b  
如果上面构造零空间的方程右侧变为任意向量的话，其解集 x 还能构成向量空间吗？如下：

$$ Ax = \begin{bmatrix} 1 & 1 & 2 \\ 2 & 1 & 3 \\ 3 & 1 & 4 \\ 4 & 1 & 5 \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} = \begin{bmatrix} 1 \\ 2 \\ 3 \\ 4 \end{bmatrix} $$

答案是不能，因为 x 的解集不包括零向量。本例中 x 的解集是一个不穿过原点的直线。


# 第七课  求解 Ax=0：主变量，特解
本课主要讲解出 Ax = 0 中的 x 构成的零空间的算法。

## 消元法求解零空间
第一步：消元法确定主变量与自由变量（消元）

假设 $ A = \begin{bmatrix} 1 & 2 & 2 & 2 \\ 2 & 4 & 6 & 8 \\ 3 & 6 & 8 & 10 \end{bmatrix} $ ，求解由 Ax = 0 中的 x 构成的零空间。

消元法并不会改变 x 的解，因为本质就是求方程式，只是会改变 A 的列空间。

$$ \begin{bmatrix} 1 & 2 & 2 & 2 \\ 2 & 4 & 6 & 8 \\ 3 & 6 & 8 & 10 \end{bmatrix} \to \begin{bmatrix} 1 & 2 & 2 & 2 \\ 0 & 0 & 2 & 4 \\ 0 & 0 & 2 & 4 \end{bmatrix}
\to \begin{bmatrix} 1 & 2 & 2 & 2 \\ 0 & 0 & 2 & 4 \\ 0 & 0 & 0 & 0 \end{bmatrix} $$

A 矩阵消元之后只有两个主元：1 和 2，主元的个数被称为**秩 Rank**。矩阵中包含主元的列为**主元列 pivot column**，不包含主元的列称为**自由列 free column**。

所谓自由列，就表示其对应的未知变量 $x_n$ (n 表示自由列是第 n 列)可以被任意分配值。所以这个 U 的主变量(主元)为 $x_1$ ，$x_3$，自由变量为 $x_2$，$x_4$。

第二步：回代  
首先给自由变量 $x_2$，$x_4$ 赋值为 1 和 0，带入到回代的方程式：

$$ \left\{ \begin{aligned} x_1 + 2x_2 + 2x_3 + 2x_4 &= 0 \\ 2x_3 + 4x_4 &= 0 \end{aligned} \right.\\ $$

得到解向量为：$ A = \begin{bmatrix} -2 \\ 1 \\ 0 \\ 0 \end{bmatrix} $

再给自由变量 $x_2$，$x_4$ 赋值为 0 和 1，得到解向量为：$ A = \begin{bmatrix} 2 \\ 0 \\ -2 \\ 1 \end{bmatrix} $

这两个解为**特解 Special solutions**，矩阵 A 的零空间就是这些特解向量的线性组合所构成的向量空间，即：  

$$ x = c\begin{bmatrix} -2 \\ 1 \\ 0 \\ 0 \end{bmatrix} + d\begin{bmatrix} 2 \\ 0 \\ -2 \\ 1 \end{bmatrix} $$

若矩阵为 m*n 的矩阵，矩阵的秩 r 等于其主元列的数目，因此自由列的数目就等于 n-r，即列的数目减去主元列的数目。这个数值等于特解的数目和零空间的维数。主元列和自由列的一个重要区别就是，自由列可以表示为其左侧所有主元列的线性组合，而主元列则不可以。

## 行最简阶梯矩阵 Reduced row echelon form (rref)
通过继续消元我们可以将矩阵 U 转变为行最简阶梯矩阵形式 R，其中主元为 1，而主元列除主元外皆为 0：

$$ U = \begin{bmatrix} 1 & 2 & 2 & 2 \\ 0 & 0 & 2 & 4 \\ 0 & 0 & 0 & 0 \end{bmatrix} \to \begin{bmatrix} 1 & 2 & 0 & -2 \\ 0 & 0 & 2 & 4 \\ 0 & 0 & 0 & 0 \end{bmatrix} \to \begin{bmatrix} 1 & 2 & 0 & -2 \\ 0 & 0 & 1 & 2 \\ 0 & 0 & 0 & 0 \end{bmatrix} = R $$

在矩阵中主元行和主元列的交汇处存在一个单位阵。通过列交换，可以将矩阵 R 中的主元列集中在左侧，从而在左上角形成这个单位阵，而将自由列集中在矩阵的右侧。如果矩阵 A 中的某些行是线性相关的，则在矩阵 R 的下半部分就会出现一些完全为 0 的行向量。即：

$$ R = \begin{bmatrix} 1 & 0 & 2 & -2 \\ 0 & 1 & 0 & 2 \\ 0 & 0 & 0 & 0 \end{bmatrix}
 = \begin{bmatrix} I & F \\ 0 & 0 \end{bmatrix} $$

这里的 I 是 rxr 的方阵，F 代表着自由列经过化简剩余的形式。

将 Ax=0 的特解作为列向量写成一个矩阵 N ，即零空间矩阵。即：

$$ Ax = Rx = \begin{bmatrix} I & F \\ 0 & 0 \end{bmatrix} \begin{bmatrix} x_{pivot} \\ x_{free} \end{bmatrix} = 0 $$

根据矩阵分块乘法运算可得：

$$ N = \begin{bmatrix} -F \\ I \end{bmatrix} $$

这里的 I 为一个 (n-r)x(n-r) 的矩阵。零空间矩阵满足 RN = 0，故零空间矩阵是一个 nx(n-r) 的矩阵。

对于矩阵 R 而言，求零空间特解就变得非常简单，只需要将消元的到的 F 部分拼接上单位阵就可以得到所有的通解。注意如果在变换出 R 左上角的单位阵的过程中采用了列交换，则最后的解要行变换回去。即：

$$ N = \begin{bmatrix} -2 & 2 \\ 0 & -2 \\ 1 & 0 \\ 0 & 1 \end{bmatrix} \to \begin{bmatrix} -2 & 2 \\ 1 & 0 \\ 0 & -2 \\ 0 & 1 \end{bmatrix} $$


# 第八课 求解 Ax=b：可解性与结构
## Ax=b 的解 
### 可解性
Ax = b，这个方程并不一定有解。我们通过一个例子来说明下这个问题：  

$$ \begin{bmatrix} 1 & 2 & 2 & 2 \\ 2 & 4 & 6 & 8 \\ 3 & 6 & 8 & 10 \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \\ x_3 \\ x_4 \end{bmatrix} = \begin{bmatrix} b_1 \\ b_2 \\ b_3 \end{bmatrix} $$

同上一课例子中的矩阵，第三行为第一行和第二行的和。因此 Ax=b 中 b 的第 3 个分量也要等于其第 1 和第 2 个分量的和。若 b 不满足 $b_3=b_1+b_2$ 则方程组无解。

检验 Ax=b 是否可解的方法也可以使用增广矩阵进行消元。如果矩阵 A 的行被完全消去的话，则对应的 b 的分量也要得 0：

$$ \left[ \begin{array}{cccc|c} 1 & 2 & 2 & 2 & b_1 \\ 2 & 4 & 6 & 8 & b_2 \\ 3 & 6 & 8 & 10 & b_3 \end{array} \right] \to \left[ \begin{array}{cccc|c} 1 & 2 & 2 & 2 & b_1 \\ 0 & 0 & 2 & 4 & b_2 - 2b_1 \\ 0 & 0 & 0 & 0 & b_3-b_2-b_1 \end{array} \right] $$

因此本方程的可解条件为 $b_3-b_2-b_1=0$ 。

前几讲讨论过，只有当 b 处于矩阵的列空间 C(A) 之中时，方程才有解。本讲推导出矩阵 A 的行向量若经过线性组合成为了零向量，则对应的 b 经同样的线性组合后也要等于 0。因此看起来我们有了两条关于b的限制条件，但实际上这两点是等价的。

### 通解
为求得 Ax=b 的所有解，我们首先检验方程是否可解，然后找到一个**特解 particular solution**。将特解和矩阵零空间的向量相加即为方程的**通解 Complete solution**。因为 $Ax_p = b$, $Ax_n = 0$，所以 $A(x_p+x_n) = b$。

求 Ax=b 特解的方法是将自由变量均赋值为 0，求解其主变量。本例中，假设 b = [1, 5, 6]，令 $x_2=x_4=0$ 得到方程组：

$$ \left\{ \begin{aligned} x_1 + 2x_3 &= 1 \\ 2x_3 &= 3 \end{aligned} \right.\\ $$

得到特解：

$$ x_p = \begin{bmatrix} -2 \\ 0 \\ 3/2 \\ 0 \end{bmatrix} $$

> 主元列和自由列的一个重要区别就是，自由列可以表示为其左侧所有主元列的线性组合，而主元列则不可以，主元列之间是线性无关的。我们将自由变量赋值为 0 就可以去掉自由列列向量的干扰，求得方程的特解。

通过上一节的知识我们很容易求出 Ax = 0 的 x 零空间的解：

$$ c_1\begin{bmatrix} -2 \\ 1 \\ 0 \\ 0 \end{bmatrix} + c_2\begin{bmatrix} 2 \\ 0 \\ -2 \\ 1 \end{bmatrix} $$

因此上述方程的通解为(式中 c1 和 c2 为任意实数)：  

$$ x_{complete} = \begin{bmatrix} -2 \\ 0 \\ 3/2 \\ 0 \end{bmatrix} + c_1\begin{bmatrix} -2 \\ 1 \\ 0 \\ 0 \end{bmatrix} + c_2\begin{bmatrix} 2 \\ 0 \\ -2 \\ 1 \end{bmatrix} $$

矩阵的零空间 N(A) 是 $R^4$ 空间中的二维子空间，方程的解 Ax=b 构成了穿过 $x_p$ 点并且和矩阵零空间平行的二维平面。但该平面并不是 $R^4$ 空间的子空间，因为不包括零向量，不是向量空间。

## m*n 的矩阵 A 的秩与解的关系
矩阵的秩等于矩阵的主元数。如果 m x n 矩阵的秩为 r ，则必有 r <= m 且 r <= n。

①列满秩：r = n < m。每列都有主元，x 的每一个分量都是主变量，没有自由变量。零空间 N(A) 之内只有零向量。方程无解或者有唯一解 $x_p$ 。例如：

$$ A = \begin{bmatrix} 1 & 3 \\ 2 & 1 \\ 6 & 1 \\ 5 & 1 \end{bmatrix} \to \begin{bmatrix} 1 & 0 \\ 0 & 1 \\ 0 & 0 \\ 0 & 0 \end{bmatrix} = \begin{bmatrix} I \\ 0 \end{bmatrix} $$

②行满秩：r = m < n。每行都有主元，无论 b 取何值，方程 Ax=b 都有无穷多个解。主变量 r 个，自由变量 n-r 个。例如：  

$$ A = \begin{bmatrix} 1 & 2 & 6 & 5 \\ 3 & 1 & 1 & 1 \end{bmatrix} \to \begin{bmatrix} 1 & 0 & * & * \\ 0 & 1 & * & * \end{bmatrix} = \begin{bmatrix} I & F \end{bmatrix} $$

③满秩：r = m = n，矩阵可逆。零空间只有零向量，无论 b 取何值，方程 Ax=b 都有唯一解，因为自由变量个数为 0。只能得到一个全是主元的方程组。例如： 

$$ A = \begin{bmatrix} 1 & 2 \\ 3 & 1 \end{bmatrix} \to \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix} = I $$

④不满秩：r < n, r < m，此时 A 可化简为 $ \begin{bmatrix} I & F \\ 0 & 0 \end{bmatrix} $ 形式，最后化简结果中有 0 行。如本节课开头中的矩阵，b 的分量与零行牵扯出了可解条件的存在。所以这样的矩阵 A 所构成的 Ax = b 方程解有两种情况：不满足可解条件或无穷多个解。

总结：

| r = m = n | r = n < m | r = m < n | r < n, r < m |
| :---- | :---- | :---- | :---- |
| $R=I$ | $R=\begin{bmatrix} I \\ 0 \end{bmatrix}$ | $R=\begin{bmatrix} I & F \end{bmatrix}$ | $ \begin{bmatrix} I & F \\ 0 & 0 \end{bmatrix} $ |
| 唯一解 | 无解或唯一解 | 无穷多解 | 无解或无穷多解 |

秩决定了方程组解的数量。mxn 给出了矩阵的尺寸，但是秩 r 给出的是矩阵的实际“大小”。关于这个随后会有讨论。

如上表，①可解条件的产生是由于 A 消元之后的 0 行导致的：消元后有零行产生时，需要考虑方程是否满足可解条件；消元后没有零行时，方程不用考虑可解条件的影响。②自由变量总为（n-r）个，根据自由变量个数可以初步判断 Ax = b 的解的结构：n − r = 0 时，方程即为唯一解，否则为无穷解。


# 第九课 线性相关性，基和维数
## 线性无关 Independence 与线性相关 Dependence
一般来说，线性无关，线性相关是向量组内的关系。

矩阵 A 为 m x n 矩阵，其中 m < n。因此 Ax = b 中未知数个数多于方程数，未知数一共 n 个，方程一共 m 个，则 A 中具有至少一个自由变量，那么 Ax = 0 一定具有非零解。此时，由于 A 的列向量可以线性组合得到零向量，所以 A 的列向量必定是线性相关的。

线性无关的定义：若 $c_1x_1 + c_2x_2 + \cdots + c_nx_n = 0$ 仅在 $c_1 = c_2 = \cdots = c_n = 0$ 时才成立，则称向量 $x_1, x_2 \cdots x_n$ 是线性无关的。即若这些向量作为列向量构成矩阵 A，则方程 Ax = 0 只有零解 x = 0，或称矩阵 A 的零空间只有零向量。换而言之，若存在非零向量 c，使得 Ac = 0，则这个矩阵 A 的列向量线性相关。

> 注：如果一个向量组中有零向量存在，那么这个向量组一定是线性相关的。

在 R2 空间中，两个向量只要不在一条直线上就是线性无关的。在 R3 中，三个向量线性无关的条件是它们不在一个平面上。若选定空间 R2 中的三个向量，则他们必然是线性相关的。例如，如下的三个向量 v1，v2 和 v3 是线性相关的。

$$A = \begin{bmatrix} v_1 & v_2 & v_3 \end{bmatrix} = \begin{bmatrix} 2 & 1 & 2.5 \\ 1 & 2 & -1 \end{bmatrix}$$

显然，A 矩阵是 n > m 型的矩阵。Ac = 0 这个方程对应的零空间中，除了零向量肯定还有其他向量，也就是存在一种 c 不全为 0 的情况，使 A 各列线性组合后得到 0。也就是 A 各列的 v1，v2 和 v3 线性相关。

## 零空间和线性相关/无关
假设现有一 m x n 矩阵 A：  
①如果 A 各列向量构成的向量组是线性无关的，那么矩阵 A 的零空间中只有零向量；线性无关对应向量组构成的矩阵，秩为 n，此时没有自由变量，零空间中只有零向量存在。  
②如果 A 各列向量构成的向量组是线性相关的，那么矩阵 A 零空间中除零向量之外还一定有其他向量。线性相关对应向量组构成的矩阵，秩小于 n，有 n-r 个自由变量，零空间中有很多向量。

## 生成(张成)空间 Spanning a space
所谓生成空间，即为此空间由向量 $v_1,v_2,v_3 \cdots v_n$ 的线性组合构成，就称 $v_1,v_2,v_3 \cdots v_n$ 生成了一个空间。

但是 $v_1,v_2,v_3 \cdots v_n$ 不一定是线性无关的，只是我们更关心线性无关的 $v_1,v_2,v_3 \cdots v_n$，因为它们可以表示出空间的特征，这就引出了“基”的概念。

## 基 Basis
基的定义：一组向量 $v_1,v_2,v_3 \cdots v_n$ ，具有两个性质：  
①$v_1,v_2,v_3 \cdots v_n$ 线性无关；  
②$v_1,v_2,v_3 \cdots v_n$ 生成整个空间。

例如三维空间中的一组基：$\begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix}$，$\begin{bmatrix} 0 \\ 1 \\ 0 \end{bmatrix}$，$\begin{bmatrix} 0 \\ 0 \\ 1 \end{bmatrix}$。因为它们满足 $c_1, c_2, c_3$ 只有零解。

而 $\begin{bmatrix} 1 \\ 1 \\ 2 \end{bmatrix}$，$\begin{bmatrix} 2 \\ 2 \\ 5 \end{bmatrix}$，$\begin{bmatrix} 3 \\ 3 \\ 8 \end{bmatrix}$ 则不能构成一组基，因为以它们为列向量组成的矩阵，有两个相同的行，消元肯定有自由列存在，因此这三个向量并非线性无关。

从矩阵是否为可逆矩阵也可以判断是否为一组基：若以 R(n) 空间中的 n 个向量为列向量构成的矩阵为可逆矩阵，则这些向量可以构成 R(n) 空间中的一组基。

但是可以发现：一个空间的不同基，其中向量的个数是一定的。如果 A 是 R(n) 空间的基，那么 A 中向量的个数就是 n 个。比如三维空间 R3，基一定是三个向量构成的向量组。这里给出一个性质：R(n) 中的 n 个向量构成基，则以这 n 个向量构成的 n × n 矩阵必须可逆。矩阵可逆就意味着任意两行，两列都线性无关，所以可以构成一组生成空间的基。 

## 维数 Dimension
R(n) 空间的基中向量的个数就是 n 个，这个 n 称之为维数。

## 总结举例
假设列空间由矩阵 A 确定：

$$ A = \begin{bmatrix} 1 & 2 & 3 & 1 \\ 1 & 1 & 2 & 1 \\ 1 & 2 & 3 & 1 \end{bmatrix} $$

讨论**列空间**：矩阵 A 的四个列向量生成了矩阵 A 的列空间，其中第 3 列和第 4 列与前两列线性相关，而前两个列向量线性无关。可以取前两列为主元列，他们组成了列空间C(A)的一组基。矩阵的秩为2。A 的列空间的维数也为 2。

所以有：**矩阵 A 的秩 = 矩阵 A 主列的个数 = A 列空间的维数**

> 注意：矩阵具有秩 rank 而不是维数 dimension，而空间有维数而不是秩。

当知道了列空间的维数，可以从矩阵列向量中随意选取足够数量的线性无关的向量，它们每一组都可以构成列空间的一组基。

讨论**零空间**：所谓零空间维数，即是零空间基的个数，也是 Ax = 0 的特解的个数，还可以理解为：Ax = 0 的解中自由变量的个数。本例中矩阵的列向量不是线性无关的，因此其零空间 N(A) 不止包含零向量。

经过消元，自由变量赋值，回代，可以得到两个特解：

$$ \begin{bmatrix} -1 \\ -1 \\ 1 \\ 0 \end{bmatrix},\begin{bmatrix} -1 \\ 0 \\ 0 \\ 1\end{bmatrix} $$

所以此零空间的维数为 2，这两个特解就构成了零空间的一组基。所以有：**m × n 矩阵中，主列个数为 r，秩为 r，则有：零空间维数 = n - r。**


# 第十课 四个基本子空间
## 四个基本空间介绍
对于一个 m × n 矩阵 A 来说：  
①**列空间 $C(A)$**  
列空间即是矩阵 A 的列向量线性组合构成的空间。对于 m × n  的矩阵 A 来说，每个列向量有 m 个分量，即列向量属于 $R^m$ 空间。所以列空间是 $R^m$ 的子空间。  
②**零空间 $N(A)$**  
即由 Ax = 0 的解构成的空间。由于 x 本质是对 A 列向量的线性组合，A 一共有 n 个列向量，所以零空间是 $R^n$ 的子空间。  
③**行空间 $C(A^T)$**  
行空间就是矩阵 A 各行线性组合构成的子空间。也可以理解为 A 转置的列空间，即 $C(A^T)$。A 的每个行向量都有 n 个分量，所以每个行向量都在 $R^n$ 中。也就是 A 的行空间是 $R^n$ 的子空间。  
④**左零空间 $N(A^T)$**  
左零空间我们接下来会再介绍，先理解为 $A^T$ 的零空间就好。很明显，$A^T$ 是一个 n × m 的矩阵。联系零空间的介绍，$A^T$ 一共有 m 个列向量，所以左零空间是 $R^m$ 的子空间。

## 四个基本空间的维数与基
还是对于一个 m × n 矩阵 A 来说：  
①**列空间**  
设矩阵 A 的秩为 r，则 A 有 r 个主列，这 r 个主列就是列空间 C(A) 的一组基，一组基里有 r 个向量，所以列空间维数为：r 。  
②**零空间**  
矩阵 A 秩为 r 时，自由列为 n - r 列。这 n - r 列决定了 x 中的 n - r 个自由变元，赋值后就构成了零空间的 n - r 个基向量，故零空间维数为：n - r 。  
③**行空间**  
A 的行空间可以化为 $A^T$ 的列空间。但我们这里使用的方法是直接对 A 的行向量进行变换（其实一样），最后行空间的维数也是秩数 r。  

以下述矩阵为例：

$$ A = \begin{bmatrix} 1 & 2 & 3 & 1 \\ 1 & 1 & 2 & 1 \\ 1 & 2 & 3 & 1 \end{bmatrix} \to \begin{bmatrix} 1 & 0 & 1 & 1 \\ 0 & 1 & 1 & 0 \\ 0 & 0 & 0 & 0 \end{bmatrix} = \begin{bmatrix} I & F \\ 0 & 0 \end{bmatrix} = R $$

显然，A 只有两行线性无关，所以 A 秩为 2，所以 A 行向量的基就是 R 的前两行。维数为 2。

> 注：经过行变换，矩阵 A 的列空间显然改变了：C(A) ≠ C(R)。但是行变换并没有改变 A 的行空间，因为所谓行空间就是 A 行向量的线性组合，而我们进行的行变换就是取原来行向量的一些线性组合，并没有改变行空间。

从上面这个例子中，可以得知，行空间会在行最简型 R 中以最佳形式表现出来。也就是说，将 A 化简为行最简型 R 后取前 r 行向量，即为 A 行空间的基。

④**左零空间**  
左零空间，写成方程形式，即 $A^Ty = 0$，将方程两边同时转置，得到：$y^TA = 0$。我们看到，对于 A 矩阵本身来说，$y^T$ 左乘矩阵 A 得到零向量，所以我们称之为左零空间。然而，理解为 $A^T$ 的零空间更直接一点。因为 $A^T$ 是一个 n × m 的矩阵，所以以 $A^T$ 零空间维数为 m - r。

为找到左零空间的基，我们应用高斯-若尔当消元法使用增广矩阵：$[A_{m \times n} \quad I_{m \times n}] \to [R_{m \times n} \quad E_{m \times n}]$，因为我们将 A 通过消元得到矩阵 R ，其消元矩阵记为 E ，即 EA = R。那么 A 变为 R 相当于左乘 E 矩阵，同样处理单位阵 I，得到的即是矩阵 E。

还是上面的例子中的矩阵：

$$ EA = \begin{bmatrix} -1 & 2 & 0 \\ 1 & -1 & 0 \\ -1 & 0 & 1 \end{bmatrix} \begin{bmatrix} 1 & 2 & 3 & 1 \\ 1 & 1 & 2 & 1 \\ 1 & 2 & 3 & 1 \end{bmatrix} = \begin{bmatrix} 1 & 0 & 1 & 1 \\ 0 & 1 & 1 & 0 \\ 0 & 0 & 0 & 0 \end{bmatrix} = R $$

以“行操作”的观点来看矩阵 E 和 A 的乘法，则矩阵 E 最下面的 m - r 个行向量使得矩阵 A 的行向量线性组合成为 0，也就是矩阵 R 最下面的 m - r 个零向量。本例中，m - r = 1。

矩阵 E 的这 m - r 个行向量满足 $y^TA = 0$ ，它组成了矩阵 A 左零空间的一组基。


# 第十一课 矩阵空间、秩1矩阵和小世界图
