---
title: 屏幕空间环境光遮蔽（二）HBAO 与 GTAO
date: 2025-09-09 20:10:09
categories: 
  - [图形学]
  - [unity, pipeline]
tags:
  - 图形学
  - 游戏开发
  - unity
top_img: /images/black.jpg
cover: https://s2.loli.net/2025/09/09/Uq93S46lgTAHs7Q.gif
mathjax: true
description: 本文章主要内容有XXXXXXXXXXXXXX。
---

# HBAO

> HBAO 参考文献如下：  
> ① Image-Space Horizon-Based Ambient Occlusion (Siggraph 2008)：https://developer.download.nvidia.com/presentations/2008/SIGGRAPH/HBAO_SIG08b.pdf 、https://www.researchgate.net/publication/215506032_Image-space_horizon-based_ambient_occlusion ；  
> ② NVIDIA DirectX 11 SDK Sample：https://developer.download.nvidia.com/assets/gamedev/files/sdk/11/SSAO11.pdf 、 https://github.com/LiveMirror/NVIDIA-Direct3D-SDK-11/tree/master/SSAO11 ；  
> ③ An alternative implementation for HBAO：https://www.derschmale.com/2013/12/20/an-alternative-implementation-for-hbao-2/ ；  
> ④ NVIDIA's HBAO+ ：https://github.com/NVIDIAGameWorks/HBAOPlus ；

## HBAO 原理及流程
### 基本流程
书接上文，话说秦琼卖马……不好意思放错碟了。正如上篇文章所说，**Horizon-Based Ambient Occlusion (HBAO)** 由 NVIDIA 的 Louis Bavoil 于 SIGGRAPH 2008 中提出，资料详见上面参考文献中的 **①** Image-Space Horizon-Based Ambient Occlusion，有演讲的 PPT 和对应的论文。HBAO 的主要思路就是将 Z-Buffer 视做高度场，然后在屏幕空间中朝着一定数量的等角的方向进行步进，如下图：

<div align="center">  
<img src="https://s2.loli.net/2025/09/16/cDQAqnUwX6k4MFg.png" width = "20%" height = "20%" alt="图14 - Raymarching Depth Buffer"/>
</div>

同时在每个方向上的一定范围内寻找一个最高高度，这个最高高度所形成的仰角称为 **Horizon Angle**，它是计算 Ambient Occlusion 的依据之一。

<div align="center">  
<img src="https://s2.loli.net/2025/09/16/vaNzfwH2FbgTcxr.png" width = "45%" height = "45%" alt="图15 - Marching on the heightfield"/>
</div>

但是这样得到的角度，是基于视角方向的高度角，而 AO 是基于法线的，我们需要额外考虑法线和视角方向的夹角，即 **Tangent Angle**：  

<div align="center">  
<img src="https://s2.loli.net/2025/09/16/vHUQhs9BaCS57y4.png" width = "40%" height = "40%" alt="图16 - Tangent Angle"/>
</div>

最近计算 AO 值：  

<div align="center">  
<img src="https://s2.loli.net/2025/09/16/g91xjpuCdOF5laW.png" width = "45%" height = "45%" alt="图17 - Horizon-Based AO"/>
</div>

这里要注意一下，Horizon Angle 和 Tangent Angle 都是带正负符号的角度值，所以 AO 的计算公式看似是两个角度的正弦值相减，但在上图中其实可以说是相加。

### 数学原理
HBAO 的 AO 计算公式如下：  

$$ A = 1 - \cfrac {1} {2\pi} \int_{\Omega} V(\vec{\omega})W(\vec{\omega})d{\omega} $$

其中 $\,V(\vec{\omega})\,$ 是可见性函数，在 $\,\omega\,$ 方向上与遮挡物相交则返回 1，没相交则返回 0，和上篇文章中的可见性函数是反过来的，所以这里 AO 要用 1 减。$\,W(\vec{\omega})\,$ 是线性距离衰减函数。可以发现上述公式和上一篇文章的 AO 公式是不同的，这个公式实际上是 AO 的另外一种形式，上一篇文章的 AO 公式是带余弦权重的，如果不带余弦权重，就可以退化为上述公式，GTAO 的 [PPT](https://blog.selfshadow.com/publications/s2016-shading-course/activision/s2016_pbs_activision_occlusion.pdf) 中也提到了这一点，但是这个公式相对于带余弦权重的公式是没有那么 ground truth 的，这应该也是 GTAO 相比 HBAO 更真实的原因之一吧。

接下来就是对上述公式进行拆分，拆分为球坐标下的积分：  

$$ A = 1 - \cfrac {1} {2\pi} \int_{\theta = \pi}^{-\pi} \int_{\alpha = t(\theta)}^{h(\theta)} W(\vec{\omega}) cos\alpha d{\alpha}d{\theta} $$

<div align="center">  
<img src="https://s2.loli.net/2025/09/16/84956z3m2luIMCt.png" width = "40%" height = "40%" alt="图18 - Horizon-Based AO"/>
</div>

首先要注意一下，球坐标的**天顶角 Polar angle** 是 $\,\theta\,$，**方位角 Azimuthal angle** 是 $\,\phi\,$。但上述公式的方位角是 $\,\theta\,$，而 $\,\alpha\,$ 并非是常规的天顶角，而称为**仰角 Elevation angle**。常规球坐标的天顶角是相对于 Z 轴的角度，而这里的 Elevation angle 是基于 xy 平面的角度，这也是为什么上述公式拆分时多出来的是 $\,cos\alpha\,$ 而非 $\,sin\alpha\,$ 的原因。

上述公式的理解也比较简单，就是对于半球中心点 P 的每一个方向，累计从 $\,t(\theta)\,$ 到 $\,h(\theta)\,$ 范围（即被遮挡的范围）的距离衰减函数，作为该方向的 AO 值，再将方向旋转 $\,2\pi\,$ 角度，累计形成半球，即最终 P 点的 AO 值。

又因为 $\,cos\alpha\,$ 的积分就是 $\,sin\alpha\,$，且 $\,W(\vec{\omega})\,$ 是与 $\,\alpha\,$ 无关的函数，上述公式可以进一步简化为：  

$$ A = 1 - \cfrac {1} {2\pi} \int_{\theta = \pi}^{-\pi} (sin(h(\theta)) - sin(t(\theta)))W(\theta) d{\theta} $$

其中 $\,W(\theta) = max(0, 1 - r(\theta) / R)\,$，$\,r(\theta)\,$ 是点 P 和 Horizon Point 的距离，R 是 AO 的影响范围。这就是 HBAO 最终的公式，这也是图 17 中 $\,AO = sinh - sint\,$ 的数学来源。在屏幕空间中朝着一定数量的等角的方向进行步进，就相当于使用黎曼和求解上述积分公式，故上述公式最终可以写为如下：  

$$ A \approx 1 - \cfrac {1} {2\pi} \cdot \cfrac {\pi - (-\pi)} {N} \sum_{i = 1}^N (sin(h(\theta)) - sin(t(\theta))) W(\theta) = 1 - \cfrac {1} {N} \sum_{i = 1}^N (sin(h(\theta)) - sin(t(\theta))) W(\theta) $$

## 具体实现
以下内容主要参考了 [NVIDIA DirectX 11 SDK Sample](https://github.com/LiveMirror/NVIDIA-Direct3D-SDK-11/tree/master/SSAO11) 的代码，略微做出了点改动，最主要的改动是原代码使用了邻近像素点重建切线，而我直接使用了 Normal Buffer。

### 计算步长
首先要先采样 Depth Buffer 重构当前像素点的观察空间坐标，以及采样 Normal Buffer 获取世界空间的 Normal 并且转换至观察空间，具体如何重构观察空间坐标我就不再赘述了，属于基础知识：  

    float rawDepth = LoadDepth(id.xy);
    float3 P = FetchViewPosition(screenUV, rawDepth);

    float3 normalWS = LoadAndDecodeNormal(id.xy);
    float3 normalVS = TransformWorldToViewNormal(normalWS, true);

这里要注意一下 Unity 观察空间 z 轴的方向问题，+z 是指向摄像机的方向，为了方便理解建议反转一下，不反转也可以，就是后面计算时有些符号需要修改：  

    P.z = -P.z;
    normalVS.z = -normalVS.z;

因为我们往往会在观察空间（或世界空间下）定义 AO 的影响范围或半径 **Radius**，所以需要计算 AO 的影响范围在屏幕上的大小，以便我们计算在屏幕空间中每次步进的距离，同时若半径在屏幕上的大小比一个像素还小，就直接设置 AO 值为 1（即无 AO 效果），计算代码如下：  

    float radiusInUV = 0.5 * GetHBAORadius() * _CameraSettings.y / P.z;
    float radiusInPixel = radiusInUV * _TextureSize.w;
    
    if (radiusInPixel < 1)
    {
        _OutputTexture[id.xy] = float2(1.0, P.z);
        return;
    }

其中 `_CameraSettings.y` 是 $\,cot(FOV/2)\,$，为什么这么算，看看透视投影矩阵的 m00 和 m11 就明白了，除以 z 是透视除法，乘以 0.5 是因为 \[-1, 1\] 的范围要映射至 \[0, 1\]。得到了屏幕空间上的半径，就可以根据步进的步数计算步长了，一般步数 `NUM_STEPS` 为 4 ~ 8：  

    // Avoid oversampling if NUM_STEPS is greater than the kernel radius in pixels
    float numSteps = min(NUM_STEPS, radiusInPixel);
    float stepSizeInPixel = radiusInPixel / numSteps;
  
NVIDIA 还规定了一个最大采样像素半径，我没有使用，想添加可以看 NVIDIA 的代码。

### 步进
***①方向循环***  
可以开始循环步进了，有两个循环，分别是方向循环以及步进循环，首先处理方向循环，先根据设定的方向数量 `NUM_DIRECTIONS` 计算每个步进方向之间角度，同时给每个方向添加一个随机旋转，根据最后计算出来的方向，得到每次步进的步长 step 的向量：  

    float ao = 0;
    float dirAngle = TWO_PI / NUM_DIRECTIONS;
    float noise = LOAD_TEXTURE2D_LOD(_BlueNoise64, id.xy % _BlueNoise64_TexelSize.zw, 0).r;
    float randomRadian = (noise + _Jitter.w * IsTemporalBlurEnabled()) * TWO_PI;

    UNITY_UNROLL
    for (int d = 0; d < NUM_DIRECTIONS; ++d)
    {
        float angle = dirAngle * d + randomRadian;
        float2 dir = float2(cos(angle), sin(angle));
        float2 pixelDelta = dir * stepSizeInPixel;
        ...

        for (float j = 0; j < numSteps; ++j)
        {
            ...
        }
    }

我还是使用了蓝噪声，尝试过其他的噪声，感觉还是蓝噪声最适配 Temporal Filter。除了对方向应用 Noise，我们也要对每次步进的 sample 应用一个随机偏移：  

    float rand = (d + 1.0 + _Jitter.w * IsTemporalBlurEnabled()) / (NUM_DIRECTIONS + 1.0);
    float2 sampleCoord = id.xy + rand * pixelDelta;

得到的 sampleCoord 就是第一次步进的 sample 的屏幕像素坐标。在进入步进循环之前，已经可以计算 $\,sinT\,$ 了。我这里计算 $\,sinT\,$ 跟 NVIDIA 的原代码有两处不同，但是渲染结果是一样的，第一是 NVIDIA 是获取临近像素点重构切线再计算 $\,sinT\,$ 的，而我是通过 Normal Buffer 获取的法线计算切线的：  

    float3 viewDir = normalize(-P);
    float3 sliceNormal = normalize(cross(float3(dir, 0), viewDir));
    float3 T = normalize(cross(normalVS, sliceNormal));

第二是 NVIDIA 是先计算 $\,tanT\,$ 再转化为 $\,sinT\,$，我 $\,sinT\,$ 是通过归一化的切线的 z 分量获取的：  

    float sinT = -T.z;

***②步进循环***  
接下来就可以进入步进循环了，代码如下：  

    float lastSinH = sinT;
    float r2 = GetHBAORadius() * GetHBAORadius();
    
    for (float j = 0; j < numSteps; ++j)
    {
        // ------------------------- Fetch Sample Position -------------------------
        sampleCoord = clamp(sampleCoord, 0, _TextureSize.zw - 1);
        float2 sampleUV = (sampleCoord + 0.5) * _TextureSize.xy;
        float sDepth = LoadDepth(sampleCoord);
        float3 S = FetchViewPosition(sampleUV, sDepth);
        float d2 = Length2(S - P);

        // ------------------------- Calculate SinH -------------------------
        float3 H = (S - P) * rsqrt(d2);
        float sinH = -H.z;

        // ------------------------- Per-Sample Attenuation -------------------------
        [branch]
        if (d2 < r2 && sinH > lastSinH)
        {
            ao += Falloff(d2, r2) * (sinH - lastSinH);
            lastSinH = sinH;
        }
    
        sampleCoord += pixelDelta;
    }

获取每个 sample 的观察空间坐标以及计算 $\,sinH\,$ 没什么好说的，重点说一说 Per-Sample Attenuation，如果在步进的过程中，选择最大的 $\,sinH\,$ 计算 AO，由于 AO 的范围问题，会导致 AO 的不连续性，为了解决不连续性，首先我们会应用一个距离衰减函数，上面讲原理的时候也提到过，但是代码中的距离衰减函数多了一个平方：  

$$ r = \cfrac {||S - P||} {R} $$
$$ W(r) = 1 - r^2 $$

    inline float Falloff(float d2, float r2)
    {
        return saturate(1.0 - d2 * rcp(r2));
    }

其次是步进的过程中，不选用最高的 $\,sinH\,$ 值，只有下一个 sample 比当前 sample 高，就累计乘以距离衰减函数的 $\,sinH\,$ 值。即对于第一个 sample（S1）：  

$$ AO(S_1) = W(S_1)(sinH(S_1) - sinT) $$

对于后面的 sample，若 $\,sinH\,$ 值更大，则累计 AO 值：  

$$ AO(S_1) + W(S_2)(AO(S_2) - AO(S_1)) = AO(S_1) + W(S_2)(sinH(S_2) - sinH(S_1)) $$

HBAO 最终效果如下，过滤跟上一篇文章 SSAO 是一样的：  

<div align="center">  
<img src="https://s2.loli.net/2025/09/21/CNni3TkrojgsPtZ.png" width = "100%" height = "100%" alt="图19 - HBAO 1080P，NUM_DIRECTIONS 为 4，NUM_STEPS 为 4，Radius 为 1，上图：Half-Resolution 无过滤；左图：Half-Resolution + Spatial Filter（sigma 为 0.6）+ Temporal Filter；右图：Full-Resolution + Spatial Filter（sigma 为 0.6）+ Temporal Filter"/>
</div>

NVIDIA 推荐 AO 在 Half-Resolution 下进行，但过滤在 Full-Resolution 下进行，我上图中 AO 和过滤都是 Half-Resolution 或 Full-Resolution 下进行的。我感觉 HBAO 的噪点是比较重的，最好过滤在 Full-Resolution 下进行，即先 Half-Resolution AO，再上采样至 Full-Resolution 进行过滤。下面与 SSAO 对比中，我也会大致说明我认为的噪点比 SSAO 重的原因。

HBAO 还有一个问题，就是在比较细的物体边缘会有闪烁问题，在 [Stable SSAO in Battlefield 3 with Selective Temporal Filtering](https://d29g4g2dyqv443.cloudfront.net/sites/default/files/akamai/gamedev/files/gdc12/GDC12_Bavoil_Stable_SSAO_In_BF3_With_STF.pdf) 里面也有提到这一点。但由于后面会用升级版的 HBAO 即 GTAO 来替代该算法，我就没有花时间处理这些问题。

## 其他说明
### Angle Bias
法线插值后，会导致错误的法线，从而引入 false occlusion，导致 AO 不连续的问题。此时可以引入一个 Angle Bias 抬高切线，减少 AO 不连续的问题：  

    sinT += g_AngleBias;

我没有遇到 AO 不连续的问题，所以我没有加上这个 Angle Bias，但是 PPT 中展示的效果如下：  

<div align="center">  
<img src="https://s2.loli.net/2025/09/21/CispyEnavdz8rZ2.png" width = "75%" height = "75%" alt="图20 - Angle Bias"/>
</div>

### HBAO+ 的方法
我找到的这篇文章 [An alternative implementation for HBAO](https://www.derschmale.com/2013/12/20/an-alternative-implementation-for-hbao-2/) 有提到 HBAO 的另外一种计算方法：原本 HBAO 是让半球绕着观察方向（观察空间的 z 轴）旋转，即 z 轴是球坐标的基。但这个方法做出了一个简化，直接使用 normal 方向作为球坐标的基，但是还是在观察空间中做步进，如下图：  

<div align="center">  
<img src="https://s2.loli.net/2025/09/21/2kR1Zn6POKjm9sG.png" width = "40%" height = "40%" alt="图21 - Height field with Horizon angle relative to t"/>
</div>

此时公式就比较简单了，就不需要两个角度相减了，直接将 normal 和 horizon 方向的 cos 值作为 AO 即可，这个 cos 值就等于 $\,sin(h(\theta))\,$。而 NVIDIA 在 HBAO 的改进 [HBAO+](https://github.com/NVIDIAGameWorks/HBAOPlus/tree/master) 中，计算 AO 的代码也是如此：  

    //----------------------------------------------------------------------------------
    // P = view-space position at the kernel center
    // N = view-space normal at the kernel center
    // S = view-space position of the current sample
    //----------------------------------------------------------------------------------
    float ComputeAO(float3 P, float3 N, float3 S, AORadiusParams Params)
    {
        float3 V = S - P;
        float VdotV = dot(V, V);
        float NdotV = dot(N, V) * rsqrt(VdotV);

        // Use saturate(x) instead of max(x,0.f) because that is faster
        return saturate(NdotV - g_fNDotVBias) * saturate(Falloff(VdotV, Params));
    }


但是我实际实践过后，发现这个方法有个致命缺陷，不知道是不是我自己代码的问题，就是当 normal 越接近垂直于视角方向，AO 就越淡。我仔细想了想发生这种现象的原因，应该是因为当 normal 接近垂直于视角方向时，步进方向错误的问题，因为若使用上述方法，我们步进的方向应该是基于 normal 方向的，但实际上我们是基于屏幕步进的，也就是说 normal 并不在我们步进的平面（视角方向和步进方向组成的平面）上，导致计算的角度产生了问题。而之前两个 sin 相减的方法中，tangent 的计算方式保证了 tangent 在步进的平面上。

我看知乎上很多人的 HBAO 的计算方式也是直接计算 cos 值的，但是展示的图片有些感觉是存在上述问题的，有些又感觉没有，所以我不确定是不是我自己代码写错的问题（虽然我没发现自己代码的错误）。因为后面肯定要实现 GTAO 的，HBAO 作为 GTAO 的弱化版，我没打算最终使用 HBAO 作为 YPipeline 的一项功能，所以也就没有花时间来彻底搞明白这个问题。讲道理 HBAO+ 的效果展示挺正常的，应该不存在这样的问题。但 GTAO 的 [PPT](https://blog.selfshadow.com/publications/s2016-shading-course/activision/s2016_pbs_activision_occlusion.pdf) 有这么一句话：Note that HBAO+ is the latest implementation and seems to not be horizon based，根据这句话我感觉可能这个问题确实存在，否则 GTAO 为什么不用这个方法。

> 我写到这里的时候，还没有仔细阅读 GTAO 的 PPT，但后来发现 GTAO 中确实提到了 normal 有可能不在步进平面（slice 平面）上，并给出了解决方案，详见 GTAO 原理的注意事项小节。

### Compute Shader 优化
NVIDIA 在 DirectX 11 SDK Sample 中，除了在像素着色器的实现外（即我讲述的实现），还有一个 Compute Shader 的实现，对 HBAO 进行了优化。方法就是类似于拆分高斯模糊的方式，将 HBAO 的计算拆分为了 horizontal、vertical 两个 Pass，这样就可以利用 Group Shared Memory 来提前存储要采样区域的像素信息了，从而减少重复采样，缺点就是这样就有了一个 AO 的最大范围，而且还是基于像素的范围，并且固定了 AO 的步进方向。我没有实践过这个优化方案，有优化需求可以看看 NVIDIA 的代码。

除了上述 Compute Shader 的优化，NVIDIA 还在 HBAO+ 中使用了 **Deinterleaved Texturing** 的优化方案，具体详细查看以下链接：[Deinterleaved Texturing for Cache-Efficient Interleaved Sampling](https://developer.nvidia.com/sites/default/files/akamai/gameworks/samples/DeinterleavedTexturing.pdf) 、[Particle Shadows & Cache-Efficient Post-Processing](https://developer.nvidia.com/sites/default/files/akamai/gamedev/docs/BAVOIL_ParticleShadowsAndCacheEfficientPost.pdf)。

### 与 SSAO 对比
首先在相同采样数的情况下，HBAO 的噪点比 SSAO 要明显一点，因为 HBAO 的采样点并不是均匀地分布在圆盘当中，而是取均匀分布的几个方向，再在方向上取均匀分布的采样点，而 SSAO 是均匀分布在半球内，故 HBAO 相对于 SSAO 来说采样点更不均匀，造成的结果就是相同采样数下噪点更大。但是从 AO 效果而言，HBAO 比 SSAO 更加真实更物理正确一点，如下图：  

<div align="center">  
<img src="https://s2.loli.net/2025/09/22/SFj6fkrO2uepKHY.png" width = "100%" height = "100%" alt="图22 - 4K，Full-Resolution，左图：HBAO + Temporal Filter，NUM_DIRECTIONS 为 8，NUM_STEPS 为 4；右图：SSAO + Temporal Filter，32 次采样。"/>
</div>

可以看出 HBAO 的效果是更加合理的，特别是墙上的酒瓶处，SSAO 几乎没有 AO 现象，这肯定是不合理的。之所以会这样，是因为 SSAO 计算遮蔽的方式是基于深度值的，深度远的被深度近的遮挡，但是实际上遮蔽不应该是这样的。但是最终选用哪个算法，还是得基于美术，合理不一定是好看的。若追求真实度，还是得使用 HBAO，当然 GTAO 更好。

# GTAO
> HBAO 参考文献如下：  
> ① **Practical Realtime Strategies for Accurate Indirect Occlusion (SIGGRAPH 2016)** 的 PPT：https://blog.selfshadow.com/publications/s2016-shading-course/activision/s2016_pbs_activision_occlusion.pdf ；
> ② 上述 PPT 对应的技术报告(论文)：老版为 https://www.activision.com/cdn/research/PracticalRealtimeStrategiesTRfinal.pdf ，  
> 新版为 https://www.activision.com/cdn/research/Practical_Real_Time_Strategies_for_Accurate_Indirect_Occlusion_NEW%20VERSION_COLOR.pdf ；  
> ③ Unity HDRP 的 GTAO：https://github.com/Unity-Technologies/Graphics/blob/master/Packages/com.unity.render-pipelines.high-definition/Runtime/Lighting/ScreenSpaceLighting/GTAO.compute ；  
> ④ MaxwellGengYF 的开源 GTAO 库：https://github.com/MaxwellGengYF/Unity-Ground-Truth-Ambient-Occlusion 。


## GTAO 原理
**Ground Truth Based Ambient Occlusion (GTAO)** 由动视暴雪于 SIGGRAPH 2016 中提出，是对 HBAO 的改进。相对于 HBAO，GTAO 考虑了**余弦权重**，并且除了 **Diffuse Occlusion** 还额外计算了 **Specular Occlusion**，称为 **Ground Truth Based Specular Occlusion (GTSO)**。从 GTAO 的名字可以看出，这个算法追求的是绝对真实的 AO 效果，正如 PPT 中展示的下图所示：  

<div align="center">  
<img src="https://s2.loli.net/2025/09/22/E2ag4oMGiYQWvKf.png" width = "65%" height = "65%" alt="图23 - GTAO vs Monte Carlo Ground Truth"/>
</div>

GTAO 的基础公式如下，跟 HBAO 类似，分为里外两层积分：  

$$ V_d = \cfrac {1}{\pi} \int_{\Omega} V(\omega_i) (n \cdot \omega_i) d \omega_i = \cfrac {1}{\pi} \int_0^{\pi} \int_{- \pi / 2}^{\pi / 2} V(\theta, \phi) (n \cdot \omega_i) |sin(\theta)| d\theta d\phi $$

除了多了余弦权重外，要额外注意两点，**①**公式中的 $\,\theta\,$ 和 $\,\phi\,$ 就是基于视角方向 v 的球坐标的**天顶角**和**方位角**，所以这里多出来的是 $\,|sin(\theta)|\,$，而不是 HBAO 中基于 Elevation Angle 的 $\,cos\alpha\,$，至于为什么多出正弦值，可以回去看 [GAMES101-图形学入门公开课笔记（二）](https://ybniaobu.github.io/2024/04/23/2024-04-23-GAMES_101_2/) 的立体角相关知识。**②**是公式中积分的范围，外积分是 180 度，内积分也是 180 度，而 HBAO 外积分是 360 度，内积分是 90 度。区别就在于 HBAO 的每个 Slice 是四分之一的圆，即 90 度，所以它需要转 360 度形成半球，而 GTAO 每个 Slice 是半圆，即 180 度，只需转 180 度就可以形成半球，如下图所示：  

<div align="center">  
<img src="https://s2.loli.net/2025/09/22/F5gCPAvqKfB7kWL.png" width = "50%" height = "50%" alt="图24 - GTAO double integral illustration"/>
</div>

GTAO 同样是使用 Depth Buffer 作为来计算 AO，但缺点就是上图中真正被遮挡的区域（红色区域）无法与高度区域（即红色加绿色区域）进行区分，所以绿色的未被遮挡区域会被错误计算 AO，结果就是一些细小物体很难会被错误计算 AO，比如树叶等等，但 GTAO 提供了一个叫做 **Thickness Heuristic** 的方式来减轻这个问题，后面会专门提到。

### 积分化简
接下来就是对公式进行化简，先处理内积分，因为一个 Slice 是一个半圆，所以存在两个 Horizon Angle，即 $\,h_1\,$ 和 $\,h_2\,$，要将积分拆分为两个，还有要注意我们的余弦权重 $\,n \cdot \omega_i\,$ 理论上应该基于法线方向的，而不是基于视角方向的，如下：  

<div align="center">  
<img src="https://s2.loli.net/2025/09/22/QJmeDcWXO7ogxUF.png" width = "30%" height = "30%" alt="图25 - Solve Ambient Occlusion with Cosine Weighting"/>
</div>

$$ V_d^{cosine} = \cfrac {1}{\pi} \int_0^{\pi}\int_{-\pi/2}^{\pi/2} V(\theta, \phi) cos(\theta - n) |sin(\theta)| d\theta d\phi $$

其中内积可以拆分为：  

$$ IntegrateArc(h_1, h_2, n) = \int_0^{h_1} cos(\theta - n) |sin(\theta)| d\theta + \int_0^{h_2} cos(\theta - n) |sin(\theta)| d\theta $$

接下来就是求定积分了，首先根据三角函数中的和角公式：  

$$ sin(\alpha + \beta) = sin\alpha cos\beta + cos\alpha sin\beta $$
$$ sin(\alpha - \beta) = sin\alpha cos\beta - cos\alpha sin\beta $$
$$ \Rightarrow sin\alpha cos\beta = \cfrac{1}{2} [sin(\alpha + \beta) + sin(\alpha - \beta)] $$

故内积分的被积函数可以写为：  

$$ cos(\theta - n) sin(\theta) = \cfrac{1}{2} sin(2\theta - n) + \cfrac{1}{2} sin(n) $$

然后就是分别求不定积分了：  

$$ \int \cfrac{1}{2} sin(2\theta - n) + \cfrac{1}{2} sin(n) d\theta = -\cfrac{1}{4} cos(2\theta - n) + \cfrac{1}{2} sin(n) \theta + C $$

最终定积分为：  

$$ IntegrateArc(h_1, h_2, n) = \cfrac {1}{4} (-cos(2h_1 - n) + cos(n) + 2h_1sin(n)) + \cfrac {1}{4} (-cos(2h_2 - n) + cos(n) + 2h_2sin(n)) $$

> 提一嘴，内积分实际上 $\,|sin(\theta)|\,$ 是带绝对值的，所以当 $\,\theta\,$ 为负数时，$\,|sin(\theta)|\,$ 应该变为 $\,-sin(\theta)\,$，内积的不定积分应该也全部加个负号。但是因为积分范围对于 $\,h_1\,$ 来说，应该是 $\,h_1\,$ 到 0（$\,h_1\,$ 是负的），而不是 0 到 $\,h_1\,$，所以负负得正，导致 $\,h_1\,$ 和 $\,h_2\,$ 的最终积分是相同的。

### 注意事项
上述公式还不能直接使用，有两点需要注意：**①** $\,h_1\,$ 和 $\,h_2\,$ 很有可能不在以 normal 为轴的半球之内，需要钳制（注意 $\,h_1\,$ 是负的）：  

$$ h_1' = n + max(h_1 - n, -\pi / 2) $$
$$ h_2' = n + min(h_2 - n, \pi / 2) $$

<div align="center">  
<img src="https://s2.loli.net/2025/09/23/rtPa1XJ3WyGiFYH.png" width = "30%" height = "30%" alt="图26 - Clamp horizons in the normal hemisphere"/>
</div>

**②** normal 可能不在 Slice 的平面之上，这点我在 HBAO 中也有略微提到，需要将 normal 投影到 Slice 平面上，同时修改一下 GTAO 的公式：  

$$ \begin{align*} V_d^{cosine} &= \cfrac {1}{\pi} \int_0^{\pi} \int_{- \pi / 2}^{\pi / 2} V(\theta, \phi) (\vec{n} \cdot \vec{\theta}) |sin(\theta)| d\theta d\phi \\ &= \cfrac {1}{\pi} \int_0^{\pi} ||\vec{n_p}||\int_{- \pi / 2}^{\pi / 2} V(\theta, \phi) (\vec{n_p} \cdot \vec{\theta}) |sin(\theta)| d\theta d\phi \end{align*} $$

<div align="center">  
<img src="https://s2.loli.net/2025/09/23/Xyc8U1wdKhZQP4o.png" width = "25%" height = "25%" alt="图27 - Normal projection"/>
</div>

## 具体实现
### 步长
这一步和 HBAO 几乎没什么区别。首先获取当前像素点的观察空间坐标以及法线的观察空间坐标，就不再赘述了。计算步长和 HBAO 在逻辑上也是没有区别的，就是需要注意暴露给艺术家的参数的定义，步数可以定义在半径上，也可以定义在直径上（毕竟 GTAO 的 Slice 是一个半圆），为了方便理解和后续代码的书写，我选择跟 HBAO 一样，AO 范围为半径，步数定义在半径上，这样子计算屏幕空间半径和步长的代码就和 HBAO 的一模一样了，我就不重复摘抄了。

### Noise
跟 HBAO 一样，需要计算步进方向之间角度，同时给这个角度和上面计算的步长添加一个 Noise。计算步进方向之间角度和 HBAO 有个小区别，就是 GTAO 的总旋转角度是 180 度，而不是 360 度：  

    float dirAngle = PI / GTAO_NUM_DIRECTIONS;

GTAO 和各种随机技术一样，比较依赖于 Temporal Filter 的降噪。故角度和步长的 Noise 的选择是比较重要的，在 GTAO 的 PPT 中，给出了 Noise 的计算方式，代码大致如下：  

    float noise = (1.0 / 16.0) * ((((id.x + id.y) & 0x3) << 2) + ((id.x) & 0x3));
    const float rotations[] = {60.0, 300.0, 180.0, 240.0, 120.0, 0.0};
    float rotation = rotations[_TimeParams.x % 6] / 360.0;
    float randomRadian = (noise + rotation * IsTemporalBlurEnabled()) * TWO_PI;

    float noise2 = 0.25 * ((id.y - id.x) & 0x3);
    const float offsets[] = {0.0, 0.5, 0.25, 0.75};
    float offset = offsets[(_TimeParams.x / 6) % 4];
    float randomOffset = frac(noise2 + offset * IsTemporalBlurEnabled());

其中 `_TimeParams.x` 是当前帧数 Frame Count。我实践之后跟 Blue Noise 方案做了个对比，觉得 GTAO PPT 中的 Noise 方案比 Blue Noise 的方案更稳定一点，但是噪点存在一定的固定 Pattern，虽然这个 Pattern 能在视觉上减少对噪点的感知。Blue Noise 的方案整体的降噪能力更强，但是噪点闪烁也更严重。选择什么方案看项目需求，我更喜欢 Blue Noise 的方案，如下：  

    float2 noise = LOAD_TEXTURE2D_LOD(_BlueNoise64, id.xy % _BlueNoise64_TexelSize.zw, 0).rg;
    float randomRadian = (noise.r + _Jitter.w * IsTemporalBlurEnabled()) * TWO_PI;
    float randomOffset = frac(noise.g + _Jitter.z * IsTemporalBlurEnabled());

    for (int d = 0; d < GTAO_NUM_DIRECTIONS; d++)
    {
        float angle = dirAngle * d + randomRadian;
        float3 dir = float3(cos(angle), sin(angle), 0);
        float2 pixelDelta = dir.xy * stepSizeInPixel;
        ...

        for (int s = 0; s < numSteps; s++)
        {
            float2 offset = (randomOffset + s) * pixelDelta;
            ...
        }
    }

我选择了一张彩色 Blue Noise 的前两个通道（蓝噪声可以看 NVIDIA 的这篇文章：[Rendering in Real Time with Spatiotemporal Blue Noise Textures](https://developer.nvidia.com/blog/rendering-in-real-time-with-spatiotemporal-blue-noise-textures-part-1/)）。我还发现增加方向数量可以减少噪点，而减少步数并不会增加噪点，也就是说 NUM_DIRECTIONS 和 NUM_STEPS 都为 4 的噪点，比 NUM_DIRECTIONS 为 2 以及 NUM_STEPS 为 8 的噪点要少，就是 AO 效果会淡一点。我觉得 Blue Noise 的方案应该还可以再优化，减少噪点闪烁问题，就是没想到什么好办法，以后再看看有什么更好的解决方案。

### 计算 AO
拿到了步长和方向，就可以计算采样点的屏幕坐标了，从而获取 Depth 并重构出观察空间的坐标。这里和 HBAO 的区别在于，一次性要获取两个采样点（即 $\,h_1\,$ 和 $\,h_2\,$）的坐标：  

    float2 cosH;

    for (int s = 0; s < numSteps; s++)
    {
        float2 offset = (randomOffset + s) * pixelDelta;
        float4 sampleCoord = clamp(id.xyxy + float4(-offset, offset), 0, _TextureSize.zwzw - 1);
        float4 sampleUV = (sampleCoord + 0.5) * _TextureSize.xyxy;
        float sh1Depth = LoadDepth(sampleCoord.xy); // sample h1
        float sh2Depth = LoadDepth(sampleCoord.zw); // sample h2
        float3 sh1 = FetchViewPosition(sampleUV.xy, sh1Depth) - P; // sample h1
        float3 sh2 = FetchViewPosition(sampleUV.zw, sh2Depth) - P; // sample h1
        ...
    }

拿到坐标后，就可以利用点乘计算 $\,h_1\,$ 和 $\,h_2\,$ 与视角方向 V 的夹角的余弦值了，即 cosH 值：  

    float2 length2 = float2(dot(sh1, sh1), dot(sh2, sh2));
    cosH = float2(dot(sh1, V), dot(sh2, V)) * rsqrt(length2);

这个 cosH 值要分别搜索出两个最大值，同时剔除掉超出 AO 范围的 cosH：  

    float2 cosH;
    float2 maxCosH = -1.0; // cos(pi)

    for (int s = 0; s < numSteps; s++)
    {
        ...
        maxCosH = lerp(maxCosH, max(cosH, maxCosH), length2 < r2);
    }

拿到最大 cosH 值之后，步进循环就可以结束了，接下来是回到方向循环中计算当前方向（Slice）的 AO 值了。首先先对 normal 进行投影，投影到当前 Slice 的平面上去：  

    float3 sliceNormal = normalize(cross(dir, V));
    float3 tangent = cross(normalVS, sliceNormal);
    float3 projectedNormal = normalVS - sliceNormal * dot(normalVS, sliceNormal);
    float projectedNormalLength = length(projectedNormal);

因为 projectedNormal 和观察方向 v 的夹角是通过点乘计算而得的，所以无法判断 n 的正负号，需要通过上面计算的 tangent 判断：  

    float cosn = dot(normalize(projectedNormal), V);
    float n = -sign(dot(V, tangent)) * acos(cosn);

接下来就是将 $\,h_1\,$ 和 $\,h_2\,$ 钳制到 normal 为轴的半球之内，之前都提到过：  

    maxCosH = clamp(maxCosH, -1.0, 1.0);
    float2 h = acos(maxCosH);
    h.x = n + max(-h.x - n, -HALF_PI); // H1
    h.y = n + min(h.y - n, HALF_PI); // H2

最后就可以计算 ao 值了：  

    ao += projectedNormalLength * IntegrateArcCosWeight(h, n);

其中 `IntegrateArcCosWeight` 如下：

    float IntegrateArcCosWeight(float2 h, float n)
    {
        float2 arc = -cos(2 * h - n) + cos(n) + 2 * h * sin(n);
        return 0.25 * (arc.x + arc.y);
    }

**【书签】**
由于反三角函数是超越函数，GTAO 提供了

    float GTAOFastAcos(float x)
    {
        float res = -0.156583 * abs(x) + HALF_PI;
        res *= sqrt(1.0 - abs(x));
        return x >= 0 ? res : PI - res;
    }

## Thickness Heuristic

## Multi-Bounce

## Temporal Filter 优化

# GTSO
