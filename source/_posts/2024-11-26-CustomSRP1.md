---
title: Unity Custom SRP 基础（一）
date: 2024-11-26 12:43:30
categories: 
  - [图形学]
  - [unity, pipeline]
tags:
  - 图形学
  - 游戏开发
  - unity
top_img: /images/black.jpg
cover: https://s2.loli.net/2024/11/26/zxA7bEi36HYDQKP.gif
description: 
---

> 本文章是关于 Unity 的**自定义可编程渲染管线**的入门基础，即 **SRP (Scriptable Rendering Pipeline)**，主要参考了著名的教程 https://catlikecoding.com/ 的 Custom SRP Tutorial，以及知乎上各位图形学大神们的文章。  
>    
> 笔者使用的 Unity 版本是 6000.0.27f1，Core RP Library 的版本是 17.0.3。
> 
> 既然是入门基础，暂不考虑 Pipeline 的框架或架构问题，日后正式写自定义渲染管线时再处理。

# 基础概念介绍
## SRP 和 CommandBuffer
Unity 的 **CommandBuffer** 是一个渲染命令列表，类似于 DirectX 中的**命令列表 Command list**，它们的作用主要是为了 CPU 与 GPU 间的交互。每个 GPU 都至少有一个**命令队列 Command queue**，借助图形 API（比如 Direct3D），CPU 可以利用**命令列表 Command list** 将命令提交到这个队列中。所以 Unity 的 SRP 可以理解为是对图形 API 的封装，并提供了 C# 调用接口。我们使用 C# 脚本来配置渲染命令，告诉 Unity C++ 底层图形框架去执行这些命令，然后 Unity 底层再传递指令给图形 API。

而在 SRP 中，连接 C# 渲染管线代码和底层 C++ 图形框架的正是 **ScriptableRenderContext** 类。SRP 渲染工作使用的是延迟执行，我们使用 `ScriptableRenderContext.ExecuteCommandBuffer` 将 CommandBuffer 队列信息缓存到 ScriptableRenderContext 中，最后 `ScriptableRenderContext.Submit` 集中提交绘制指令。

一个简易的渲染流程图如下：  

<div  align="center">  
<img src="https://s2.loli.net/2024/11/26/hwqQCckXT4eUOn1.png" width = "30%" height = "30%" alt="图1 - 简易渲染流程"/>
</div>

## RenderTarget
**渲染目标 RenderTarget** 是现代图形处理单元 GPU 的一个特征，它允许将 3D 场景渲染到中间存储缓冲区或**渲染目标纹理 RenderTargetTexture（RTT）**，而不是帧缓冲区或后缓冲区。然后可以通过像素着色器操纵此 RTT ，以便在显示最终图像之前将其他效果应用于最终图像。

而**延迟渲染 Deferred Rendering** 正是得益于硬件对于**多重渲染目标 Multiple Render Target（MRT）** 的支持。其核心在于 **G-Buffer** ，延迟渲染将计算光照的参数渲染至 G-Buffer 中，也就是若干张纹理贴图，通常包含了 Depth，Normal，Albedo，Roughness，Specular 和 Metallic。最后将上述几张贴图进行相关计算混合，生成了游戏中的一帧。

# 创建基本的自定义 SRP
## 前置工作
①切换色彩空间：在 Edit -> Project Settings -> Player -> Other Settings -> Color Space 中选择 Linear。  
②在 PackageManager 下载 Core RP Library，这个包里有一些可以重复利用的代码来帮助我们创建自己的渲染管线。

## 创建管线资产和实例
要创建基于 SRP 的自定义渲染管线，项目中必须包含以下三个要素：  
①需要有一个脚本继承自 `RenderPipelineAsset` 并覆写它的 `CreatePipeline()` 方法，这个脚本定义了**渲染管线资产 Render Pipeline Asset**；  
②需要有一个脚本继承自 `RenderPipeline` 并覆写它的 `Render()` 方法，这个脚本定义了**渲染管线实例 Render Pipeline Instance**，同时也是写自定义渲染代码的入口；  
③一个从第一步的脚本创建出来的渲染管线资产，这个资产作为创建渲染管线实例的工厂。

首先第一步：创建一个名为 XXRenderPipelineAsset 的 C# 脚本：  

``` C#
using UnityEngine;
using UnityEngine.Rendering;

[CreateAssetMenu(menuName = "XXXX/XXRenderPipelineAsset")]
public class XXRenderPipelineAsset : RenderPipelineAsset
{
    protected override RenderPipeline CreatePipeline() 
    {
        return new XXRenderPipeline();
    }
}
```

Unity 在渲染第一帧前会调用 `CreatePipeline()` 方法，如果 Render Pipeline Asset 的设置发生了改变，Unity 会释放当前的 Render Pipeline Instance 并在下一帧渲染前重新调用这个方法。而这个 Render Pipeline Asset 则是一个存储渲染设置的地方，只不过这里暂时还没有设置，我们可以在 Render Pipeline Asset 存储一些信息以便 Render Pipeline Instance 使用。

第二步：创建一个名为 XXRenderPipeline 的 C# 脚本：  

``` C#
using System.Collections.Generic;
using UnityEngine;
using UnityEngine.Rendering;

public class XXRenderPipeline : RenderPipeline
{
    public XXRenderPipeline() {}

    protected override void Render(ScriptableRenderContext context, Camera[] cameras) 
    {
        // Older version of the Render function that can generate garbage, needed for backwards compatibility
    }

    protected override void Render(ScriptableRenderContext context, List<Camera> cameras) {}
}
```

这个 `Render()` 方法就是我们自定义渲染循环 render loop 的入口，这个方法接受一个 ScriptableRenderContext 和摄像机数组。我们可以看到两个 `Render()` 方法，一个接受摄像机数组，一个接受集合中的列表。而接受摄像机数组的方法由于会因为数组长度变化而造成堆分配的原因而不推荐使用，所以我们使用那个接受摄像机列表的 `Render()` 方法。但是即使我们不使用接受摄像机数组的 `Render()` 方法，我们仍然需要覆写它，因为它是一个抽象方法。

第三步：根据第一步脚本自己设定的 AssetMenu 位置，在项目中右键创建自己的渲染管线资产 XXRenderPipelineAsset，并在 Edit -> Project Settings -> Graphics -> Default Render Pipeline 中替换为自己的渲染管线资产 XXRenderPipelineAsset。此时屏幕会全黑，因为我们还没有设置任何东西，无法渲染。

## 创建渲染循环
Unity 会在渲染的每一帧调用 Render Pipeline Instance 的 `Render()` 方法，并传递一个 ScriptableRenderContext 结构体，用于连接 Unity C++ 底层，以及 Cameras 列表。通过传递过来的 Cameras 列表，可以使用一个循环遍历所有摄像机对 ScriptableRenderContext 进行绘制。

一个简单的渲染循环包含以下三个基本的操作：  
①**Clearing the render target**，摄像机的渲染目标要么是**帧缓冲 framebuffer** 要么是**渲染纹理 render texture**。但无论是哪一个，上一帧绘制的东西仍然在那里，所以我们要清除掉；  
②**Culling**，剔除掉摄像机视锥体以外的物体；  
③**Drawing**，告诉 GPU 绘制哪些几何物体，怎么去绘制。

### Clearing the render target
正如文章开头所说，因为 ScriptableRenderContext 是延迟提交的，直到我们调用 `ScriptableRenderContext.Submit()` 方法把所有安排好的 commands 提交到渲染循环进行执行。所以一开始我们要配置 ScriptableRenderContext 去添加 commands。

首先我们要创建 CommandBuffer 实例，同时给 CommandBuffer 一个名字用于在 Frame debugger 中显示，再加上清除渲染目标的内容，代码如下：  

``` C#
const string bufferName = "Custom Rendering Event";
CommandBuffer buffer = new CommandBuffer 
{
    name = bufferName
};

protected override void Render(ScriptableRenderContext context, List<Camera> cameras) 
{
    foreach(Camera camera in cameras)
    {
        context.SetupCameraProperties(camera);

        // Clearing the render target
        buffer.ClearRenderTarget(true, true, Color.clear);
        buffer.BeginSample(bufferName);
        context.ExecuteCommandBuffer(buffer);
        buffer.Clear();
                
        // Submit all scheduled commands
        buffer.EndSample(bufferName);
        context.ExecuteCommandBuffer(buffer);
        buffer.Clear();
        context.Submit();
    }
}
```

上述代码解释：  
①首先 `CommandBuffer.BeginSample()` 和 `CommandBuffer.EndSample()` 方法是用于添加 Unity 的 performance profiling sample 命令的，也就是 Window -> Analysis 里的 Profiler 和 Frame Debugger 这两个分析工具。其实这两个方法以及之间的代码都可以不要了，后面的 Drawing 里会提到原因，使用老的废弃的 API `ScriptableRenderContext.DrawRenderers()`，`ScriptableRenderContext.DrawSkybox()` 等时才需要用到；  
②使用 `ScriptableRenderContext.ExecuteCommandBuffer(buffer)` API 提交 CommandBuffer 到 ScriptableRenderContext 的命令队列当中去。提交 CommandBuffer 后，CommandBuffer 并不会被清空，为了防止之后再提交 CommandBuffer 时产生重复的命令，需要将其清空，即 `CommandBuffer.Clear()`。最后使用 `ScriptableRenderContext.Submit()` API 让图形 API 去执行 ScriptableRenderContext 中的命令队列；  
③接下来就是 `CommandBuffer.ClearRenderTarget()` 了，它至少接受 3 个参数，一是是否清除深度缓冲 depth buffer 和模板缓冲 stencil buffer，二是是否清除颜色缓冲 color buffer，三是清除颜色缓冲使用的颜色，使用了 Color.clear。depth buffer 的默认替代值为 1.0，stencil buffer 的默认替代值为 0.0。但是为什么 `CommandBuffer.ClearRenderTarget()` 要放在 `CommandBuffer.BeginSample()` 上面，是因为 ClearRenderTarget() 方法自带了带有 CommandBuffer 名字的 profiling sample 命令，不放在上面会导致 Frame Debugger 里嵌套 profiling sample 命令；  
④如果不在 `CommandBuffer.ClearRenderTarget()` 之前设置好摄像机的属性的话，ClearRenderTarget() 会调用一个 Draw GL 的渲染事件（可以在 Frame Debugger 里看到），它会使用 Hidden/InternalClear shader 绘制一个全屏幕的矩形写入 RenderTarget，这并不是一个最有效率的做法。如果在清除渲染目标前设置相机属性，就可以在 Frame Debugger 中看到 Clear(Color + Depth + Stencil)，如下图所示：  

<div  align="center">  
<img src="https://s2.loli.net/2024/11/28/JraiSnjGtOxkQu3.png" width = "35%" height = "35%" alt="图2 - 上图：不设置摄像机属性；下图：正确的 Clear，在 ClearRenderTarget() 前设置摄像机属性"/>
</div>

同时 `ScriptableRenderContext.SetupCameraProperties(camera);` 的主要作用是设置摄像机的观察投影矩阵全局 shader 变量，即 unity_MatrixVP。

### Culling
为了知道哪些物体可以被裁切，我们需要知道摄像机的一些设置以及相关矩阵，这些数据可以用 `ScriptableCullingParameters` 结构体存储，并通过 `Camera.TryGetCullingParameters(out ScriptableCullingParameters)` 获取这些数据。然后我们使用 `ScriptableRenderContext.Cull(ref ScriptableCullingParameters)`（这里是引用参数的原因是为了防止形参复制导致的内存分配）返回 `CullingResults` 结构体，这个结构体包含了可见物体、光源以及反射探针的信息，并且在 Drawing 时会被使用。上述的代码如下（我写在了 SetupCameraProperties 前）：  

``` C#
if (camera.TryGetCullingParameters(out ScriptableCullingParameters cullingParameters))
{
    CullingResults cullingResults = context.Cull(ref cullingParameters);
}
else
{
    return;
}
                
context.SetupCameraProperties(camera);
```

`Camera.TryGetCullingParameters()` 方法会返回一个 bool 来判断摄像机是否会无效渲染，比如不正确的远近裁切平面等。如果返回 false，就直接退出 `Render()` 方法。这里也用到了一个小语法糖，即直接在方法调用时的参数列表中声明变量：out ScriptableCullingParameters cullingParameters。


### Drawing
在 catlikecoding 的教程中，使用的是老的 API `ScriptableRenderContext.DrawRenderers()`，`ScriptableRenderContext.DrawSkybox()`，`ScriptableRenderContext.DrawShadows()`。但是在调用这些方法前，需要调用 `ScriptableRenderContext.ExecuteCommandBuffer(buffer)`。比如 catlikecoding 中绘制 Skybox 的代码中：  

``` C#
// Clearing the render target
buffer.ClearRenderTarget(true, true, Color.clear);
buffer.BeginSample(bufferName);
context.ExecuteCommandBuffer(buffer);
buffer.Clear();

// Drawing
context.DrawSkybox(camera);
                
// Submit all scheduled commands
buffer.EndSample(bufferName);
context.ExecuteCommandBuffer(buffer);
buffer.Clear();
context.Submit();
```

如果删除 `buffer.BeginSample(bufferName);` 后的 `context.ExecuteCommandBuffer(buffer);` 以及 `buffer.Clear();`，就会先绘制 Skybox 再 ClearRenderTarget，因为我们提交 CommandBuffer 在绘制 Skybox 的后面。而且我们还需要把 `context.DrawSkybox(camera)` 包裹在 BeginSample 和 EndSample 之间，也没法把绘制 Skybox 放置在最后面。这就很蠢，不能集中提交 CommandBuffer 了，所以 Unity 废弃了这些 API（`DrawRenderers()`、`DrawSkybox()`、`DrawShadows()`），并使用 `CommandBuffer.DrawRendererList()` API 替代了这些方法。我下面使用的就是新的 API。

---

Drawing 的过程可以分为 4 个步骤：  
①创建并配置 `FilteringSettings` 结构体，它描述了如何过滤这些绘制指令接受的物体的相关设置，比如可以传递进  `RenderQueueRange.transparent` 或 `RenderQueueRange.opaque` 来只绘制不透明或透明物体；  
②创建并配置 `DrawingSettings` 结构体，它描述了怎么去排序可见的物体以及使用哪个 Shader Pass 去绘制，所以它的构造函数接受两个参数，一个是 `SortingSettings` 结构体，一个是 `ShaderTagId`（就是我们写的 Shader 里 Pass 的 LightMode 标签）；   
③创建并配置 `RendererListParams` 结构体，并传递进 `CullingResults`、`FilteringSettings`、`DrawingSettings`；  
④使用 `ScriptableRenderContext.CreateRendererList(ref RendererListParams)` 方法创建 RendererList，最后使用 `CommandBuffer.DrawRendererList()` 添加命令。

> 上述的结构体的属性设置内容并没有全部提到，强烈建议看看官方文档，很多设置之后肯定是要用到的。

``` C#
// Clear the render target
buffer.ClearRenderTarget(true, true, Color.clear);

// Draw Opaque
FilteringSettings filteringSettings = new FilteringSettings(RenderQueueRange.opaque);

SortingSettings sortingSettings = new SortingSettings(camera)
{
    criteria = SortingCriteria.CommonOpaque
};

ShaderTagId unlitShaderTagId = new ShaderTagId("SRPDefaultUnlit");

DrawingSettings drawingSettings = new DrawingSettings(unlitShaderTagId, sortingSettings);

RendererListParams rendererListParams =
    new RendererListParams(cullingResults, drawingSettings, filteringSettings);

RendererList opaqueRendererList = context.CreateRendererList(ref rendererListParams);
buffer.DrawRendererList(opaqueRendererList);

// Draw Skybox
RendererList skyboxRendererList = context.CreateSkyboxRendererList(camera);
buffer.DrawRendererList(skyboxRendererList);

// Draw Transparent
filteringSettings.renderQueueRange = RenderQueueRange.transparent;
sortingSettings.criteria = SortingCriteria.CommonTransparent;
drawingSettings.sortingSettings = sortingSettings;
rendererListParams.filteringSettings = filteringSettings;
rendererListParams.drawSettings = drawingSettings;

RendererList transparentRendererList = context.CreateRendererList(ref rendererListParams);
buffer.DrawRendererList(transparentRendererList);

// Submit all scheduled commands
context.ExecuteCommandBuffer(buffer);
buffer.Clear();
context.Submit();
```

上述代码一共绘制了不透明物体、Skybox 以及透明物体，注意透明物体一定要最后渲染，忘记原因了回去看《Unity Shader入门精要》的第七章透明效果，而先画不透明物体再画 Skybox 可以减少一些被遮挡的像素的重复绘制。  
①先从最简单的 Skybox 说起：Skybox 的 RendererList 的获取比较简单，不需要像代码的上面说的传递 RendererListParams 给 `CreateRendererList`，只需要传递进 camera 就行，即 `context.CreateSkyboxRendererList(camera)`，然后用 `DrawRendererList` 添加命令即可；  
②接下来就是绘制不透明物体了：首先是 `FilteringSettings`，可以使用构造函数加参数创建对象，也可以使用对象初始化语句，这两个方法的默认值并不一样，详见官方文档 [FilteringSettings](https://docs.unity3d.com/ScriptReference/Rendering.FilteringSettings-ctor.html) 。比较建议使用构造函数加参数，这样 layerMask、renderingLayerMask 就不会被设置为 0 了，同时传递进 RenderQueueRange.opaque，在渲染时过滤掉其他非不透明物体了；然后是 `SortingSettings`，它的构造函数只接受 camera，所以要使用对象初始化语句设置一些属性，比如 criteria，其规定了如何在渲染时为物体排序，建议为不透明物体使用 SortingCriteria.CommonOpaque，为透明物体使用 SortingCriteria.CommonTransparent；接下来是 `ShaderTagId`，这个就是 Pass 里的 LightMode，对于没设置 LightMode 的 Pass，SRP 仍然可以用 SRPDefaultUnlit 索引到这些 Pass；将 SortingSettings 和  ShaderTagId 传递给 `DrawingSettings`，以便 `RendererListParams` 使用。接下来就不说了，之前都提到过；   
③绘制透明物体和绘制不透明物体类似，修改一下 filteringSettings 和 sortingSettings 就行。

总之，Drawing 的目的就是根据我们的设置，用我们选择的 Pass 绘制物体至 RenderTarget。另外提一下，上述代码删除了 CommandBuffer.BeginSample 和 CommandBuffer.EndSample，是因为 CommandBuffer.DrawRendererList 跟 ClearRenderTarget 一样自带了带有 CommandBuffer 名字的 profiling sample 命令。我们不需要重复嵌套，上述代码的 Frame Debugger 如下图所示：

<div  align="center">  
<img src="https://s2.loli.net/2024/11/29/9wZmjEY3DBh2Rpu.png" width = "35%" height = "35%" alt="图3 - 绘制不透明物体、Skybox 以及透明物体"/>
</div>

## 编辑器渲染
### 绘制错误材质
目前为止，使用其他非 SRPDefaultUnlit 的 Pass 的物体不会被渲染，所以在场景中它们是不可见的。这就会让我们不知道场景中哪些物体使用了不受支持的 Shader。比如，如果想让 Unity 的 Built-in 的 Shader 都显示为错误的紫色，首先 Built-in 的 LightMode tag（shaders tag IDs）有 Always, ForwardBase, PrepassBase, Vertex, VertexLMRGBM, and VertexLM，如下：  

``` C#
static ShaderTagId[] legacyShaderTagIds = 
{
    new ShaderTagId("Always"),
    new ShaderTagId("ForwardBase"),
    new ShaderTagId("PrepassBase"),
    new ShaderTagId("Vertex"),
    new ShaderTagId("VertexLMRGBM"),
    new ShaderTagId("VertexLM")
};
```

接着还是老样子，绘制出这些 Pass：

``` C#
Material errorMaterial = new Material(Shader.Find("Hidden/InternalErrorShader"));

var drawingSettings = new DrawingSettings(legacyShaderTagIds[0], new SortingSettings(camera))
{
    overrideMaterial = errorMaterial
};

for (int i = 1; i < legacyShaderTagIds.Length; i++)
{
    drawingSettings.SetShaderPassName(i, legacyShaderTagIds[i]);
}

var filteringSettings = FilteringSettings.defaultValue;
var rendererListParams = new RendererListParams(cullingResults, drawingSettings, filteringSettings);
RendererList editorRendererList = context.CreateRendererList(ref rendererListParams);
buffer.DrawRendererList(editorRendererList);
```

这些代码可以放在绘制出所有可见物体的后面。我们通过 `DrawingSettings.SetShaderPassName()` 的 API 传递多个 shaders tag IDs，用以绘制多个 Pass。同时使用了 Hidden/InternalErrorShader 覆盖了这些物体的绘制，这样这些使用了 Built-in Shaders 的物体都会显示为紫色。最后，若只想将这些内容绘制在 Editor 中而不是在构建中，就将这些代码包裹在 `#if UNITY_EDITOR` 和 `#endif` 之间。

### 绘制 Gizmos
目前为止 Scene 和 Game 窗口中都看不到 Gizmos。为了绘制它们，我们首先可以通过 `UnityEditor.Handles.ShouldRenderGizmos()` 来确认我们是否在 Scene 和 Game 窗口的右上方开启了 Gizmos。然后通过 `ScriptableRenderContext.CreateGizmoRendererList()` 来创建 Gizmos 渲染列表，Gizmo 有两个子集可以绘制，一个是 PreImageEffects，一个是 PostImageEffects。目前我们还没支持屏幕后处理的效果，所以都先直接绘制了。

``` C#
#if UNITY_EDITOR
    if (Handles.ShouldRenderGizmos()) 
    {
        RendererList gizmosRendererList = context.CreateGizmoRendererList(camera, GizmoSubset.PreImageEffects);
        buffer.DrawRendererList(gizmosRendererList);
        gizmosRendererList = context.CreateGizmoRendererList(camera, GizmoSubset.PostImageEffects);
        buffer.DrawRendererList(gizmosRendererList);
    }
#endif
```

### 绘制 UI
我们在场景中创建一个 UI -> Button。此时 Canvas 的默认的 Render Mode 为 Screen Space - Overlay，在 frame debugger 中，UI 的渲染和我们自建的 RP 是分开的，如下图：  

<div  align="center">  
<img src="https://s2.loli.net/2024/12/02/8OfhYlv62s4Jgdt.png" width = "35%" height = "35%" alt="图4 - UI - Screen Space Overlay"/>
</div>

如果我们把 Render Mode 设置为 Screen Space - Camera，UI 渲染会成为自定义 RP 中透明物体渲染的一部分，如下：  

<div  align="center">  
<img src="https://s2.loli.net/2024/12/02/qgx9zMFd7tUPRIE.png" width = "35%" height = "35%" alt="图5 - UI - Screen Space Camera"/>
</div>

在 Game 窗口中 UI 是正常绘制的，但是在 Scene 中是看不到的。我们需要通过 `ScriptableRenderContext.EmitWorldGeometryForSceneView()` 静态方法将 UI 物体添加到世界的物体当中去，代码如下：  

``` C#
#if UNITY_EDITOR
    if (camera.cameraType == CameraType.SceneView) 
    {
        ScriptableRenderContext.EmitWorldGeometryForSceneView(camera);
    }
#endif

// Culling codes
```

同时添加 UI 物体的操作必须要在 culling 操作之前。现在 Scene 界面中就能正常绘制出 UI 物体了。

## 多相机渲染
每个相机都会有个 Depth 的属性，该属性决定了渲染的顺序（从低到高）。如果我们新建一个摄像机，将它的 Depth 设置为 0（Main Camera 的默认 Depth 为 -1），那么 Game 窗口就会被新摄像机的渲染所覆盖，并且场景渲染了两次，第一次渲染的结果被 clear 了，如下：  

<div  align="center">  
<img src="https://s2.loli.net/2024/12/02/tBXJcQ2Ko8VeZYF.png" width = "35%" height = "35%" alt="图6 - Two Cameras"/>
</div>

我们可以通过设置 buffer.name 让不同的摄像机渲染在 frame debugger 中有不同的范围：  

``` C#
#if UNITY_EDITOR
    buffer.name = camera.name;
#endif
```

代码写在 for 循环中的最前面，效果如下：

<div  align="center">  
<img src="https://s2.loli.net/2024/12/02/nWV68CA3ES7cD1Q.png" width = "35%" height = "35%" alt="图7 - Separate samples per camera"/>
</div>

### Layers
目前相机已经支持剔除特定的 Layer 的物体进行渲染了，我们可以把某些物体的 Layer 设置为 Ignore Raycast layer。然后在摄像机的 Occlusion Culling 属性中，只选择 Ignore Raycast，这样我们就只会看到设置为 Ignore Raycast 的物体了。

### Clear Flags
相机的 Clear Flags 属性仍然只有部分效果，如果我们把 Clear Flags 属性设置为不是 Skybox，再打开 frame debugger，会发现 Camera.RenderSkybox 不见了，但是 Solid Color 的 BackGround Color 仍然不起效，这是因为我们还没做好相关设置。首先我们要通过 `CameraClearFlags` 枚举获取到摄像机的 Clear Flags 属性：  

``` C#
...
context.SetupCameraProperties(camera);
CameraClearFlags flags = camera.clearFlags;
buffer.ClearRenderTarget(true, true, Color.clear);
...
```

`CameraClearFlags` 枚举有四个值：Skybox、SolidColor、Depth、Nothing，分别对应 0 到 3。为什么名字叫 ClearFlags 呢，是因为它本质是在设置 ClearRenderTarget 的属性，比如 Solid Color，就是在 ClearRenderTarget 时用设置的 BackGround 颜色替换掉 RenderTarget；而 Depth Only，指 ClearRenderTarget 时只清除掉 depth buffer；Don't clear 就是不清除 RenderTarget。

首先设置 CommandBuffer.ClearRenderTarget 的第一个参数，即是否清除 depth buffer。当 camera.clearFlags 小于 3 时，就清除：  

    buffer.ClearRenderTarget(flags < CameraClearFlags.Nothing, true, Color.clear);

接下来是第二个参数，即是否清除 color buffer。当 camera.clearFlags 小于 2 时，就清除：  

    buffer.ClearRenderTarget(flags < CameraClearFlags.Nothing, flags < CameraClearFlags.Depth, Color.clear);

最后替换颜色改为 `camera.backgroundColor.linear`：

    buffer.ClearRenderTarget(flags < CameraClearFlags.Nothing, flags < CameraClearFlags.Depth, camera.backgroundColor.linear);

第二个相机的 Clear Flags 属性本质上是用于决定第一个摄像机和第二个摄像机的混合模式，如果是 Skybox 和 Solid Color，则是完全替换掉上个相机的结果。当选择 Depth Only 时，第一个摄像机的结果则是第二个摄像机的渲染背景，并且第二个摄像机渲染的物体会全部覆盖到第一个摄像机的结果上面。当选择 Don't clear 时，第二个摄像机渲染的物体会和第一个摄像机的物体有正确的遮挡关系，但是透明物体除外，因为透明物体没有深度信息，就产生了渲染顺序上的冲突。

# Draw Calls
## Shaders
先创建

