---
title: IBL 基于图像的光照（一）
date: 2024-07-09 15:25:54
categories: 
  - [图形学]
tags:
  - 图形学
  - 游戏开发
top_img: /images/black.jpg
cover: https://s2.loli.net/2024/07/22/nD1y67NcRpQOHbS.gif
mathjax: true
description: 本笔记的主要内容有 IBL 技术的相关介绍；环境映射的实现；漫反射环境光的实现：包括 Irradiance mapping（黎曼和、蒙特卡洛积分）和球谐光照的实现。
---

> 本篇文章主要参考了著名的 LearnOpenGL 教程：https://learnopengl-cn.github.io/ 或 https://learnopengl.com/ 、著名图形学书籍《Real-Time Rendering 4th》以及谷歌的 Filament PBR 白皮书：https://google.github.io/filament/Filament.md.html#materialsystem/diffusebrdf 。

# Image based lights (IBL) 介绍
## 前言
$$ 光照模型 = 直接光漫反射 + 直接光镜面反射 + 间接光漫反射 + 间接光镜面反射 $$

**直接光漫反射 + 直接光镜面反射**就是上一篇文章《PBR 理论基础（BRDF）》介绍的，本篇文章介绍的就是**间接光漫反射 + 间接光镜面反射**。

在之前的文章 PBR 理论基础（BRDF）有提到过，对于一个点光源来说，当我们为一个表面上的特定的点 $\,p\,$ 着色时，在其半球领域 $\,\Omega\,$ 的所有可能的入射方向上，只有一个入射方向向量 $\,\omega_i\,$ 直接来自于该点光源。

在实现上来说，对于直接点光源的情况，计算**入射辐射亮度 radiance**，即 $\,L_i(p, \omega_i)\,$，先获取光源的颜色值，然后按照光源和某点 $\,p\,$ 的距离进行衰减，接着按照 $\,n \cdot \omega_i\,$ 缩放，写成代码如下：  

    vec3  lightColor  = vec3(r, g, b);
    vec3  wi          = normalize(lightPos - fragPos);
    float cosTheta    = max(dot(N, Wi), 0.0);
    float attenuation = calculateAttenuation(fragPos, lightPos);
    float radiance    = lightColor * attenuation * cosTheta;

> 这里 NdotL 若在 radiance 里乘了，就不要在运用反射方程的时候再乘一次了。我对颜色的理解是，辐射通量可以用颜色 RGB 表示，我们要计算的 radiance 是单位立体角单位接受面积的辐射通量。因为辐射强度，即单位立体角辐射通量，不会产生衰减，无论我们从哪个角度观察点光源，它总具有相同的辐射强度，我们可以有效地将其辐射强度建模为其辐射通量，即 RGB 颜色常量。真正的光线衰减产生自辐射照度 Irradiance，即单位接受面积辐射通量，若忘了详见《GAMES101-图形学入门公开课笔记（二）》第十四课 Ray Tracing II 中的辐射度量学。所以在计算 radiance 需要考虑颜色在距离上的衰减。

若场景中有多个光源，为了满足反射率方程，我们只需要循环遍历每一个光源，计算他们各自的辐射亮度然后求和，接着根据 BRDF 和光源的入射角和法线夹角进行缩放即可。我们不需要去尝试去求解对于表面的半球领域 $\,\Omega\,$ 的积分。而当我们之后把**环境照明 IBL** 也考虑在内，就必须采取积分去计算了，这是因为光线可能会在任何一个方向入射。

## IBL 简介
在真实世界中，光要么直接来自光源，要么间接来自环境中经过多次弹射后的光（会被部分吸收）。太阳光受到大气介质以及云层的散射后，会间接对物体进行照射，此时整个天空可以被看做是一个巨大的光源。

故物体周围的环境可以被视为一个光源，**图像 Images**（**立方体贴图 Cubemap** 或者**等距柱状投影图 Equirectangular image**）可以有效地捕捉**环境光照 Environment light**，这就被称为**基于图像的光照 Image Based Lighting (IBL)** 或**间接光照 Indirect Lighting**。

这些环境贴图要么需要从真实世界中拍摄获取，要么在游戏引擎中生成。我们可以将环境贴图的每个像素视为光源，在渲染方程中直接使用它，故基于图像的光照可以说是一种全局光照的粗略近似。

在现代游戏引擎中，有四种常见的 IBL 技术：  
①**全局/远处光照探针 Distant light probes**：用于捕捉无限距离上的光照信息，包括天空、地形建筑等光照信息，一般使用**高动态范围图像 HDRI**；  
②**局部光照探针 Local light probes**：用于捕捉某一特定地点的光照信息，通过投射到立方体或球上来捕捉到周围的几何信息（就是 Unity 的 Reflection Probe）。局部光照探针经常用于给材质增加局部反射信息；  
③**平面反射 Planar reflections**：该技术仅限于平坦的表面比如地板、路面或者水面等等，来渲染反射的场景；  
④**屏幕空间反射 Screen space reflection**：使用深度缓存构建世界坐标，利用光线步进的方法在屏幕空间中捕获反射信息，可以得到较好的反射信息但较为昂贵。

本文主要讲解 **Distant light probes**。

> Distant light probes 是从无限远的地方接受 radiance 对物体表面进行着色，它和真正意义上的全局光照的本质区别就是，它没有考虑场景中物体之间的遮挡以及光线的反弹，所以会出现一些不正确的渲染效果，比如一个室内的金属球会反射整个屋子外的天空，此时就需要用到上面说到的其他三种技术了。

## IBL 计算
IBL 对 PBR 很有意义，当我们将环境光纳入计算之后，物体在物理方面看起来会更加准确。那么将 IBL 引入 PBR 系统，先回忆一下反射方程：  

$$ L_o(p, \omega_o) = \int_{\Omega}(k_d \cfrac {c} {\pi} + k_s \cfrac {DFG} {4 (\omega_o \cdot n)(\omega_i \cdot n)}) L_i(p,\omega_i) n \cdot \omega_i d \omega_i $$

> 整个环境对某一特定像素点的光照贡献即**辐射照度 Irradiance**，弹射出该像素点的某一出射方向上的光线或射入该像素点的某一入射方向上的光线即**辐射亮度 Radiance/Luminance**。

我们的主要目标是计算半球 $\,\Omega\,$ 上所有入射光方向 $\,\omega_i\,$ 的积分。那么我们要解决两个问题：  
**①**在给定任何方向向量 $\,\omega_i\,$，我们首先需要获取这个方向上场景的 Radiance/Luminance，即 $\,L_i(p,\omega_i)\,$；  
**②**在实时渲染的前提下，解决积分问题。

第一点：这一点比较容易，使用方向向量 $\,\omega_i\,$ 对**环境贴图 Environment Map** 进行采样即可：  

    vec3 radiance =  texture(_cubemapEnvironment, w_i).rgb;

第二点：由于积分操作十分昂贵，无法直接在实时渲染中暴力计算实现，所以我们需要进行**预处理或预计算**，并将结果存储在 **Irradiance Map** 当中，以方便在运行时进行采样获取。

为了方便计算，我们可以将积分分成两部分，即 BRDF 的漫反射项和镜面反射项：  

$$ L_o(p, \omega_o) = \int_{\Omega}(k_d \cfrac {c} {\pi}) L_i(p,\omega_i) n \cdot \omega_i d \omega_i + \int_{\Omega}(k_s \cfrac {DFG} {4 (\omega_o \cdot n)(\omega_i \cdot n)}) L_i(p,\omega_i) n \cdot \omega_i d \omega_i $$

通过将积分分成两部分，我们可以分开研究漫反射和镜面反射部分，而这两部分主要使用的技术有：  
①漫反射部分：**辐射照度/辉度 Irradiance mapping**：主要包括**黎曼和 Riemann Sum**、**蒙特卡洛积分 Monte Carlo Integration** 这两种方法进行预积分；或者使用**球面或半球面函数 Spherical or Hemispherical Functions** 使用多个基函数用以表示原函数（类似于傅里叶级数）：主要有**球谐函数 Spherical harmonics**、**球面高斯 Spherical Gaussians**、**半球球谐/H-基 H-basis** 等方法，本文只介绍前三种方法，球面高斯和 H-basis 日后有需求自行查阅，《教团1886》使用的就是球面高斯。  
②镜面反射部分：**预过滤环境映射 Prefiltered environment mapping**（简单介绍）；**分解求和近似 Split-sum approximation**（详细介绍）；**非对称与各向异性波瓣 Asymmetric and Anisotropic lobes**（简单介绍）。

# 环境映射 Environment Mapping
**环境映射 Environment mapping** 也称为反射映射 Reflection mapping，是 IBL 技术的基础，因为需要将环境贴图作为光照的来源照亮场景。环境贴图的每个纹素记录的是 Radiance/Luminance，环境贴图既可以从真实世界用特制的全景相机来获取，也可以搭建场景离线渲染出来。我们常使用的 HDRI 就是环境贴图的一种，常见的 HDRI 的存储格式有 **.exr**、**.hdr**、**.tif(.tiff)**。这里不对这些格式进行说明，建议额外去了解。

> HDRI 往往非常大，一张图片往往几百 Mb，可以使用基于物理的天空来替代，也建议额外去了解。

那么如何从环境贴图采样来获取 Radiance/Luminance 信息？一般步骤如下：  
①根据视角方向计算反射视角方向：$\,r = 2(n \cdot v) n - v\,$;  
②将反射视角向量 $\,( x,y,z )\,$ 转换为环境贴图的 uv 坐标 $\,( u,v )\,$。

<div  align="center">  
<img src="https://s2.loli.net/2024/07/22/L6AU91VvpJSzg3r.png" width = "70%" height = "70%" alt="图1 - 环境贴图采样步骤"/>
</div>

但是不同形式的环境贴图具有不同的投影/映射方式，这就决定了第二步的转换方式。

## 经纬映射 Latitude-Longitude Mapping
**经纬投影 Latitude-Longitude projection**（又称**等距柱状投影 Equirectangular projection**），类似于地图常用的**墨卡托投影 Mercator projection**（又称**等角柱状投影 Conformal cylindrical projection**）。经纬投影和墨卡托投影的区别在于墨卡托投影的纬度是不均匀的，在两个极点的维度间隔会趋于无穷大，而经纬投影的经维度间隔都是均匀的。

<div  align="center">  
<img src="https://s2.loli.net/2024/07/22/ErVUbRljTYq8PxX.png" width = "100%" height = "100%" alt="图2 - 经纬投影（不是墨卡托投影）"/>
</div>

这两种投影都具有同一个问题，就是越接近极点，图像拉扯越严重，所使用的像素点也越多。所以整个环境贴图是不均匀的，图像过滤的时候会出问题。直接采样也需要耗费额外的性能，因为需要额外的坐标变换以及使用反三角函数这样的**超越函数 transcendental function**，所以一般在渲染引擎中，会提前将**等距柱状投影图 Equirectangular map** 转换为 Cubemap 以便进行卷积操作或者在运行时使用。

直接采样的方法如下：首先先将视角反射方向向量 $\,( x,y,z )\,$ 给归一化，得到归一化方向向量 $\,( r_x,r_y,r_z )\,$，然后计算球坐标系下的坐标（左手坐标系下，物理学约定下的球坐标）：$\,\theta = asin(r_y)\,$，$\,\phi = atan2(r_z,r_x)\,$。最后将**天顶角 Polar angle** $\,\theta\,$ 和**方位角 Azimuthal angle** $\,\phi\,$ 映射至 UV 坐标下（$\,\theta\,$ 相当于维度，其弧度值范围为 $\,[-1/2\pi,1/2\pi]\,$；$\,\phi\,$ 相当于经度，其其弧度值范围为 $\,[-\pi,\pi]\,$）：  

$$ u = \cfrac {\phi}{2 \pi} + 0.5, v = \cfrac{\theta}{\pi} + 0.5 $$

> 我查阅了网上关于球坐标约定的相关事项，不同领域对天顶角、方位角的约定都各不相同，也很少有资料是关于左手坐标系下球坐标的，一时搞的我很头大。但其实只要球坐标转换到笛卡尔坐标的公式和笛卡尔坐标转换到球坐标的公式统一即可，这样就不影响我们使用。上面的公式是基于 LearnOpenGL 教程中的代码转变过来的，在 LearnOpenGL 里的约定（左手坐标系）应该就是 $\,\phi\,$ 是 xz 平面上 r 和 x 的夹角，$\,\theta\,$ 是 r 和 xz 平面的夹角。

> 我们一般使用的 HDRI 贴图就是**等距柱状投影图 Equirectangular image**，也可以称为**全景图 panorama**。在 Unity 中可以有两种方式使用它，一种是使用 Skybox/Cubemap shader，另外一种是 Skybox/Panoramic shader。第一种，我们导入 HDRI 贴图时，Texture Shape 需要使用 Cube，Mapping 使用 Latitude-Longitude Layout（Cylindrical），这样 HDRI 就转换成了 Cubemap，再在 shader 里使用就行。第二种，我们导入 HDRI 贴图时，Texture 使用 2D，贴图导入 shader 里，在 shader 里的 Mapping 选择  Latitude-Longitude Layout。**建议使用第一种方式**，因为第二种在 Shader 里进行坐标转换，而第一种方式是运行外转换。

## 球面映射 Sphere Mapping
**球面映射 Sphere mapping** 假定观察者以正交投影的方式观察一个完美反射的球体，这个球体捕捉各个方向上的光照信息。

<div  align="center">  
<img src="https://s2.loli.net/2024/07/23/wSHuI7Nya3rBUPj.png" width = "60%" height = "60%" alt="图3 - 球面贴图（左）和经纬度映射的等效贴图（右）"/>
</div>

反射球只会在球的正面显示整个环境，它会将每个反射观察方向映射到球面二维图像上的一个点，如下图所示：  

<div  align="center">  
<img src="https://s2.loli.net/2024/07/23/t8xP3rfk5qK7IdU.png" width = "35%" height = "35%" alt="图4 - 球面映射的方式，图中还展示了球面贴图空间中 h 的坐标和球面贴图的纹理坐标 v（和观察向量 v 区分）之间的关系。"/>
</div>

在给定的球面贴图空间中，球面上的法线 $\,n\,$ 是反射观察向量 $\,r\,$ 与原始观察向量 $\,v\,$ 之间的半角向量，观察向量 $\,v\,$ 在球面贴图空间中坐标为 $\,(0,0,1)\,$。因此这里的球面法线 $\,n\,$ 是原始观察向量 $\,v\,$ 和反射观察向量 $\,r\,$ 的和，即 $\,(x,y,z + 1)\,$。将球面法线归一化得到单位球面法线：  

$$ n = \left( \cfrac{x} {m}, \cfrac{y} {m}, \cfrac{z + 1} {m} \right), \text{where} \,\,\, {m = \sqrt{x^2 + y^2 +(z + 1)^2}} $$

对于位于原点的单位球（半径为 1）来说，交点 $\,h\,$ 与单位法线向量 $\,n\,$ 具有相同的坐标。因为球面贴图空间球的值范围在 $\,[-1,1]\,$，将其映射至 uv 坐标即可：  

$$ u = \cfrac {n_x}{2} + 0.5, v = \cfrac {n_y}{2} + 0.5 $$

球面映射虽然简单，缺点就是其所捕获的环境贴图仅对单一观察方向有效，若根据新的观察方向重新计算纹理坐标会出现一些视觉瑕疵，除非根据新的观察方向生成一张新的贴图。因此球形贴图一般只适用于观察方向不会变化的场合。

球面映射很少在环境光照中使用，更多是用在 **Matcap（Material Capture）** 技术中。因为球面贴图每个点定义了表面法线的方向以及反射方向，我们可以把 BRDF 的结果存储在球面贴图当中，只要观察方向不变，就可以获取到一个廉价但还不错的材质效果。这个技术最早是 Zbrush 在使用的，这也是为什么 Zbrush 几百万面不会卡的原因。

## 立方体映射 Cube Mapping
**立方体贴图 Cubemap** 是最为广泛应用的方法。通过将环境投影到以相机位置为中心的立方体侧面，来创建一个立方体贴图，然后将立方体表面上的图像用作环境贴图。立方体贴图会被存储为 6 个正方形纹理。

立方体贴图的生成方式就是：将相机放置在立方体的中心，面向立方体六个面设置六个不同的视图矩阵，给定投影矩阵的 fov 为 90 度以捕捉整个面，并渲染立方体六次。

与球面映射不同，立方体映射是与视角无关的。立方体贴图也具有比经纬度映射更加均匀的采样特征。对立方体贴图采样也比较简单，图形 API 提供的函数允许我们直接将输入向量作为纹理坐标，在其所指的方向上获取数据。

> Unity URP 里可以直接使用 `SAMPLE_TEXTURECUBE(textureName, sampler_textureName, dir)` 采样，在 CPU 里采样的 API 会麻烦一些。

实际上一张立方体贴图的每个 mipmap 级别拥有 6 个面，每个面都有一个 uv 坐标，如下图：

<div  align="center">  
<img src="https://s2.loli.net/2024/07/27/ZliA3g6yaIkeQnH.webp" width = "60%" height = "60%" alt="图5 - Cubemap 坐标"/>
</div>

用三维向量对 Cubemap 采样的实际步骤如下：  
①取 x, y, z 坐标中绝对值最大的为主轴，再用正负号判定正负轴。例如 (-0.8, 0.5, 0.4)，对应 -x 轴；  
②坐标除以主轴的绝对值，换算到立方体上。(-0.8, 0.5, 0.4) => (-1, 0.625, 0.5)；  
③根据对应轴的 UV 坐标换算关系，求得 UV。(-1, 0.625, 0.5) => u = z = 0.5, v = y = 0.625；  
④从 [-1, 1] 缩放到 [0, 1]。(0.5, 0.625) => (0.75, 0.8125)；  
⑤从 -x 轴的贴图上以 UV 坐标采样。


## 其他投影方法
其他投影方法主要包括：  
①**双抛物面映射 Dual paraboloid mapping** 使用两个抛物线投影创建两个半球贴图。《GTA5》、《荒野大嫖客2》和《赛博朋克2077》都有使用到，主要是为了降低开销；  
②**八面体映射 Octahedral mapping** 就是将环境映射到一个八面体当中，这个八面体的八个三角面正好可以排列在一张贴图中。

这些方法不再这里多做阐述，日后有需求再去详细了解。


# 漫反射 BRDF 积分
## Irradiance mapping
观察漫反射积分，可以发现兰伯特项是一个常数项，不依赖于任何积分变量。将常数项移出漫反射积分：  

$$ L_o(p, \omega_o) = k_d^* \cfrac {c} {\pi} \int_{\Omega} L_i(p,\omega_i) n \cdot \omega_i d \omega_i $$

> 理论上，$\,k_d\,$ 不能直接移出积分，$\,k_d = 1 - F\,$，而 $\,F = F_0 + (1 - F_0)(1 - v \cdot h)^5\,$，但是为了简化计算，我们通常用法线 n 替代微平面法线 h，用以体现宏观上的菲涅耳效应。因为在宏观层面下，环境光来自半球内围绕法线 n 的所有方向，因此没有一个确定的半角向量来计算菲涅耳效应。这样我们就可以用法线和视线之间的夹角计算出的 $\,k_d^*\,$ 直接在积分外部计算以对环境光的漫反射部分进行加权。

由于环境光是无穷远的，所以可以忽略位置信息而只考虑法线信息，可以认为着色点就位于天空盒的中心点，也就是采样的 $\,L_i(p,\omega_i)\,$ 就跟位置 p 无关了。而 $\,\Omega\,$ 是半球空间，即和法线 n 点积为正的部分，那么可以发现漫反射 BRDF 积分的结果就只跟法线 n 相关。于是就可以**计算每一个法线 n 对应的积分结果，即 Irradiance，并将结果存储在一张 Cubemap 里，然后在使用的时候只需要用法线对贴图进行采样即可**。这样的 Cubemap 也称为**辐射照度图 Irradiance map**。

为了计算积分值，计算上又不可能从半球 $\,\Omega\,$ 的每个可能的方向采样环境光照，理论上可能的方向数量是无限的。不过我们可以对有限数量的方向采样以近似求解，在半球内均匀间隔或随机取方向可以获得一个相当精确的辐照度近似值，从而离散地计算积分。所以我们要做的就是在半球 $\,\Omega\,$ 上的所有方向对原 Cubemap 的每个纹素进行离散采样，并按照余弦进行加权并求和。这也相当于一个非常宽的**滤波器 filter**或者**卷积 convolution** 操作，这个滤波器覆盖整个半球范围，还包含余弦因子。而主要的采样方法包括**黎曼和 Riemann Sum**、**蒙特卡洛积分 Monte Carlo Integration**。

### 黎曼和 Riemann Sum
***1. 数学原理回顾***  
黎曼和是一种简单的估计积分的方法，简单地来讲就是把面积分为 N 等份。比如 $\,\int_a^b g(x) dx\,$，求解它可以将 $\,(a,b)\,$ 划分为 N 等份，每份长度 $\,\Delta x = \cfrac {b - a}{N}\,$。这样这个积分的黎曼和为：  

$$ \begin{align*} S &= \Delta x [g(a) + g(a + \Delta x) + g(a + 2 \Delta x) + \cdots + g(b - \Delta x)] \\ &= \Delta x \sum_{i=1}^N g(x_i) \end{align*} $$  

当 N 趋向于无穷大时，黎曼和就趋向于定积分的值。

***2. 漫反射积分求解***  
漫反射 BRDF 积分是定义在立体角上的积分，为了避免对难处理的立体角求积分，我们需要其转换到球面坐标系下的两重积分进行求解。对于围绕半球大圆的方位角 $\,\phi\,$，在 0 到 2π 内采样，而对于天顶角 $\,\theta\,$ 在 0 到 1/2π 内采样：  

$$ \int_{\Omega}dw = \int_0^{2\pi} \int_0^{1/2\pi} sin \theta d \theta d \phi = 2 \pi $$

于是（把 $\,\cfrac {1}{\pi}\,$ 放入 Irradiance map 中，这样采样的时候就不用除以 $\,\pi\,$ 了）：

$$ \cfrac {1}{\pi} \int_{\Omega} L_i(p,\omega_i) n \cdot \omega_i d \omega_i = \cfrac {1}{\pi} \int_0^{2\pi} \int_0^{1/2\pi} L_i(p,\theta_i, \phi_i) cos \theta sin \theta d \theta d \phi $$

将 $\,\phi\,$ 和 $\,\theta\,$ 分别划分为 $\,n_1\,$，$\,n_2\,$ 等份，即转为黎曼和形式（可以看作为一种特殊的蒙特卡洛积分）：  

$$ \begin{align*} \cfrac {1}{\pi} \int_{\Omega} L_i(p,\omega_i) n \cdot \omega_i d \omega_i & \approx \cfrac {1}{\pi} \cdot \cfrac {2\pi - 0}{n_1} \cdot \cfrac {1/2\pi - 0}{n_2} \sum^{n_1}_{a = 0} \sum^{n_2}_{b = 0} L_i(p,\theta_b, \phi_a) cos \theta_b sin \theta_b \\ &= \cfrac {\pi}{n_1n_2} \sum^{n_1}_{a = 0} \sum^{n_2}_{b = 0} L_i(p,\theta_b, \phi_a) cos \theta_b sin \theta_b \end{align*} $$

***3. 代码实现***  
在 Unity 实现代码如下，使用了名为 Odin Inspector 的插件，方便在 Unity Editor 里直接操作（本来是想对 Cubemap 进行操作，但 Cubemap 有六个面，在 CPU 里使用 Unity 提供的 API 对其进行采样实在太麻烦，最终还是选择对等距柱状投影图进行积分操作。但是在 CPU 上对图片进行逐像素处理是极度慢的，在编辑器中运行都无法接受，更不要说在游戏中运行，最好还是使用 compute shader 运行来加速处理。下面的代码对 2048 × 1024 的每个像素的 normal 采样 20 \* 80 = 1600 次，花费了 27 分钟。而我用 compute shader 就是一瞬间的事情，compute shader 不在这里展示了，可以看蒙特卡洛积分部分，有展示采样 50 \* 200 = 10000 次的黎曼和结果）

> 使用 `GetPixel` 、`SetPixel` 时，好像 Unity 会自动做 gamma 校正，不知道跟我使用的图片是 sRGB 有没有关系，故我没有写校正的代码，获取到的 pixel 的 RGB 值是在线性空间的。

``` C#
using UnityEngine;
using UnityEditor;
using Sirenix.OdinInspector;
using Sirenix.OdinInspector.Editor;
using Unity.Collections;

public class IrradianceMapPrecomputeTool : OdinEditorWindow
{
    [MenuItem("Tools/IrradianceMap Precompute Tool")]
    private static void ShowWindow()
    {
        IrradianceMapPrecomputeTool window = OdinEditorWindow.GetWindow<IrradianceMapPrecomputeTool>();
        window.Show();
    }
    
    [InlineEditor(InlineEditorModes.LargePreview)]
    public Texture2D latitudeLongitudeMap;
    
    [TitleGroup("Riemann Sum")]
    public int sampleNumber = 20; //n2 = 20, n1 = 20 * 4 = 80

    [InlineEditor(InlineEditorModes.LargePreview)]
    public Texture2D riemannSumIrradianceMap;
    
    [Button(ButtonSizes.Large), GUIColor(0.4f, 0.8f, 1)]
    private void RiemannSumPrecompute()
    {
        riemannSumIrradianceMap = new Texture2D(latitudeLongitudeMap.width, latitudeLongitudeMap.height, TextureFormat.RGBA32, false);
        var llImageData = latitudeLongitudeMap.GetPixelData<Color32>(0);
        var rsImageData = riemannSumIrradianceMap.GetPixelData<Color32>(0);

        Vector2 uv = new Vector2();
        Vector3 normal = new Vector3();
        Color irradiance = new Color();
        for (int y = 0; y <= latitudeLongitudeMap.height - 1; y++)
        {
            for (int x = 0; x <= latitudeLongitudeMap.width - 1; x++)
            {
                uv.x = ((float) x) / (riemannSumIrradianceMap.width - 1);
                uv.y = ((float) y) / (riemannSumIrradianceMap.height - 1);
                normal = LatLongUVtoCartesian(uv);
                irradiance = RiemannSum(normal, llImageData);
                rsImageData[y * riemannSumIrradianceMap.width + x] = (Color32) irradiance;
            }
        }
        riemannSumIrradianceMap.SetPixelData(rsImageData, 0, 0);
        riemannSumIrradianceMap.Apply();
    }

    private Vector3 LatLongUVtoCartesian(Vector2 uv) //左手坐标系下，约定phi是xz平面上r和x的夹角，theta是r和xz平面的夹角，这样phi的范围就是-pi到pi，theta是-1/2pi到1/2pi
    {
        float phi = (uv.x - 0.5f) * 2 * Mathf.PI;
        float theta = (uv.y - 0.5f) * Mathf.PI;
        Vector3 cartesianCoord = new Vector3(Mathf.Cos(theta) * Mathf.Cos(phi), Mathf.Sin(theta), Mathf.Cos(theta) * Mathf.Sin(phi));
        return cartesianCoord;
    }
    
    private Vector2 CartesiantoLatLongUV(Vector3 cartesianCoord)
    {
        cartesianCoord = Vector3.Normalize(cartesianCoord);
        float theta = Mathf.Asin(cartesianCoord.y);
        float phi = Mathf.Atan2(cartesianCoord.z, cartesianCoord.x);
        Vector2 uv = new Vector2(phi / (2 * Mathf.PI) + 0.5f, theta / Mathf.PI + 0.5f);
        return uv;
    }

    private Color RiemannSum(Vector3 normal,NativeArray<Color32> imageData) //normal是左手坐标系的y轴
    {
        Color irradiance = new Color();

        normal = Vector3.Normalize(normal);
        Vector3 up = normal.y > 0.999f ? new Vector3(0, 0, 1) : new Vector3(0, 1, 0);
        Vector3 tangent = Vector3.Normalize(Vector3.Cross(up, normal)); //左手坐标系的x轴
        Vector3 binormal = Vector3.Normalize(Vector3.Cross(tangent, normal)); //左手坐标系的z轴
        
        float sampleDelta = 0.5f * Mathf.PI / sampleNumber;
        float sampleNumberN1 = sampleNumber;
        float sampleNumberN2 = sampleNumber * 4;
        
        for(float phi = 0; phi < 2.0f * Mathf.PI; phi += sampleDelta)
        {
            for(float theta = 0; theta < 0.5f * Mathf.PI; theta += sampleDelta)
            {
                Vector3 tangentSpaceCoord = new Vector3(Mathf.Cos(theta) * Mathf.Cos(phi), Mathf.Sin(theta), Mathf.Cos(theta) * Mathf.Sin(phi));
                Vector3 sampleCartesianCoord = tangentSpaceCoord.x * tangent + tangentSpaceCoord.y * normal + tangentSpaceCoord.z * binormal;
                Vector2 sampleUVCoord = CartesiantoLatLongUV(sampleCartesianCoord);
                int x = Mathf.FloorToInt((latitudeLongitudeMap.width - 1) * sampleUVCoord.x);
                int y = Mathf.FloorToInt((latitudeLongitudeMap.height - 1) * sampleUVCoord.y);
                irradiance += Mathf.Cos(theta) * Mathf.Sin(theta) * (Color) imageData[y * latitudeLongitudeMap.width + x];
            }
        }
        
        irradiance = Mathf.PI / sampleNumberN1 / sampleNumberN2 * irradiance;
        return irradiance;
    }
}
```

采样结果如下（采样 1600 次）：  

<div  align="center">  
<img src="https://s2.loli.net/2024/07/27/iC8K6nWRz9D4PEX.png" width = "80%" height = "80%" alt="图6 - 原经纬图（上图）与黎曼和采样后的辐射照度图（下图）"/>
</div>

### 蒙特卡洛积分 Monte Carlo Integration
***1. 数学原理回顾***  
**①** 首先是概率论回顾：  
假设 $\,X\,$ 是随机变量，$\,Y = g(X)\,$。若 $\,X\,$ 是离散随机变量，则 $\,X\,$ 的数学期望为 $\,EX = \sum_a^b x_i p_i\,$，$\,Y\,$ 的数学期望为 $\,E[g(X)] = \sum_a^b g(x_i) p_i\,$ ；若 $\,X\,$ 是连续随机变量，其**概率密度函数 PDF** 为 $\,f(x)\,$，则 $\,X\,$ 的数学期望为 $\,EX = \int_a^b x f(x) dx\,$，$\,Y\,$ 的数学期望为 $\,E[g(X)] = \int_a^b g(x) f(x) dx\,$。

**概率密度函数 Probability Density Function，PDF** 是用来衡量某一区间的连续随机变量的概率值的函数，而随机变量的取值落在该区间的概率为概率密度函数在此区间上的积分。概率密度可以理解为单位长度的概率。由于概率不会超过 1，所以可以知道概率密度函数在定义域上的积分为 1，即 $\,\int_a^b f(x) dx = 1\,$。

而**累计分布函数 Cumulative Distribution Function，CDF** 是概率密度函数的积分，其描述的是随机变量 $\,X\,$ 小于函数自变量 $\,x\,$ 值的累计概率和。那么若函数自变量为随机变量的上限时，该函数（概率和）为 1。

根据牛顿-莱布尼茨公式的表述，一个连续函数（被积函数）在区间 $\,[a, b]\,$ 上的定积分等于它的原函数在区间 $\,[a, b]\,$ 上的增量。由此可以知道累积分布函数和概率密度函数之间的关系，即概率密度函数在区间 $\,[a, b]\,$ 上的积分是累计分布函数的概率增量。

<div  align="center">  
<img src="https://s2.loli.net/2024/07/29/kS9RUPVtZu4Gwje.png" width = "70%" height = "70%" alt="图7 - 正太分布的概率密度函数（左图）与累计分布函数（右图）"/>
</div>

**②** 蒙特卡洛积分：  
我们从打靶概率问题引申到蒙特卡洛积分：设 x 为射击者击中点到靶心的距离，$\,g(x)\,$ 表示的 x 处的得分，概率密度函数 $\,f(x)\,$ 表示击中点的分布，那么得分的数学期望 $\,E[g(x)]\,$：

$$ E[g(x)] = \int_a^b g(x) f(x) dx $$

为了得到该期望值，我们可以让射击者射击 $\,N\,$ 次，用得到的样本值 $\,x_1, x_2, \cdots, x_n\,$ 的算术平均数作为对数学期望的估计，其中 N 越大估计越准：  

$$ \overline {g_n} = \cfrac {1}{n} \sum_{i=1}^n g(x_i) \approx E[g(x)] = \int_a^b g(x) f(x) dx $$

那么由上面可以推出，对于任意函数 h(x) 的定积分：  

$$ \int_a^b h(x) dx = \int_a^b \cfrac {h(x)} {f(x)} f(x) dx \approx \cfrac {1}{n} \sum_{i=1}^n \cfrac {h(x_i)} {f(x_i)} $$

其中 $\,f(x)\,$ 是某一随机变量的概率密度函数。

那么总结一下，使用**蒙特卡洛积分 Monte Carlo Integration** 估计定积分 $\,\int_a^b g(x) dx\,$，我们可以选择一个概率密度函数 $\,f_X(x)\,$ 进行采样，该 $\,f_X(x)\,$ 需要保证在区间 $\,[a, b]\,$ 的概率和为 1，即 $\,\int_a^b f_X(x) dx = 1\,$。已知概率密度函数的随机变量 $\,X\,$，那么该定积分可以表示为：  

$$\int_a^b g(x) dx \approx \cfrac {1}{N} \sum_{i=1}^n \cfrac {g(X_i)} {f_X(X_i)} $$

**③**随机数生成：  
综上所述，蒙特卡洛积分估计把积分问题转变为了对概率密度函数 $\,f_X(x)\,$ 采样的问题，那我们就需要从概率密度函数生成一系列随机变量 $\,X\,$。我们可以生成**均匀分布的随机变量 Uniformly distributed random numbers** 和**非均匀分布/服从指定分布的随机变量 Non-uniformly distributed random numbers**。生成均匀分布的随机变量的常用方法就是用计算机生成**伪随机数 Pseudo-random number**，因为从算法层面生成随机数是不可能的，但是生成类似于随机数的统计特征的数是可以的，所以称为伪随机数。各种编程语言的 Random 库或类都是一种**伪随机数生成器 Pseudo-random number generator，PRNG**。

但是对于蒙特卡洛积分，均匀分布不是最合适的分布，我们需要生成服从指定分布的随机变量，这种方法也称为**直接抽样法 Direct sampling technique** 或者**逆变换采样 Inverse transform sampling**。逆变换采样简单来说就是，已知概率密度函数 $\,PDF(X)\,$ 和累计分布函数 $\,CDF(X)\,$，想要生成符合该概率分布的随机样本，我们只需要在 $\,[0, 1]\,$ 生成均匀随机变量 $\,Y\,$，即在累计分布函数的 y 轴生成均匀随机变量（累计的概率为 $\,[0, 1]\,$），然后将 $\,Y\,$ 代入累计分布函数的反函数 $\,CDF^{-1}(X)\,$，用以得到符合该概率分布的随机样本 $\,X\,$。

其他采样方法，比如**拒绝采样 Rejection Sampling**，由于不太常用就不在这里详细介绍了，简单来讲它就是再找一个辅助用的易于采样的分布函数，对其采样并做出加工，拒绝不符合原分布函数的样本。

**④**方差缩减  
缩小蒙特卡洛估计的误差有两种途径：一是增加采样次数 N，蒙特卡洛估计的误差收敛速度为 $\,O(\sqrt N)\,$，即四倍采样会使误差减少一半；二是在不增加采样次数的情况下减少方差，即**方差缩减 Variance reduction**。被积函数 $\,g(x)\,$ 是确定的，而概率密度函数 $\,f_X(x)\,$ 是任选的，故针对不同的 $\,g(x)\,$ 选择合适的 $\,f_X(x)\,$ 是方差缩减的核心。这就引出了**重要性采样 Importance sampling**：简单来讲，就是概率密度函数 $\,f_X(x)\,$ 和被积函数 $\,g(x)\,$ 形状越像，越能有效减少蒙特卡洛估计的误差。

***2. 漫反射积分求解***  
使用蒙特卡洛积分来估计 Irradiance 如下式所示：  

$$ \cfrac {1}{\pi} \int_{\Omega} L_i(p,\omega_i) n \cdot \omega_i d \omega_i \approx \cfrac {1}{\pi} \cdot \cfrac {1}{N} \sum_{i=1}^N \cfrac {L_i(p,\omega_i) n \cdot \omega_i}{\rho(w_i)} $$

其中 $\,\rho(w_i)\,$ 是概率密度函数，根据密度函数的定义 $\,\int_{\Omega}\rho(w_i) dw_i = 1\,$。我们知道单位球体的立体角为 $\,4\pi\,$，我们只对半球进行采样，即 $\,\int_{\Omega}dw_i = 2 \pi\,$。于是我们可以得到：  

$$ \rho(w_i) = \cfrac {1}{2\pi} $$

那么：  

$$ \cfrac {1}{\pi} \int_{\Omega} L_i(p,\omega_i) n \cdot \omega_i d \omega_i \approx \cfrac {1}{\pi} \cdot 2 \pi \cdot \cfrac {1}{N} \sum_{i=1}^N L_i(p,\omega_i) cos \theta_i = \cfrac {2}{N} \sum_{i=1}^N L_i(p,\omega_i) cos \theta_i $$

那么只要我们提前生成法线半球上的 N 个随机采样点就可以估算积分了。但是随机采样点的生成是个需要注意的问题，因为我们首先想到的会是生成球坐标系的 $\,\theta\,$ 和 $\,\phi\,$ 的均匀分布，如下代码。但是这样生成的点实际上是不均匀的，而是在极点处更加密集，如下图。

``` python
import matplotlib.pyplot as plt
import numpy as np

def SphereCoordToCartesianCoord(theta, phi):
    x = np.sin(theta) * np.cos(phi)
    y = np.sin(theta) * np.sin(phi)
    z = np.cos(theta)
    return x, y, z

def GenerateSphereSurfaceRandomPoints(sampleNumber): #右手坐标系
    x_list, y_list, z_list = [], [], []

    for i in range(sampleNumber):
        theta = np.pi * np.random.random_sample()
        phi = 2 * np.pi * np.random.random_sample()
        x, y, z = SphereCoordToCartesianCoord(theta, phi)
        x_list.append(x), y_list.append(y), z_list.append(z)
    
    return x_list, y_list, z_list

fig = plt.figure()
ax = fig.add_subplot(projection='3d')
ax.set_xlim(-1, 1) , ax.set_ylim(-1, 1), ax.set_zlim(-1, 1) 
ax.set_aspect("equal")

ax.scatter(*GenerateSphereSurfaceRandomPoints(5000), s = 1)
plt.show()
```

<div  align="center">  
<img src="https://s2.loli.net/2024/07/30/mJTP2QESuOsUlwN.png" width = "50%" height = "50%" alt="图8 - 球面均匀采样"/>
</div>

可以看到采样点在球体的南北极点，即 $\,\theta = 0 \, or \, \pi\,$ 时更加密集，其原因在于单位立体角对应的面积和球坐标两个角度的关系，如下式：  

$$ dA = r^2 d\omega = r^2 sin \theta d \theta d \phi $$

当 $\,\theta \rightarrow 0 \, or \, \pi \,$ 时，$\,d\omega \rightarrow 0 \,$，即采样点对应的面积变小，采样点就会越密集。这也是我们不能使用均匀采样的原因，我们需要使用**逆变换采样**，因为我们已知概率密度函数 $\,\rho(w_i)\,$，具体步骤如下：  
①求 $\,\rho(w_i)\,$ 的累计分布函数 $\,F(w_i)\,$，即对 $\,\rho(w_i)\,$ 积分：

$$ \int_{\Omega} \rho(w_i) dw_i = \int_{\Omega} \cfrac {1}{2\pi} sin \theta d \theta d\phi = 1 $$

即概率密度函数 $\,\rho(w_i)\,$ 可以化作球坐标上的函数：  

$$ \rho(w_i) = \rho(\theta, \phi) = \cfrac {1}{2 \pi} sin \theta $$

②接着求出对于 $\,\theta\,$、$\,\phi\,$ 的边缘概率密度函数：  

$$ \rho_{\theta}(\theta, \phi) = \int_0^{2\pi} \cfrac {1}{2\pi} sin \theta d\phi = sin \theta $$
$$ \rho_{\phi}(\theta, \phi) = \int_0^{\pi/2} \cfrac {1}{2\pi} sin \theta d\theta = \cfrac {1} {2\pi} $$

③求出对于 $\,\theta\,$、$\,\phi\,$ 的边缘累计分布函数：  

$$ F_{\theta}(\theta, \phi) = \int_0^{\theta} sin \theta d\theta = 1 - cos \theta $$
$$ F_{\phi}(\theta, \phi) = \int_0^{\phi} \cfrac {1} {2\pi} d\phi = \cfrac {\phi} {2 \pi} $$

④最后求出反函数：  

$$ F_{\theta}^{-1}(\theta, \phi) = arccos(1 - \theta) $$
$$ F_{\phi}^{-1}(\theta, \phi) = 2 \pi \phi $$

⑤最后取在 $\,[0, 1]\,$ 区间的均匀分布的随机值 $\,\xi_1\,$，$\,\xi_2\,$，计算：

$$ \theta = arccos(1 - \xi_1) $$
$$ \phi = 2 \pi \xi_2 $$

> 这里得到的结果是右手坐标系下的结果。$\,\theta \in [0, \pi /2] \,$，$\,\phi \in [0, 2 \pi] \,$，不同的范围规定会对采样的公式产生影响的。

代码就把之前的 theta 和 phi 改一下就行，和采样图如下：  

``` Python
theta = np.acos(1 - np.random.random_sample())
phi = 2 * np.pi * np.random.random_sample()
```

<div  align="center">  
<img src="https://s2.loli.net/2024/08/01/maHJZ4heidrST19.png" width = "50%" height = "50%" alt="图9 - 半球面逆变换采样（视角问题边缘看起来更密集，实际上是均匀的）"/>
</div>

***3. 代码实现***  
在 CPU 里实现太慢了，故使用了 Compute Shader，首先是 C# 部分，主要在 C# 里生成随机数传递给 Compute Shader，当然其实可以利用伪随机数生成算法在 Compute Shader 里生成（太麻烦，懒得搞）：  

``` C#
using UnityEngine;
using UnityEditor;
using Sirenix.OdinInspector;
using Sirenix.OdinInspector.Editor;

public class MonteCarloByComputeShader : OdinEditorWindow
{
    [MenuItem("Tools/Monte Carlo Integration by ComputeShader")]
    private static void ShowWindow()
    {
        MonteCarloByComputeShader window = OdinEditorWindow.GetWindow<MonteCarloByComputeShader>();
        window.Show();
    }
    
    public ComputeShader monteCarloComputeShader;
    [InlineEditor(InlineEditorModes.LargePreview)]
    public Texture2D inputTexture;
    public int sampleNumber = 10000;
    private RenderTexture m_IrradianceMap;
    [InlineEditor(InlineEditorModes.LargePreview)]
    public Texture2D m_OutputTexture;
    
    [Button(ButtonSizes.Large), GUIColor(0.4f, 0.8f, 1)]
    private void MonteCarloIntegrationCompute()
    {
        m_IrradianceMap = new RenderTexture(inputTexture.width, inputTexture.height, 32, RenderTextureFormat.ARGB32);
        m_IrradianceMap.enableRandomWrite = true;
        m_IrradianceMap.Create();
        
        int kernelIndex = monteCarloComputeShader.FindKernel("IrradianceMapping");
        monteCarloComputeShader.SetTexture(kernelIndex, "inputTexture", inputTexture);
        monteCarloComputeShader.SetTexture(kernelIndex, "outputTexture", m_IrradianceMap);
        
        //Compute Shader里生成随机数不方便，在CPU里生成后传递进去
        ComputeBuffer buffer = new ComputeBuffer(sampleNumber, sizeof(float) * 3);
        Vector3[] samples = new Vector3[sampleNumber];

        for (int i = 0; i < sampleNumber; i++) 
        {
            float theta = Mathf.Asin(Random.value); //左手坐标系的推导结果
            float phi = 2 * Mathf.PI * (Random.value - 0.5f); //左手坐标系的推导结果
            samples[i] = new Vector3(Mathf.Cos(theta) * Mathf.Cos(phi), Mathf.Sin(theta), Mathf.Cos(theta) * Mathf.Sin(phi));
        }
        buffer.SetData(samples);
        
        monteCarloComputeShader.SetBuffer(kernelIndex, "samples", buffer);
        monteCarloComputeShader.SetInt("sampleNumber", sampleNumber);
        monteCarloComputeShader.SetInt("inputTextureWidth", inputTexture.width);
        monteCarloComputeShader.SetInt("inputTextureHeight", inputTexture.height);
        
        monteCarloComputeShader.Dispatch(kernelIndex, inputTexture.width / 32, inputTexture.height / 16, 1);

        m_OutputTexture = new Texture2D(inputTexture.width, inputTexture.height, TextureFormat.RGBA32, false);
        Graphics.CopyTexture(m_IrradianceMap, m_OutputTexture);
    }
}
```

接下来就是 Compute Shader 部分了，就是蒙特卡洛积分的实际计算部分：

> 这里的 C 只是为了代码高亮。

``` C
#pragma kernel IrradianceMapping

#define PI 3.14159265358979323846

Texture2D inputTexture;
RWStructuredBuffer<float3> samples;
RWTexture2D<float4> outputTexture;
int sampleNumber;
int inputTextureWidth;
int inputTextureHeight;

float3 LatLongUVToCartesian (float2 uv)
{
    float phi = (uv.x - 0.5f) * 2.0f * PI;
    float theta = (uv.y - 0.5f) * PI;
    float3 cartesianCoord = float3(cos(theta) * cos(phi), sin(theta), cos(theta) * sin(phi));
    return cartesianCoord;
}

float2 CartesianToLatLongUV (float3 cartesianCoord)
{
    cartesianCoord = normalize(cartesianCoord);
    float theta = asin(cartesianCoord.y);
    float phi = atan2(cartesianCoord.z, cartesianCoord.x);
    float2 uv = float2(phi/(2 * PI) + 0.5f, theta/PI + 0.5f);
    return uv;
}

float3 MonteCarloIntegration (float3 normal)
{
    float3 irradiance = float3(0.0f, 0.0f, 0.0f);
    normal = normalize(normal);
    float3 up = normal.y > 0.999f ? float3(0.0f, 0.0f, 1.0f) : float3(0.0f, 1.0f, 0.0f);
    float3 tangent = normalize(cross(up, normal));
    float3 binormal = normalize(cross(tangent, normal));

    for (int i = 0; i < sampleNumber; i++)
    {
        float3 tangentSpaceCoord = samples[i];
        float3 sampleCartesianCoord = tangentSpaceCoord.x * tangent + tangentSpaceCoord.y * normal + tangentSpaceCoord.z * binormal;
        float2 sampleUVCoord = CartesianToLatLongUV(sampleCartesianCoord);
        float2 samplePixelCoord = float2(sampleUVCoord.x * (inputTextureWidth - 1), sampleUVCoord.y * (inputTextureHeight - 1));

        float sinTheta = tangentSpaceCoord.y; //因为左手坐标系规定的球坐标的theta是r和xz平面的夹角，故cos改为sin
        irradiance += inputTexture[samplePixelCoord.xy].rgb * sinTheta;
    }
    irradiance = irradiance * 2 / sampleNumber;
    return irradiance;
}

[numthreads(32,16,1)]
void IrradianceMapping (uint3 id : SV_DispatchThreadID)
{
    float2 uv = float2((float) id.x / (inputTextureWidth - 1), (float) id.y / (inputTextureHeight - 1));
    float3 normal = LatLongUVToCartesian(uv);
    outputTexture[id.xy] = pow(saturate(float4(MonteCarloIntegration(normal), 1.0f)), 1.0f/2.2f);
}
```

黎曼和我也写了个类似的，它们的采样结果如下，可以看到都是 10000 次采样，结果几乎一模一样：

<table><tr>
<td><img src='https://s2.loli.net/2024/08/03/gpfTD1CWSMolZsn.png' width="500" alt="图10- 黎曼和采样 50 × 200 = 10000 次"></td>
<td><img src='https://s2.loli.net/2024/08/03/6bGmaptLBAKCvEl.png' width="500" alt="图11- 蒙特卡洛积分采样 10000 次"></td>
</tr></table>

## 球谐函数
### 球谐函数公式
首先来看**球谐函数 Spherical Harmonics** 的表达式：  
①复数形式的球谐基函数表达式如下（其中 $\,Y_l^m\,$ 为球谐基，$\,K_l^m\,$ 是归一化缩放系数，$\,P_l^m\,$ 是伴随勒让德多项式 the associated Legendre polynomials；$\,l\,$ 是球谐函数的波段 band，每个波段包括 $\,2l + 1\,$ 个函数，$\,m\,$ 即表示这些函数的索引）：  

$$ Y_l^m(\theta, \phi) = K_l^m e^{im \theta} P_l^{|m|} (cos \theta), l \in N, -l \leq m \leq l $$

②在图形学中只需关心定义在球面的实函数，故表达式可以写为如下： 

$$ y_l^{m > 0} = \sqrt 2 K_l^m cos(m \phi) P_l^m(cos \theta) $$
$$ y_l^{m < 0} = \sqrt 2 K_l^m sin(|m| \phi) P_l^{|m|} (cos \theta) $$
$$ y_l^{m = 0} = K_l^0 P_l^0(cos \theta) $$

③归一化系数为：  

$$ K_l^m = \sqrt {\cfrac {(2l + 1)(l - |m|)!} {4 \pi (l + |m|)!} } $$

④伴随勒让德多项式 the associated Legendre polynomials 可以用以下递归式算出：  

$$ P_0^0(x) = 1 $$
$$ P_1^0(x) = x $$
$$ P_l^l(x) = (-1)^l(2l - 1)!!(1 - x^2)^{l / 2} $$
$$ P_l^m(x) = \cfrac {((2l - 1)x P_{l - 1}^m - (l + m - 1)P_{l - 2}^m)} {l - m} $$

> 好了，看到这我已经吓死了，但是不要慌，其实这些公式只是计算基函数的表达式，继续往下看！我们要理解这些基函数是干嘛的。

### 球谐函数简单理解
球谐函数和上面的两种方法（黎曼和和蒙特卡洛积分）不同，其本质就是使用球谐基函数来近似模拟光照函数，即任意球面函数可以由一组球谐基函数 $\,Y_i(x)\,$ 和系数 $\,c_i\,$ 来表示：  

$$ f(x) = \sum_{l = 0}^{\infty} \sum_{m = -l}^l c_l^m Y_l^m(x) = \sum_{i = 0}^n c_i \times Y_i(x) $$

就跟**傅里叶级数 Fourier series** 逻辑类似，其能将任意周期函数都表示成三角函数的线性组合。傅里叶级数的基就是 $\,sin(nx)\,$ 和 $\,cos(nx)\,$，这些基函数都是**正交的 orthogonal** 的，即相互积分为 0，这就跟直角坐标系下的 x、y、z 轴类似，只是说这些基函数是定义在函数空间的。球谐基函数也是同理，是一组定义在球面坐标系上的基函数，对于任何 $\,f(r, \theta, \phi)\,$ 都可以表示为一组球谐基的和。既然可以使用球面坐标系，那也可以转换为直角坐标系，如下表：

*<center>表：直角坐标系下 3 阶球谐基函数</center>*

| Band | $\,\small{m = -2}\,$ | $\,\small{m = -1}\,$ | $\,\small{m = 0}\,$ | $\,\small{m = 1}\,$ | $\,\small{m = 2}\,$ |
| :---- | :---- | :---- | :---- | :---- | :---- |
| $\,\small{l = 0}\,$ | | | $\,\small{Y_0^0 = \sqrt{\cfrac {1}{4 \pi}}}\,$ | | |
| $\,\small{l = 1}\,$ | | $\,\small{Y_1^{-1} = \sqrt{\cfrac {3}{4 \pi r^2}}y}\,$ | $\,\small{Y_1^0 = \sqrt{\cfrac {3}{4 \pi r^2}}z}\,$ | $\,\small{Y_1^1 = \sqrt{\cfrac {3}{4 \pi r^2}}x}\,$ | |
| $\,\small{l = 2}\,$ | $\,\small{Y_2^{-2} = \cfrac {1}{2} \sqrt{\cfrac {15}{ \pi}} \cfrac {xy}{r^2}}\,$ | $\,\small{Y_2^{-1} = \cfrac {1}{2} \sqrt{\cfrac {15}{ \pi}} \cfrac {yz}{r^2}}\,$ | $\,\small{Y_2^0 = \cfrac {1}{4} \sqrt{\cfrac {5}{ \pi}} \cfrac {3z^2 - r^2}{r^2}}\,$ | $\,\small{Y_2^1 = \cfrac {1}{2} \sqrt{\cfrac {15}{\pi}} \cfrac {zx}{r^2}}\,$ | $\,\small{Y_2^2 = \cfrac {1}{4} \sqrt{\cfrac {15}{\pi}} \cfrac {x^2 - y^2}{r^2}}\,$ |

因为基函数 $\,Y_i(x)\,$ 有无数多个，我们只要取足够多个基函数，找到可以拟合 $\,f(x)\,$ 函数的每个基函数的系数 $\,c_i\,$，这样我们就可以用系数和基函数的组合来**重构 Reconstruction** $\,f(x)\,$。

理论上，我们使用的基函数越多，我们拟合的准确度就越高，一般阶数靠前的基函数，被称为低频部分，它定了 $\,f(x)\,$ 的基调，而 band 越高越表达高频信息，展现了 $\,f(x)\,$ 的噪声部分。而在漫反射环境光的实践中，一般用到 2 阶球谐基就足够拟合低频的漫反射 Irradiance map。

我们已经知道了基函数，接下来的问题就是如何求出基函数的系数。

### 球谐系数计算（投影）
首先球谐基函数构成了一个函数空间，每个基函数可以理解为函数空间的各个轴，对于给定 $\,f(x)\,$，我们可以把它投影到各个轴上，就可以求出它在函数空间的坐标，即系数 $\,c_i\,$。这就跟向量是各个轴上的投影的和是类似的。

而这个**投影 Projection**，即生成系数的过程，是积分求出来的，公式如下：  

$$ c_l^m = \int_S f(s) Y_l^m(s) ds $$

其中，$\,s\,$ 表示球面面积。即原函数 $\,f(x)\,$ 和球谐基函数 $\,Y_l^m\,$ 的乘积在球面上的积分，为原函数 $\,f(x)\,$ 在球谐基函数上的投影。

> 这部分比较难以理解，我们还是得借用比较熟悉的向量内积和傅里叶变换来近似理解。首先**内积**、**积分**、**投影**从某种角度而言可以视为同个意思，这点其实《MIT 线性代数公开课笔记（二）》的第二十四课的傅里叶级数也有大致提到过。
>
> 首先向量内积可以视为向量 a 在向量 b 上的一组投影：$\,\alpha \beta = \alpha_1 \beta_1 + \cdots + \alpha_n \beta_n = \sum_{i=1}^n \alpha_i \beta_i \,$，把 $\,\beta_i\,$ 视为基函数，把 $\,\alpha_i\,$ 视为坐标（系数）。因为向量内积是离散的求和，而函数内积是连续的求和，而连续的求和就是积分，即 $\,\int_a^b f(x) g(x) dx\,$。题外话：这个式子和卷积积分很像，卷积积分可以理解为移动的内积。而内积的本质就最小化误差，想想线性代数里的投影和最小二乘法的关系。
>
> 我们再来看看傅里叶变换在干嘛：$\,F(\omega) = \cfrac {1}{2\pi} \int^{\infty}_{-\infty} f(t) e^{i \omega t} dt\,$，再引入上帝公式欧拉公式：$\,e^{ix} = cosx + isinx\,$。那么傅里叶变换的本质就是两个函数的内积，即将原函数 $\,f(t)\,$ 投影到三角函数组成的频率空间 $\,\omega\,$ 中。

### 应用一：拟合 irradiance
我在网上看到了两种应用方法：第一种是用球谐函数拟合我们已经计算好的 irradiance map；第二种是用球谐函数拟合漫反射 BRDF 函数中的 radiance 项和余弦项，然后推导出 irradiance。先来介绍第一种方法。
 
我们之前使用黎曼和或蒙特卡洛积分计算出来的 irradiance map 本质上表达的是 irradiance 和法线之间的映射关系，那么这个关系就可以用球谐函数来拟合，即 $\,irradiance = \sum_i^n c_i \times Y_i(n)\,$，其中 n 为法线。

注意，irradiance 具有 rgb 三个分量，故我们需要对每一个分量的每一阶球谐基函数计算出对应的球谐系数，故使用前三阶（$\,l = 2\,$）球谐基函数的话，一共有 3 × 9 = 27 个球谐系数。

每一项球谐系数的 $\,c_i\,$ 的求解就是之前说的投影，即积分：

$$ c_i = \int_{\Omega} irradiance(n) Y_i(n) dw $$

因为 irradiance 是整个球面领域的，所以这里也要在整个球面上积分。所以还是要用黎曼和或蒙特卡洛积分。其实还有一种办法就是计算出 irradiance map 中每一个像素所对应的立体角，然后遍历 irradiance map 中每一个像素乘积后求和，毕竟贴图本质上是离散的，该方法详见后面的积分方法补充。这里展示的还是使用蒙特卡洛积分来计算球谐系数，代码如下（计算球谐系数都在 `GetCoefficients()` 函数里，下面的 `Reconstruction()` 就是为将计算出来的球谐系数传递给 compute shader，然后 compute shader 使用这些系数来重新构建出 irradiance map）：

``` C#
using UnityEngine;
using UnityEditor;
using Sirenix.OdinInspector;
using Sirenix.OdinInspector.Editor;

public class SphericalHarmonicsIrradiance : OdinEditorWindow
{
    [MenuItem("Tools/Spherical Harmonics Irradiance Construction")]
    private static void ShowWindow()
    {
        SphericalHarmonicsIrradiance window = OdinEditorWindow.GetWindow<SphericalHarmonicsIrradiance>();
        window.Show();
    }
    
    public ComputeShader irradianceReConstructionComputeShader;
    [InlineEditor(InlineEditorModes.LargePreview)]
    public Texture2D irradianceMap;
    [InlineEditor(InlineEditorModes.LargePreview)]
    public RenderTexture reconstructedIrradianceMap;
    
    public int integrationSampleNumber = 10000;
    private readonly float[] m_BasisFunctions = { 0.282094792f, 0.488602512f, 1.092548431f, 0.315391565f, 0.546274215f };

    private float GetBasisFunctions(int index, float x, float y, float z)
    {
        float[] basisFunctions = new float[9];
        basisFunctions[0] = m_BasisFunctions[0];
        basisFunctions[1] = m_BasisFunctions[1] * y;
        basisFunctions[2] = m_BasisFunctions[1] * z;
        basisFunctions[3] = m_BasisFunctions[1] * x;
        basisFunctions[4] = m_BasisFunctions[2] * x * y;
        basisFunctions[5] = m_BasisFunctions[2] * y * z;
        basisFunctions[6] = m_BasisFunctions[3] * (3 * z * z - 1);
        basisFunctions[7] = m_BasisFunctions[2] * z * x;
        basisFunctions[8] = m_BasisFunctions[4] * (x * x - y * y);
        return basisFunctions[index];
    }
    
    private Vector2 CartesiantoLatLongUV(Vector3 cartesianCoord)
    {
        cartesianCoord = Vector3.Normalize(cartesianCoord);
        float theta = Mathf.Asin(cartesianCoord.y);
        float phi = Mathf.Atan2(cartesianCoord.z, cartesianCoord.x);
        Vector2 uv = new Vector2(phi / (2 * Mathf.PI) + 0.5f, theta / Mathf.PI + 0.5f);
        return uv;
    }

    private Vector3[] GetCoefficients()
    {
        Vector3[] coefficients = new Vector3[9];
        for (int j = 0; j < 9; j++)
        {
            for (int i = 0; i < integrationSampleNumber; i++)
            {
                float theta = Mathf.Asin(2.0f * Random.value - 1.0f); //左手坐标系，theta在-90到90之间
                float phi = Mathf.PI * (2.0f * Random.value - 1.0f); //左手坐标系，phi在-180到180之间
                Vector3 normal = new Vector3(Mathf.Cos(theta) * Mathf.Cos(phi), Mathf.Sin(theta), Mathf.Cos(theta) * Mathf.Sin(phi));
                Vector2 uv = CartesiantoLatLongUV(normal);
                int uPixel = Mathf.FloorToInt(uv.x * (irradianceMap.width - 1));
                int vPixel = Mathf.FloorToInt(uv.y * (irradianceMap.height - 1));
                Color irradiance = irradianceMap.GetPixel(uPixel, vPixel);

                coefficients[j].x += irradiance.r * GetBasisFunctions(j, normal.x, normal.y, normal.z);
                coefficients[j].y += irradiance.g * GetBasisFunctions(j, normal.x, normal.y, normal.z);
                coefficients[j].z += irradiance.b * GetBasisFunctions(j, normal.x, normal.y, normal.z);
            }

            coefficients[j] = coefficients[j] * 4.0f * Mathf.PI / integrationSampleNumber;
        }
        return coefficients;
    }

    [Button(ButtonSizes.Large), GUIColor(0.4f, 0.8f, 1)]
    private void Reconstruction()
    {
        reconstructedIrradianceMap = new RenderTexture(irradianceMap.width, irradianceMap.height, 32, RenderTextureFormat.ARGB32);
        reconstructedIrradianceMap.enableRandomWrite = true;
        reconstructedIrradianceMap.Create();
        
        int kernelIndex = irradianceReConstructionComputeShader.FindKernel("SphericalHarmonicsIrradianceConstruction");
        irradianceReConstructionComputeShader.SetTexture(kernelIndex, "result", reconstructedIrradianceMap);
        irradianceReConstructionComputeShader.SetInt("inputTextureWidth", irradianceMap.width);
        irradianceReConstructionComputeShader.SetInt("inputTextureHeight", irradianceMap.height);
        
        ComputeBuffer buffer = new ComputeBuffer(9, sizeof(float) * 3);
        buffer.SetData(GetCoefficients());
        irradianceReConstructionComputeShader.SetBuffer(kernelIndex, "coefficients", buffer);
        
        irradianceReConstructionComputeShader.Dispatch(kernelIndex, irradianceMap.width / 8, irradianceMap.height / 8, 1);
    }
}
```

这样我们就可以用 27 个数字来替代 irradiance map 了。接下来的代码就是在 computer shader 中使用这 27 个计算好的球谐系数来重构 irradiance map：  

> 这里的 C 只是为了代码高亮。

``` C
#pragma kernel SphericalHarmonicsIrradianceConstruction

#define PI 3.14159265358979323846f
#define SHBasis0  0.28209479177387814347f 
#define SHBasis1  0.48860251190291992159f
#define SHBasis2  1.09254843059207907054f
#define SHBasis3  0.31539156525252000603f
#define SHBasis4  0.54627421529603953527f

RWTexture2D<float4> result;
RWStructuredBuffer<float3> coefficients;
int inputTextureWidth;
int inputTextureHeight;

float3 LatLongUVToCartesian (float2 uv)
{
    float phi = (uv.x - 0.5f) * 2.0f * PI;
    float theta = (uv.y - 0.5f) * PI;
    float3 cartesianCoord = float3(cos(theta) * cos(phi), sin(theta), cos(theta) * sin(phi));
    return cartesianCoord;
}

[numthreads(8,8,1)]
void SphericalHarmonicsIrradianceConstruction (uint3 id : SV_DispatchThreadID)
{
    float2 uv = float2((float) id.x / (inputTextureWidth - 1), (float) id.y / (inputTextureHeight - 1));
    float3 normal = LatLongUVToCartesian(uv);
    float4 reconstructedIrradiance = float4(0.0f, 0.0f, 0.0f, 1.0f);
    
    reconstructedIrradiance.rgb += SHBasis0 * coefficients[0];
    
    reconstructedIrradiance.r += SHBasis1 * coefficients[1].r * normal.y;
    reconstructedIrradiance.g += SHBasis1 * coefficients[1].g * normal.y;
    reconstructedIrradiance.b += SHBasis1 * coefficients[1].b * normal.y;
    
    reconstructedIrradiance.r += SHBasis1 * coefficients[2].r * normal.z;
    reconstructedIrradiance.g += SHBasis1 * coefficients[2].g * normal.z;
    reconstructedIrradiance.b += SHBasis1 * coefficients[2].b * normal.z;
    
    reconstructedIrradiance.r += SHBasis1 * coefficients[3].r * normal.x;
    reconstructedIrradiance.g += SHBasis1 * coefficients[3].g * normal.x;
    reconstructedIrradiance.b += SHBasis1 * coefficients[3].b * normal.x;
    
    reconstructedIrradiance.r += SHBasis2 * coefficients[4].r * normal.x * normal.y;
    reconstructedIrradiance.g += SHBasis2 * coefficients[4].g * normal.x * normal.y;
    reconstructedIrradiance.b += SHBasis2 * coefficients[4].b * normal.x * normal.y;
    
    reconstructedIrradiance.r += SHBasis2 * coefficients[5].r * normal.y * normal.z;
    reconstructedIrradiance.g += SHBasis2 * coefficients[5].g * normal.y * normal.z;
    reconstructedIrradiance.b += SHBasis2 * coefficients[5].b * normal.y * normal.z;
    
    reconstructedIrradiance.r += SHBasis3 * coefficients[6].r * (3.0f * normal.z * normal.z - 1);
    reconstructedIrradiance.g += SHBasis3 * coefficients[6].g * (3.0f * normal.z * normal.z - 1);
    reconstructedIrradiance.b += SHBasis3 * coefficients[6].b * (3.0f * normal.z * normal.z - 1);
    
    reconstructedIrradiance.r += SHBasis2 * coefficients[7].r * normal.z * normal.x;
    reconstructedIrradiance.g += SHBasis2 * coefficients[7].g * normal.z * normal.x;
    reconstructedIrradiance.b += SHBasis2 * coefficients[7].b * normal.z * normal.x;
    
    reconstructedIrradiance.r += SHBasis4 * coefficients[8].r * (normal.x * normal.x - normal.y * normal.y);
    reconstructedIrradiance.g += SHBasis4 * coefficients[8].g * (normal.x * normal.x - normal.y * normal.y);
    reconstructedIrradiance.b += SHBasis4 * coefficients[8].b * (normal.x * normal.x - normal.y * normal.y);
    
    result[id.xy] = reconstructedIrradiance;
}
```

重新构建出的 irradiance map 如下（100,000 次采样），可以看到重构出来的和原图非常像：  

<div  align="center">  
<img src="https://s2.loli.net/2024/08/08/9jqNKyr6t5a3Us1.png" width = "80%" height = "80%" alt="图12 - 原 irradiance map（上图）与球谐函数构建的 irradiance map（下图）"/>
</div>

### 应用二：Zonal Harmonics
上面方法的问题就是要做两次积分，先求出 irradiance，再求出球谐系数，这样太麻烦。而这个方法主要是运用到了球谐函数的一些性质，让我们可以简化计算，只需要对原环境贴图，即 radiance map 做一次积分即可，计算出 radiance map 的球谐系数，然后我们就可以直接构建出 irradiance map。

首先介绍利用的球谐函数的性质：  
①正交完备性：即不同的球谐基函数内积为 0，之前也提到过。只有相同的球谐基函数的内积为 1；  
②旋转不变性：即旋转目标函数后再投影和直接旋转根据投影值重建的函数是等价的；  
③在所有球谐基函数中，处于 Band 中间位置（m = 0）的球谐基函数比较特殊，称为**带谐函数 Zonal Harmonics**，简称 **ZH**。ZH 的笛卡尔坐标系的公式只受到 Z 轴的影响，因此任意投影到 SH 空间后沿 Z 轴圆形对称的函数，将只会在 ZH 基函数上具有非 0 系数。

> 这部分的推导逻辑实在过分复杂，根本看不懂！！！故不在这里做详细摘抄，只记录大致的推导逻辑和结果公式，有兴趣去看论文：《Spherical Harmonic Lighting:The Gritty Details》

首先我们的漫反射 BRDF 公式：  

$$ \cfrac {1}{\pi} \int_{\Omega} L(p,\omega_i) n \cdot \omega_i d \omega_i $$

我们分别对里面的 $\,L(p,\omega)\,$ 和 $\,n \cdot \omega\,$ 做球谐函数展开：  

$$ L(p,\omega) = light(w) = \sum_{i = 0}^N L_i Y_i(w) $$
$$ n \cdot \omega = t(w) = \sum_{i = 0}^N t_i Y_i(w) $$

把展开的函数代入回漫反射 BRDF：  

$$ \cfrac {1}{\pi} \int_{\Omega} L(p,\omega_i) n \cdot \omega_i d \omega_i $$
$$ = \cfrac {1}{\pi} \int_{\Omega} (\sum_{i = 0}^N L_i Y_i(w)) (\sum_{j = 0}^N t_j Y_j(w)) d \omega_i  $$
$$ = \cfrac {1}{\pi} \sum_{i = 0}^N \sum_{j = 0}^N L_i t_j \int_{\Omega} Y_i(w)Y_j(w) d \omega_i  $$

下面重点来了，因为正交完备性，当且仅当 i == j 时，上述基函数内积为 1，其他基函数内积都为 0，故上式还可以简化为：  

$$ \cfrac {1}{\pi} \int_{\Omega} L(p,\omega_i) n \cdot \omega_i d \omega_i = \cfrac {1}{\pi} \sum_{i = 0}^N L_i t_i $$

---

那么漫反射 BRDF 就只剩下两个球谐系数了：  
①先来看系数 $\,L_i\,$ 的计算：  

$$ L_i = \int_{\Omega} L(p,\omega_i) Y_i(\omega) d\omega $$

这个积分很简单，就是遍历 radiance map 求积分就行，黎曼和、蒙特卡洛积分和下面积分方法补充的方法任君挑选。下面的示例用的是积分方法补充里提到的方法。

②再来看系数 $\,t_i\,$ 的计算： 

$$ t_i = \int_{\Omega} n \cdot \omega Y_i(\omega) d\omega $$

问题就来了，我们要计算每一个法线方向 n 的积分，就又需要一张贴图记录每个法线方向上的球谐系数，那我们用球谐函数的意义何在。这时候就需要用到 Zonal Harmonics，经过一系列不可名状的推导（真看不懂，但不影响我们使用，ps: 痛苦面具），最终漫反射 BRDF 可以写为如下：  

$$ \cfrac {1}{\pi} \int_{\Omega} L(p,\omega_i) n \cdot \omega_i d \omega_i = \cfrac {1}{\pi} \sum_{l = 0}^N \sum_{m = -l}^l \sqrt{\cfrac {4 \pi} {2l + 1}} L_l^m t_l Y_l^m(n) $$

注意 $\,t\,$ 的下标是 $\,l\,$ 的索引，而该球谐系数的值如下（和根号下的数值的乘积）：

$$ l = 0: \sqrt{\cfrac {4 \pi} {2 \times 0 + 1}} t_0 = \pi $$
$$ l = 1: \sqrt{\cfrac {4 \pi} {2 \times 1 + 1}} t_1 = \cfrac {2} {3} \pi $$
$$ l = 2: \sqrt{\cfrac {4 \pi} {2 \times 2 + 1}} t_2 = \cfrac {1} {4} \pi $$

实践代码如下，在 C# 中计算拟合 radiance map 的球谐系数，再传递给 compute shader 重建 irradiance map：  

``` C#
using UnityEngine;
using UnityEditor;
using Sirenix.OdinInspector;
using Sirenix.OdinInspector.Editor;

public class ZonalHarmonic : OdinEditorWindow
{
    [MenuItem("Tools/Zonal Harmonic Irradiance Construction")]
    private static void ShowWindow()
    {
        ZonalHarmonic window = OdinEditorWindow.GetWindow<ZonalHarmonic>();
        window.Show();
    }
    
    public ComputeShader irradianceReConstructionComputeShader;
    private readonly float[] m_BasisFunctions = { 0.282094792f, 0.488602512f, 1.092548431f, 0.315391565f, 0.546274215f };
    [InlineEditor(InlineEditorModes.LargePreview)]
    public Texture2D radianceMap;
    [InlineEditor(InlineEditorModes.LargePreview)]
    public RenderTexture reconstructedIrradianceMap;
    
    private float GetBasisFunctions(int index, float x, float y, float z)
    {
        float[] basisFunctions = new float[9];
        basisFunctions[0] = m_BasisFunctions[0];
        basisFunctions[1] = m_BasisFunctions[1] * y;
        basisFunctions[2] = m_BasisFunctions[1] * z;
        basisFunctions[3] = m_BasisFunctions[1] * x;
        basisFunctions[4] = m_BasisFunctions[2] * x * y;
        basisFunctions[5] = m_BasisFunctions[2] * y * z;
        basisFunctions[6] = m_BasisFunctions[3] * (3 * z * z - 1);
        basisFunctions[7] = m_BasisFunctions[2] * z * x;
        basisFunctions[8] = m_BasisFunctions[4] * (x * x - y * y);
        return basisFunctions[index];
    }

    ... //下面积分方法补充的代码

    private Vector3[] GetRadianceCoefficients()
    {
        Vector3[] coefficients = new Vector3[9];
        for (int i = 0; i < 9; i++)
        {
            for (int u = 0; u < radianceMap.width; u++)
            {
                for (int v = 0; v < radianceMap.height; v++)
                {
                    Vector2 uv = new Vector2((float)u /(radianceMap.width - 1), (float)v /(radianceMap.height - 1));
                    Color irradiance = radianceMap.GetPixel(u, v);
                    Vector2 sphericalCoord = UVToSphericalCoord(uv);
                    Vector3 dir = new Vector3(Mathf.Cos(sphericalCoord.y) * Mathf.Cos(sphericalCoord.x), Mathf.Sin(sphericalCoord.y), Mathf.Cos(sphericalCoord.y) * Mathf.Sin(sphericalCoord.x));
                    float basisFunctions = GetBasisFunctions(i, dir.x, dir.y, dir.z);
                    float dSolidAngle = TexelCoordSolidAngle(uv, radianceMap.width, radianceMap.height);
                    coefficients[i].x += irradiance.r * basisFunctions * dSolidAngle;
                    coefficients[i].y += irradiance.g * basisFunctions * dSolidAngle;
                    coefficients[i].z += irradiance.b * basisFunctions * dSolidAngle;
                }
            }
        }
        return coefficients;
    }

    [Button(ButtonSizes.Large), GUIColor(0.4f, 0.8f, 1)]
    private void Reconstruction()
    {
        Vector3[] coefficients = GetRadianceCoefficients();
        reconstructedIrradianceMap = new RenderTexture(radianceMap.width, radianceMap.height, 32, RenderTextureFormat.ARGB32);
        reconstructedIrradianceMap.enableRandomWrite = true;
        reconstructedIrradianceMap.Create();
        
        int kernelIndex = irradianceReConstructionComputeShader.FindKernel("ZonalHarmonicsReconstruction");
        irradianceReConstructionComputeShader.SetTexture(kernelIndex, "result", reconstructedIrradianceMap);
        irradianceReConstructionComputeShader.SetInt("inputTextureWidth", radianceMap.width);
        irradianceReConstructionComputeShader.SetInt("inputTextureHeight", radianceMap.height);
        
        ComputeBuffer buffer = new ComputeBuffer(9, sizeof(float) * 3);
        buffer.SetData(coefficients);
        irradianceReConstructionComputeShader.SetBuffer(kernelIndex, "coefficients", buffer);
        
        irradianceReConstructionComputeShader.Dispatch(kernelIndex, radianceMap.width / 8, radianceMap.height / 8, 1);
    }
}
```

接下来就是重建 irradiance map，见证奇迹的时刻：  

``` C
#pragma kernel ZonalHarmonicsReconstruction

#define PI 3.14159265358979323846f
#define SHBasis0  0.28209479177387814347f 
#define SHBasis1  0.48860251190291992159f
#define SHBasis2  1.09254843059207907054f
#define SHBasis3  0.31539156525252000603f
#define SHBasis4  0.54627421529603953527f

RWTexture2D<float4> result;
RWStructuredBuffer<float3> coefficients;
int inputTextureWidth;
int inputTextureHeight;

float3 LatLongUVToCartesian (float2 uv)
{
    float phi = (uv.x - 0.5f) * 2.0f * PI;
    float theta = (uv.y - 0.5f) * PI;
    float3 cartesianCoord = float3(cos(theta) * cos(phi), sin(theta), cos(theta) * sin(phi));
    return cartesianCoord;
}

[numthreads(8,8,1)]
void ZonalHarmonicsReconstruction (uint3 id : SV_DispatchThreadID)
{
    float2 uv = float2((float) id.x / (inputTextureWidth - 1), (float) id.y / (inputTextureHeight - 1));
    float3 normal = LatLongUVToCartesian(uv);
    float4 reconstructedIrradiance = float4(0.0f, 0.0f, 0.0f, 1.0f);

    reconstructedIrradiance.rgb += SHBasis0 * coefficients[0] * PI;
    
    reconstructedIrradiance.r += SHBasis1 * coefficients[1].r * normal.y * 2 / 3 * PI;
    reconstructedIrradiance.g += SHBasis1 * coefficients[1].g * normal.y * 2 / 3 * PI;
    reconstructedIrradiance.b += SHBasis1 * coefficients[1].b * normal.y * 2 / 3 * PI;
    
    reconstructedIrradiance.r += SHBasis1 * coefficients[2].r * normal.z * 2 / 3 * PI;
    reconstructedIrradiance.g += SHBasis1 * coefficients[2].g * normal.z * 2 / 3 * PI;
    reconstructedIrradiance.b += SHBasis1 * coefficients[2].b * normal.z * 2 / 3 * PI;
    
    reconstructedIrradiance.r += SHBasis1 * coefficients[3].r * normal.x * 2 / 3 * PI;
    reconstructedIrradiance.g += SHBasis1 * coefficients[3].g * normal.x * 2 / 3 * PI;
    reconstructedIrradiance.b += SHBasis1 * coefficients[3].b * normal.x * 2 / 3 * PI;
    
    reconstructedIrradiance.r += SHBasis2 * coefficients[4].r * normal.x * normal.y * 1 / 4 * PI;
    reconstructedIrradiance.g += SHBasis2 * coefficients[4].g * normal.x * normal.y * 1 / 4 * PI;
    reconstructedIrradiance.b += SHBasis2 * coefficients[4].b * normal.x * normal.y * 1 / 4 * PI;
    
    reconstructedIrradiance.r += SHBasis2 * coefficients[5].r * normal.y * normal.z * 1 / 4 * PI;
    reconstructedIrradiance.g += SHBasis2 * coefficients[5].g * normal.y * normal.z * 1 / 4 * PI;
    reconstructedIrradiance.b += SHBasis2 * coefficients[5].b * normal.y * normal.z * 1 / 4 * PI;
    
    reconstructedIrradiance.r += SHBasis3 * coefficients[6].r * (3.0f * normal.z * normal.z - 1) * 1 / 4 * PI;
    reconstructedIrradiance.g += SHBasis3 * coefficients[6].g * (3.0f * normal.z * normal.z - 1) * 1 / 4 * PI;
    reconstructedIrradiance.b += SHBasis3 * coefficients[6].b * (3.0f * normal.z * normal.z - 1) * 1 / 4 * PI;
    
    reconstructedIrradiance.r += SHBasis2 * coefficients[7].r * normal.z * normal.x * 1 / 4 * PI;
    reconstructedIrradiance.g += SHBasis2 * coefficients[7].g * normal.z * normal.x * 1 / 4 * PI;
    reconstructedIrradiance.b += SHBasis2 * coefficients[7].b * normal.z * normal.x * 1 / 4 * PI;
    
    reconstructedIrradiance.r += SHBasis4 * coefficients[8].r * (normal.x * normal.x - normal.y * normal.y) * 1 / 4 * PI;
    reconstructedIrradiance.g += SHBasis4 * coefficients[8].g * (normal.x * normal.x - normal.y * normal.y) * 1 / 4 * PI;
    reconstructedIrradiance.b += SHBasis4 * coefficients[8].b * (normal.x * normal.x - normal.y * normal.y) * 1 / 4 * PI;
    
    result[id.xy] = reconstructedIrradiance / PI;
}
```

重建后的 irradiance map 如下：  

<div  align="center">  
<img src="https://s2.loli.net/2024/08/09/vSjpkOQ2h8WbIwP.png" width = "80%" height = "80%" alt="图13 - radiance map（上图）与球谐函数方法二构建的 irradiance map（下图）"/>
</div>

### 积分方法补充
因为图片本身是离散的数据，如果我们用蒙特卡洛方法在球面做积分，我们往往会**过采样 oversample** 或**欠采样 undersample** 一些纹素，这就会造成数据的浪费，毕竟一张图的数据是有限的。所以我们可以采取一种方法，就是遍历图片的每一个纹素，以及计算出每个纹素的立体角 solid angle，计算它们的乘积和就是积分，即：

$$ \int_{S} color(w) dw = \sum_{i = 0}^N color_i \times w_i$$

所以该方法的重点就是如何计算纹素对应的立体角，这里介绍的是左手坐标系下的 Latitude-longitude map 的计算方法，Cubemap 的方法见这篇文章：https://www.rorydriscoll.com/2012/01/15/cubemap-texel-solid-angle/。

> 注意这里约定的是左手坐标系，球坐标的 $\,\phi\,$ 是 xz 平面上 r 和 x 的夹角，$\,\theta\,$ 是 r 和 xz 平面的夹角，所以是 $\, S = \int_{- \pi}^{\pi} \int_{- \pi /2}^{\pi/2} cos \theta d\theta d\phi = 4 \pi\,$

首先我们要求球面上的一点对于球面中心点（即 Latitude-longitude map 的中心点，其球坐标的 $\,\phi\,$ 和 $\,\theta\,$ 都为 0）所组成的面积的立体角大小，已知球面上的一点的球坐标为 $\,\phi\,$ 和 $\,\theta\,$，那么立体角 $\,\Omega\,$ 为：  

$$ \begin{align*} \Omega &= \int_0^{|\phi|} d\phi \int_0^{|\theta|} cos\theta d\theta \\ &= (|\phi| - 0)(sin|\theta| - sin0) \\ &= |\phi| sin |\theta| \end{align*} $$

这里之所以要绝对值是因为我们的 $\,\phi \in [-\pi, \pi] \,$，$\,\theta \in [-\pi/2, \pi/2] \,$，球面中心点都是 0，要从 0 积分到 $\,\phi\,$ 和 $\,\theta\,$，但 $\,\phi\,$ 和 $\,\theta\,$ 可正可负，故加绝对值。

接下来就是获取纹素的四个点各自对应的对于球面中心点的立体角，然后简单加减就可以得到一个纹素的立体角了，如下图：  

$$ \Omega_{Texel} = \Omega_{A} - \Omega_{B} + \Omega_{C} - \Omega_{D} $$

<div  align="center">  
<img src="https://s2.loli.net/2024/08/09/tPTQqyY7k4bs2ZW.png" width = "40%" height = "40%" alt="图14 - 纹素立体角计算"/>
</div>

在 Unity 中实现脚本如下：  

``` C#
private float SphericalCoordToSolidAngle(Vector2 sphericalCoord)
{
    float solidAngle = Mathf.Abs(sphericalCoord.x) * (1 - Mathf.Sin(Mathf.Abs(sphericalCoord.y)));
    return solidAngle;
}

private Vector2 UVToSphericalCoord(Vector2 uv)
{
    float phi = (uv.x - 0.5f) * 2 * Mathf.PI;
    float theta = (uv.y - 0.5f) * Mathf.PI;
    Vector2 sphericalCoord = new Vector2(phi, theta);
    return sphericalCoord;
}

private float TexelCoordSolidAngle(Vector2 uv, int width, int height)
{
    float uTexelWidth = 1.0f / width;
    float vTexelHeight = 1.0f / height;

    Vector2 sphericalCoord0 = UVToSphericalCoord(uv);
    Vector2 sphericalCoord1 = UVToSphericalCoord(uv + new Vector2(uTexelWidth, 0));
    Vector2 sphericalCoord2 = UVToSphericalCoord(uv + new Vector2(uTexelWidth, vTexelHeight));
    Vector2 sphericalCoord3 = UVToSphericalCoord(uv + new Vector2(0, vTexelHeight));

    float solidAngle = SphericalCoordToSolidAngle(sphericalCoord0) - SphericalCoordToSolidAngle(sphericalCoord1) + SphericalCoordToSolidAngle(sphericalCoord2) - SphericalCoordToSolidAngle(sphericalCoord3);

    return Mathf.Abs(solidAngle);
}
```

## 漫反射环境光最终实现
之前说过，在宏观层面下，环境光来自半球内围绕法线 n 的所有方向，因此没有一个确定的半角向量来计算菲涅耳效应。为了体现宏观上的菲涅耳效应，我们使用法线和视线的夹角计算菲涅耳，同时补充上粗糙度的影响，粗糙度越高 F90 越小：  

    vec3 fresnelSchlickRoughness(float cosTheta, vec3 F0, float roughness)
    {
        return F0 + (max(vec3(1.0 - roughness), F0) - F0) * pow(1.0 - cosTheta, 5.0);
    }  

环境光代码最终确定为：

    vec3 kS = fresnelSchlickRoughness(max(dot(N, V), 0.0), F0, roughness); 
    vec3 kD = 1.0 - kS;
    vec3 irradiance = texture(irradianceMap, N).rgb; //或者用球谐采样
    vec3 diffuse    = irradiance * albedo;
    vec3 ambient    = (kD * diffuse) * ao; 

## Unity 的漫反射环境光实现
在 URP 中当我们在 Lighting 里设置好了 Skybox 并 Generate Lighting 之后，会计算出球谐光照的系数，根据 RGB 三通道，分别为 $\,LR_n^m\,$，$\,LG_n^m\,$，$\,LB_n^m\,$。然后 Unity 会将球谐系数和球谐基函数的参数部分相乘（应该使用的是 Zonal Harmonics，也就是说把所有系数都乘了进去，也把 $\,\cfrac {1}{\pi}\,$ 乘了进去，故使用时无需除以 $\,\pi\,$），并使用 SphericalHarmonicsL2 这个 struct 存储起来，如下：  

$$ SH[0,0] = \sqrt {\cfrac {1}{4 \pi}} LR_0^0 \,,\, SH[0,1] = \sqrt {\cfrac {1}{3 \pi}} LR_1^{-1} \,,\, SH[0,2] = \sqrt {\cfrac {1}{3 \pi}} LR_1^0 $$  

$$ SH[0,3] = \sqrt {\cfrac {1}{3 \pi}} LR_1^1 \,,\, SH[0,4] = \cfrac {1}{8} \sqrt {\cfrac {15}{\pi}} LR_2^{-2} \,,\, SH[0,5] = \cfrac {1}{8} \sqrt {\cfrac {15}{\pi}} LR_2^{-1} $$

$$ SH[0,6] = \cfrac {1}{16} \sqrt {\cfrac {5}{\pi}} LR_2^{0} \,,\, SH[0,7] = \cfrac {1}{8} \sqrt {\cfrac {15}{\pi}} LR_2^{1} \,,\, SH[0,8] = \cfrac {1}{16} \sqrt {\cfrac {15}{\pi}} LR_2^{2} $$

其中 $\,SH[0, x]\,$ 存储 R 通道，$\,SH[1, x]\,$ 存储 G 通道，$\,SH[2, x]\,$ 存储 B 通道。然后 Unity 将参数传入 Shader：  

    unity_SHAr = float4(SH[0, 3], SH[0, 1], SH[0, 2], SH[0, 0] - SH[0, 6]);
    unity_SHBr = float4(SH[0, 4], SH[0, 5], SH[0, 6] * 3, SH[0, 7]);
    unity_SHAg = float4(SH[1, 3], SH[1, 1], SH[1, 2], SH[1, 0] - SH[1, 6]);
    unity_SHBg = float4(SH[1, 4], SH[1, 5], SH[1, 6] * 3, SH[1, 7]);
    unity_SHAb = float4(SH[2, 3], SH[2, 1], SH[2, 2], SH[2, 0] - SH[2, 6]);
    unity_SHBb = float4(SH[2, 4], SH[2, 5], SH[2, 6] * 3, SH[2, 7]);
    unity_SHC  = float4(SH[0, 8], SH[1, 8], SH[2, 8]);

上面代码为什么要减去 $\,SH[x, 6]\,$，以及 $\,SH[x, 6] * 3\,$，不觉得熟悉吗？是因为第 7 个球谐基函数要乘上 $\,3z^2 -1\,$，我们和采样代码合在一起看（采样函数在 SphericalHarmonics.hlsl 的 `SHEvalLinearL0L1()` 函数和 `SHEvalLinearL2()` 函数中）：  

    float3 L0L1;
    float4 vA = float4(n, 1.0f); //n 是法线
    L0L1.r = dot(unity_SHAr, vA);
    L0L1.g = dot(unity_SHAg, vA);
    L0L1.b = dot(unity_SHAb, vA);

    float3 L2;
    float4 vB = n.xyzz * n.yzzx;
    L2.r = dot(unity_SHBr, vB);
    L2.g = dot(unity_SHBg, vB);
    L2.b = dot(unity_SHBb, vB);
    float vC = n.x * n.x - n.y * n.y;
    L2.rgb += unity_SHC.xyz * vC;

    float3 result = L0L1 + L2;

`unity_SHAr、unity_SHAg、unity_SHAb` 的第四项 `SH[x, 0] - SH[x, 6]` 正好在点乘中乘上 1.0f ，和 `unity_SHBr、unity_SHBg、unity_SHBb` 的第三项 `SH[x, 6] * 3` 正好在点乘中乘上 $\,z^2\,$，就可以得到 $\,(3z^2 -1) SH[x, 6]\,$。和之前的球谐基函数的表格结合起来看，很容易就看懂了。总之 Unity 用 7 个参数（$\,7 \times 4 = 28\,$），存储了原本的 $\,9 \times 3 = 27\,$ 个参数，减少了实时计算的开销。