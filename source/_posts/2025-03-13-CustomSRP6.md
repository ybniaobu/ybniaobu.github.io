---
title: Unity Custom SRP 基础（六）
date: 2025-03-13 20:44:31
categories: 
  - [图形学]
  - [unity, pipeline]
tags:
  - 图形学
  - 游戏开发
  - unity
top_img: /images/black.jpg
cover: https://s2.loli.net/2025/03/13/LozNxAmnlEJSOyV.gif
mathjax: true
description: 本笔记的主要内容包含 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX。
---

> 本笔记是关于 Unity 的**自定义可编程渲染管线**的入门基础，即 **SRP (Scriptable Rendering Pipeline)**，主要参考了著名的教程 https://catlikecoding.com/ 的 Custom SRP Tutorial，以及知乎上各位图形学大神们的文章。  
>    
> 笔者使用的 Unity 版本是 6000.0.27f1，Core RP Library 的版本是 17.0.3。

# HDR
到目前为止，我们输出到相机的帧缓冲仍然是 LDR 格式，即 B8G8R8A8_SRGB 格式。这意味着输出的颜色都会被限制在 0.0 到 1.0 之间，任何大于 1.0 的颜色值都会被 clamp 到 1.0，相当于在片元着色器函数的结尾做了一次 `saturate()`。但是在 Shader 里计算时，部分像素的颜色值很可能会高于 1.0，特别是在多光源的情况下，这就会造成部分区域非常白，导致场景细节的丢失。

为了解决这一问题，我们就需要使用 **HDR (High Dynamic Range，高动态范围)** 的帧缓冲了，一般 HDR 会使用 R16G16B16A16_FLOAT 的格式（最大值为 65504），也有为了减少带宽的开销，而压缩成 R11G11B10_FLOAT 格式的。这样子大于 1.0 的颜色值就可以存储在纹理当中了，从而获取更大范围的黑暗或明亮值。但是大部分显示器仍然只能显示 sRGB 色彩空间的颜色（这里暂时不讨论支持 HDR 输出的显示器），即 [0, 255] 或 [0.0, 1.0] 范围的值，此时就需要将 HDR 重新映射回 LDR 值，而这个操作就叫做**色调映射 Tone Mapping**，该操作的主要目的就是尽可能地保留场景的黑暗与明亮细节，所以它本质上就是增强明暗的对比度。

> 注意区分 Tone Mapping 和 **Gamma 校正**，这两个操作是相互独立的，Tonemapping 将 HDR 颜色转换到 LDR 颜色，但两者仍然都在线性空间，之后仍然需要做 Gamma 校正。  

## 支持 HDR rendering
我们可以在 RenderPipelineAsset 里面增加一个 bool 字段，用于控制 HDR 的开启。然后在创建 FrameBuffer 的地方根据该字段生成 HDR 格式：  

``` C#
data.buffer.GetTemporaryRT(RenderTargetIDs.k_FrameBufferId, data.camera.pixelWidth, data.camera.pixelHeight, 32, FilterMode.Bilinear, asset.enableHDR ? RenderTextureFormat.DefaultHDR : RenderTextureFormat.Default);
```

default HDR 格式就是 R16G16B16A16_FLOAT。这样子，我们的场景就会使用 HDR 渲染，打开 Frame Debugger，可以看到在最后输出之前渲染出来的图片颜色变深了，这就是因为渲染到了 HDR 的线性空间当中，所以看起来变暗了。但是我们不用关心最后输出时的 gamma 校正，因为在线性空间的设置下，Unity 会自动处理 gamma 校正问题。

## HDR Bloom
之前 LDR Bloom 的预过滤和采样过程中，都是将中间结果输出到 LDR 贴图当中的。那么我们首先应该将它们改为 HDR 贴图：  

``` C#
public override void Render(YRenderPipelineAsset asset, ref PipelinePerFrameData data)
{
    // do bloom at half or quarter resolution
    ...
    // Determine the iteration count
    ...
    // Shader property and keyword setup
    ...

    // HDR
    RenderTextureFormat format = asset.enableHDRFrameBufferFormat ? RenderTextureFormat.DefaultHDR : RenderTextureFormat.Default;

    // Prefilter
    data.buffer.GetTemporaryRT(k_BloomPrefilterId, width, height, 0, FilterMode.Bilinear, format);
    ...

    // Downsample - gaussian pyramid
    int sourceId = k_BloomPrefilterId;
    for (int i = 0; i < iterationCount; i++)
    {
        data.buffer.GetTemporaryRT(m_BloomPyramidUpIds[i], width, height, 0, FilterMode.Bilinear, format);
        data.buffer.GetTemporaryRT(m_BloomPyramidDownIds[i], width, height, 0, FilterMode.Bilinear, format);
        ...
    }

    // Upsample - bilinear or bicubic
    ...
    // Final Blit
    ...
    // Release RT
    ...
}
```

这样子 Addictive Bloom 就可以在 HDR 下正常工作了。HDR Bloom 和 LDR Bloom 的重要区别在于，HDR Bloom 中一个特别大的值会影响到一个非常大的区域，即使是一个像素，也可能会产生非常高亮的 Bloom 区域。产生这个现象的原因就是平均值的极端值效应，本来 4 个像素平均，LDR 下无论怎么平均都是小于 1 的平均数，现在 HDR 下，4 个像素中一个像素值为 10，其他像素值再小，平均值也会被拉得很大。于是乎，就产生了 HDR Bloom 的一个最大弊端，也是必须要克服的弊端，即闪烁现象。

### Bloom 闪烁问题
HDR Bloom 的闪烁问题在镜头移动的情况下会格外严重，我这里 gif 就不放出来了，URP 下该现象就挺严重的（看了下 URP 的 Bloom Shader，确实没解决闪烁问题）。而解决方案是在 Prefilter 阶段做一次模糊处理，并使用以下权重做平均来降低动态范围，这个方法叫做 **Karis Average**：  

$$ weight = \cfrac {1} {1 + luminance} $$

在该权重下，亮度越高，权重越低。这个方法虽然损失一部分的 bloom 范围和亮度，但是能在一定程度减少 Bloom 闪烁问题，虽然做不到完全解决，完全解决可以说是不可能的。该方法的实现如下：①将 Prefilter 的 Bilinear 2 × 2 采样扩展为 6 × 6 的 box 核，在采样时（模糊平均前）应用 bloom threshold 提取较亮区域。②使用 Karis Average 在模糊时做加权平均，替代 box 核的算术平均，对颜色进行修正。

    #include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Color.hlsl"

    float4 BloomPrefilterFrag(Varyings IN) : SV_TARGET
    {
        float3 color = float3(0.0, 0.0, 0.0);
        float2 offsets[9] = { float2(0.0, 0.0), float2(-1.0, -1.0), float2(-1.0, 1.0), float2(1.0, -1.0), float2(1.0, 1.0), float2(-1.0, 0.0), float2(1.0, 0.0), float2(0.0, -1.0), float2(0.0, 1.0)};

        UNITY_UNROLL
        for (int i = 0; i < 9; i++)
        {
            float2 offset = offsets[i] * _BlitTexture_TexelSize.xy * 2.0;
            float3 c = ApplyBloomThreshold(SAMPLE_TEXTURE2D_LOD(_BlitTexture, sampler_LinearClamp, IN.uv + offset, 0).rgb);
            float w = 1.0 / (Luminance(c) + 1.0);
            color += c * w;
            weight += w;
        }
        color /= weight;

        color = max(color, 0.0);
        return float4(color, 1.0);
    }

亮度的计算之前《Unity Shader入门精要》读书笔记（四）中也讲过，Core RP Library 的 Color.hlsl 也提供了相关的函数。上面之所以在 offset 中乘以 2.0 是因为我们使用的是 bilinear 采样器，采样一次可以覆盖 2 × 2 个像素，这样我们使用一个 3 × 3 的像素之间距离为 2 的 box 核，就可以覆盖到 6 × 6 个像素。最后一定要将颜色 clamp 到 0 以上，否则画面有可能会出现黑块。

这样子就可以解决大部分的闪烁问题了。但上面代码还可以再优化一步，因为下采样阶段使用了高斯模糊，我们可以将上述代码再减少 4 次采样，即与中心点相邻的 4 个采样点：  

    float4 BloomPrefilterFrag(Varyings IN) : SV_TARGET
    {
        ...
        float2 offsets[5] = { float2(0.0, 0.0), float2(-1.0, -1.0), float2(-1.0, 1.0), float2(1.0, -1.0), float2(1.0, 1.0)};

        for (int i = 0; i < 5; i++)
        {
            ...
        }
        ...
    }

这将会使 Prefilter 阶段产生的结果中一个较亮像素变为 x 形状，可以点开 Frame Debugger 查看。但是经过一次下采样，这种图案样式就会消失。


# Scattering Bloom
Scattering Bloom 和 Additive Bloom 在实现方法上是非常类似的，但是对于各自所想要呈现的效果却有所不同，这两种方法的出发点是不同的，故它们之间没有优劣之分。**Addictive Bloom** 更偏向艺术化的表达，相对 Scattering Bloom 更不遵守能量守恒，因为我们在上采样阶段不断叠加会导致 bloom 区域亮度超过了原本图片中的亮度。而 **Scattering Bloom** 考虑了能量守恒，它只模糊但不添加额外的亮度，这使得特别是在灯光或者发光物体使用物理光照单位时，能够更正确地表现出其原本拥有的亮度值。

Scattering Bloom 的实现步骤也比较简单，就是在上采样阶段使用 Scatter 属性在 high-resolution 和 low-resolution 的贴图之间做 lerp，而不是直接相加。这样我们上采样阶段最后得到的贴图的亮度值就不会发生变化，最后在叠加到 frame buffer 时（final blit 阶段）先将 Prefilter 阶段提取的较亮区域抠出来，再将上采样阶段得到的贴图贴上去。

## Scatter
我们先在 Bloom 的 VolumeComponent 里增加一个 enum 用于切换 Addictive Bloom 和 Scattering Bloom，同时添加一个新的属性 scatter，其范围在 0 - 1：  

``` C#
public enum BloomMode
{
    Additive,
    Scattering
}

[System.Serializable]
public sealed class BloomDownscaleParameter : VolumeParameter<BloomDownscaleMode>
{
    public BloomDownscaleParameter(BloomDownscaleMode value, bool overrideState = false) : base(value, overrideState) { }
}

[System.Serializable, VolumeComponentMenu("YPipeline Post Processing/Bloom")]
[SupportedOnRenderPipeline(typeof(YRenderPipelineAsset))]
public class Bloom : VolumeComponent, IPostProcessComponent
{
    public BloomModeParameter mode = new BloomModeParameter(BloomMode.Scattering, true);
    ...
    public ClampedFloatParameter scatter = new ClampedFloatParameter(0.5f, 0.0f, 1.0f);
    ...
}
```

我们要为上采样阶段添加一个新的 Pass，我命名为了 BloomScatteringUpsampleFrag，我们要根据选择的模式选择对应的 Pass，同时 scatter 也通过之前说的 `_BloomIntensity` 传递：  

``` C#
public override void Render(YRenderPipelineAsset asset, ref PipelinePerFrameData data)
{
    // do bloom at half or quarter resolution
    ...
    // Determine the iteration count
    ...
    // Shader property and keyword setup
    float bloomIntensity = settings.mode.value == BloomMode.Additive ? 1.0f : settings.scatter.value;
    data.buffer.SetGlobalFloat(k_BloomIntensityId, bloomIntensity);
    ...
    // HDR
    ...
    // Prefilter
    ...
    // Downsample - gaussian pyramid
    ...
    // Upsample - bilinear or bicubic
    int upsamplePass = settings.mode.value == BloomMode.Additive ? 3 : 4;
    ...
    for (int i = iterationCount - 2; i >= 0; i--)
    {
        ...
        BlitUtility.BlitTexture(data.buffer, m_BloomPyramidDownIds[i], m_BloomPyramidUpIds[i], BloomMaterial, upsamplePass);
        ...
    }
    // Final Blit
    ...
    // Release RT
    ...
}
```

BloomScatteringUpsampleFrag 也只需要对原本的上采样函数做一个更改即可，即将返回值的叠加改为 lerp：  

    float4 BloomScatteringUpsampleFrag(Varyings IN) : SV_TARGET
    {
        #if _BLOOM_BICUBIC_UPSAMPLING
        float3 lowerTex = SampleTexture2DBicubic(_BloomLowerTexture, sampler_LinearClamp, IN.uv, _BloomLowerTexture_TexelSize.zwxy, (1.0).xx, 0.0).rgb;
        #else
        float3 lowerTex = SAMPLE_TEXTURE2D_LOD(_BloomLowerTexture, sampler_LinearClamp, IN.uv, 0).rgb;
        #endif
        
        float3 higherTex = SAMPLE_TEXTURE2D_LOD(_BlitTexture, sampler_LinearClamp, IN.uv, 0).rgb;
        return float4(lerp(higherTex, lowerTex, _BloomIntensity), 1.0);
    }

可以看出 scatter 为 0 就意味着只使用金字塔最高层级的贴图，为 1 就只使用金字塔最低层级的贴图。为了确保中间层级都被使用，可以选择限制 scatter 的范围为 0.05 – 0.95。

## Final Blit
上面的步骤本质就是将较亮区域进行模糊，并在叠加的同时不额外增加亮度。为了保证能量守恒，我们叠加到原图时，也需要先将较亮区域从原图抠出来，再叠加上模糊后的较亮区域，从而呈现一种 Bloom 效果。创建一个新的 Pass，如下：  

    float4 BloomScatteringFinalBlitFrag(Varyings IN) : SV_TARGET
    {
        #if _BLOOM_BICUBIC_UPSAMPLING
        float3 lowerTex = SampleTexture2DBicubic(_BloomLowerTexture, sampler_LinearClamp, IN.uv, _BloomLowerTexture_TexelSize.zwxy, (1.0).xx, 0.0).rgb;
        #else
        float3 lowerTex = SAMPLE_TEXTURE2D_LOD(_BloomLowerTexture, sampler_LinearClamp, IN.uv, 0).rgb;
        #endif
        
        float3 higherTex = SAMPLE_TEXTURE2D_LOD(_BlitTexture, sampler_LinearClamp, IN.uv, 0).rgb;

        lowerTex += higherTex - ApplyBloomThreshold(higherTex);
        return float4(lerp(higherTex, lowerTex, _BloomIntensity), 1.0);
    }

我们在原图片和有 bloom 效果的新图片使用 _BloomIntensity 做插值方便我们控制整体的 Bloom 强度。传递参数的工作如下，最好将 Scattering Bloom 和 Addictive Bloom 的 Intensity 属性分开，因为 Scattering Bloom 的 Intensity 的范围是 0 - 1 之间，而 Addictive Bloom 可以无限大：  

``` C#
public override void Render(YRenderPipelineAsset asset, ref PipelinePerFrameData data)
{
    ...
    // Final Blit
    bloomParams = settings.mode.value == BloomMode.Additive ? new Vector4(settings.intensity.value, 0.0f) : new Vector4(settings.finalIntensity.value, 0.0f);
    int finalPass = settings.mode.value == BloomMode.Additive ? 3 : 5;
    data.buffer.SetGlobalVector(k_BloomParamsId, bloomParams);
    data.buffer.SetGlobalTexture(k_BloomLowerTextureID, new RenderTargetIdentifier(lastDst));
    BlitUtility.BlitTexture(data.buffer, RenderTargetIDs.k_FrameBufferId, BuiltinRenderTextureType.CameraTarget, BloomMaterial, finalPass);
    ...
}
```

这样子就实现了 Scattering Bloom，和 Addictive Bloom 的效果对比如下：  

<div  align="center">  
<img src="https://s2.loli.net/2025/03/19/FtsGQbrKnMxoh5q.png" width = "90%" height = "90%" alt="图94 - Scattering Bloom 和 Addictive Bloom 的效果对比"/>
</div>

从上图可以看出，Scattering Bloom 的效果相对比较不易察觉的，它是一个相对更加真实的效果，没有改变场景的整体亮度，并且只有在亮度很大的时候才会展现得比较明显，它的这种特性只能在亲自体验后才能感觉到，只看上图可能感受不是很明显。Addictive Bloom 则改变了场景中的亮度，所以它看起来比 Scattering Bloom 的效果更明显，也更亮。


# Tone Mapping
Tone Mapping 经过了一个很长时间的发展，在这个过程中出现了很多的 tone mapping 算法。常见的有 **Reinhard Tone Mapping**、**Uncharted 2 Filmic Tone Mapping**、**Khronos PBR Neutral Tone Mapping**、**ACES Tone Mapping**、**AgX Tone Mapping**。

在实现上述 Tone Mapping 算法之前，先大致说一下 Tone Mapping 相关类在 CPU 端的准备工作。因为我们之前 Bloom 后处理完是直接绘制到 CameraTarget 的，我们要对 Bloom 完的结果进行 Tone Mapping，所以我们要先将 Bloom 的结果输出到一个纹理中，我命名为了 _BloomTexture。创建 RT，释放 RT 以及 BloomRenderer 中绘制代码的更改我这里就不做记录了，也比较简单。整个后处理管线的顺序问题，下面讲到 Color Grading 时再讨论。

Tone Mapping 的 VolumeComponent 和 PostProcessingRenderer 类，参考前面 Bloom 的写法就行，也没什么好说的，在 VolumeComponent 里创建对应的 Tone Mapping Mode，再根据选择的 mode 对应的 Shader Pass 去绘制 _BloomTexture 即可，最后输出到 CameraTarget。下面直接讲 Shader 里的处理，以及对应的效果了。为了相对更好地展示不同 Tone Mapping 算法的效果以及方便对比，一个基本的渲染图如下（这张参考图的场景颜色比较少，可能不是很能展现不同 Tone Mapping 之间的不同），场景中有一个范围较大的点光源，和台灯位置的聚光灯，聚光灯亮度较高，可以看到台灯照亮位置已经有点过曝了，并且使用了 Scattering Bloom：  

<div  align="center">  
<img src="https://s2.loli.net/2025/03/21/eXAwZqBa1fY5GxO.jpg" width = "80%" height = "80%" alt="图95 - 未做 Tone Mapping 前的基准图"/>
</div>

## Reinhard
Reinhard Tone Mapping 来自于这篇论文：https://www-old.cs.utah.edu/docs/techreports/2002/pdf/UUCS-02-001.pdf 。从该篇论文中，可以提炼出 3 种应用：  

**①**第一个是最基础的 Reinhard tone mapping，可以称为 "Simple" Reinhard：  

$$ L_d = \cfrac {L} {1 + L} $$

    float3 Reinhard_Simple(float3 color)
    {
        return color / (color + 1.0);
    }

在 Unity 中实现后的基准参考图效果如下：  

<div  align="center">  
<img src="https://s2.loli.net/2025/03/21/fpNIHz4c6UOKJ1j.jpg" width = "80%" height = "80%" alt="图96 - Reinhard Simple"/>
</div>

可以感受到效果像是蒙了一层灰色。

**②**第二个是 "Simple" Reinhard 的扩展，可以称为 "Extended" Reinhard：  

$$ L_d = \cfrac {L(1 + \cfrac {L} {L_{white}^2})} {1 + L}$$

    float3 Reinhard_Extended(float3 color, float minWhite)
    {
        float minWhite2 = minWhite * minWhite;
        float3 numerator = color * (1.0 + color / minWhite2);
        return numerator / (1.0 + color);
    }

上述公式中的 $\,L_{white}\,$ 是用户控制的变量，代表着在场景中纯白色的最低亮度值。当 $\,L_{white}\,$ 趋向于无穷大时，"Extended" Reinhard 就会跟 "Simple" Reinhard 一样。$\,L_{white}\,$ 设置为 2 时的基准参考图效果如下：  

<div  align="center">  
<img src="https://s2.loli.net/2025/03/21/sU2So8fgZdOL1Bb.jpg" width = "80%" height = "80%" alt="图97 - Reinhard Extended（minWhite = 2）"/>
</div>

效果比 Reinhard Simple 要鲜艳一点，但整体仍然灰蒙蒙的。

**③**从上面公式可以看出，理论上我们不应该直接用颜色进行计算，而应该用亮度值，因为 L 代表着 luminance。但是因为我们无法将 RGB 转化为 luminance 后，再从 luminance 转换回 RGB。所以下面代码中，使用 Tone Mapping 前的 luminance 和后的 luminance 对最后的输出颜色做了一次缩放：  

    float3 Reinhard_ExtendedLuminance(float3 color, float minWhite)
    {
        float l_in = Luminance(color);
        float minWhite2 = minWhite * minWhite;
        float numerator = l_in * (1.0 + l_in / minWhite2);
        float l_out = numerator / (1.0 + l_in);
        return color * l_out / l_in;
    }

$\,L_{white}\,$ 还是设置为 2，效果如下：  

<div  align="center">  
<img src="https://s2.loli.net/2025/03/21/dv6UhEnNG5uM7I4.jpg" width = "80%" height = "80%" alt="图98 - Reinhard Luminance"/>
</div>

仍然没能解决灰蒙蒙的问题。

## Uncharted 2 Filmic
Uncharted 2 Filmic Tone Mapping 最早来自于 GDC 2010 的一个演讲 Uncharted 2: HDR Lighting，演讲者为顽皮狗 Naughty Dog 公司的 John Hable。后来 John Hable 在自己的博客中做了总结和修改：http://filmicworlds.com/blog/filmic-tonemapping-operators/ 。之后他又提出了对 Filmic 曲线进行更多控制的手段：http://filmicworlds.com/blog/filmic-tonemapping-with-piecewise-power-curves/ 。本篇文章只涉及他第一篇文章内的 Uncharted 2 Filmic Tone Mapping，不涉及对 Filmic Tonemapping curves 进行自定义。代码如下：  

    float3 Uncharted2(float3 x)
    {
        const float A = 0.15;
        const float B = 0.50;
        const float C = 0.10;
        const float D = 0.20;
        const float E = 0.02;
        const float F = 0.30;
        return ((x * (A * x + C * B) + D * E) / (x * (A * x + B) + D * F)) - E / F;
    }

    float3 Uncharted2Filmic(float3 color, float exposureBias)
    {
        float3 curr = Uncharted2(color * exposureBias);
        const float W = 11.2;
        float3 whiteScale = 1.0 / Uncharted2(W);
        return whiteScale * curr;
    }

exposureBias 在博客文章中，默认值为 2，下面实现后的基准参考图的设置也是 2：  

<div  align="center">  
<img src="https://s2.loli.net/2025/03/21/lFcvCnE7x3HZz9g.jpg" width = "80%" height = "80%" alt="图99 - Uncharted 2 Filmic"/>
</div>

## Khronos PBR Neutral
Khronos PBR Neutral Tone Mapping 是由 Khronos Group 组织提出的，该组织由很多国际知名多媒体行业领导者创立，致力于发展开放标准的应用程序接口 API。Vulkan API 就是由该组织研发并发布的。该 Tone Mapping 的研发者还写了一篇文章，说明了该算法所要解决的问题：https://modelviewer.dev/examples/tone-mapping 。顾名思义，该算法想要更好地体现 PBR 所展现出来的最真实最还原的状态，保留其色调和饱和度，代码如下：  

    float3 KhronosPBRNeutral(float3 color)
    {
        const float startCompression = 0.76;
        const float desaturation = 0.15;

        float x = min(color.r, min(color.g, color.b));
        float offset = x < 0.08 ? x - 6.25 * x * x : 0.04;
        color -= offset;

        float peak = max(color.r, max(color.g, color.b));
        if (peak < startCompression) return color;

        const float d = 0.24;
        float newPeak = 1.0 - d * d / (peak + d - startCompression);
        color *= newPeak / peak;

        float g = 1.0 - 1.0 / (desaturation * (peak - newPeak) + 1.);
        return lerp(color, newPeak * float3(1.0, 1.0, 1.0), g);
    }

实现后，基准参考图效果如下：  

<div  align="center">  
<img src="https://s2.loli.net/2025/03/21/qSl2zf1cO7V8xvG.jpg" width = "80%" height = "80%" alt="图100 - Khronos PBR Neutral"/>
</div>

## ACES
**Academy Color Encoding System（ACES）** 是由美国电影艺术与科学学院（AMPAS）和行业合作伙伴开发的开放式色彩管理和互换系统，它规范了所有不同类型的项目中的色彩科学，其创立的目的是为行业提供标准化的色彩管理系统。ACES 是开源的，具体详见 https://github.com/ampas/aces 。整套色彩转换工作流程极其复杂，下面简单梳理一下（可能描述得不是很准确）：  

首先 ACES 流程有如下几个组成部分：  
**①Input Device Transform (IDT)**：这一步骤也称为 Input Transform，主要目的是将输入设备颜色数据转换至 ACES 色彩空间。ACES 色彩空间又包括：  
&emsp;&emsp; - **ACES2065-1**：这是一个非常广域的线性色彩空间，比人眼还广，主要是为了存储归档以及部门之间传递素材使用；  
&emsp;&emsp; - **ACEScc**、**ACEScct**：log 色彩空间，主要用于色彩校正或调色；  
&emsp;&emsp; - **ACEScg**：线性色彩空间，主要用于 CG 或特效制作。  

下面三个组成部分又合称为 ACES viewing pipeline，其中：  
**②Look Modification Transform (LMT)**：这一步骤不是必需的，主要是给艺术家更方便地调色，LMT 始终在 ACES 色彩空间中工作；  

③ 和 ④ 又合称为 Output Transform，要将 ACES 色彩空间转换为非 ACES 色彩空间都需要有 RRT 的参与：  
**③Reference Rendering Transform (RRT)**：这步就是核心的一步，将 IDT 转换获得的标准的、高精度的、高动态范围的场景参考线性图像数据，使用一个 S 形曲线，映射到输出颜色编码空间以适用于参考显示设备的观看。  
**④Output Device Transform (ODT)** 这是 ACES 色彩管理流程中图像信号最终输出转换，就是转换成最终播出设备所需要的色彩空间，例如 Rec.709、Rec.2020、DCI-P3 等。

可以看到一个完整的 ACES 流程非常复杂，所幸的是 Unity 提供了相关的函数，在 Core RP Library 的 ACES.hlsl 和 Color.hlsl 文件中，调用代码如下（顺便提一下，Unity 的 `AcesTonemap()` 函数默认情况下也是使用的较为复杂的拟合函数，除非我们设置 `TONEMAPPING_USE_FULL_ACES` 为 1），先将颜色转换至 ACES 色彩空间，再映射：  

    float4 ToneMappingACESFullFrag(Varyings IN) : SV_TARGET
    {
        float3 color = SAMPLE_TEXTURE2D_LOD(_BlitTexture, sampler_LinearClamp, IN.uv, 0).rgb;
        return float4(AcesTonemap(unity_to_ACES(color)), 1.0);
    }

由于完整的 ACES 流程计算量较大，所以有大佬提出了提出了拟合 ACES 曲线的代码，比较出名的有 Stephen Hill Fit 和 Krzysztof Narkowicz Fit，代码分别来源于：https://github.com/TheRealMJP/BakingLab/blob/master/BakingLab/ACES.hlsl ，https://knarkowicz.wordpress.com/2016/01/06/aces-filmic-tone-mapping-curve/ 。

**Stephen Hill Fit**：  

    static const float3x3 ACESInputMat =
    {
        {0.59719, 0.35458, 0.04823},
        {0.07600, 0.90834, 0.01566},
        {0.02840, 0.13383, 0.83777}
    };

    static const float3x3 ACESOutputMat =
    {
        { 1.60475, -0.53108, -0.07367},
        {-0.10208,  1.10813, -0.00605},
        {-0.00327, -0.07276,  1.07602}
    };

    float3 RRTAndODTFit(float3 v)
    {
        float3 a = v * (v + 0.0245786f) - 0.000090537f;
        float3 b = v * (0.983729f * v + 0.4329510f) + 0.238081f;
        return a / b;
    }

    float3 ACESStephenHillFit(float3 color)
    {
        color = mul(ACESInputMat, color);

        // Apply RRT and ODT
        color = RRTAndODTFit(color);

        color = mul(ACESOutputMat, color);

        // Clamp to [0, 1]
        color = saturate(color);
        return color;
    }

**Krzysztof Narkowicz Fit**：

    float3 ACESApproxFit(float3 color)
    {
        color *= 0.6;
        float a = 2.51;
        float b = 0.03;
        float c = 2.43;
        float d = 0.59;
        float e = 0.14;
        return saturate(color * (a * color + b)/(color * (c * color + d) + e));
    }

Krzysztof Narkowicz Fit 相对来说拟合误差更大，但是计算量小很多。上述 3 种实现方式的效果就不一一展示了，效果大差不差，下面展示的是 Stephen Hill Fit 的基准参考图效果：  

<div  align="center">  
<img src="https://s2.loli.net/2025/03/21/l3PMc9TmE4oVK27.jpg" width = "80%" height = "80%" alt="图101 - ACES"/>
</div>

## AgX
AgX 因为 Blender 在使用开始逐渐出名，是由 Troy Sobotka 开发的，详见 https://github.com/sobotka ，最初为 OpenColorIO 编写。**OpenColorIO (OCIO)** 是一个开源的色彩管理框架，专为电影、视觉效果、动画和游戏等视觉创作行业设计。OCIO 包含一个配置文件：config.ocio，该配置文件包含了 LUT 文件的索引，支持多种 LUT 格式，如 .cube、.3dl、.spi1d 等。LUT 的相关知识，后面讲 Color Grading 时会详细讲解。

AgX 的 LUT 生成代码可以看 https://github.com/sobotka/SB2383-Configuration-Generation/blob/main/AgX.py 或 https://github.com/EaryChow/AgX_LUT_Gen 。有人将其代码转换为了 Shader 代码，见 https://github.com/MrLixm/AgXc 或 https://www.shadertoy.com/view/dtSGD1 。但实现起来仍然过于复杂，我又在网上找到了近似的方案：详见 https://iolite-engine.com/blog_posts/minimal_agx_implementation 或 https://www.shadertoy.com/view/cd3XWr 。近似代码如下：  

    // 0: Default, 1: Golden, 2: Punchy
    #define AGX_LOOK 0

    float3 AgXDefaultContrastApprox(float3 x)
    {
        float3 x2 = x * x;
        float3 x4 = x2 * x2;
    
        return + 15.5     * x4 * x2
            - 40.14    * x4 * x
            + 31.96    * x4
            - 6.868    * x2 * x
            + 0.4298   * x2
            + 0.1191   * x
            - 0.00232;
    }

    float3 AgX(float3 val)
    {
        const float3x3 agx_mat = float3x3( 0.842479062253094,   0.0784335999999992,  0.0792237451477643,
                                        0.0423282422610123,  0.878468636469772,   0.0791661274605434,
                                        0.0423756549057051,  0.0784336,           0.879142973793104);
            
        const float min_ev = -12.47393f;
        const float max_ev = 4.026069f;
        
        // Input transform
        val = mul(agx_mat, val);
        
        // Log2 space encoding
        val = clamp(log2(val), min_ev, max_ev);
        val = (val - min_ev) / (max_ev - min_ev);
        
        // Apply sigmoid function approximation
        val = AgXDefaultContrastApprox(val);
        
        return val;
    }

    float3 AgXEotf(float3 val)
    {
        const float3x3 agx_mat_inv = float3x3(  1.19687900512017,    -0.0980208811401368,  -0.0990297440797205,
                                            -0.0528968517574562,   1.15190312990417,    -0.0989611768448433,
                                            -0.0529716355144438,  -0.0980434501171241,   1.15107367264116);
            
        // Undo input transform
        val = mul(agx_mat_inv, val);
        
        // sRGB IEC 61966-2-1 2.2 Exponent Reference EOTF Display
        // NOTE: We're linearizing the output here. Comment/adjust when not using a sRGB render target
        val = pow(val, 2.2);
        
        return val;
    }

    float3 AgXLook(float3 val)
    {
        const float3 lw = float3(0.2126, 0.7152, 0.0722);
        float luma = dot(val, lw);
        
        // Default look
        float3 offset = float3(0.0, 0.0, 0.0);
        float3 slope = float3(1.0, 1.0, 1.0);
        float3 power = float3(1.0, 1.0, 1.0);
        float sat = 1.0;

        #if AGX_LOOK == 1
        // Golden
        slope = float3(1.0, 0.9, 0.5);
        power = float3(0.8, 0.8, 0.8);
        sat = 0.8;
        #elif AGX_LOOK == 2
        // Punchy
        slope = float3(1.0, 1.0, 1.0);
        power = float3(1.35, 1.35, 1.35);
        sat = 1.4;
        #endif
        
        // ASC CDL
        val = pow(val * slope + offset, power);
        return luma + sat * (val - luma);
    }

    float3 AgXApprox(float3 color)
    {
        color = AgX(color);
        color = AgXLook(color);
        color = AgXEotf(color);
        return color;
    }

<div  align="center">  
<img src="https://s2.loli.net/2025/03/21/PSK4FfIHzbQ8C7l.jpg" width = "80%" height = "80%" alt="图102 - AgX default"/>
</div>

<div  align="center">  
<img src="https://s2.loli.net/2025/03/21/dyEtIKrWqRm5P4Y.jpg" width = "80%" height = "80%" alt="图103 - AgX Punchy"/>
</div>


# Color Grading
从理论上来说，调色阶段可以分为两个步骤：①**色彩校正 Color Correction**，该步骤的主要目的是让画面进入一个中性的基线，以便开始调色工作，其中包括调整白平衡、平衡曝光、减少高光、增加中间色调和降噪等等。色彩校正完进入 ②**色彩分级 Color Grading**，即风格化地调整颜色，以满足美学上的需求。但是在实际操作中，人们不会特别地区分这两个步骤，常常将它们合并称为 Color Grading。而且对于游戏来说，我们得到的渲染图在没调色前就已经处于相对来说较为中性的状态，故可以直接进行 Color Grading 工作。Color Grading 发生在 Tone Mapping 之前。

