---
title: Unity Custom SRP 基础（二）
date: 2024-12-09 16:00:29
categories: 
  - [图形学]
  - [unity, pipeline]
tags:
  - 图形学
  - 游戏开发
  - unity
top_img: /images/black.jpg
cover: https://s2.loli.net/2024/12/09/paBhbkD6Vd9CIsy.gif
mathjax: true
description: 本笔记的主要内容有对阴影技术的相关知识补充；如何在管线中实现方向光阴影，特别是级联阴影的实现；如何优化阴影质量，主要包括 Shadow Bias 处理自阴影以及 PCF 实现软阴影。本文不包括 PCSS 的实现。
---

> 本笔记是关于 Unity 的**自定义可编程渲染管线**的入门基础，即 **SRP (Scriptable Rendering Pipeline)**，主要参考了著名的教程 https://catlikecoding.com/ 的 Custom SRP Tutorial，以及知乎上各位图形学大神们的文章。  
>    
> 笔者使用的 Unity 版本是 6000.0.27f1，Core RP Library 的版本是 17.0.3。

# 阴影技术知识补充
在 SRP 中实现方向光阴影之前，先补充一些实时阴影技术的相关基础知识（这里主要参考了《Real-Time Rendering 4th》的 Chapter 7 Shadows）。常见的阴影技术主要包括**平面阴影 planar shadows**、**阴影体算法 shadow volume** 以及最主流的**阴影贴图技术 shadow map**。

## 阴影的组成
首先，阴影可被分为两个部分：**本影 umbra** 和**半影 penumbra**，如下图所示：  

<div  align="center">  
<img src="https://s2.loli.net/2024/12/16/zhkS4t928eCTGlY.jpg" width = "35%" height = "35%" alt="图8 - umbra and penumbra"/>
</div>

**精确光源 punctual light**，即没有面积的光源，只会产生完全被阴影覆盖的区域，即本影区域，这样的阴影也被称为**硬阴影 hard shadows**。如果使用了面光源或者体积光源，那么则会产生**软阴影 soft shadows**。

如果仅仅使用低通滤波来处理硬阴影的边缘来模拟软阴影效果是不太正确的。⼀个正确渲染的软阴影应当有这样的现象：遮挡物 occluder 越靠近接收物 receiver，阴影的边缘就会越清晰。同时，软阴影的本影区域并不等同于由精确光源所产生的硬阴影；相反，软阴影的本影区域会随着光源的变大而减小。如果光源足够大，或者接收物距离遮挡物足够远的话，那么本影区域甚⾄可能会完全消失。

## 平面阴影
这是一个比较简单的，应用范围比较窄的平面投射阴影技术，常用于地表是平面的游戏（比如战斗场景切换至某一特定的平面）。在这个方法中，三维物体会被渲染两次，其中第二次用于创建阴影。根据平面的位置，我们可以推导出一个投影矩阵，将物体的坐标变换到平面上去。

①首先一个平面可以用法向量 $\,n\,$ 和平面上已知一点 $\,p_0\,$ 来表示。假设平面任意一点为 $\,p\,$，那么向量 $\,(p - p_0)\,$ 必然正交于平面。于是**平面方程 plane equation** 可以写为：  

$$ n \cdot (p - p_0) = 0 $$

这个方程可以改写为：  

$$ n \cdot p - n \cdot p_0 = n \cdot p + d = 0 $$

其中 $\,d = -n \cdot p_0\,$。若 n 为单位法向量，这个 d 也是原点距离平面的最短距离（因为点乘有个 cos）。若 $\,n = (a, b, c)\,$ 且 $\,p\,$ 为未知点 $\,(x, y, z)\,$，就得到了我们最熟悉的平面方程：  

$$ ax + by + cz + d = 0 $$

②知道了平面方程，就可以推导出投影矩阵了，如下图所示：  

<div  align="center">  
<img src="https://s2.loli.net/2024/12/16/d4i86AsMTcrX2US.png" width = "35%" height = "35%" alt="图9 - 阴影投射到任意平面"/>
</div>

物体的任意一点 v 我们是知道的，那么 p 就等于（推导过程就不放了）：  

$$ p = l - \cfrac {d + n \cdot l} {n \cdot (v - l)}(v - l) $$

而上述方程可以转换为投影矩阵 M，满足 $\,Mv = p\,$：  

$$ M = \begin{bmatrix} n \cdot l + d - l_xn_x & -l_xn_y & -l_xn_z & -l_xd \\ -l_yn_x & n \cdot l + d - l_yn_y & -l_yn_z & -l_yd \\ -l_zn_x & -l_zn_y & n \cdot l + d - l_zn_z & -l_zd \\ -n_x & -n_y & -n_z & n \cdot l \end{bmatrix} $$

③我们只要将这个矩阵应用到要在平面上投射阴影的物体上，然后再将投影后的物体（即阴影）渲染为深色，并且不接收光照即可。

但是在实践中，阴影可能会被渲染到平面的下面去，简单的解决方案则是对投影平面或者阴影进行偏移。另一种方法则是，先绘制投影平面，然后在关闭 z-buffer 的情况下，再去绘制阴影，最后再渲染投射阴影的物体。如果接受阴影的平面是一个有限的矩形，则阴影有可能会绘制到区域外面，此时可能需要通过 stencil buffer 标记出需要接受阴影的部分作为遮罩，这样就可以只让阴影产生在需要产生的平面上。

当然，也可以将阴影渲染到⼀个纹理中，然后再将其应用到平面上，这个纹理其实是⼀种**光照贴图 light map**。对这个纹理使用卷积（即滤波），可以对硬阴影进行模糊来模拟软阴影效果。我们甚至可以在面光源表面上进行采样，将每个采样点作为⼀个精确光源，并各自渲染一张纹理，将所有的这些图像相加并取平均值，便可以生成地面的阴影纹理，这种方法可以用于获取 ground-truth 图像，以便对其他更快算法的质量进行测试对比。

## 阴影体算法
Shadow Volume 这个方法我就大致提一下，其在实际应用中非常少见。它需要利用 stencil buffer 来进行实现。假设从光源沿着模型边缘拉伸至无限远处，在模型下方的部分称为 shadow volume。可以说，位于 shadow volume 内部的物体，在渲染时具有阴影，在 shadow volume 外部的物体，在渲染时没有阴影，如下图：  

<div  align="center">  
<img src="https://s2.loli.net/2024/12/16/1CZi25wOozsSUrx.jpg" width = "40%" height = "40%" alt="图10 - Shadow Volume"/>
</div>

假设从视点观察场景，从视点发出射线到与场景物体相交的过程中，每当射线穿过了 shadow volume 的正面（即面向观察者的一面）时，我们就让计数器加 1；也就是说，每当射线进入阴影区域时，计数器就会增加。每当光线穿过 shadow volume 的背面时，我们便将相同的计数器减 1，这代表了光线从阴影区域中射出。我们会一直持续这个过程，增加或者减少计数器的值，直到光线击中了场景中的物体。此时，如果计数器大于 0，则说明该像素位于阴影中；如果计数器为 0，则说明该像素位于阴影之外。

具体实现方法比较麻烦，需要生成 shadow volume 的几何体，利用两个 pass 分别绘制 shadow volume 几何体的正面和背面，最后再渲染整个场景。就不在这里详细地阐述了，想了解可以查询 z-pass、z-fail 算法。

## 阴影贴图
### 实现原理
这个就是在[《Unity Shader入门精要》读书笔记（三）](https://ybniaobu.github.io/2023/11/22/2023-11-22-UnityShader3/) 的第八章的 Unity 的阴影小节中提到的 Shadow Map 技术，也是之后自定义 SRP 中要实现的方法，那里主要介绍的是如何写 Shader，故介绍得比较简单。Shadow Map 的实现方法里面也提到过，分为两步：  
**①**从光源出发，构造出光源空间，渲染整个场景，将产生阴影的物体的深度写入到 z-buffer 中，就可以得到代表了最靠近光源的物体深度值的**阴影贴图 shadow map**。  
**②**然后在渲染时，我们根据渲染物体的世界坐标，变换到上一阶段的光源空间坐标，得到光源空间深度，再计算出该点在 shadow map 中的 uv 坐标，采样得到深度值并进行比较，如果在光源空间的深度比 shadow map 中的深度要大，就说明该点处在阴影中，否则就说明不在阴影中。

<div  align="center">  
<img src="https://s2.loli.net/2024/12/16/Q6oJmnNrptLfW2k.jpg" width = "50%" height = "50%" alt="图11 - 存储在纹素 a 处深度值大于点 Va 到光源的深度，因此点 Va 会被照亮；点 Vb 相对于光源的深度要大于存储在纹素 b 处的深度值，因此点 Vb 位于阴影中。"/>
</div>

对于聚光灯而言，其有个天然的**光照视锥体 light frustrum**，故使用透视投影渲染阴影贴图，位于视锥体之外的物体都不会被照亮。但对于方向光（平行光）来说，这个光源的视野无限大，要使用正交投影来渲染阴影贴图，我们需要保证其能够看到场景中的所有物体，即光照视锥体至少要包含整个摄像机视锥体。在实践中，对于方向光会有多个不同等级或不同绘制面积的摄像机，以此实现基于距离的阴影等级划分，从而提高阴影的质量，即**级联阴影 cascade shadow maps，CSM**（后面也会介绍）。如果是点光源，为了能保存各个方向的深度值，一般需要使用 cubemap，其核心问题在于避免在每个面的贴图接缝处出现瑕疵。

### Shadow acne
阴影贴图的阴影质量取决于阴影贴图的分辨率以及 zbuffer 的数值精度。在采样阴影贴图时，一个纹素代表着一个小范围区域的深度，从而导致一种交替黑线样式的锯齿问题。这个现象称为**自阴影走样 self-shadow aliasing** 或者**阴影痤疮 shadow acne**，如下图所示：  

<div  align="center">  
<img src="https://s2.loli.net/2024/12/17/efnDVCU5Qo7YjcI.jpg" width = "30%" height = "30%" alt="图12 - shadow acne"/>
</div>

产生这个现象的原因是，阴影贴图受限于分辨率，一定范围内不同的点可能会从阴影贴图采样得到同一个值。比如下图中，每个斜坡代表阴影贴图一个单独的纹理像素。可以看到，一个小范围的特定区域都可能采样得到同一个深度值，而这个特定区域的深度一部分比采样得到的深度大，一部分比采样得到的深度小，从而导致了图片中的条纹样式。

<div  align="center">  
<img src="https://s2.loli.net/2024/12/17/GrFIpwYK4Z7OT6M.png" width = "50%" height = "50%" alt="图13 - shadow acne 的原因"/>
</div>

常见的解决这个问题的方法是**阴影偏移 shadow bias**，又分为**深度偏移 Constant bias/Depth bias**、**斜率偏移 Slope bias/Slope scaled depth bias**、**法线偏移 Normal bias**：  

<div  align="center">  
<img src="https://s2.loli.net/2024/12/17/aCWD5EG27FoyqzT.png" width = "50%" height = "50%" alt="图14 - shadow bias"/>
</div> 

***①Constant bias/Depth bias***  
这个方法就是将阴影贴图的深度添加一个常量（增加深度就是沿着光照方向增加距离），故称为 Constant bias 或 Depth bias。这个方法比较简单，但是仍然可能会在斜平面上产生问题。斜面角度较大，固定的偏移值就越容易产生问题，如下图所示：  

<div  align="center">  
<img src="https://s2.loli.net/2024/12/17/KmPMsCqFYgRB1pH.jpg" width = "55%" height = "55%" alt="图15 - 图中的灰色的竖线代表阴影贴图的像素中心。左图中，如果没有添加偏移，那么蓝色和橙色样本将会被错误地认为处于阴影中，因为与对应的阴影贴图深度相比，它们距离光源更远。中图使用了 Depth bias，但是此时蓝色样本仍然会被认为处于阴影中，因为斜率高需要的偏移量更大。右图中，在构建阴影贴图的时候，会根据斜率，对其偏移量进行修正，即 Slope scaled depth bias。"/>
</div> 

***②Slope bias/Slope scaled depth bias***  
如上所说，表面相对于光源的倾斜角度越大，所需要的偏移量也就越大，所以我们可以将偏移量修正为与光源方向和表面法线之间夹角的正切值 $\,tan \theta\,$（即斜率）成正比，公式如下。但是有个问题就是，当表面和光源呈掠射夹角（90°）时，正切值接近于无限大，故需要为偏移值设置一个最大值。

$$ offset = \cfrac {frustrumSize} {shadowmapSize} * tan(\theta) * Slope\,\,bias $$

frustrumSize 是光源视锥体的大小，其除以 shadowmapSize 就是阴影贴图的一个纹素在世界空间的大小，通常情况下，需要半个纹素的偏移，故可以将 Slope bias 设置为 0.5。

***③Normal bias***  
顾名思义，就是将阴影投射体沿着物体表面的法线偏移，移动的距离与光源方向和表面法线之间夹角的正弦值 $\,sin \theta\,$ 成正比，公式如下。这个操作不仅改变了样本的深度值，还改变了它在阴影贴图上的 uv 值。

$$ offset = \cfrac {frustrumSize} {shadowmapSize} * sin(\theta) * Normal\,\,bias $$

> Unity 的 HDRP 中使用了 Normal bias + Slope scaled depth bias 的设置，UE5 使用了 Constant bias + Slope scaled depth bias。

当然，我们的 bias 值也不能设置得过大，否则会出现的**漏光 light leak** 或者 **Peter Panning** 问题，即物体看起来像是悬浮在表⾯上方一样。

Depth bias 和 Slope scaled depth bias 可以通过硬件实现也可以通过软件实现，比如在 DirectX 中可以在合并输出阶段设置这两个参数以及 DepthBiasClamp（允许的最大深度偏移量），计算过程如下：  

$$ Bias = (float)DepthBias * r + SlopeScaledDepthBias * MaxDepthSlope $$

其中 r 跟深度缓冲区位数有关，比如 24 位，r = 1 / 2^24。

至于 Normal bias 就只能通过软件实现了。添加 bias 可以在生成 shadow map 阶段完成，也可以在阴影计算阶段。生成 shadow map 时，可以在 vertex shader 中通过反向添加 bias 的方式来偏移计算处的 shadow map 深度值，这样在采样阴影时，就无需考虑计算偏移的问题。

### Shadow aliasing
**阴影走样 Shadow aliasing** 泛指阴影贴图中的纹素覆盖大量像素，从而导致的块状阴影问题，如下图所示：  

<div  align="center">  
<img src="https://s2.loli.net/2024/12/17/FkchHlBNsbTE3i8.jpg" width = "30%" height = "30%" alt="图16 - 阴影走样"/>
</div> 

提高阴影贴图的分辨率可以减少块状阴影的出现，但是需要额外的内存开销。其他解决方案有如下一些技术：  

#### 透视变形 perspective warping
这些算法，通过修改光照空间的投影矩阵，试图将光源的采样率与相机的采样率进行更好地匹配，包括透视阴影贴图 perspective shadow map，PSM、梯形阴影贴图 trapezoidal shadow maps，TSM 和光源空间透视阴影贴图 light space perspective shadow map，LiSPSM。这类技术被统称为**透视变形 perspective warping** 方法。这些矩阵扭曲 matrix-warping 算法的一个优点就是，除了对光源的投影矩阵进行修改之外，不需要进行其他额外的工作。

这类方式虽然使用起来简单，但是有很多无法处理的特殊情况，比如观察方向和光照方向完全相同时，这类方式就完全无法发挥作用。而且在摄影机移动时，这种方式非常的不稳定。由于这类方法的应用较少，就不在这里深入讲解相关的原理和实现。

#### 级联阴影 cascade shadow
**级联阴影贴图 cascade shadow maps，CSM** 是目前最常见的提高阴影贴图精度的手段。其实现思想是：将视锥体划分成若干个区域，对于每个划分后的视锥体区域，光源都可以生成一个包裹该区域的视锥体，各自生成一个阴影贴图，并用纹理图集 texture atlas 或纹理数组 texture array 将不同区域的阴影贴图打包成一个较大的纹理对象。

> 随着 **Virtual Texture** 技术的推广，Virtual Shadow Map 技术很有可能是未来的主流方向，建议去额外了解。

<div  align="center">  
<img src="https://s2.loli.net/2024/12/17/SzYQgKfjGr2Edoa.jpg" width = "35%" height = "35%" alt="图17 - CSM"/>
</div> 

在不同的阴影贴图之间划分深度的范围的任务，被称为 **z 划分（z-partitioning）**，其中一种方法是使用对数划分方法，从理论上来说是最佳方案，即满足：  

$$ r = \sqrt[c] {\cfrac{f}{n}} $$

其中 $\,n\,$ 是整个场景视锥体的近裁剪平面，$\,f\,$ 是整个场景视锥体的远裁剪平面；$\,c\,$ 是阴影贴图的数量，$\,r\,$ 是最终生成的比例。比如取 $\,n = 1, f = 1000, c = 3\,$，这样划分出来的三级 CSM 就是 1-10，10-100， 100-1000。但是如果我们这样来划分，最近处 1-10 这个范围的 CSM 划分，物体太少，反而会导致 shadowmap 空间的浪费。因此在实践中，常常会结合对数划分和其他划分手段来使用，或者直接由用户手动设置相应的比例值。

在使用 CSM 时，为了进一步提高算法的效率和质量，可以降低远处 CSM 的更新频率，位于较远处的阴影不需要每帧都进行更新，或者对于静态物体的阴影贴图在帧与帧之间重复使用。比如在原神中，共有八级的 CSM，前四级是每帧都更新的，后四级采用轮流更新的方式，这样相当于每帧更新 5 个等级的 CSM。

#### PCF
对阴影贴图进行简单的扩展就可以获得质量不错的伪软阴影效果，还有抗锯齿的功能。比如**百分比接近滤波 Percentage-Closer Filtering，PCF** 技术，其原理就是在对阴影贴图采样时，检索 4 个最近的样本，先将它们与表面深度进行比较，然后在对比较的结果 0 或 1 进行插值，这种过滤的结果会产生人为的软阴影。

现在的图形 API 都直接提供周围四点采样的加权 PCF 深度测试，比如 DirectX 的 `SampleCmpLevelZero` 且采样器选择 Linear 的过滤器。但是硬件的实现只采样 2 × 2 的像素点，仍然不够解决锯齿问题，此时可以再使用软件的实现将采样点范围扩大并增加采样点的个数，一种常见的解决方案是使用一个预先计算好的**泊松分布 Poisson distribution** 来对区域进行采样。为了使结果进一步平滑，还可以对采样点位置进行旋转，这样每两个相邻的像素点，采样的模式都是不同的，可以有效地平滑半影区域。  

<div  align="center">  
<img src="https://s2.loli.net/2024/12/18/1CrZqidpjaoPYUv.png" width = "50%" height = "50%" alt="图18 - 左图展示了 4 × 4 最近邻采样的 PCF 结果；圆盘中展示的是包含了 12 个点的泊松分布，使用这个分布对阴影贴图进行采样，获得第二张图。在第三张图中，采样模式围绕中心进行逐像素的随机旋转。"/>
</div>

PCF 会有如下几个问题：①自阴影问题（阴影痤疮）和漏光问题（Peter Panning）在 PCF 中会变得更加糟糕，需要手动调整各种偏移量；②由于每个采样区域的宽度保持不变，因此阴影会表现出均匀柔和的外观，即所有阴影区域都具有相同的半影宽度。它在某些情况下是可以接受的，但是在遮挡物和接收物相接触的地方，会表现得不太合理。

#### PCSS
**百分比接近软阴影 percentage-closer soft shadow，PCSS**，是目前比较主流的实时软阴影技术。本质上是 PCF 的扩展，PCF 的阴影区域具有相同的半影宽度，而 PCSS 试图通过计算阴影到遮挡物和光源距离，来决定采样区域的宽度，从而达到可变宽度的软阴影效果，其方程如下：  

$$ w_{Penumbra} = w_{Light} \cfrac {d_r - d_o} {d_o} $$

这个公式其实就是相似三角形，$\,d_r\,$ 是接受物到光源的距离，$\,d_o\,$ 是遮挡物到光源的平均距离，$\,w_{Light}\,$ 是光源的长度，$\,w_{Penumbra}\,$ 是半影的宽度。计算出采样区域的宽度后，根据它来动态调整采样的数量和滤波核的大小。PCSS 本身解决的问题是使用点光源模拟面光源的效果，因为本身点光源只会产生硬阴影，而使用面光源来生成 Shadow Map 存在着诸多困难。因此这里光源的宽度其实取决于渲染时假想的面光源宽度。

#### 过滤阴影贴图
这类方法都是对阴影贴图进行预过滤来得到软阴影效果。常见的有如下几种技术：**方差阴影贴图 variance shadow map，VSM**、**卷积阴影贴图 convolution shadow map，CSM**、**指数阴影贴图 Exponential Shadow Map，ESM**。对这些技术有兴趣可以看看这篇文章： https://developer.download.nvidia.com/presentations/2008/GDC/GDC08_SoftShadowMapping.pdf 。

这些技术的具体实现逻辑就不在这里阐述了。总之，对阴影贴图进行过滤可以被认为是一种廉价形式的 PCF，它只需要很少的样本。与 PCF 一样，这样产生的阴影具有恒定的半影宽度。这些滤波方法还可以与 PCSS 一起使用，从而提供可变宽度的半影效果。

#### Contact shadow
**接触阴影 Contact shadow** 主要是阴影贴图的一个补充，它是一个屏幕空间技术，contact shadow 会 raymarching 采样 depth buffer 一段很小的距离，来补充阴影效果。接触阴影也可以缓解 bias 导致的物体底部漏光问题。

另外一个使用场景是配合视差贴图，使用视差贴图时，阴影贴图没法精确地计算出相应的偏移值，使用 contact shadow 能补充地面的遮挡关系。

### 屏幕空间阴影贴图
屏幕空间阴影的实现是延迟渲染里面阴影的常见实现方法。延迟渲染中的光照计算绝大部分都是在屏幕空间里进行的，同样也包括阴影，实现主要有这么几个步骤：  
①首先得到从当前摄像机处观察到的深度纹理，在延迟渲染里这张深度图本来就有；  
②然后再从光源出发得到从该光源处观察到的深度纹理，也被称为这个光源的阴影贴图；  
③然后在屏幕空间做一次阴影收集计算 Shadows Collector，这次计算会得到一张屏幕空间阴影纹理。这个过程概括来说就是把每一个像素根据它在摄像机深度纹理中的深度值得到世界空间坐标，再把它的坐标从世界空间转换到光源空间中，和光源的阴影贴图里面的深度值对比，如果大于，那么就说明光源无法照到，在阴影内；  
④最后，在正常渲染物体为它计算阴影的时候，只需要按照当前处理的 fragment 在屏幕空间中的位置对屏幕空间阴影图采样就可以了。

# 方向光阴影
这里只实现方向光（平行光）的阴影，点光灯和聚光灯在后面的章节。

## 阴影贴图设置
教程中使用 texture atlas 来实现 cascade shadow（我会在之后自己的实现中会改为 texture array），就是将一张贴图分为多个 tiles，如下图所示（假设 4 个平行光以及 4 级联级阴影）：  

<div  align="center">  
<img src="https://s2.loli.net/2024/12/18/2aSADU1GTNnC9yR.png" width = "35%" height = "35%" alt="图19 - Shadow atlas"/>
</div> 

所以我们要先在 RenderPipelineAsset 中提供相关参数，让我们可以更改阴影贴图的相关设置（阴影质量相关参数在后面的小节里）。这些参数有：最大阴影距离、Shadow atlas 的分辨率、联级阴影的级数以及每级的比例、阴影的淡出、联级阴影的淡出。

``` C#
public enum TextureSize 
{
    _256 = 256, _512 = 512, _1024 = 1024,
    _2048 = 2048, _4096 = 4096, _8192 = 8192
}

[Min(0.0f)] public float maxShadowDistance = 100.0f;
public TextureSize directionalShadowAtlas = TextureSize._1024;
[Range(1, 4)] public int cascadeCount = 4;
[Range(0f, 1f)] public float spiltRatio1 = 0.1f, spiltRatio2 = 0.25f, spiltRatio3 = 0.5f;
[Range(0.001f, 1f)] public float distanceFade = 0.1f;
[Range(0.001f, 1f)] public float cascadeFade = 0.1f;
```

因为方向光是正交投影，理论上可以看到场景内的所有东西，所以我们需要给它个最大阴影距离来确定正交投影矩阵的大小。而联级阴影的级数就是对最大阴影距离的划分来确定各级的正交投影矩阵。阴影的距离淡出和联级阴影淡出是为了防止阴影在最大阴影距离的时候突然消失而感到突兀。

有了最大阴影距离，我们需要将这个参数传递给 `ScriptableCullingParameters`，以便让 `ScriptableRenderContext.Cull()` 执行剔除操作，如下：  

``` C#
if (!camera.TryGetCullingParameters(out ScriptableCullingParameters cullingParameters)) return;
cullingParameters.shadowDistance = Mathf.Min(m_Asset.maxShadowDistance, camera.farClipPlane);
m_Data.cullingResults = m_Data.context.Cull(ref cullingParameters);
```

因为阴影若超过远裁切平面的范围不管怎么样都看不到，故传递进 `maxShadowDistance` 和 `farClipPlane` 的较小值。`ScriptableCullingParameters` 的其他参数建议去官方文档好好看看。

## Cascade Shadow Maps 的实现
### 实现原理
理论上来说，我们要先将摄像头放到方向光源上并计算光源的 view matrix 和 projection matrix，然后在渲染阴影贴图使用光源的 VP 矩阵。渲染完成后，还需要将光源 VP 矩阵传递给 Shader，以便将像素转换至光源空间中，并在阴影贴图采样做对比。但是现在阴影贴图被分为了多个块，采样点需要更改，所以我们需要对光源 VP 矩阵进行修改。

我们可以通过 Unity 的一个黑盒 API `CullingResults.ComputeDirectionalShadowMatricesAndCullingPrimitives()` 计算出来光源的 VP 矩阵，假设它为 $\,m\,$。世界空间像素经过光源空间的 VP 矩阵，得到的是裁切空间的坐标，且 x、y、z 分量范围都是 [-1, 1]，不需要透视除法，因为是正交投影。首先我们要先将裁切空间的坐标，转换至屏幕空间的坐标（阴影贴图的 uv 坐标）以便采样，就是将 x、y、z 值从 [-1, 1] 映射至 [0, 1]，即先乘 0.5 再加上 0.5，本质上就是个缩放加平移矩阵：  

$$ \begin{bmatrix} 1 & 0 & 0 & 0.5 \\ 0 & 1 & 0 & 0.5 \\ 0 & 0 & 1 & 0.5 \\ 0 & 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} 0.5 & 0 & 0 & 0 \\ 0 & 0.5 & 0 & 0 \\ 0 & 0 & 0.5 & 0 \\ 0 & 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} m_{00} & m_{01} & m_{02} & m_{03} \\ m_{10} & m_{11} & m_{12} & m_{13} \\ m_{20} & m_{21} & m_{22} & m_{23} \\ m_{30} & m_{31} & m_{32} & m_{33} \end{bmatrix} = \begin{bmatrix} 0.5m_{00} + 0.5m_{30} & 0.5m_{01} + 0.5m_{31} & 0.5m_{02} + 0.5m_{32} & 0.5m_{03} + 0.5m_{33} \\ 0.5m_{10} + 0.5m_{30} & 0.5m_{11} + 0.5m_{31} & 0.5m_{12} + 0.5m_{32} & 0.5m_{13} + 0.5m_{33} \\ 0.5m_{20} + 0.5m_{30} & 0.5m_{21} + 0.5m_{31} & 0.5m_{22} + 0.5m_{32} & 0.5m_{23} + 0.5m_{33} \\ m_{30} & m_{31} & m_{32} & m_{33} \end{bmatrix} $$  

我们可以弄一个 Utility 的静态类，专门存储这类函数：  

``` C#
public static Matrix4x4 GetWorldToDirLightScreenMatrix(Matrix4x4 vp)
{
    if (SystemInfo.usesReversedZBuffer)
    {
        vp.m20 = -vp.m20;
        vp.m21 = -vp.m21;
        vp.m22 = -vp.m22;
        vp.m23 = -vp.m23;
    }
    
    vp.m00 = 0.5f * (vp.m00 + vp.m30);
    vp.m01 = 0.5f * (vp.m01 + vp.m31);
    vp.m02 = 0.5f * (vp.m02 + vp.m32);
    vp.m03 = 0.5f * (vp.m03 + vp.m33);
    vp.m10 = 0.5f * (vp.m10 + vp.m30);
    vp.m11 = 0.5f * (vp.m11 + vp.m31);
    vp.m12 = 0.5f * (vp.m12 + vp.m32);
    vp.m13 = 0.5f * (vp.m13 + vp.m33);
    vp.m20 = 0.5f * (vp.m20 + vp.m30);
    vp.m21 = 0.5f * (vp.m21 + vp.m31);
    vp.m22 = 0.5f * (vp.m22 + vp.m32);
    vp.m23 = 0.5f * (vp.m23 + vp.m33);
    
    return vp;
}
```

需要注意的是，要判断一下是否开启了 Reversed-Z，若开启了需要翻转一下 vp 矩阵的第三列。接下来就是对阴影贴图进行切分，本质上还是进行了一次缩放和平移，我们只对 x、y 值进行缩放和平移，不能改变 z 值，因为不能改变深度：  

$$ \begin{bmatrix} scale & 0 & 0 & offset \\ 0 & scale & 0 & offset \\ 0 & 0 & 1 & 0\\ 0 & 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} m_{00} & m_{01} & m_{02} & m_{03} \\ m_{10} & m_{11} & m_{12} & m_{13} \\ m_{20} & m_{21} & m_{22} & m_{23} \\ m_{30} & m_{31} & m_{32} & m_{33} \end{bmatrix} = \begin{bmatrix} scale \times m_{00} + offset \times m_{30} & \cdots & \cdots & scale \times m_{03} + offset \times m_{33} \\ scale \times m_{10} + offset \times m_{30} & \cdots & \cdots & scale \times m_{13} + offset \times m_{33} \\ m_{20} & m_{21} & m_{22} & m_{23} \\ m_{30} & m_{31} & m_{32} & m_{33} \end{bmatrix} $$

写成函数如下：  

``` C#
public static Matrix4x4 GetWorldToTiledDirLightScreenMatrix(Matrix4x4 vp, Vector2 offset, float scale = 1.0f)
{
    Matrix4x4 vps = GetWorldToDirLightScreenMatrix(vp);
    
    vps.m00 = vps.m00 * scale + offset.x * vps.m30;
    vps.m01 = vps.m01 * scale + offset.x * vps.m31;
    vps.m02 = vps.m02 * scale + offset.x * vps.m32;
    vps.m03 = vps.m03 * scale + offset.x * vps.m33;
    vps.m10 = vps.m10 * scale + offset.y * vps.m30;
    vps.m11 = vps.m11 * scale + offset.y * vps.m31;
    vps.m12 = vps.m12 * scale + offset.y * vps.m32;
    vps.m13 = vps.m13 * scale + offset.y * vps.m33;
    
    return vps;
}
```

我们可以计算阴影贴图的各个 tile 的变换矩阵后。接下来就是我们如何切分阴影贴图，并传递相关数据给 Shader ，以便采样 Shadow Atlas，毕竟我们要传递多个矩阵。

### CPU 中具体实现
首先要设定需要有多少个方向光能投射阴影，教程里假设最大方向光数量跟最大能投射阴影的方向光数量是一致的，即 4 个方向光都能投射阴影。再加上最多 4 个联级阴影级数，最大一共 16 个 tiles。故我们需要以下额外的参数以便传递给 Shader：  

``` C#
private const int m_MaxCascadeCount = 4;

private static int m_DirLightShadowDataId = Shader.PropertyToID("_DirectionalLightShadowData");
private static int m_DirShadowMapID = Shader.PropertyToID("_DirectionalShadowMap");
private static int m_DirShadowMatricesID = Shader.PropertyToID("_DirectionalShadowMatrices");
private static int m_CascadeCountID = Shader.PropertyToID("_CascadeCount");
private static int m_CascadeCullingSpheresID = Shader.PropertyToID("_CascadeCullingSpheres");
private static int m_ShadowDistanceFadeID = Shader.PropertyToID("_ShadowDistanceFade");

private Vector4[] m_DirLightShadowData = new Vector4[m_MaxDirLightCount];
private Matrix4x4[] m_DirShadowMatrices = new Matrix4x4[m_MaxDirLightCount * m_MaxCascadeCount];
private Vector4[] m_CascadeCullingSpheres = new Vector4[m_MaxCascadeCount];

struct ShadowingDirLight
{
    public int visibleLightIndex;                   
}
private int m_ShadowingDirLightCount;     
private ShadowingDirLight[] m_ShadowingDirLights = new ShadowingDirLight[m_MaxDirLightCount];
```

参数说明：  
①`m_MaxCascadeCount` 即最大级联阴影级数；   
②`_DirectionalLightShadowData` 是个向量数组，记录的是每盏方向光的一些阴影信息，x 记录该盏方向光的阴影强度，y 记录的是它在阴影贴图的 tiles 起始序号，比如说它是第二盏方向光，设定阴影联级级数为 4，那么它的起始位置为 4。zw 暂时没有信息，在阴影质量小节会添加；  
③`_DirectionalShadowMatrices` 就是上面提到的修改过的光源 VP 矩阵，一共最多可能要传递 16 个矩阵，一个 tile 一个矩阵；  
④`_CascadeCount` 指我们在 Asset 设置的阴影联级级数，和最大级联阴影级数不是一个数字，最大永远是 4；  
⑤`_CascadeCullingSpheres` 存放的是每个阴影联级级数的剔除球的中心位置（x、y、z）以及半径（w）。剔除球是 Unity 用来决定每个级数的具体覆盖范围的，也是用来决定采样哪个 tile 的依据，故需要传递至 Shader。之后也会提到；  
⑥`_ShadowDistanceFade` 的 x 存放最大阴影距离的倒数，y 存放 distanceFade 的倒数，z 存放 cascadeFade 的一个方程式结果，w 暂时没有信息；  
⑦`m_ShadowingDirLightCount` 是用来记录有多少方向光投射阴影，在场景中可能有 3 盏方向光，但只有 2 盏投射阴影。而 `ShadowingDirLight` 则是记录每盏投射阴影的方向光的一些信息的，包含它在所有可见光中的序号，方便我们索引到方向光的某些参数。其他信息在阴影质量小节会添加。

***一、首先记录并传递 `_DirectionalLightShadowData`***  
我们可以在方向光章节的 `SetupDirectionalLights()` 函数中做这件事情，上个章节遍历了所有可见光 visibleLights，当可见光为方向光时，记录下来方向光的方向和颜色，然后传递给 Shader。我们同样在遍历可见光的循环内，判断可见光为方向光后，判断可见方向光是否开启了阴影、阴影强度是否不为 0、以及可见光是否能影响到开启了阴影投射的物体。若是，则认为它是投影阴影的方向光 ShadowingDirLight，并记录下它的可见光序号。同时在 m_DirLightShadowData 中，记录它的阴影强度和 tiles 起始序号，如下：  

``` C#
private void SetupDirectionalLights(YRenderPipelineAsset asset, ref PipelinePerFrameData data)
{
    ...
    m_ShadowingDirLightCount = 0;
    for (int i = 0; i < visibleLights.Length; i++)
    {
        ...
        if (visibleLight.lightType == LightType.Directional)
        {
            if (visibleLight.light.shadows != LightShadows.None 
                && visibleLight.light.shadowStrength > 0f
                && data.cullingResults.GetShadowCasterBounds(i, out Bounds outBounds))
            {
                m_ShadowingDirLights[m_ShadowingDirLightCount] = new ShadowingDirLight 
                {
                    visibleLightIndex = i
                };
                
                m_DirLightShadowData[m_DirLightCount] = new Vector2(visibleLight.light.shadowStrength, 
                    asset.cascadeCount * m_ShadowingDirLightCount);
                m_ShadowingDirLightCount++;
            }
            else
            {
                m_DirLightShadowData[m_DirLightCount] = Vector2.zero;
            }
                
            ...
        }
    }
    
    ...
    data.buffer.SetGlobalVectorArray(m_DirLightShadowDataId, m_DirLightShadowData);
}
```

`CullingResults.GetShadowCasterBounds()` API 判断光源是否影响到了开启了阴影投射的物体，它的输出参数返回包含了所有阴影投射的物体的 AABB 包围盒，我们用不到这个参数。`m_DirLightShadowData` 里的数据根据方向光的序号保存的，所以在 Shader 里使用时也要根据方向光的序号获取。当方向光没开启阴影等，`m_DirLightShadowData` 对应的数据都为 0。

***二、创建 Shadow Atlas：`_DirectionalShadowMap`***  
我们要新写一个 `RenderToDirShadowMap` 函数，并在 RenderPipeline 脚本的 `Render()` 方法中调用它。在这个函数中我们要先调用 `CommandBuffer.GetTemporaryRT()` 创建一个临时的 render texture 用于渲染出阴影贴图，然后把它设置为 RenderTarget，设置好后，别忘了 ClearRenderTarget：  

``` C#
private void RenderToDirShadowMap(YRenderPipelineAsset asset, ref PipelinePerFrameData data)
{
    if (m_ShadowingDirLightCount > 0)
    {
        data.buffer.GetTemporaryRT(m_DirShadowMapID, 
            asset.directionalShadowAtlas, asset.directionalShadowAtlas, 
            32, FilterMode.Bilinear, RenderTextureFormat.Shadowmap);
        
        data.buffer.SetRenderTarget(
            new RenderTargetIdentifier(m_DirShadowMapID),
            RenderBufferLoadAction.DontCare, RenderBufferStoreAction.Store
        );
    
        data.buffer.ClearRenderTarget(true, false, Color.clear);
    }
    else
    {
        //这部分可以不要
        data.buffer.GetTemporaryRT(m_DirShadowMapID, 
            1, 1, 32, FilterMode.Bilinear, RenderTextureFormat.Shadowmap);
    }
}
```

上述代码中 `CommandBuffer.GetTemporaryRT()` 传入 shader 参数的 ID 后，会将这个临时的 RT 设置为 ID 对应的 shader 全局变量。参数 32 设置的是深度缓冲的位数（比特），可以设置为 0、16、24、32，我们希望阴影贴图的精度高，所以设置为 32 位。Render Texture 的类型可以设置为 `RenderTextureFormat.Shadowmap` 或者 `RenderTextureFormat.Depth`，两者的区别在于 Unity 认为 shadowmap 类型的 Render Texture 只需要比较，不需要获取深度值，因此以 ShadowMap 类型创建的 RT，其采样器会设置为比较采样器（后面会提到），有些显卡可能不支持比较采样器。而且之后做 PCFF 的时候需要获取深度值，所以我认为使用 `RenderTextureFormat.Depth` 会更好一点。还有就是，临时 RT 虽然会在最终执行完所有 CommandBuffer 自动释放，但是最好还是使用 `CommandBuffer.ReleaseTemporaryRT()` 函数手动释放资源。

如果场景中没有投射阴影的方向光，理论上我们可以不生成阴影贴图，但是这样做会导致 WebGL 2.0 出问题，因为 WebGL 2.0 将纹理和采样器绑定到了一起，如果加载了 Shader 但是少了一张贴图，而默认的贴图和阴影采样器并不兼容，所以就会产生错误。为了避免错误，可以设置一个 1 × 1 的阴影贴图。如果不需要支持 WebGL 2.0 可以直接去掉这段代码。

`CommandBuffer.SetRenderTarget()` 中的参数 `RenderBufferLoadAction` 设置的是当 RenderTarget 加载时候的行为，可以选择 Load、Clear、DontCare，我们不在乎 RenderTarget 的初始状态，因为我们之后会立即 ClearRenderTarget，故选择 `RenderBufferLoadAction.DontCare`；而参数 `RenderBufferStoreAction` 因为我们需要保留阴影信息，所以选择 `RenderBufferStoreAction.Store`。至于 `CommandBuffer.ClearRenderTarget()` 清除深度缓冲即可。

***三、渲染至 Shadow Atlas***  
设置好 Render Target 后，我们要创建并提交绘制指令，因为要对多个方向光的每个 cascade 进行绘制，可以通过一个循环来遍历所有投影阴影的方向光进行多次绘制，如下：  

``` C#
data.buffer.ClearRenderTarget(true, false, Color.clear);
                
for (int i = 0; i < m_ShadowingDirLightCount; i++) 
{
    RenderToDirShadowMapTile(asset,ref data, i);
}
```

在 `RenderToDirShadowMapTile()` 这个函数中，我们首先要创建一个 `ShadowDrawingSettings` 的结构体，以便在后面传递给 `ScriptableRenderContext.CreateShadowRendererList()` 方法，之后再利用一个循环遍历设定的阴影联级级数，调用 `CullingResults.ComputeDirectionalShadowMatricesAndCullingPrimitives()` 对每个级数计算对应的光照空间下的 VP 矩阵以及阴影联级对视锥体的一个划分数据 `ShadowSplitData`。之后就是计算并设置绘制区域，传递给 Shader 数据，将计算出来的 VP 矩阵设置好后调用渲染指令 `DrawRendererList`，代码如下：  

``` C#
private void RenderToDirShadowMapTile(YRenderPipelineAsset asset, ref PipelinePerFrameData data, int shadowingDirLightIndex)
{
    ShadowingDirLight shadowingDirLight = m_ShadowingDirLights[shadowingDirLightIndex];
    ShadowDrawingSettings shadowDrawingSettings = 
        new ShadowDrawingSettings(data.cullingResults, shadowingDirLight.visibleLightIndex);
    
    int tilesCount = asset.cascadeCount * m_ShadowingDirLightCount;
    int split = tilesCount <= 1 ? 1 : tilesCount <= 4 ? 2 : 4;
    int tileSize = asset.directionalShadowAtlas / split;
    int cascadeCount = asset.cascadeCount;
    Vector3 ratios = asset.SpiltRatios;
    
    for (int i = 0; i < cascadeCount; i++)
    {
        data.cullingResults.ComputeDirectionalShadowMatricesAndCullingPrimitives(
            shadowingDirLight.visibleLightIndex, i, cascadeCount, ratios, tileSize, 0f,
            out Matrix4x4 viewMatrix, out Matrix4x4 projectionMatrix, out ShadowSplitData splitData);
        shadowDrawingSettings.splitData = splitData;

        if (shadowingDirLightIndex == 0)
        {
            Vector4 cullingSphere = splitData.cullingSphere;
            cullingSphere.w *= cullingSphere.w;
            m_CascadeCullingSpheres[i] = cullingSphere;
        }
        
        int tileIndex = shadowingDirLightIndex * cascadeCount + i;
        Vector2 tileOffset = new Vector2(tileIndex % split, tileIndex / split);
        data.buffer.SetViewport(new Rect(
            tileOffset.x * tileSize, tileOffset.y * tileSize, tileSize, tileSize
        ));

        m_DirShadowMatrices[tileIndex] = ShadowUtility.GetWorldToTiledDirLightScreenMatrix(
            projectionMatrix * viewMatrix, tileOffset / split, 1.0f / split);
        
        data.buffer.SetViewProjectionMatrices(viewMatrix, projectionMatrix);
        RendererList shadowRendererList = data.context.CreateShadowRendererList(ref shadowDrawingSettings);
        data.buffer.DrawRendererList(shadowRendererList);
    }
}
```

①`ShadowDrawingSettings` 描述了使用哪个阴影划分的数据或者设置（splitData）来渲染哪个投射阴影的方向光（visibleLightIndex）。`splitData` 在遍历阴影联级的循环中赋值。这个 `ShadowDrawingSettings.splitData` API 在 Unity 6 中已经被废弃了，虽然仍然可以使用，但 Unity 6 中建议使用 `ScriptableRenderContext.CullShadowCasters()`，之所以换 API 是因为上面的代码阴影剔除（划分）和阴影绘制的工作是在一起的，而新 API 将这两个工作分开进行了。我会在之后自己的实现中修改这部分代码；  
②`tilesCount` 就是 Shadow Atlas 中 tiles 的总数，根据 tiles 的总数判断需要将 Shadow Atlas 划分几次，即 `split`。然后计算出每个 tile 的分辨率 `tileSize`；  
③`CullingResults.ComputeDirectionalShadowMatricesAndCullingPrimitives()` 的主要工作就是对视锥体进行划分，因为方向光是正交投影，它使用多个级数的正交投影的裁切空间立方体对视锥体进行划分，并返回指定级数的裁切空间立方体的相关数据，比如 VP 矩阵，和阴影划分数据 `ShadowSplitData`。这个函数需要的参数我就不详细说明了，具体查看官方文档；  
④我们在 Shader 中通过 `ShadowSplitData` 中的 `cullingSphere` 数据来判断具体采样 Shadow Atlas 的哪个 tile。利用像素点距离球心的距离，跟 cullingSphere.w 球的半径做比较，所以在这里将球的半径平方处理，以减少 Shader 中开平方的性能消耗。`cullingSphere` 就是包含在不同级联阴影级数的裁切空间立方体内的球体，主要目的就是让我们区分采样的范围，如下图；  

<div  align="center">  
<img src="https://s2.loli.net/2024/12/25/8DBFRQ2VIP7AXYJ.png" width = "30%" height = "30%" alt="图20 - Shadow Culling/Split Sphere"/>
</div> 

⑤接下来就是通过 `CommandBuffer.SetViewport()` 来设置每个 tile 在 Shadow Atlas 上的具体渲染区域，`tileIndex` 是每个 tile 的序号，通过序号可以算出每个 tile 的偏移位置，即 `tileOffset`；  
⑥`m_DirShadowMatrices` 就是在实现原理中所说的对矩阵的平移和缩放，调用我们自己写的方法即可；  
⑦最后就是设置渲染矩阵，创建 shadowRendererList 并渲染。这样子经过多次投射阴影方向光的多次 tile 的绘制，就能绘制出整张 Shadow Atlas 了。

渲染指令都处理完毕后，要在 `RenderToDirShadowMap` 函数的最后，传递数据给 Shader:  

``` C#
data.buffer.SetGlobalInt(m_CascadeCountID, asset.cascadeCount);
data.buffer.SetGlobalVectorArray(m_CascadeCullingSpheresID, m_CascadeCullingSpheres);
data.buffer.SetGlobalMatrixArray(m_DirShadowMatricesID, m_DirShadowMatrices);
```

### GPU 中具体实现
***一、ShadowCaster Pass***  
因为 `DrawRendererList(shadowRendererList)` 只会将拥有 ShadowCaster Pass 的物体渲染进阴影贴图，所以我们需要定义这个 pass。在这个 pass 中只需要将深度信息渲染进阴影贴图，所以只需要在顶点着色器做坐标变换即可。像素着色器不用返回任何东西，因为我们不用输出颜色，所以也不需要 SV_TARGET 语义。一个最简单的 ShadowCaster Pass 如下：  

``` C
#ifndef YPIPELINE_SHADOW_CASTER_PASS_INCLUDED
#define YPIPELINE_SHADOW_CASTER_PASS_INCLUDED

#include "../ShaderLibrary/Core/YPipelineCore.hlsl"

struct Attributes 
{
    float4 positionOS   : POSITION;
};

struct Varyings
{
    float4 positionHCS  : SV_POSITION;
};

Varyings ShadowCasterVert(Attributes IN)
{
    Varyings OUT;
    OUT.positionHCS = TransformObjectToHClip(IN.positionOS.xyz);
    return OUT;
}

void ShadowCasterFrag(Varyings input)
{
    
}

#endif
```

同时在 Shader 中要设置其 light mode 为 ShadowCaster：

    Pass
    {
        Tags { "LightMode" = "ShadowCaster" }

        ColorMask 0

        HLSLPROGRAM
        #pragma target 3.5
        
        #pragma vertex ShadowCasterVert
        #pragma fragment ShadowCasterFrag
        
        #include "../ShaderPass/ShadowCasterPass.hlsl"
        ENDHLSL
    }


***二、Shadow sampling***  
我们在 ShaderLibrary 中创建一个 ShadowsLibrary.hlsl 的文件，用于存放采样阴影贴图、计算阴影衰减等函数，方便我们在计算光照时使用。首先我们得在 YPipelineInput.hlsl 中定义几个变量和 CPU 传入的参数匹配：  

    define MAX_CASCADE_COUNT 4

    TEXTURE2D_SHADOW(_DirectionalShadowMap);
    SAMPLER_CMP(sampler_linear_clamp_compare_DirectionalShadowMap);

    CBUFFER_START(Shadows)
        float4 _DirectionalLightShadowData[MAX_DIRECTIONAL_LIGHT_COUNT];
        float4 _CascadeCullingSpheres[MAX_CASCADE_COUNT];
        float4x4 _DirectionalShadowMatrices[MAX_DIRECTIONAL_LIGHT_COUNT * MAX_CASCADE_COUNT];
        float4 _ShadowDistanceFade;
        int _CascadeCount;
    CBUFFER_END

CBuffer 中的参数之前都有提到过就不重复说明了。这里定义了一张阴影贴图和对应的比较采样器，`TEXTURE2D_SHADOW` 宏在大部分平台上都是 Texture2D，`SAMPLER_CMP` 则是创建 `SamplerComparisonState` 采样器的宏，比较采样器则是用于比较采样，即 `SampleCmp` 或 `SampleCmpLevelZero` 。这两个方法将采样一块纹素区域，对于每个纹素，将其采样出来的深度值与给定比较值进行比较，返回 0 或者 1，最后将这些纹素的每个 0 或 1 结果通过设定的纹理过滤模式混合在一起返回给着色器。比如我们设定的 linear，就是检索 4 个最近的样本进行插值混合，之前的阴影技术知识补充的 PCF 中也有提到过。

接下来在 ShadowsLibrary.hlsl 定义几个函数，首先是坐标变换函数，根据所在 tile 的序号将世界坐标转换到指定 tile 的阴影贴图坐标：  

    float3 TransformWorldToTiledShadowCoord(float3 positionWS, int tileIndex)
    {
        float3 positionTSS = mul(_DirectionalShadowMatrices[tileIndex], float4(positionWS, 1.0)).xyz;
        return positionTSS;
    }

拿到 Tiled Shadow Space（TSS）的坐标后就可以采样阴影贴图了，使用宏 `SAMPLE_TEXTURE2D_SHADOW`，它在大部分平台中等价于 `_DirectionalShadowMap.SampleCmpLevelZero(sampler, positionTSS.xy, positionTSS.z)`，即拿 positionTSS.xy 采样阴影贴图得到深度值，跟计算出来的光源空间的深度值 positionTSS.z 做比较，返回 0 或者 1。函数如下：  

> directX 中可以对 SamplerComparisonState 设置比较函数，通常设置为 LESS_EQUAL，即第三个参数 <= 采样值时返回 1。Unity 的默认情况下也是如此，即 positionTSS.z 小于等于采样阴影贴图得到的深度值时返回 1，即没有阴影，此时 shadowAttenuation 应为 1.0，即没有衰减。

    float SampleShadowMap(float3 positionTSS)
    {
        float shadowAttenuation = SAMPLE_TEXTURE2D_SHADOW(_DirectionalShadowMap, sampler_linear_clamp_compare_DirectionalShadowMap, positionTSS);
        return shadowAttenuation;
    }

然后就是计算 tileIndex 了，首先方向光在阴影贴图的 tiles 的起始序号是由 `_DirectionalLightShadowData.y` 传递进来的，所以我们只需要根据传递进来的 `_CascadeCullingSpheres` 去判断像素所在的 CascadeIndex，这样就可以得到 tileIndex 了，从而采样出阴影值，代码如下：  

    float ComputeCascadeIndex(float3 positionWS)
    {
        float3 vector0 = positionWS - _CascadeCullingSpheres[0].xyz;
        float3 vector1 = positionWS - _CascadeCullingSpheres[1].xyz;
        float3 vector2 = positionWS - _CascadeCullingSpheres[2].xyz;
        float3 vector3 = positionWS - _CascadeCullingSpheres[3].xyz;
        float4 distanceSquare = float4(dot(vector0, vector0), dot(vector1, vector1), dot(vector2, vector2), dot(vector3, vector3));
        float4 radiusSquare = float4(_CascadeCullingSpheres[0].w, _CascadeCullingSpheres[1].w, _CascadeCullingSpheres[2].w, _CascadeCullingSpheres[3].w);
        
        float4 indexes = float4(distanceSquare < radiusSquare);
        indexes.yzw = saturate(indexes.yzw - indexes.xyz);
        return 4.0 - dot(indexes, float4(4, 3, 2, 1));
    }

catlikecoding 教程中是用 for 循环来计算 CascadeIndex 的，我觉得不太好，所以看了看 URP 的阴影实现，就发现了上述不需要 for 循环的计算方式。首先计算像素世界坐标和原点的距离，跟球半径做比较。比如距离比第一个球半径长，比第二个球半径短，那么 indexes 就是 [0, 1, 1, 1]，而我们要获取的 CascadeIndex 应该是 1，即第二个球。使用的方法就是错位相减 [0, 1, 1, 1] - [0, 0, 1, 1] = [0, 1, 0, 0]。那么为什么最后 return 的时候计算 CascadeIndex，不直接 [0, 1, 0, 0] 和 float4(0, 1, 2, 3) 点乘，这样不是可以直接算出 1 吗？是因为若距离比所有球半径大的话，错位相减得到的是 [0, 0, 0, 0]，这样和 float4(0, 1, 2, 3) 点乘算出 0，就会采样到第一个球内了。

得到 CascadeIndex 就可以计算阴影值了，使用传递进来的阴影强度 `_DirectionalLightShadowData.x` 对采样值做插值，如下：  

    float GetDirShadowFalloff(int dirLightIndex, float3 positionWS)
    {
        float shadowStrength = _DirectionalLightShadowData[dirLightIndex].x;

        float cascadeIndex = ComputeCascadeIndex(positionWS);
        float tileIndex = _DirectionalLightShadowData[dirLightIndex].y + cascadeIndex;
        float3 positionTSS = TransformWorldToTiledShadowCoord(positionWS, tileIndex);
        float shadowAttenuation = SampleShadowMap(positionTSS);
        
        return lerp(1.0, shadowAttenuation, shadowStrength);
    }

计算好了，将阴影值结果乘在计算灯光 Irradiance 的函数中，就可以得到如下的阴影：  

<div  align="center">  
<img src="https://s2.loli.net/2024/12/25/DLSjfiwuapI2kQd.png" width = "35%" height = "35%" alt="图21 - 单个方向光的阴影效果"/>
</div> 

可以看到阴影质量非常差，自阴影和阴影走样同时存在，这在接下来的阴影质量小节中解决。最远处的黑色区域，是因为超过了级联阴影最大级数，计算出来的 CascadeIndex 为 4，导致采样超出范围，在下面解决。

### Shadow Fade
***一、剔除超出级联阴影范围区域***  
当像素点距离超过所有的级联阴影的 culling sphere 时，此时 CascadeIndex 计算出来为 4，这样在计算阴影坐标时会得到一个错误的矩阵。为了避免这个问题，可以使用 `step()` 函数，让 `cascadeIndex` 和传入的设定的级联阴影级数 `_CascadeCount` 比较：  

    float GetDirShadowFalloff(int dirLightIndex, float3 positionWS)
    {
        float cascadeIndex = ComputeCascadeIndex(positionWS);
        float shadowStrength = _DirectionalLightShadowData[dirLightIndex].x;
        shadowStrength *= 1 - step(_CascadeCount, cascadeIndex);
        ···
    }

`step(a, b)` 是 a <= b 时为 1，当 _CascadeCount <= cascadeIndex 时，让阴影强度为 0，这样黑色区域就会被剔除。

***二、Distance Fade***  
当在级联阴影最大级数的 culling sphere 边缘时，有时候阴影会瞬间消失，即使在最后一级的 culling sphere 内部。这是因为最后一级的 culling sphere 会有一小部分超出我们设定的最大阴影距离 `maxShadowDistance`。我们可以通过计算像素深度和最大阴影距离做比较，超过最大阴影距离则让阴影强度为 0，效果如下图：  

<div  align="center">  
<img src="https://s2.loli.net/2024/12/25/cEGMwpFDUAv4Iha.png" width = "45%" height = "45%" alt="图22 - 裁切超出最大阴影距离部分的 culling sphere"/>
</div> 

可以看到超出最大阴影距离的部分还是很大的，整体效果看起来也比较突兀。所以我们需要一个渐变效果，取名为 Distance Fade，若最大阴影距离为 m，像素深度为 d，Distance Fade 为 f，则渐变阴影强度为：  

$$ \cfrac {1 - \cfrac {d} {m}} {f} $$

即当深度超过 (1 - f)m 时，开始线性衰减。如果不想要线性可以加个平方什么的。我们通过 `_ShadowDistanceFade` 传递 maxShadowDistance 和 distanceFade 值，如下：  

``` C#
data.buffer.SetGlobalVector(m_ShadowDistanceFadeID, new Vector4(1.0f / asset.maxShadowDistance, 1.0f / asset.distanceFade));
```

再在 ShadowsLibrary.hlsl 中的 `GetDirShadowFalloff` 计算渐变阴影强度：  

    float GetDirShadowFalloff(int dirLightIndex, float3 positionWS)
    {
        ...
        float depth = -TransformWorldToView(positionWS).z;
        float distanceFade = saturate((1 - depth * _ShadowDistanceFade.x) * _ShadowDistanceFade.y);
        shadowStrength *= distanceFade;
        ...
    }

<div  align="center">  
<img src="https://s2.loli.net/2024/12/25/mlbOVzrGWfM4pS1.png" width = "45%" height = "45%" alt="图23 - Distance Fade 效果"/>
</div> 

***三、Cascade Fade***  
最后一级的 culling sphere 的边缘也比较硬，也可以软化渐变一下，方法和上面是一样的，只不过这次是距离最后一级 culling sphere 球心和半径做比值来计算，如下：  

``` C#
data.buffer.SetGlobalVector(m_ShadowDistanceFadeID, new Vector4(1.0f / asset.maxShadowDistance, 1.0f / asset.distanceFade, 1.0f / asset.cascadeFade));
```

    float GetDirShadowFalloff(int dirLightIndex, float3 positionWS)
    {
        ...
        float isInLastSphere = cascadeIndex == _CascadeCount - 1;
        float3 distanceVector = positionWS - _CascadeCullingSpheres[_CascadeCount - 1].xyz;
        float distanceSquare = dot(distanceVector, distanceVector);
        float cascadeFade = saturate((1 - distanceSquare * 1.0f / _CascadeCullingSpheres[_CascadeCount - 1].w) * _ShadowDistanceFade.z);
        shadowStrength *= lerp(1, cascadeFade, isInLastSphere);
        ...
    }

<div  align="center">  
<img src="https://s2.loli.net/2024/12/25/SGCBEWrmHNXpaZy.png" width = "40%" height = "40%" alt="图24 - Cascade Fade 效果"/>
</div> 

## 阴影质量
### 处理 Shadow acne
#### Depth and Slope Bias
之前在阴影技术知识补充有提到过，Depth and Slope Bias 可以通过硬件实现也可以通过软件实现，软件实现又分为在绘制 Shadow Map 时实现和采样 Shadow Map 时实现。

***一、硬件实现***  
Unity 提供了 `CommandBuffer.SetGlobalDepthBias(float bias, float slopeBias)` API 在硬件实现这两个 bias，在教程中，也是直接使用了这个 API，在绘制阴影贴图前调用，绘制阴影贴图后设置回 0 如下：  

``` C#
...
data.buffer.SetGlobalDepthBias(asset.depthBias * 10000, asset.slopeScaledDepthBias);
RenderToDirShadowMap(asset, ref data);
data.buffer.SetGlobalDepthBias(0, 0f); 
...
```

Depth Bias 会被乘以一个非常小的值，所以额外乘了 10000，具体效果如下：  

<div  align="center">  
<img src="https://s2.loli.net/2024/12/26/cGKPr5a9OUvYmEk.png" width = "40%" height = "40%" alt="图25 - SetGlobalDepthBias API 实现的 Depth and Slope Bias 效果"/>
</div>

我将 depthBias 和 slopeScaledDepthBias 分别设置为 2，可以看到 shadow acne 没了，但立方体的阴影已经略微有 Peter Panning 问题了，但是圆柱体上方仍然存在些许的 shadow acne。继续加大这两个 bias 会使 Peter Panning 问题更加严重，仅靠这两个 bias 取得的效果不是很令人满意，最好还是同时实现 Normal Bias。

***二、软件实现***  
**①**Unity URP 中的实现就是在绘制 Shadow Map 时进行偏移，URP 在 ShadowCasterPass 中在顶点着色器对世界空间顶点使用了 `ApplyShadowBias()` 函数。该函数在 URP 的 Shadows.hlsl 中定义，如下：  

    float3 ApplyShadowBias(float3 positionWS, float3 normalWS, float3 lightDirection)
    {
        float invNdotL = 1.0 - saturate(dot(lightDirection, normalWS));
        float scale = invNdotL * _ShadowBias.y;

        // normal bias is negative since we want to apply an inset normal offset
        positionWS = lightDirection * _ShadowBias.xxx + positionWS;
        positionWS = normalWS * scale.xxx + positionWS;
        return positionWS;
    }

URP 支持 Depth Bias 和 Normal Bias，`_ShadowBias.x` 传递进来的就是 Depth Bias，`_ShadowBias.y` 传递进来的是 Normal Bias。并且 Normal Bias 是通过 $\,1 - cos\theta\,$ 实现的，而不是 $\,sin\theta\,$ ，我感觉应该是为了节省开平方的性能消耗。我大致查阅了一下开平方的问题，可以说对于现代 GPU 来说，开平方的性能消耗已经很低了（倒数平方根只需要一个指令），无需担心性能问题。

在绘制 Shadow Map 时进行偏移有个不方便的点在于，我们需要在绘制阴影贴图时知道光照方向，需要将其传递至 ShadowCasterPass，我们无法使用每帧传递进来的方向光方向数组，因为在采样阴影贴图的计算中，我们是遍历所有的方向光方向数组进行计算的。而在 ShadowCasterPass 中无法知道绘制阴影贴图时具体是哪一个光源，所以需要每次绘制阴影贴图时（每帧多次），额外传递数据让 ShadowCasterPass 辨别是那盏灯、是什么灯在绘制阴影贴图，才能计算光照方向。在 URP 中，传递的是 `_LightDirection` 、 `_LightPosition`，分别是方向光方向和 Punctual Light 的位置，用于计算光照方向；以及关键字 `_CASTING_PUNCTUAL_LIGHT_SHADOW` 用于判断什么类型的灯。

> 我发现网上不同资料对于 Punctual Light 的定义不同，有些资料中 Punctual Light 包含 Directional Light，有些则不包含。我博客中不同的文章的 Punctual Light 的定义范围也是不同的，要根据上下文判断一下包不包含 Directional Light。

**②**在阴影采样时偏移就相对容易一点，我们可以在计算阴影空间坐标时，对 positionWS 进行偏移，从而改变物体在光源空间的深度值。首先传递参数 depthBias 、slopeScaledDepthBias，以及阴影贴图的 tile 的分辨率（tileSize），用于计算阴影贴图的 texel 的大小：  

``` C#
data.buffer.SetGlobalVector(m_CascadeParamsID, new Vector4(asset.cascadeCount, tileSize));
data.buffer.SetGlobalVector(m_ShadowBiasID, new Vector4(asset.depthBias, asset.slopeScaledDepthBias));
```

> Unity 的灯光有个 bias 和 normal bias 属性，但是我没有使用。而是在 asset 中添加了全局设置。

同时在 ShadowsLibrary.hlsl 文件中新增 `ApplyShadowBias()` 函数，通过 Culling Sphere 的直径来获取光源视锥体的大小，从而计算出阴影贴图的一个 texel 在世界空间中的大小，对偏移量进行修正。depthBias 和 slopeScaledDepthBias 都是沿着光照方向的偏移，故乘以 L，注意 L 是指向光源的方向，故会让物体接近光源，从而消除自阴影现象，所以最后是对世界坐标做加法。至于为什么是 $\,tan\theta\,$，画张图一目了然，在这里就不说明了：  

> 光源视锥体的大小也可以通过计算出来的光源投影矩阵的 m00 或 m11 判断出来，觉得 Culling Sphere 的直径不太精确的话可以使用光源投影矩阵的值进行传递。

    float3 ApplyShadowBias(float3 positionWS, float cascadeIndex, float3 normalWS, float3 L) //normalWS must be normalized
    {
        float cosTheta = saturate(dot(normalWS, L));
        float sinTheta = sqrt(1.0 - cosTheta * cosTheta);
        float tanTheta = clamp(sinTheta / cosTheta, 0.0, 50.0); // maxBias
        float texelSize = sqrt(_CascadeCullingSpheres[cascadeIndex].w) * 2 / _CascadeParams.y;

        float3 depthBias = texelSize * _ShadowBias.x * L;
        float3 scaledDepthBias = texelSize * tanTheta * _ShadowBias.y * L;
        
        return positionWS + depthBias + scaledDepthBias;
    }

最后在计算阴影空间坐标时进行偏移：  

    float GetDirShadowFalloff(int dirLightIndex, float3 positionWS, float3 normalWS, float3 L)
    {
        ...
        float3 positionTSS = TransformWorldToTiledShadowCoord(ApplyShadowBias(positionWS, cascadeIndex, normalWS, L), tileIndex);
        ...
    }

不知道为什么，这样子实现 depthBias 和 slopeScaledDepthBias 效果也比 `CommandBuffer.SetGlobalDepthBias(float bias, float slopeBias)` 的硬件实现效果好，如下图：  

<div  align="center">  
<img src="https://s2.loli.net/2024/12/30/DO1UIcZLsGdnPb5.png" width = "40%" height = "40%" alt="图26 - 采样阴影贴图实现的 Depth and Slope Bias 效果"/>
</div>

可以看到已经消除了所有的 shadow acne，但是 Peter Panning 问题比硬件的实现要小很多。

#### Normal Bias
实现 Normal Bias 方法跟上面的软件实现其实是一样。只不过 Normal Bias 是沿着物体法线方向偏移，而不是光照方向。这里有一个注意点就是，法线贴图会对物体法线进行修改，那么 Normal Bias 应该沿着物体原始法线进行偏移还是沿着法线贴图的法线偏移？我认为从理论上来说，物体原始法线更好，因为本质上 Shadow acne 的产生原因是因为物体表面的真实方向和光照方向（阴影贴图）存在一个角度，如果使用了虚假的法线贴图修改过的法线，会让斜率相关的 Bias 的效果略微下降，因为修改了角度。虽然在实际操作中，这点影响其实不大，甚至使用法线贴图的法线会让使用斜率相关的 Bias 遗留下来的 Shadow acne 变得更漂亮（笑），从而让人感受不到 Shadow acne 的存在，所以我认为这两种选择都可以。我最后决定还是使用物体原始法线，这也是为什么我上面的 `ApplyShadowBias()` 函数的参数中，法线方向写的是 normalWS，而不是 N，N 是法线贴图修改过的法线。

之前在阴影技术知识补充中提到 Normal Bias 要乘以 $\,sin\theta\,$，乘以 $\,sin\theta\,$ 本质是就是用斜率修正沿法线的偏移量，所以我将 Normal Bias 也分为了 normalBias 和 slopeScaledNormalBias，一个固定偏移值，一个是斜率修正偏移值：  

``` C#
data.buffer.SetGlobalVector(m_ShadowBiasID, new Vector4(asset.depthBias, asset.slopeScaledDepthBias, asset.normalBias, asset.slopeScaledNormalBias));
```

    float3 ApplyShadowBias(float3 positionWS, float cascadeIndex, float3 normalWS, float3 L) //normalWS must be normalized
    {
        ...
        float3 normalBias = texelSize * _ShadowBias.z * normalWS;
        float3 scaledNormalBias = texelSize * sinTheta * _ShadowBias.w * normalWS;
        
        return positionWS + depthBias + scaledDepthBias + normalBias + scaledNormalBias;
    }

<div  align="center">  
<img src="https://s2.loli.net/2024/12/30/5KCV761Gba3TYMQ.png" width = "40%" height = "40%" alt="图27 - 采样阴影贴图实现的 Normal Bias 效果"/>
</div>

仔细看，Peter Panning 问题比 depthBias 和 slopeScaledDepthBias 的实现还要更完美一些。

### 处理 Shadow pancaking
Shadow pancaking 是指当物体超出了光源视锥体的范围从而导致阴影被裁切的现象。我们知道光源视锥体会尽可能地紧贴着包围着摄像机视锥体，从而增加阴影精度以及渲染效率，所以当物体超过了摄像机视锥体以及光源视锥体的范围，会被裁切掉，具体表现如下：  

<div  align="center">  
<img src="https://s2.loli.net/2024/12/30/jD3JSXEbcm8dWCH.png" width = "25%" height = "25%" alt="图28 - Shadow Pancaking 现象"/>
</div>

解决方法就是在 ShadowCasterPass 里的顶点着色器中改变裁切空间中的深度值，以防止被裁切。当顶点深度超出了光源的近裁切平面，将其设置为近裁切平面的深度。`UNITY_REVERSED_Z` 和 `UNITY_NEAR_CLIP_VALUE` 都是定义在 core library 的 API 相关文件中的宏，用于判断不同 API 是否会反转深度，主要是 DirectX 会反转深度：  

    Varyings ShadowCasterVert(Attributes IN)
    {
        Varyings OUT;
        OUT.positionHCS = TransformObjectToHClip(IN.positionOS.xyz);

        #if UNITY_REVERSED_Z
        OUT.positionHCS.z = min(OUT.positionHCS.z, OUT.positionHCS.w * UNITY_NEAR_CLIP_VALUE);
        #else
        OUT.positionHCS.z = max(OUT.positionHCS.z, OUT.positionHCS.w * UNITY_NEAR_CLIP_VALUE);
        #endif
        
        return OUT;
    }

但是这样做又会导致一个新的问题，就是超长物体的阴影变形问题，如下图：  

<div  align="center">  
<img src="https://s2.loli.net/2024/12/30/5KCUa79ngDsGfMA.png" width = "70%" height = "70%" alt="图29 - 超长物体的阴影变形"/>
</div>

看阴影贴图第二个 tile，可以明显看到长方体的一部分深度在平面上面，一部分在平面下面。产生这种现象的原因是，被光源视锥体裁切的顶点的深度值被设置到了近裁切平面处，然后在光栅化阶段影响到了顶点插值计算像素的值。比如上图中，长方体只有 8 个顶点，最远处被裁切掉的 4 个顶点的深度是光源近裁切平面，看得见的 4 个顶点深度是正常深度，中间的像素深度是由远处和近处顶点插值而来，像素深度的变化率降低了，导致平面深度比部分长方体像素浅了。

解决这一问题的方法就是拉远光源的近裁切平面，可以通过 `CullingResults.ComputeDirectionalShadowMatricesAndCullingPrimitives()` 需要传入的参数 shadowNearPlaneOffset 设置。也就是灯光设置中的 Near Plane 属性，因为我觉得这个属性是逐灯光属性，可以使用灯的属性，而不是像上面的 Shadow Bias 通过全局设置来设置。

> 上述现象也可以通过增加模型顶点来解决。而且我觉得超长物体模型一般顶点较多，产生上述现象的概率也不大。

``` C#
...
struct ShadowingDirLight
{
    public int visibleLightIndex;
    public float nearPlaneOffset;
}
...

...
m_ShadowingDirLights[m_ShadowingDirLightCount] = new ShadowingDirLight 
{
    visibleLightIndex = i,
    nearPlaneOffset = visibleLight.light.shadowNearPlane
};
...

...
data.cullingResults.ComputeDirectionalShadowMatricesAndCullingPrimitives(
                    shadowingDirLight.visibleLightIndex, i, cascadeCount, 
                    ratios, tileSize, shadowingDirLight.nearPlaneOffset,
                    out Matrix4x4 viewMatrix, out Matrix4x4 projectionMatrix, out ShadowSplitData splitData);
...
```

改变灯光设置中的 Near Plane 属性就能解决超长物体的阴影变形问题了，图片我就不放了。

### 处理 Shadow aliasing
处理 Shadow aliasing 的方法就是**百分比接近滤波 PCF**，还能顺便实现软阴影效果。这部分只涉及 PCF，不涉及 PCSS，等点光源和聚光灯都实现了会专门出一篇文章对 PCSS 技术进行详细介绍和实现。我们之前在采样阴影贴图声明的采样器 `sampler_linear_clamp_compare_DirectionalShadowMap`，因为选择的是 linear 的过滤方式，所以实现了 2 × 2 的阴影 PCF 效果，如下图：  

<div  align="center">  
<img src="https://s2.loli.net/2025/01/03/JDrp69FEdiASI7g.png" width = "50%" height = "50%" alt="图30 - 左图：point 过滤；右图：linear 过滤（PCF 2 × 2）"/>
</div>

可以看到确实模糊了边缘，但效果仍然很差，并不能消除锯齿，因此人们自然而然地想到了扩大 PCF 核。最直接的扩大 PCF 核的方法就是偏移 uv 并采样多次，代码大致如下：  

    float shadowAttenuation = 0.0;
    float count = 0.0;

    for (float i = -a; i <= a; i++)
    {
        for (float j = -a; j <= a; j++)
        {
            float2 uv = positionTSS.xy + float2(i, j) / _ShadowMapSize;
            shadowAttenuation += _ShadowMap.SampleCmpLevelZero(sampler_linear_clamp_compare_ShadowMap, uv, positionTSS.z);
            count++;
        }
    }

    return shadowAttenuation / count;

将 a 设置为 0.5，可以进行 4 次采样就可以覆盖 9 个像素，即 PCF 3 × 3，如下图：

<div  align="center">  
<img src="https://s2.loli.net/2025/01/04/QSH6AmOVyolEge9.png" width = "45%" height = "45%" alt="图31 - PCF 3 × 3"/>
</div>

可以看出，虽然阴影模糊的范围变大了，但是仍然存在一块一块的感觉。之所以会有这种现象是因为采样点是离散值，在进行线性插值后会变成如下图：  

<div  align="center">  
<img src="https://s2.loli.net/2025/01/04/64NqT1mC8dZjGbU.png" width = "30%" height = "30%" alt="图32 - 上图：离散采样点；下图：线性插值后"/>
</div>

可以看到导数在 A 点是不连续的，带来的效果就是 A 点很尖锐，于是形成了鲜明的分界线。Bilinear Interpolation 本质上是一个离散的 Tent Filter 正是因为 Filter 是离散的，它将像素看成了点，只计算了那个点的权重，而不是计算像素整个面积所占据的权重。故这种采样方式去扩大 PCF 的核的效果并不好，而且 N \* N 的核需要进行 (N-1) \* (N-1) 次采样，特别消耗性能。

#### Unity 的 PCF
为了让 A 点不那么尖锐，Unity 使用了连续的 Tent Filter 来代替离散的加法，即使用面积作为像素的权重。比如一个 3 x 3 的核：  

<div  align="center">  
<img src="https://s2.loli.net/2025/01/04/JoxpviAnYmHQEbP.png" width = "30%" height = "30%" alt="图33 - 面积作为权重"/>
</div>

我们将每个坐标区间看成一个个像素，一个像素在 Tent 核下所占据的权重，应当是 f(x) 在像素区间上的积分。例如 [0, 1] 区间所代表的像素，其权重应当是图中画出的阴影部分的面积。这样子处理可以将阴影变为更加柔和。

Unity 中的相关实现都在 core library 的 `ShadowSamplingTent.hlsl` 文件中，计算每个像素权重的函数为 `SampleShadow_GetTexelAreas_Tent_3x3()`，函数上面有这么一段注释：  

    // Assuming a isoceles triangle of 1.5 texels height and 3 texels wide lying on 4 texels.
    // This function return the area of the triangle above each of those texels.
    //    |    <-- offset from -0.5 to 0.5, 0 meaning triangle is exactly in the center
    //   / \   <-- 45 degree slop isosceles triangle (ie tent projected in 2D)
    //  /   \
    // _ _ _ _ <-- texels

Unity 将 3 x 3 的 Tent 核采样范围扩大到至多 16 个像素，如下图：  

<div  align="center">  
<img src="https://s2.loli.net/2025/01/04/TBd74DqraiISVnX.png" width = "25%" height = "25%" alt="图34 - 4 次采样最多可以覆盖 16 个像素"/>
</div>

共 4 个采样点，每个采样点至多可以覆盖 2 x 2 个像素，假设 4 个采样点依次为 P1 ~ P4，那么中心点的阴影值应该是：  

$$ Shadow = \omega_1 Sample(P_1) + \omega_2 Sample(P_2) + \omega_3 Sample(P_3) + \omega_4 Sample(P_4) $$

具体计算权重的逻辑我就不在这里阐述了，要想详细了解建议查看其他文章。使用 Unity 提供的函数的代码如下：  

    float weights[4];
    float2 positions[4];
    float4 size = float4(1 / _ShadowAtlasSize, 1 / _ShadowAtlasSize, _ShadowAtlasSize, _ShadowAtlasSize);
    SampleShadow_ComputeSamples_Tent_3x3(size, positionTSS.xy, weights, positions);
    float shadowAttenuation = 0;
    for (int i = 0; i < 4; i++)
    {
        shadowAttenuation += weights[i] * _ShadowMap.SampleCmpLevelZero(sampler_linear_clamp_compare_ShadowMap, 
            positions[i].xy, positionTSS.z);
    }

若使用 Unity 5 x 5 的实现，则需要把 weights、positions 和循环次数 i 改为 9。5 x 5 的 Tent 核仅需 9 次采样，覆盖到 36 个像素。7 x 7 的 Tent 核仅需 16 次采样，覆盖到 64 个像素。具体实现效果如下图：

<div  align="center">  
<img src="https://s2.loli.net/2025/01/04/LhSRHZt4lTk7suw.png" width = "60%" height = "60%" alt="图35 - 左：3 x 3；中：5 x 5；右：7 x 7"/>
</div>

可以看到效果确实比之前的方法好了不少。

#### 泊松采样或低差异序列实现 PCF
***①泊松采样实现 PCF***  
《Real-Time Rendering 4th》中有提到可以使用预先计算好的泊松分布来对区域进行采样。我在网上随便找了个预计算出来的泊松分布：  

    static const float2 poissonDisk[16] = {
        float2( -0.94201624, -0.39906216 ), float2( 0.94558609, -0.76890725 ), float2( -0.094184101, -0.92938870 ), float2( 0.34495938, 0.29387760 ),
        float2( -0.91588581, 0.45771432 ), float2( -0.81544232, -0.87912464 ), float2( -0.38277543, 0.27676845 ), float2( 0.97484398, 0.75648379 ),
        float2( 0.44323325, -0.97511554 ), float2( 0.53742981, -0.47373420 ), float2( -0.26496911, -0.41893023 ), float2( 0.79197514, 0.19090188 ),
        float2( -0.24188840, 0.99706507 ), float2( -0.81409955, 0.91437590 ), float2( 0.19984126, 0.78641367 ), float2( 0.14383161, -0.14100790 )
    };

其分布如下图：  

<div  align="center">  
<img src="https://s2.loli.net/2025/01/06/afgWnTXdwGHzFc2.png" width = "25%" height = "25%" alt="图36 - 一个预先计算好的泊松分布"/>
</div>

代码和之前类似，只不过要加上一个随机旋转用以平滑半影区域，随机函数可以借鉴这个网址里的相关回复：https://stackoverflow.com/questions/4200224/random-noise-functions-for-glsl ：  

    float shadowAttenuation = 0.0;
    float random = Random_NoSine(positionWS);
    float randomRadian = random * TWO_PI;
    float2x2 rotation = float2x2(cos(randomRadian), -sin(randomRadian), sin(randomRadian), cos(randomRadian));
    for (int i = 0; i < 16; i++)
    {
        float2 offset = mul(rotation, poissonDisk[i]) / _ShadowMapSize * penumbraWidthParam;
        float2 uv = positionTSS.xy + offset;
        shadowAttenuation += _ShadowMap.SampleCmpLevelZero(sampler_linear_clamp_compare_ShadowMap, uv, positionTSS.z);
    }
    shadowAttenuation = shadowAttenuation / 16;

我将 penumbraWidthParam 设置为了 2，这样子方便和 Unity 7 x 7 PCF 做比较，毕竟 7 x 7 采样范围较宽，且都是 16 次采样。效果如下：  

<div  align="center">  
<img src="https://s2.loli.net/2025/01/06/RgexlLahGXSCIqn.png" width = "75%" height = "75%" alt="图37 - 左：Unity 7 x 7；中：无随机旋转的泊松分布采样；右：有随机旋转的泊松分布采样"/>
</div>

可以看到 Unity 7 x 7 的阴影相对来说更加平滑，而有随机旋转的泊松分布采样有噪点。至于哪个更好看就仁者见仁智者见智了，我是喜欢有噪点的阴影的，而且实现 TAA 后噪点可以进一步消除，之后在实现 PCSS 的文章中我会进行更详细地对比。

***②低差异序列实现 PCF***  
低差异序列主要包含 **Hammersley sequence**、**Halton sequence** 和 **Sobol sequence**，具体实现方法请参考：https://pbr-book.org/4ed/Sampling_and_Reconstruction 里的相关内容。直接使用低差异序列采样产生的阴影噪点会非常明显，所以我们可以把采样区域从正方形变为圆形（或称为 disk shape），其实就是圆形逆变换采样，代码如下：  

    // From [0, 1] to [-1, 1]
    float2 InverseSampleCircle(float2 xi)
    {
        float r = sqrt(xi.x);
        float theta = TWO_PI * xi.y;
        return r * float2(cos(theta), sin(theta));
    }

采样分布大致如下图（32 个样本）：  

<div  align="center">  
<img src="https://s2.loli.net/2025/01/06/NgeA3EqmPJrlnak.png" width = "75%" height = "75%" alt="图38 - 左 1：Hammersley sequence 及其圆盘化的分布；左 2：Halton sequence 及其圆盘化的分布；右 2：Sobol sequence 及其圆盘化的分布；右 1：Scrambled Sobol sequence 及其圆盘化的分布"/>
</div>

代码没什么变化，改一下 offset 就行：  

    float2 offset = mul(rotation, InverseSampleCircle(Hammersley_Bits(i, sampleNumber))) / _ShadowMapSize * penumbraWidthParam;

效果如下（都是 16 次采样）：   

<div  align="center">  
<img src="https://s2.loli.net/2025/01/06/xgowOIVp32JTzyi.png" width = "75%" height = "75%" alt="图39 - 左 1：Hammersley sequence；左 2：Halton sequence；右 2：Sobol sequence；右 1：Scrambled Sobol sequence。上图都是无圆盘化的采样结果，下图都为圆盘化的采样结果。"/>
</div>

采样 64 次噪点几乎就没有了：  

<div  align="center">  
<img src="https://s2.loli.net/2025/01/06/OogKsD2zChxeTq3.png" width = "40%" height = "40%" alt="图40 - 左图：Hammersley sequence 16 次采样；右图：Hammersley sequence 64 次采样。"/>
</div>

据其他文章说，实现 TAA 后，16 次采样可以达到 64 次采样的效果。综上所有实现，可以看到不同的低差异序列实现的效果没有特别明显的区别，那么在使用时肯定就是性能优先了。也可以像泊松分布的预计算实现一样，存储预计算的 16、32、64 个样本的低差异序列，这样就不用在运行时计算采样点了。

#### PCF 与半影宽度
为了更好地对半影宽度进行控制，我们可以在 RenderPipelineAsset 里添加参数 `penumbraWidth`，并传递给 Shader。因为我们对阴影贴图按单个纹素进行偏移并采样，所以场景中的半影宽度受到当前级联阴影在世界空间下单个纹素大小的影响。为了剔除掉级联阴影不同级数的不同纹素大小的影响，我们需要将之前代码中提到的 penumbraWidthParam 除以世界空间下单个纹素大小，纹素大小的计算跟 Shadow Bias 提到的一样：  

    float penumbraWidthParam = _PenumbraWidth / (sqrt(_CascadeCullingSpheres[cascadeIndex].w) * 2.0 / _CascadeParams.y);
    float2 offset = mul(rotation, InverseSampleCircle(Hammersley_Bits(i, sampleNumber))) / _ShadowMapSize * penumbraWidthParam / 100.0;

这样子就可以控制半影宽度了，并且更改 Shadow Map 的分辨率也不会感受到明显的半影宽度变化。在不同级联阴影交界处，同样也不会出现明显的半影宽度变化，如下图：  

<div  align="center">  
<img src="https://s2.loli.net/2025/01/06/oHaXjvzAC3BlpId.png" width = "90%" height = "90%" alt="图41 - 左：无半影（硬阴影）；中：半影宽带 3，Shadow Atlas 分辨率 8192；右：半影宽带 3，Shadow Atlas 分辨率 2048。"/>
</div>

catlikecoding 教程中处理级联阴影交界处半影宽度突变导致的接缝衔接问题，是在两级之间做混合，我觉得效果不如我上面的方法好，也更耗性能，也没法保证不同联级以及不同分辨率下半影宽度一致，故没有摘抄。但是教程中提到了 Core Library 中的 Random.hlsl 文件中，有个函数：`InterleavedGradientNoise()`，它可以根据 uv 坐标生成**仿色（抖动）图案 Dither Pattern**。它是一个非常好看的画面或后处理效果，建议看这篇文章：https://zhuanlan.zhihu.com/p/60325181。

#### PCF 与 Shadow Bias
阴影技术知识补充中提到过自阴影问题在 PCF 中会变得更加糟糕，就如同上图中，半影宽带为 3 时，自阴影现象又出现了。产生这一现象的原因如下图：  

<div  align="center">  
<img src="https://s2.loli.net/2025/01/07/1up5Qc2HSeV6XAx.png" width = "60%" height = "60%" alt="图42 - PCF 核过大导致的深度误判示意图"/>
</div>

原本我们会将平面沿光照方向偏移 CB 长度（即世界空间下半个纹素乘以 $\,tan\theta\,$）或者沿法线偏移 B 到 AC 的高度（即世界空间下半个纹素乘以 $\,sin\theta\,$）。但是在 PCF 中，我们扩大了采样范围，假设从 BD 段扩大一个阴影贴图像素，即扩大至 EF 段。要注意我们的代码：  

    float2 uv = positionTSS.xy + offset;
    shadowAttenuation += _ShadowMap.SampleCmpLevelZero(sampler_linear_clamp_compare_ShadowMap, uv, positionTSS.z);

假设我们采样的是 BD 段任意一点，我们只是偏移了阴影贴图上的 uv 值，但没有改变深度值 positionTSS.z。也就是我们拿着偏移后在阴影贴图采样得到的深度值，跟未偏移 uv 的深度值 positionTSS.z 做对比。未偏移 uv 的深度值 positionTSS.z 就是 BD 段任意一点的深度值，而 BD 段任意一点的深度值无论如何都比 BD 段和 BF 段在阴影贴图上的深度值小，但是比 ED 段在阴影贴图上的深度值大。于是我们将 3 次采样结果进行插值得到结果是 BD 段任意一点的阴影值为 1/3。由此可知，PCF 会加剧自阴影问题。

解决方法就是继续增大 Shadow Bias。扩大的数值为（假设 PCF 核偏移了 r 个阴影贴图的像素）：  

$$ \text{Slope scaled depth bias} = \cfrac{1}{2} \cdot \cfrac{frustrumSize}{shadowmapSize} \cdot tan\theta \cdot (1 + r) $$

$$ \text{Normal bias} = \cfrac{1}{2} \cdot \cfrac{frustrumSize}{shadowmapSize} \cdot sin\theta \cdot (1 + r) $$

那么基于上述公式，`ApplyShadowBias()` 函数就需要做出更改，由于我们偏移的阴影贴图的像素的半径 r（即半影宽度）是根据 Shadow Cascade 自适应变化的，除以了世界空间下纹素的大小，所以一乘一除可以抵消掉一部分，故只需要对 Shadow Bias 增加如下部分：  

    depthBias += _PenumbraWidth / 100 * _ShadowBias.x * L;
    scaledDepthBias += _PenumbraWidth / 100 * tanTheta * _ShadowBias.y * L;
    normalBias += _PenumbraWidth / 100 * _ShadowBias.z * normalWS;
    scaledNormalBias += _PenumbraWidth / 100 * sinTheta * _ShadowBias.w * normalWS;

<div  align="center">  
<img src="https://s2.loli.net/2025/01/07/cgxFWbt4oR9Z5L2.png" width = "80%" height = "80%" alt="图43 - PCF 自适应 Shadow Bias 效果"/>
</div>

可以看到增大了半影宽度，Shadow Bias 设置没变，仍然不产生自阴影现象。

## 其他
***① Shadow Culling Factor***  
Unity 做阴影裁切或剔除时相对比较保守，在渲染更远的级联阴影时，如果确保阴影投射体一定被更近的级联阴影所覆盖，其实可以在远的级联阴影中剔除掉这些阴影投射体，因为我们总是在更近的级联阴影中采样这些阴影投射体。在 Unity 中可以通过设置 `ShadowSplitData.shadowCascadeBlendCullingFactor` 的值来调节是否裁切掉更多的阴影投射体，可以设置为 0 ~ 1 的值，值越高裁切越多：  

``` C#
splitData.shadowCascadeBlendCullingFactor = 1.0f;
shadowDrawingSettings.splitData = splitData;
```

这个值调整的是剔除球的半径以剔除更多阴影投射体，为了防止阴影投射体在级联阴影边缘过渡区域被裁切，可以将 `shadowCascadeBlendCullingFactor` 设置为 0.8 减去 Cascade Fade：  

``` C#
splitData.shadowCascadeBlendCullingFactor = Mathf.Max(0.0f, 0.8f - asset.cascadeFade)
```

***②透明物体的阴影***  
透明度测试的阴影的实现相对比较简单，只要在 ShadowCasterPass 中使用 `clip()` 在片元着色器做裁切就行。至于半透明物体，可以使用一些 Noise 函数，比如之前提到的 Dither Pattern 函数 `InterleavedGradientNoise()`，在 ShadowCasterPass 中做随机裁切，并且透明度越大裁切得越多，这样配合 PCF 就能实现一个较为不错的半透明物体阴影。具体实现，以后有半透明物体渲染需求时再处理，应该不难，且一般游戏中较少会出现半透明物体。